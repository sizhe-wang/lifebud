import { ServerResponse } from 'node:http';
import { ServerResponse as ServerResponse_2 } from 'http';
import { z } from 'zod/v4';
import * as z3 from 'zod/v3';
import * as z4 from 'zod/v4';
import { ZodType } from 'zod/v4';

export declare abstract class AbstractChat<UI_MESSAGE extends UIMessage> {
    readonly id: string;
    readonly generateId: IdGenerator;
    protected state: ChatState<UI_MESSAGE>;
    private messageMetadataSchema;
    private dataPartSchemas;
    private readonly transport;
    private onError?;
    private onToolCall?;
    private onFinish?;
    private onData?;
    private sendAutomaticallyWhen?;
    private activeResponse;
    private jobExecutor;
    constructor({ generateId, id, transport, messageMetadataSchema, dataPartSchemas, state, onError, onToolCall, onFinish, onData, sendAutomaticallyWhen, }: Omit<ChatInit<UI_MESSAGE>, 'messages'> & {
        state: ChatState<UI_MESSAGE>;
    });
    /**
     * Hook status:
     *
     * - `submitted`: The message has been sent to the API and we're awaiting the start of the response stream.
     * - `streaming`: The response is actively streaming in from the API, receiving chunks of data.
     * - `ready`: The full response has been received and processed; a new user message can be submitted.
     * - `error`: An error occurred during the API request, preventing successful completion.
     */
    get status(): ChatStatus;
    protected setStatus({ status, error, }: {
        status: ChatStatus;
        error?: Error;
    }): void;
    get error(): Error | undefined;
    get messages(): UI_MESSAGE[];
    get lastMessage(): UI_MESSAGE | undefined;
    set messages(messages: UI_MESSAGE[]);
    /**
     * Appends or replaces a user message to the chat list. This triggers the API call to fetch
     * the assistant's response.
     *
     * If a messageId is provided, the message will be replaced.
     */
    sendMessage: (message?: (CreateUIMessage<UI_MESSAGE> & {
        text?: never;
        files?: never;
        messageId?: string;
    }) | {
        text: string;
        files?: FileList | FileUIPart[];
        metadata?: InferUIMessageMetadata<UI_MESSAGE>;
        parts?: never;
        messageId?: string;
    } | {
        files: FileList | FileUIPart[];
        metadata?: InferUIMessageMetadata<UI_MESSAGE>;
        parts?: never;
        messageId?: string;
    }, options?: ChatRequestOptions) => Promise<void>;
    /**
     * Regenerate the assistant message with the provided message id.
     * If no message id is provided, the last assistant message will be regenerated.
     */
    regenerate: ({ messageId, ...options }?: {
        messageId?: string;
    } & ChatRequestOptions) => Promise<void>;
    /**
     * Attempt to resume an ongoing streaming response.
     */
    resumeStream: (options?: ChatRequestOptions) => Promise<void>;
    /**
     * Clear the error state and set the status to ready if the chat is in an error state.
     */
    clearError: () => void;
    addToolOutput: <TOOL extends keyof InferUIMessageTools<UI_MESSAGE>>({ state, tool, toolCallId, output, errorText, }: {
        state?: "output-available";
        tool: TOOL;
        toolCallId: string;
        output: InferUIMessageTools<UI_MESSAGE>[TOOL]["output"];
        errorText?: never;
    } | {
        state: "output-error";
        tool: TOOL;
        toolCallId: string;
        output?: never;
        errorText: string;
    }) => Promise<void>;
    /** @deprecated Use addToolOutput */
    addToolResult: <TOOL extends keyof InferUIMessageTools<UI_MESSAGE>>({ state, tool, toolCallId, output, errorText, }: {
        state?: "output-available";
        tool: TOOL;
        toolCallId: string;
        output: InferUIMessageTools<UI_MESSAGE>[TOOL]["output"];
        errorText?: never;
    } | {
        state: "output-error";
        tool: TOOL;
        toolCallId: string;
        output?: never;
        errorText: string;
    }) => Promise<void>;
    /**
     * Abort the current request immediately, keep the generated tokens if any.
     */
    stop: () => Promise<void>;
    private makeRequest;
}

declare namespace _ai_sdk_provider {
    export {
        JSONSchema7,
        JSONSchema7Definition,
        AISDKError,
        APICallError,
        EmbeddingModelV2,
        EmbeddingModelV2Embedding,
        EmptyResponseBodyError,
        ImageModelV2,
        ImageModelV2CallOptions,
        ImageModelV2CallWarning,
        ImageModelV2ProviderMetadata,
        InvalidArgumentError_2 as InvalidArgumentError,
        InvalidPromptError,
        InvalidResponseDataError,
        JSONArray,
        JSONObject,
        JSONParseError,
        JSONValue_2 as JSONValue,
        LanguageModelV2,
        LanguageModelV2CallOptions,
        LanguageModelV2CallWarning,
        LanguageModelV2Content,
        LanguageModelV2DataContent,
        LanguageModelV2File,
        LanguageModelV2FilePart,
        LanguageModelV2FinishReason,
        LanguageModelV2FunctionTool,
        LanguageModelV2Message,
        LanguageModelV2Middleware,
        LanguageModelV2Prompt,
        LanguageModelV2ProviderDefinedTool,
        LanguageModelV2Reasoning,
        LanguageModelV2ReasoningPart,
        LanguageModelV2ResponseMetadata,
        LanguageModelV2Source,
        LanguageModelV2StreamPart,
        LanguageModelV2Text,
        LanguageModelV2TextPart,
        LanguageModelV2ToolCall,
        LanguageModelV2ToolCallPart,
        LanguageModelV2ToolChoice,
        LanguageModelV2ToolResultOutput,
        LanguageModelV2ToolResultPart,
        LanguageModelV2Usage,
        LoadAPIKeyError,
        LoadSettingError,
        NoContentGeneratedError,
        NoSuchModelError,
        ProviderV2,
        SharedV2Headers,
        SharedV2ProviderMetadata,
        SharedV2ProviderOptions,
        SpeechModelV2,
        SpeechModelV2CallOptions,
        SpeechModelV2CallWarning,
        TooManyEmbeddingValuesForCallError,
        TranscriptionModelV2,
        TranscriptionModelV2CallOptions,
        TranscriptionModelV2CallWarning,
        TypeValidationError,
        UnsupportedFunctionalityError,
        getErrorMessage_2 as getErrorMessage,
        isJSONArray,
        isJSONObject,
        isJSONValue
    }
}

declare namespace _ai_sdk_provider_utils {
    export {
        EventSourceMessage,
        EventSourceParserStream,
        AssistantContent,
        AssistantModelMessage,
        DataContent,
        DelayedPromise,
        FetchFunction,
        FilePart,
        FlexibleSchema,
        FlexibleValidator,
        IdGenerator,
        ImagePart,
        InferSchema,
        InferToolInput,
        InferToolOutput,
        InferValidator,
        LazySchema,
        LazyValidator,
        ModelMessage,
        ParseResult,
        ProviderDefinedToolFactory,
        ProviderDefinedToolFactoryWithOutputSchema,
        ProviderOptions,
        ReasoningPart,
        Resolvable,
        ResponseHandler,
        Schema,
        SystemModelMessage,
        TextPart,
        Tool,
        ToolCall,
        ToolCallOptions,
        ToolCallPart,
        ToolContent,
        ToolExecuteFunction,
        ToolModelMessage,
        ToolResult,
        ToolResultPart,
        UserContent,
        UserModelMessage,
        VERSION,
        ValidationResult,
        Validator,
        asSchema,
        asValidator,
        combineHeaders,
        convertAsyncIteratorToReadableStream,
        convertBase64ToUint8Array,
        convertToBase64,
        convertUint8ArrayToBase64,
        createBinaryResponseHandler,
        createEventSourceResponseHandler,
        createIdGenerator,
        createJsonErrorResponseHandler,
        createJsonResponseHandler,
        createJsonStreamResponseHandler,
        createProviderDefinedToolFactory,
        createProviderDefinedToolFactoryWithOutputSchema,
        createStatusCodeErrorResponseHandler,
        delay,
        dynamicTool,
        executeTool,
        extractResponseHeaders,
        generateId,
        getErrorMessage,
        getFromApi,
        getRuntimeEnvironmentUserAgent,
        injectJsonInstructionIntoMessages,
        isAbortError,
        isParsableJson,
        isUrlSupported,
        isValidator,
        jsonSchema,
        lazySchema,
        lazyValidator,
        loadApiKey,
        loadOptionalSetting,
        loadSetting,
        mediaTypeToExtension,
        normalizeHeaders,
        parseJSON,
        parseJsonEventStream,
        parseProviderOptions,
        postFormDataToApi,
        postJsonToApi,
        postToApi,
        removeUndefinedEntries,
        resolve,
        safeParseJSON,
        safeValidateTypes,
        standardSchemaValidator,
        tool,
        validateTypes,
        validator,
        withUserAgentSuffix,
        withoutTrailingSlash,
        zodSchema,
        StandardJSONSchemaV1,
        StandardSchemaV1,
        StandardTypedV1
    }
}

/**
 * Custom error class for AI SDK related errors.
 * @extends Error
 */
export declare class AISDKError extends Error {
    private readonly [symbol$d];
    /**
     * The underlying cause of the error, if any.
     */
    readonly cause?: unknown;
    /**
     * Creates an AI SDK Error.
     *
     * @param {Object} params - The parameters for creating the error.
     * @param {string} params.name - The name of the error.
     * @param {string} params.message - The error message.
     * @param {unknown} [params.cause] - The underlying cause of the error.
     */
    constructor({ name, message, cause, }: {
        name: string;
        message: string;
        cause?: unknown;
    });
    /**
     * Checks if the given error is an AI SDK Error.
     * @param {unknown} error - The error to check.
     * @returns {boolean} True if the error is an AI SDK Error, false otherwise.
     */
    static isInstance(error: unknown): error is AISDKError;
    protected static hasMarker(error: unknown, marker: string): boolean;
}

export declare class APICallError extends AISDKError {
    private readonly [symbol$c];
    readonly url: string;
    readonly requestBodyValues: unknown;
    readonly statusCode?: number;
    readonly responseHeaders?: Record<string, string>;
    readonly responseBody?: string;
    readonly isRetryable: boolean;
    readonly data?: unknown;
    constructor({ message, url, requestBodyValues, statusCode, responseHeaders, responseBody, cause, isRetryable, // server error
        data, }: {
        message: string;
        url: string;
        requestBodyValues: unknown;
        statusCode?: number;
        responseHeaders?: Record<string, string>;
        responseBody?: string;
        cause?: unknown;
        isRetryable?: boolean;
        data?: unknown;
    });
    static isInstance(error: unknown): error is APICallError;
}

export declare function asSchema<OBJECT>(schema: FlexibleSchema<OBJECT> | undefined): Schema<OBJECT>;

/**
 Content of an assistant message.
 It can be a string or an array of text, image, reasoning, redacted reasoning, and tool call parts.
 */
export declare type AssistantContent = string | Array<TextPart | FilePart | ReasoningPart | ToolCallPart | ToolResultPart>;

/**
 An assistant message. It can contain text, tool calls, or a combination of text and tool calls.
 */
export declare type AssistantModelMessage = {
    role: 'assistant';
    content: AssistantContent;
    /**
     Additional provider-specific metadata. They are passed through
     to the provider from the AI SDK and enable provider-specific
     functionality that can be fully encapsulated in the provider.
     */
    providerOptions?: ProviderOptions;
};

export declare const assistantModelMessageSchema: z.ZodType<AssistantModelMessage>;

declare type asUITool<TOOL extends UITool | Tool> = TOOL extends Tool ? InferUITool<TOOL> : TOOL;

declare function asValidator<OBJECT>(value: FlexibleValidator<OBJECT>): Validator<OBJECT>;

/**
 * A type that combines AsyncIterable and ReadableStream.
 * This allows a ReadableStream to be consumed using for-await-of syntax.
 */
export declare type AsyncIterableStream<T> = AsyncIterable<T> & ReadableStream<T>;

/**
 * Attributes is a map from string to attribute values.
 *
 * Note: only the own enumerable keys are counted as valid attribute keys.
 */
declare interface Attributes {
    [attributeKey: string]: AttributeValue | undefined;
}

/**
 * Attribute values may be any non-nullish primitive value except an object.
 *
 * null or undefined attribute values are invalid and will result in undefined behavior.
 */
declare type AttributeValue = string | number | boolean | Array<null | undefined | string> | Array<null | undefined | number> | Array<null | undefined | boolean>;

export declare function callCompletionApi({ api, prompt, credentials, headers, body, streamProtocol, setCompletion, setLoading, setError, setAbortController, onFinish, onError, fetch, }: {
    api: string;
    prompt: string;
    credentials: RequestCredentials | undefined;
    headers: HeadersInit | undefined;
    body: Record<string, any>;
    streamProtocol: 'data' | 'text' | undefined;
    setCompletion: (completion: string) => void;
    setLoading: (loading: boolean) => void;
    setError: (error: Error | undefined) => void;
    setAbortController: (abortController: AbortController | null) => void;
    onFinish: ((prompt: string, completion: string) => void) | undefined;
    onError: ((error: Error) => void) | undefined;
    fetch: ReturnType<typeof getOriginalFetch> | undefined;
}): Promise<string | null | undefined>;

export declare type CallSettings = {
    /**
     Maximum number of tokens to generate.
     */
    maxOutputTokens?: number;
    /**
     Temperature setting. The range depends on the provider and model.

     It is recommended to set either `temperature` or `topP`, but not both.
     */
    temperature?: number;
    /**
     Nucleus sampling. This is a number between 0 and 1.

     E.g. 0.1 would mean that only tokens with the top 10% probability mass
     are considered.

     It is recommended to set either `temperature` or `topP`, but not both.
     */
    topP?: number;
    /**
     Only sample from the top K options for each subsequent token.

     Used to remove "long tail" low probability responses.
     Recommended for advanced use cases only. You usually only need to use temperature.
     */
    topK?: number;
    /**
     Presence penalty setting. It affects the likelihood of the model to
     repeat information that is already in the prompt.

     The presence penalty is a number between -1 (increase repetition)
     and 1 (maximum penalty, decrease repetition). 0 means no penalty.
     */
    presencePenalty?: number;
    /**
     Frequency penalty setting. It affects the likelihood of the model
     to repeatedly use the same words or phrases.

     The frequency penalty is a number between -1 (increase repetition)
     and 1 (maximum penalty, decrease repetition). 0 means no penalty.
     */
    frequencyPenalty?: number;
    /**
     Stop sequences.
     If set, the model will stop generating text when one of the stop sequences is generated.
     Providers may have limits on the number of stop sequences.
     */
    stopSequences?: string[];
    /**
     The seed (integer) to use for random sampling. If set and supported
     by the model, calls will generate deterministic results.
     */
    seed?: number;
    /**
     Maximum number of retries. Set to 0 to disable retries.

     @default 2
     */
    maxRetries?: number;
    /**
     Abort signal.
     */
    abortSignal?: AbortSignal;
    /**
     Additional HTTP headers to be sent with the request.
     Only applicable for HTTP-based providers.
     */
    headers?: Record<string, string | undefined>;
};

/**
 Warning from the model provider for this call. The call will proceed, but e.g.
 some settings might not be supported, which can lead to suboptimal results.
 */
export declare type CallWarning = LanguageModelV2CallWarning;

export declare interface ChatInit<UI_MESSAGE extends UIMessage> {
    /**
     * A unique identifier for the chat. If not provided, a random one will be
     * generated.
     */
    id?: string;
    messageMetadataSchema?: Validator<InferUIMessageMetadata<UI_MESSAGE>> | StandardSchemaV1<InferUIMessageMetadata<UI_MESSAGE>>;
    dataPartSchemas?: UIDataTypesToSchemas<InferUIMessageData<UI_MESSAGE>>;
    messages?: UI_MESSAGE[];
    /**
     * A way to provide a function that is going to be used for ids for messages and the chat.
     * If not provided the default AI SDK `generateId` is used.
     */
    generateId?: IdGenerator;
    transport?: ChatTransport<UI_MESSAGE>;
    /**
     * Callback function to be called when an error is encountered.
     */
    onError?: ChatOnErrorCallback;
    /**
     Optional callback function that is invoked when a tool call is received.
     Intended for automatic client-side tool execution.

     You can optionally return a result for the tool call,
     either synchronously or asynchronously.
     */
    onToolCall?: ChatOnToolCallCallback<UI_MESSAGE>;
    /**
     * Function that is called when the assistant response has finished streaming.
     */
    onFinish?: ChatOnFinishCallback<UI_MESSAGE>;
    /**
     * Optional callback function that is called when a data part is received.
     *
     * @param data The data part that was received.
     */
    onData?: ChatOnDataCallback<UI_MESSAGE>;
    /**
     * When provided, this function will be called when the stream is finished or a tool call is added
     * to determine if the current messages should be resubmitted.
     */
    sendAutomaticallyWhen?: (options: {
        messages: UI_MESSAGE[];
    }) => boolean | PromiseLike<boolean>;
}

export declare type ChatOnDataCallback<UI_MESSAGE extends UIMessage> = (dataPart: DataUIPart<InferUIMessageData<UI_MESSAGE>>) => void;

export declare type ChatOnErrorCallback = (error: Error) => void;

/**
 * Function that is called when the assistant response has finished streaming.
 *
 * @param message The assistant message that was streamed.
 * @param messages The full chat history, including the assistant message.
 *
 * @param isAbort Indicates whether the request has been aborted.
 * @param isDisconnect Indicates whether the request has been ended by a network error.
 * @param isError Indicates whether the request has been ended by an error.
 * @param finishReason The reason why the generation finished.
 */
export declare type ChatOnFinishCallback<UI_MESSAGE extends UIMessage> = (options: {
    message: UI_MESSAGE;
    messages: UI_MESSAGE[];
    isAbort: boolean;
    isDisconnect: boolean;
    isError: boolean;
    finishReason?: FinishReason;
}) => void;

export declare type ChatOnToolCallCallback<UI_MESSAGE extends UIMessage = UIMessage> = (options: {
    toolCall: InferUIMessageToolCall<UI_MESSAGE>;
}) => void | PromiseLike<void>;

export declare type ChatRequestOptions = {
    /**
     Additional headers that should be to be passed to the API endpoint.
     */
    headers?: Record<string, string> | Headers;
    /**
     Additional body JSON properties that should be sent to the API endpoint.
     */
    body?: object;
    metadata?: unknown;
};

export declare interface ChatState<UI_MESSAGE extends UIMessage> {
    status: ChatStatus;
    error: Error | undefined;
    messages: UI_MESSAGE[];
    pushMessage: (message: UI_MESSAGE) => void;
    popMessage: () => void;
    replaceMessage: (index: number, message: UI_MESSAGE) => void;
    snapshot: <T>(thing: T) => T;
}

export declare type ChatStatus = 'submitted' | 'streaming' | 'ready' | 'error';

/**
 * Transport interface for handling chat message communication and streaming.
 *
 * The `ChatTransport` interface provides fine-grained control over how messages
 * are sent to API endpoints and how responses are processed. This enables
 * alternative communication protocols like WebSockets, custom authentication
 * patterns, or specialized backend integrations.
 *
 * @template UI_MESSAGE - The UI message type extending UIMessage
 */
export declare interface ChatTransport<UI_MESSAGE extends UIMessage> {
    /**
     * Sends messages to the chat API endpoint and returns a streaming response.
     *
     * This method handles both new message submission and message regeneration.
     * It supports real-time streaming of responses through UIMessageChunk events.
     *
     * @param options - Configuration object containing:
     * @param options.trigger - The type of message submission:
     *   - `'submit-message'`: Submitting a new user message
     *   - `'regenerate-message'`: Regenerating an assistant response
     * @param options.chatId - Unique identifier for the chat session
     * @param options.messageId - ID of the message to regenerate (for regenerate-message trigger) or undefined for new messages
     * @param options.messages - Array of UI messages representing the conversation history
     * @param options.abortSignal - Signal to abort the request if needed
     * @param options.headers - Additional HTTP headers to include in the request
     * @param options.body - Additional JSON properties to include in the request body
     * @param options.metadata - Custom metadata to attach to the request
     *
     * @returns Promise resolving to a ReadableStream of UIMessageChunk objects.
     *   The stream emits various chunk types like:
     *   - `text-start`, `text-delta`, `text-end`: For streaming text content
     *   - `tool-input-start`, `tool-input-delta`, `tool-input-available`: For tool calls
     *   - `data-part-start`, `data-part-delta`, `data-part-available`: For data parts
     *   - `error`: For error handling
     *
     * @throws Error when the API request fails or response is invalid
     */
    sendMessages: (options: {
        /** The type of message submission - either new message or regeneration */
        trigger: 'submit-message' | 'regenerate-message';
        /** Unique identifier for the chat session */
        chatId: string;
        /** ID of the message to regenerate, or undefined for new messages */
        messageId: string | undefined;
        /** Array of UI messages representing the conversation history */
        messages: UI_MESSAGE[];
        /** Signal to abort the request if needed */
        abortSignal: AbortSignal | undefined;
    } & ChatRequestOptions) => Promise<ReadableStream<UIMessageChunk>>;
    /**
     * Reconnects to an existing streaming response for the specified chat session.
     *
     * This method is used to resume streaming when a connection is interrupted
     * or when resuming a chat session. It's particularly useful for maintaining
     * continuity in long-running conversations or recovering from network issues.
     *
     * @param options - Configuration object containing:
     * @param options.chatId - Unique identifier for the chat session to reconnect to
     * @param options.headers - Additional HTTP headers to include in the reconnection request
     * @param options.body - Additional JSON properties to include in the request body
     * @param options.metadata - Custom metadata to attach to the request
     *
     * @returns Promise resolving to:
     *   - `ReadableStream<UIMessageChunk>`: If an active stream is found and can be resumed
     *   - `null`: If no active stream exists for the specified chat session (e.g., response already completed)
     *
     * @throws Error when the reconnection request fails or response is invalid
     */
    reconnectToStream: (options: {
        /** Unique identifier for the chat session to reconnect to */
        chatId: string;
    } & ChatRequestOptions) => Promise<ReadableStream<UIMessageChunk> | null>;
}

/**
 * Detects the first chunk in a buffer.
 *
 * @param buffer - The buffer to detect the first chunk in.
 *
 * @returns The first detected chunk, or `undefined` if no chunk was detected.
 */
export declare type ChunkDetector = (buffer: string) => string | undefined | null;

declare function combineHeaders(...headers: Array<Record<string, string | undefined> | undefined>): Record<string, string | undefined>;

export declare type CompletionRequestOptions = {
    /**
     An optional object of headers to be passed to the API endpoint.
     */
    headers?: Record<string, string> | Headers;
    /**
     An optional object to be passed to the API endpoint.
     */
    body?: object;
};

/**
 * Consumes a ReadableStream until it's fully read.
 *
 * This function reads the stream chunk by chunk until the stream is exhausted.
 * It doesn't process or return the data from the stream; it simply ensures
 * that the entire stream is read.
 *
 * @param {ReadableStream} stream - The ReadableStream to be consumed.
 * @returns {Promise<void>} A promise that resolves when the stream is fully consumed.
 */
export declare function consumeStream({ stream, onError, }: {
    stream: ReadableStream;
    onError?: (error: unknown) => void;
}): Promise<void>;

declare type ConsumeStreamOptions = {
    onError?: ErrorHandler;
};

declare type ContentPart<TOOLS extends ToolSet> = {
    type: 'text';
    text: string;
    providerMetadata?: ProviderMetadata;
} | ReasoningOutput | ({
    type: 'source';
} & Source) | {
    type: 'file';
    file: GeneratedFile;
    providerMetadata?: ProviderMetadata;
} | ({
    type: 'tool-call';
} & TypedToolCall<TOOLS> & {
    providerMetadata?: ProviderMetadata;
}) | ({
    type: 'tool-result';
} & TypedToolResult<TOOLS> & {
    providerMetadata?: ProviderMetadata;
}) | ({
    type: 'tool-error';
} & TypedToolError<TOOLS> & {
    providerMetadata?: ProviderMetadata;
});

declare interface Context {
    /**
     * Get a value from the context.
     *
     * @param key key which identifies a context value
     */
    getValue(key: symbol): unknown;
    /**
     * Create a new context which inherits from this context and has
     * the given key set to the given value.
     *
     * @param key context key for which to set the value
     * @param value value to set for the given key
     */
    setValue(key: symbol, value: unknown): Context;
    /**
     * Return a new context which inherits from this context but does
     * not contain a value for the given key.
     *
     * @param key context key for which to clear a value
     */
    deleteValue(key: symbol): Context;
}

/**
 * Converts an AsyncIterator to a ReadableStream.
 *
 * @template T - The type of elements produced by the AsyncIterator.
 * @param { <T>} iterator - The AsyncIterator to convert.
 * @returns {ReadableStream<T>} - A ReadableStream that provides the same data as the AsyncIterator.
 */
declare function convertAsyncIteratorToReadableStream<T>(iterator: AsyncIterator<T>): ReadableStream<T>;

declare function convertBase64ToUint8Array(base64String: string): Uint8Array<ArrayBuffer>;

export declare function convertFileListToFileUIParts(files: FileList | undefined): Promise<Array<FileUIPart>>;

declare function convertToBase64(value: string | Uint8Array): string;

/**
 @deprecated Use `convertToModelMessages` instead.
 */
export declare const convertToCoreMessages: typeof convertToModelMessages;

/**
 Converts an array of UI messages from useChat into an array of ModelMessages that can be used
 with the AI functions (e.g. `streamText`, `generateText`).

 @param messages - The UI messages to convert.
 @param options.tools - The tools to use.
 @param options.ignoreIncompleteToolCalls - Whether to ignore incomplete tool calls. Default is `false`.
 @param options.convertDataPart - Optional function to convert data parts to text or file model message parts. Returns `undefined` if the part should be ignored.

 @returns An array of ModelMessages.
 */
export declare function convertToModelMessages<UI_MESSAGE extends UIMessage>(messages: Array<Omit<UI_MESSAGE, 'id'>>, options?: {
    tools?: ToolSet;
    ignoreIncompleteToolCalls?: boolean;
    convertDataPart?: (part: DataUIPart<InferUIMessageData<UI_MESSAGE>>) => TextPart | FilePart | undefined;
}): ModelMessage[];

declare function convertUint8ArrayToBase64(array: Uint8Array): string;

/**
 @deprecated Use `AssistantModelMessage` instead.
 */
export declare type CoreAssistantMessage = AssistantModelMessage;

/**
 @deprecated Use `assistantModelMessageSchema` instead.
 */
export declare const coreAssistantMessageSchema: z.ZodType<AssistantModelMessage, unknown, z.core.$ZodTypeInternals<AssistantModelMessage, unknown>>;

/**
 @deprecated Use `ModelMessage` instead.
 */
export declare type CoreMessage = ModelMessage;

/**
 @deprecated Use `modelMessageSchema` instead.
 */
export declare const coreMessageSchema: z.ZodType<CoreMessage>;

/**
 @deprecated Use `SystemModelMessage` instead.
 */
export declare type CoreSystemMessage = SystemModelMessage;

/**
 @deprecated Use `systemModelMessageSchema` instead.
 */
export declare const coreSystemMessageSchema: z.ZodType<SystemModelMessage, unknown, z.core.$ZodTypeInternals<SystemModelMessage, unknown>>;

/**
 @deprecated Use `ToolModelMessage` instead.
 */
export declare type CoreToolMessage = ToolModelMessage;

/**
 @deprecated Use `toolModelMessageSchema` instead.
 */
export declare const coreToolMessageSchema: z.ZodType<ToolModelMessage, unknown, z.core.$ZodTypeInternals<ToolModelMessage, unknown>>;

/**
 @deprecated Use `UserModelMessage` instead.
 */
export declare type CoreUserMessage = UserModelMessage;

/**
 @deprecated Use `userModelMessageSchema` instead.
 */
export declare const coreUserMessageSchema: z.ZodType<UserModelMessage, unknown, z.core.$ZodTypeInternals<UserModelMessage, unknown>>;

/**
 * Calculates the cosine similarity between two vectors. This is a useful metric for
 * comparing the similarity of two vectors such as embeddings.
 *
 * @param vector1 - The first vector.
 * @param vector2 - The second vector.
 *
 * @returns The cosine similarity between vector1 and vector2.
 * @returns 0 if either vector is the zero vector.
 *
 * @throws {InvalidArgumentError} If the vectors do not have the same length.
 */
export declare function cosineSimilarity(vector1: number[], vector2: number[]): number;

declare const createBinaryResponseHandler: () => ResponseHandler<Uint8Array>;

declare const createEventSourceResponseHandler: <T>(chunkSchema: FlexibleValidator<T>) => ResponseHandler<ReadableStream<ParseResult<T>>>;

/**
 Create a remote provider instance.
 */
export declare function createGateway(options?: GatewayProviderSettings): GatewayProvider;

/**
 Creates an ID generator.
 The total length of the ID is the sum of the prefix, separator, and random part length.
 Not cryptographically secure.

 @param alphabet - The alphabet to use for the ID. Default: '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'.
 @param prefix - The prefix of the ID to generate. Optional.
 @param separator - The separator between the prefix and the random part of the ID. Default: '-'.
 @param size - The size of the random part of the ID to generate. Default: 16.
 */
export declare const createIdGenerator: ({ prefix, size, alphabet, separator, }?: {
    prefix?: string;
    separator?: string;
    size?: number;
    alphabet?: string;
}) => IdGenerator;

declare const createJsonErrorResponseHandler: <T>({ errorSchema, errorToMessage, isRetryable, }: {
    errorSchema: FlexibleValidator<T>;
    errorToMessage: (error: T) => string;
    isRetryable?: (response: Response, error?: T) => boolean;
}) => ResponseHandler<APICallError>;

declare const createJsonResponseHandler: <T>(responseSchema: FlexibleValidator<T>) => ResponseHandler<T>;

declare const createJsonStreamResponseHandler: <T>(chunkSchema: ZodType<T>) => ResponseHandler<ReadableStream<ParseResult<T>>>;

declare function createProviderDefinedToolFactory<INPUT, ARGS extends object>({ id, name, inputSchema, }: {
    id: `${string}.${string}`;
    name: string;
    inputSchema: FlexibleSchema<INPUT>;
}): ProviderDefinedToolFactory<INPUT, ARGS>;

declare function createProviderDefinedToolFactoryWithOutputSchema<INPUT, OUTPUT, ARGS extends object>({ id, name, inputSchema, outputSchema, }: {
    id: `${string}.${string}`;
    name: string;
    inputSchema: FlexibleSchema<INPUT>;
    outputSchema: FlexibleSchema<OUTPUT>;
}): ProviderDefinedToolFactoryWithOutputSchema<INPUT, OUTPUT, ARGS>;

/**
 * Creates a registry for the given providers with optional middleware functionality.
 * This function allows you to register multiple providers and optionally apply middleware
 * to all language models from the registry, enabling you to transform parameters, wrap generate
 * operations, and wrap stream operations for every language model accessed through the registry.
 *
 * @param providers - A record of provider instances to be registered in the registry.
 * @param options - Configuration options for the provider registry.
 * @param options.separator - The separator used between provider ID and model ID in the combined identifier. Defaults to ':'.
 * @param options.languageModelMiddleware - Optional middleware to be applied to all language models from the registry. When multiple middlewares are provided, the first middleware will transform the input first, and the last middleware will be wrapped directly around the model.
 * @returns A new ProviderRegistryProvider instance that provides access to all registered providers with optional middleware applied to language models.
 */
export declare function createProviderRegistry<PROVIDERS extends Record<string, ProviderV2>, SEPARATOR extends string = ':'>(providers: PROVIDERS, { separator, languageModelMiddleware, }?: {
    separator?: SEPARATOR;
    languageModelMiddleware?: LanguageModelMiddleware | LanguageModelMiddleware[];
}): ProviderRegistryProvider<PROVIDERS, SEPARATOR>;

declare const createStatusCodeErrorResponseHandler: () => ResponseHandler<APICallError>;

export declare function createTextStreamResponse({ status, statusText, headers, textStream, }: ResponseInit & {
    textStream: ReadableStream<string>;
}): Response;

export declare type CreateUIMessage<UI_MESSAGE extends UIMessage> = Omit<UI_MESSAGE, 'id' | 'role'> & {
    id?: UI_MESSAGE['id'];
    role?: UI_MESSAGE['role'];
};

export declare function createUIMessageStream<UI_MESSAGE extends UIMessage>({ execute, onError, originalMessages, onFinish, generateId, }: {
    execute: (options: {
        writer: UIMessageStreamWriter<UI_MESSAGE>;
    }) => Promise<void> | void;
    onError?: (error: unknown) => string;
    /**
     * The original messages. If they are provided, persistence mode is assumed,
     * and a message ID is provided for the response message.
     */
    originalMessages?: UI_MESSAGE[];
    onFinish?: UIMessageStreamOnFinishCallback<UI_MESSAGE>;
    generateId?: IdGenerator;
}): ReadableStream<InferUIMessageChunk<UI_MESSAGE>>;

export declare function createUIMessageStreamResponse({ status, statusText, headers, stream, consumeSseStream, }: UIMessageStreamResponseInit & {
    stream: ReadableStream<UIMessageChunk>;
}): Response;

/**
 * Creates a custom provider with specified language models, text embedding models, image models, transcription models, speech models, and an optional fallback provider.
 *
 * @param {Object} options - The options for creating the custom provider.
 * @param {Record<string, LanguageModel>} [options.languageModels] - A record of language models, where keys are model IDs and values are LanguageModel instances.
 * @param {Record<string, EmbeddingModel<string>>} [options.textEmbeddingModels] - A record of text embedding models, where keys are model IDs and values are EmbeddingModel<string> instances.
 * @param {Record<string, ImageModel>} [options.imageModels] - A record of image models, where keys are model IDs and values are ImageModel instances.
 * @param {Record<string, TranscriptionModel>} [options.transcriptionModels] - A record of transcription models, where keys are model IDs and values are TranscriptionModel instances.
 * @param {Record<string, SpeechModel>} [options.speechModels] - A record of speech models, where keys are model IDs and values are SpeechModel instances.
 * @param {Provider} [options.fallbackProvider] - An optional fallback provider to use when a requested model is not found in the custom provider.
 * @returns {Provider} A Provider object with languageModel, textEmbeddingModel, imageModel, transcriptionModel, and speechModel methods.
 *
 * @throws {NoSuchModelError} Throws when a requested model is not found and no fallback provider is available.
 */
export declare function customProvider<LANGUAGE_MODELS extends Record<string, LanguageModelV2>, EMBEDDING_MODELS extends Record<string, EmbeddingModelV2<string>>, IMAGE_MODELS extends Record<string, ImageModelV2>, TRANSCRIPTION_MODELS extends Record<string, TranscriptionModelV2>, SPEECH_MODELS extends Record<string, SpeechModelV2>>({ languageModels, textEmbeddingModels, imageModels, transcriptionModels, speechModels, fallbackProvider, }: {
    languageModels?: LANGUAGE_MODELS;
    textEmbeddingModels?: EMBEDDING_MODELS;
    imageModels?: IMAGE_MODELS;
    transcriptionModels?: TRANSCRIPTION_MODELS;
    speechModels?: SPEECH_MODELS;
    fallbackProvider?: ProviderV2;
}): ProviderV2 & {
    languageModel(modelId: ExtractModelId<LANGUAGE_MODELS>): LanguageModelV2;
    textEmbeddingModel(modelId: ExtractModelId<EMBEDDING_MODELS>): EmbeddingModelV2<string>;
    imageModel(modelId: ExtractModelId<IMAGE_MODELS>): ImageModelV2;
    transcriptionModel(modelId: ExtractModelId<TRANSCRIPTION_MODELS>): TranscriptionModelV2;
    speechModel(modelId: ExtractModelId<SPEECH_MODELS>): SpeechModelV2;
};

/**
 Data content. Can either be a base64-encoded string, a Uint8Array, an ArrayBuffer, or a Buffer.
 */
export declare type DataContent = string | Uint8Array | ArrayBuffer | Buffer;

declare type DataUIMessageChunk<DATA_TYPES extends UIDataTypes> = ValueOf<{
    [NAME in keyof DATA_TYPES & string]: {
        type: `data-${NAME}`;
        id?: string;
        data: DATA_TYPES[NAME];
        transient?: boolean;
    };
}>;

export declare type DataUIPart<DATA_TYPES extends UIDataTypes> = ValueOf<{
    [NAME in keyof DATA_TYPES & string]: {
        type: `data-${NAME}`;
        id?: string;
        data: DATA_TYPES[NAME];
    };
}>;

/**
 Create a type from an object with all keys and nested keys set to optional.
 The helper supports normal objects and Zod schemas (which are resolved automatically).
 It always recurses into arrays.

 Adopted from [type-fest](https://github.com/sindresorhus/type-fest/tree/main) PartialDeep.
 */
export declare type DeepPartial<T> = T extends z3.ZodTypeAny ? DeepPartialInternal<z3.infer<T>> : T extends z4.core.$ZodType ? DeepPartialInternal<z4.infer<T>> : DeepPartialInternal<T>;

declare type DeepPartialInternal<T> = T extends null | undefined | string | number | boolean | symbol | bigint | void | Date | RegExp | ((...arguments_: any[]) => unknown) | (new (...arguments_: any[]) => unknown) ? T : T extends Map<infer KeyType, infer ValueType> ? PartialMap<KeyType, ValueType> : T extends Set<infer ItemType> ? PartialSet<ItemType> : T extends ReadonlyMap<infer KeyType, infer ValueType> ? PartialReadonlyMap<KeyType, ValueType> : T extends ReadonlySet<infer ItemType> ? PartialReadonlySet<ItemType> : T extends object ? T extends ReadonlyArray<infer ItemType> ? ItemType[] extends T ? readonly ItemType[] extends T ? ReadonlyArray<DeepPartialInternal<ItemType | undefined>> : Array<DeepPartialInternal<ItemType | undefined>> : PartialObject<T> : PartialObject<T> : unknown;

export declare class DefaultChatTransport<UI_MESSAGE extends UIMessage> extends HttpChatTransport<UI_MESSAGE> {
    constructor(options?: HttpChatTransportInitOptions<UI_MESSAGE>);
    protected processResponseStream(stream: ReadableStream<Uint8Array<ArrayBufferLike>>): ReadableStream<UIMessageChunk>;
}

/**
 * Applies default settings for a language model.
 */
export declare function defaultSettingsMiddleware({ settings, }: {
    settings: Partial<{
        maxOutputTokens?: LanguageModelV2CallOptions['maxOutputTokens'];
        temperature?: LanguageModelV2CallOptions['temperature'];
        stopSequences?: LanguageModelV2CallOptions['stopSequences'];
        topP?: LanguageModelV2CallOptions['topP'];
        topK?: LanguageModelV2CallOptions['topK'];
        presencePenalty?: LanguageModelV2CallOptions['presencePenalty'];
        frequencyPenalty?: LanguageModelV2CallOptions['frequencyPenalty'];
        responseFormat?: LanguageModelV2CallOptions['responseFormat'];
        seed?: LanguageModelV2CallOptions['seed'];
        tools?: LanguageModelV2CallOptions['tools'];
        toolChoice?: LanguageModelV2CallOptions['toolChoice'];
        headers?: LanguageModelV2CallOptions['headers'];
        providerOptions?: LanguageModelV2CallOptions['providerOptions'];
    }>;
}): LanguageModelMiddleware;

/**
 * Creates a Promise that resolves after a specified delay
 * @param delayInMs - The delay duration in milliseconds. If null or undefined, resolves immediately.
 * @param signal - Optional AbortSignal to cancel the delay
 * @returns A Promise that resolves after the specified delay
 * @throws {DOMException} When the signal is aborted
 */
declare function delay(delayInMs?: number | null, options?: {
    abortSignal?: AbortSignal;
}): Promise<void>;

/**
 * Delayed promise. It is only constructed once the value is accessed.
 * This is useful to avoid unhandled promise rejections when the promise is created
 * but not accessed.
 */
declare class DelayedPromise<T> {
    private status;
    private _promise;
    private _resolve;
    private _reject;
    get promise(): Promise<T>;
    resolve(value: T): void;
    reject(error: unknown): void;
    isResolved(): boolean;
    isRejected(): boolean;
    isPending(): boolean;
}

export declare class DownloadError extends AISDKError {
    private readonly [symbol$2_2];
    readonly url: string;
    readonly statusCode?: number;
    readonly statusText?: string;
    constructor({ url, statusCode, statusText, cause, message, }: {
        url: string;
        statusCode?: number;
        statusText?: string;
        message?: string;
        cause?: unknown;
    });
    static isInstance(error: unknown): error is DownloadError;
}

/**
 Helper function for defining a dynamic tool.
 */
export declare function dynamicTool(tool: {
    description?: string;
    providerOptions?: ProviderOptions;
    inputSchema: FlexibleSchema<unknown>;
    execute: ToolExecuteFunction<unknown, unknown>;
    toModelOutput?: (output: unknown) => LanguageModelV2ToolResultPart['output'];
}): Tool<unknown, unknown> & {
    type: 'dynamic';
};

export declare type DynamicToolCall = {
    type: 'tool-call';
    toolCallId: string;
    toolName: string;
    input: unknown;
    providerExecuted?: boolean;
    dynamic: true;
    providerMetadata?: ProviderMetadata;
    /**
     * True if this is caused by an unparsable tool call or
     * a tool that does not exist.
     */
    invalid?: boolean;
    /**
     * The error that caused the tool call to be invalid.
     */
    error?: unknown;
};

export declare type DynamicToolError = {
    type: 'tool-error';
    toolCallId: string;
    toolName: string;
    input: unknown;
    error: unknown;
    providerExecuted?: boolean;
    providerMetadata?: ProviderMetadata;
    dynamic: true;
};

export declare type DynamicToolResult = {
    type: 'tool-result';
    toolCallId: string;
    toolName: string;
    input: unknown;
    output: unknown;
    providerExecuted?: boolean;
    providerMetadata?: ProviderMetadata;
    dynamic: true;
    preliminary?: boolean;
};

export declare type DynamicToolUIPart = {
    type: 'dynamic-tool';
    /**
     * Name of the tool that is being called.
     */
    toolName: string;
    /**
     * ID of the tool call.
     */
    toolCallId: string;
    title?: string;
    /**
     * Whether the tool call was executed by the provider.
     */
    providerExecuted?: boolean;
} & ({
    state: 'input-streaming';
    input: unknown | undefined;
    output?: never;
    errorText?: never;
} | {
    state: 'input-available';
    input: unknown;
    output?: never;
    errorText?: never;
    callProviderMetadata?: ProviderMetadata;
} | {
    state: 'output-available';
    input: unknown;
    output: unknown;
    errorText?: never;
    callProviderMetadata?: ProviderMetadata;
    preliminary?: boolean;
} | {
    state: 'output-error';
    input: unknown;
    output?: never;
    errorText: string;
    callProviderMetadata?: ProviderMetadata;
});

/**
 Embed a value using an embedding model. The type of the value is defined by the embedding model.

 @param model - The embedding model to use.
 @param value - The value that should be embedded.

 @param maxRetries - Maximum number of retries. Set to 0 to disable retries. Default: 2.
 @param abortSignal - An optional abort signal that can be used to cancel the call.
 @param headers - Additional HTTP headers to be sent with the request. Only applicable for HTTP-based providers.

 @returns A result object that contains the embedding, the value, and additional information.
 */
export declare function embed<VALUE = string>({ model: modelArg, value, providerOptions, maxRetries: maxRetriesArg, abortSignal, headers, experimental_telemetry: telemetry, }: {
    /**
     The embedding model to use.
     */
    model: EmbeddingModel<VALUE>;
    /**
     The value that should be embedded.
     */
    value: VALUE;
    /**
     Maximum number of retries per embedding model call. Set to 0 to disable retries.

     @default 2
     */
    maxRetries?: number;
    /**
     Abort signal.
     */
    abortSignal?: AbortSignal;
    /**
     Additional headers to include in the request.
     Only applicable for HTTP-based providers.
     */
    headers?: Record<string, string>;
    /**
     Additional provider-specific options. They are passed through
     to the provider from the AI SDK and enable provider-specific
     functionality that can be fully encapsulated in the provider.
     */
    providerOptions?: ProviderOptions;
    /**
     * Optional telemetry configuration (experimental).
     */
    experimental_telemetry?: TelemetrySettings;
}): Promise<EmbedResult<VALUE>>;

/**
 Embedding.
 */
export declare type Embedding = EmbeddingModelV2Embedding;

/**
 Embedding model that is used by the AI SDK Core functions.
 */
export declare type EmbeddingModel<VALUE = string> = string | EmbeddingModelV2<VALUE>;

/**
 Represents the number of tokens used in an embedding.
 */
export declare type EmbeddingModelUsage = {
    /**
     The number of tokens used in the embedding.
     */
    tokens: number;
};

/**
 Specification for an embedding model that implements the embedding model
 interface version 1.

 VALUE is the type of the values that the model can embed.
 This will allow us to go beyond text embeddings in the future,
 e.g. to support image embeddings
 */
declare type EmbeddingModelV2<VALUE> = {
    /**
     The embedding model must specify which embedding model interface
     version it implements. This will allow us to evolve the embedding
     model interface and retain backwards compatibility. The different
     implementation versions can be handled as a discriminated union
     on our side.
     */
    readonly specificationVersion: 'v2';
    /**
     Name of the provider for logging purposes.
     */
    readonly provider: string;
    /**
     Provider-specific model ID for logging purposes.
     */
    readonly modelId: string;
    /**
     Limit of how many embeddings can be generated in a single API call.

     Use Infinity for models that do not have a limit.
     */
    readonly maxEmbeddingsPerCall: PromiseLike<number | undefined> | number | undefined;
    /**
     True if the model can handle multiple embedding calls in parallel.
     */
    readonly supportsParallelCalls: PromiseLike<boolean> | boolean;
    /**
     Generates a list of embeddings for the given input text.

     Naming: "do" prefix to prevent accidental direct usage of the method
     by the user.
     */
    doEmbed(options: {
        /**
         List of values to embed.
         */
        values: Array<VALUE>;
        /**
         Abort signal for cancelling the operation.
         */
        abortSignal?: AbortSignal;
        /**
         Additional provider-specific options. They are passed through
         to the provider from the AI SDK and enable provider-specific
         functionality that can be fully encapsulated in the provider.
         */
        providerOptions?: SharedV2ProviderOptions;
        /**
         Additional HTTP headers to be sent with the request.
         Only applicable for HTTP-based providers.
         */
        headers?: Record<string, string | undefined>;
    }): PromiseLike<{
        /**
         Generated embeddings. They are in the same order as the input values.
         */
        embeddings: Array<EmbeddingModelV2Embedding>;
        /**
         Token usage. We only have input tokens for embeddings.
         */
        usage?: {
            tokens: number;
        };
        /**
         Additional provider-specific metadata. They are passed through
         from the provider to the AI SDK and enable provider-specific
         results that can be fully encapsulated in the provider.
         */
        providerMetadata?: SharedV2ProviderMetadata;
        /**
         Optional response information for debugging purposes.
         */
        response?: {
            /**
             Response headers.
             */
            headers?: SharedV2Headers;
            /**
             The response body.
             */
            body?: unknown;
        };
    }>;
};

/**
 An embedding is a vector, i.e. an array of numbers.
 It is e.g. used to represent a text as a vector of word embeddings.
 */
declare type EmbeddingModelV2Embedding = Array<number>;

/**
 Embed several values using an embedding model. The type of the value is defined
 by the embedding model.

 `embedMany` automatically splits large requests into smaller chunks if the model
 has a limit on how many embeddings can be generated in a single call.

 @param model - The embedding model to use.
 @param values - The values that should be embedded.

 @param maxRetries - Maximum number of retries. Set to 0 to disable retries. Default: 2.
 @param abortSignal - An optional abort signal that can be used to cancel the call.
 @param headers - Additional HTTP headers to be sent with the request. Only applicable for HTTP-based providers.

 @returns A result object that contains the embeddings, the value, and additional information.
 */
export declare function embedMany<VALUE = string>({ model: modelArg, values, maxParallelCalls, maxRetries: maxRetriesArg, abortSignal, headers, providerOptions, experimental_telemetry: telemetry, }: {
    /**
     The embedding model to use.
     */
    model: EmbeddingModel<VALUE>;
    /**
     The values that should be embedded.
     */
    values: Array<VALUE>;
    /**
     Maximum number of retries per embedding model call. Set to 0 to disable retries.

     @default 2
     */
    maxRetries?: number;
    /**
     Abort signal.
     */
    abortSignal?: AbortSignal;
    /**
     Additional headers to include in the request.
     Only applicable for HTTP-based providers.
     */
    headers?: Record<string, string>;
    /**
     * Optional telemetry configuration (experimental).
     */
    experimental_telemetry?: TelemetrySettings;
    /**
     Additional provider-specific options. They are passed through
     to the provider from the AI SDK and enable provider-specific
     functionality that can be fully encapsulated in the provider.
     */
    providerOptions?: ProviderOptions;
    /**
     * Maximum number of concurrent requests.
     *
     * @default Infinity
     */
    maxParallelCalls?: number;
}): Promise<EmbedManyResult<VALUE>>;

/**
 The result of a `embedMany` call.
 It contains the embeddings, the values, and additional information.
 */
export declare interface EmbedManyResult<VALUE> {
    /**
     The values that were embedded.
     */
    readonly values: Array<VALUE>;
    /**
     The embeddings. They are in the same order as the values.
     */
    readonly embeddings: Array<Embedding>;
    /**
     The embedding token usage.
     */
    readonly usage: EmbeddingModelUsage;
    /**
     Optional provider-specific metadata.
     */
    readonly providerMetadata?: ProviderMetadata;
    /**
     Optional raw response data.
     */
    readonly responses?: Array<{
        /**
         Response headers.
         */
        headers?: Record<string, string>;
        /**
         The response body.
         */
        body?: unknown;
    } | undefined>;
}

/**
 The result of an `embed` call.
 It contains the embedding, the value, and additional information.
 */
export declare interface EmbedResult<VALUE> {
    /**
     The value that was embedded.
     */
    readonly value: VALUE;
    /**
     The embedding of the value.
     */
    readonly embedding: Embedding;
    /**
     The embedding token usage.
     */
    readonly usage: EmbeddingModelUsage;
    /**
     Optional provider-specific metadata.
     */
    readonly providerMetadata?: ProviderMetadata;
    /**
     Optional response data.
     */
    readonly response?: {
        /**
         Response headers.
         */
        headers?: Record<string, string>;
        /**
         The response body.
         */
        body?: unknown;
    };
}

export declare class EmptyResponseBodyError extends AISDKError {
    private readonly [symbol$b];
    constructor({ message }?: {
        message?: string;
    });
    static isInstance(error: unknown): error is EmptyResponseBodyError;
}

export declare type ErrorHandler = (error: unknown) => void;

/**
 * A parsed EventSource message event
 *
 * @public
 */
declare interface EventSourceMessage {
    /**
     * The event type sent from the server. Note that this differs from the browser `EventSource`
     * implementation in that browsers will default this to `message`, whereas this parser will
     * leave this as `undefined` if not explicitly declared.
     */
    event?: string | undefined
    /**
     * ID of the message, if any was provided by the server. Can be used by clients to keep the
     * last received message ID in sync when reconnecting.
     */
    id?: string | undefined
    /**
     * The data received for this message
     */
    data: string
}

/**
 * A TransformStream that ingests a stream of strings and produces a stream of `EventSourceMessage`.
 *
 * @example Basic usage
 * ```
 * const eventStream =
 *   response.body
 *     .pipeThrough(new TextDecoderStream())
 *     .pipeThrough(new EventSourceParserStream())
 * ```
 *
 * @example Terminate stream on parsing errors
 * ```
 * const eventStream =
 *  response.body
 *   .pipeThrough(new TextDecoderStream())
 *   .pipeThrough(new EventSourceParserStream({terminateOnError: true}))
 * ```
 *
 * @public
 */
declare class EventSourceParserStream extends TransformStream<string, EventSourceMessage> {
    constructor({onError, onRetry, onComment}?: StreamOptions)
}

/**
 * Defines Exception.
 *
 * string or an object with one of (message or name or code) and optional stack
 */
declare type Exception = ExceptionWithCode | ExceptionWithMessage | ExceptionWithName | string;

declare interface ExceptionWithCode {
    code: string | number;
    name?: string;
    message?: string;
    stack?: string;
}

declare interface ExceptionWithMessage {
    code?: string | number;
    message: string;
    name?: string;
    stack?: string;
}

declare interface ExceptionWithName {
    code?: string | number;
    message?: string;
    name: string;
    stack?: string;
}

declare function executeTool<INPUT, OUTPUT>({ execute, input, options, }: {
    execute: ToolExecuteFunction<INPUT, OUTPUT>;
    input: INPUT;
    options: ToolCallOptions;
}): AsyncGenerator<{
    type: 'preliminary';
    output: OUTPUT;
} | {
    type: 'final';
    output: OUTPUT;
}>;

export declare class Experimental_Agent<TOOLS extends ToolSet, OUTPUT = never, OUTPUT_PARTIAL = never> {
    private readonly settings;
    constructor(settings: Experimental_AgentSettings<TOOLS, OUTPUT, OUTPUT_PARTIAL>);
    get tools(): TOOLS;
    generate(options: Prompt & {
        /**
         Additional provider-specific metadata. They are passed through
         from the provider to the AI SDK and enable provider-specific
         results that can be fully encapsulated in the provider.
         */
        providerMetadata?: ProviderMetadata;
        /**
         Additional provider-specific metadata. They are passed through
         to the provider from the AI SDK and enable provider-specific
         functionality that can be fully encapsulated in the provider.
         */
        providerOptions?: ProviderOptions;
    }): Promise<GenerateTextResult<TOOLS, OUTPUT>>;
    stream(options: Prompt & {
        /**
         Additional provider-specific metadata. They are passed through
         from the provider to the AI SDK and enable provider-specific
         results that can be fully encapsulated in the provider.
         */
        providerMetadata?: ProviderMetadata;
        /**
         Additional provider-specific metadata. They are passed through
         to the provider from the AI SDK and enable provider-specific
         functionality that can be fully encapsulated in the provider.
         */
        providerOptions?: ProviderOptions;
    }): StreamTextResult<TOOLS, OUTPUT_PARTIAL>;
    /**
     * Creates a response object that streams UI messages to the client.
     */
    respond(options: {
        messages: UIMessage<never, never, InferUITools<TOOLS>>[];
    }): Response;
}

export declare type Experimental_AgentSettings<TOOLS extends ToolSet, OUTPUT = never, OUTPUT_PARTIAL = never> = CallSettings & {
    /**
     * The system prompt to use.
     */
    system?: string;
    /**
     The language model to use.
     */
    model: LanguageModel;
    /**
     The tools that the model can call. The model needs to support calling tools.
     */
    tools?: TOOLS;
    /**
     The tool choice strategy. Default: 'auto'.
     */
    toolChoice?: ToolChoice<NoInfer<TOOLS>>;
    /**
     Condition for stopping the generation when there are tool results in the last step.
     When the condition is an array, any of the conditions can be met to stop the generation.

     @default stepCountIs(1)
     */
    stopWhen?: StopCondition<NoInfer<TOOLS>> | Array<StopCondition<NoInfer<TOOLS>>>;
    /**
     Optional telemetry configuration (experimental).
     */
    experimental_telemetry?: TelemetrySettings;
    /**
     Limits the tools that are available for the model to call without
     changing the tool call and result types in the result.
     */
    activeTools?: Array<keyof NoInfer<TOOLS>>;
    /**
     Optional specification for parsing structured outputs from the LLM response.
     */
    experimental_output?: Output_2<OUTPUT, OUTPUT_PARTIAL>;
    /**
     * @deprecated Use `prepareStep` instead.
     */
    experimental_prepareStep?: PrepareStepFunction<NoInfer<TOOLS>>;
    /**
     Optional function that you can use to provide different settings for a step.
     */
    prepareStep?: PrepareStepFunction<NoInfer<TOOLS>>;
    /**
     A function that attempts to repair a tool call that failed to parse.
     */
    experimental_repairToolCall?: ToolCallRepairFunction<NoInfer<TOOLS>>;
    /**
     Callback that is called when each step (LLM call) is finished, including intermediate steps.
     */
    onStepFinish?: GenerateTextOnStepFinishCallback<NoInfer<TOOLS>>;
    /**
     * Context that is passed into tool calls.
     *
     * Experimental (can break in patch releases).
     *
     * @default undefined
     */
    experimental_context?: unknown;
    /**
     * Internal. For test use only. May change without notice.
     */
    _internal?: {
        generateId?: IdGenerator;
        currentDate?: () => Date;
    };
};

/**
 * @deprecated Use `createProviderRegistry` instead.
 */
export declare const experimental_createProviderRegistry: typeof createProviderRegistry;

/**
 * @deprecated Use `customProvider` instead.
 */
export declare const experimental_customProvider: typeof customProvider;

/**
 * Experimental. Can change in patch versions without warning.
 *
 * Download function. Called with the array of URLs and a boolean indicating
 * whether the URL is supported by the model.
 *
 * The download function can decide for each URL:
 * - to return null (which means that the URL should be passed to the model)
 * - to download the asset and return the data (incl. retries, authentication, etc.)
 *
 * Should throw DownloadError if the download fails.
 *
 * Should return an array of objects sorted by the order of the requested downloads.
 * For each object, the data should be a Uint8Array if the URL was downloaded.
 * For each object, the mediaType should be the media type of the downloaded asset.
 * For each object, the data should be null if the URL should be passed through as is.
 */
export declare type Experimental_DownloadFunction = (options: Array<{
    url: URL;
    isUrlSupportedByModel: boolean;
}>) => PromiseLike<Array<{
    data: Uint8Array;
    mediaType: string | undefined;
} | null>>;

/**
 Generates images using an image model.

 @param model - The image model to use.
 @param prompt - The prompt that should be used to generate the image.
 @param n - Number of images to generate. Default: 1.
 @param size - Size of the images to generate. Must have the format `{width}x{height}`.
 @param aspectRatio - Aspect ratio of the images to generate. Must have the format `{width}:{height}`.
 @param seed - Seed for the image generation.
 @param providerOptions - Additional provider-specific options that are passed through to the provider
 as body parameters.
 @param maxRetries - Maximum number of retries. Set to 0 to disable retries. Default: 2.
 @param abortSignal - An optional abort signal that can be used to cancel the call.
 @param headers - Additional HTTP headers to be sent with the request. Only applicable for HTTP-based providers.

 @returns A result object that contains the generated images.
 */
export declare function experimental_generateImage({ model: modelArg, prompt, n, maxImagesPerCall, size, aspectRatio, seed, providerOptions, maxRetries: maxRetriesArg, abortSignal, headers, }: {
    /**
     The image model to use.
     */
    model: ImageModel;
    /**
     The prompt that should be used to generate the image.
     */
    prompt: string;
    /**
     Number of images to generate.
     */
    n?: number;
    /**
     Number of images to generate.
     */
    maxImagesPerCall?: number;
    /**
     Size of the images to generate. Must have the format `{width}x{height}`. If not provided, the default size will be used.
     */
    size?: `${number}x${number}`;
    /**
     Aspect ratio of the images to generate. Must have the format `{width}:{height}`. If not provided, the default aspect ratio will be used.
     */
    aspectRatio?: `${number}:${number}`;
    /**
     Seed for the image generation. If not provided, the default seed will be used.
     */
    seed?: number;
    /**
     Additional provider-specific options that are passed through to the provider
     as body parameters.

     The outer record is keyed by the provider name, and the inner
     record is keyed by the provider-specific metadata key.
     ```ts
     {
     "openai": {
     "style": "vivid"
     }
     }
     ```
     */
    providerOptions?: ProviderOptions;
    /**
     Maximum number of retries per embedding model call. Set to 0 to disable retries.

     @default 2
     */
    maxRetries?: number;
    /**
     Abort signal.
     */
    abortSignal?: AbortSignal;
    /**
     Additional headers to include in the request.
     Only applicable for HTTP-based providers.
     */
    headers?: Record<string, string>;
}): Promise<Experimental_GenerateImageResult>;

/**
 The result of a `generateImage` call.
 It contains the images and additional information.
 */
export declare interface Experimental_GenerateImageResult {
    /**
     The first image that was generated.
     */
    readonly image: GeneratedFile;
    /**
     The images that were generated.
     */
    readonly images: Array<GeneratedFile>;
    /**
     Warnings for the call, e.g. unsupported settings.
     */
    readonly warnings: Array<ImageModelCallWarning>;
    /**
     Response metadata from the provider. There may be multiple responses if we made multiple calls to the model.
     */
    readonly responses: Array<ImageModelResponseMetadata>;
    /**
     * Provider-specific metadata. They are passed through from the provider to the AI SDK and enable provider-specific
     * results that can be fully encapsulated in the provider.
     */
    readonly providerMetadata: ImageModelProviderMetadata;
}

/**
 Generates speech audio using a speech model.

 @param model - The speech model to use.
 @param text - The text to convert to speech.
 @param voice - The voice to use for speech generation.
 @param outputFormat - The output format to use for speech generation e.g. "mp3", "wav", etc.
 @param instructions - Instructions for the speech generation e.g. "Speak in a slow and steady tone".
 @param speed - The speed of the speech generation.
 @param providerOptions - Additional provider-specific options that are passed through to the provider
 as body parameters.
 @param maxRetries - Maximum number of retries. Set to 0 to disable retries. Default: 2.
 @param abortSignal - An optional abort signal that can be used to cancel the call.
 @param headers - Additional HTTP headers to be sent with the request. Only applicable for HTTP-based providers.

 @returns A result object that contains the generated audio data.
 */
export declare function experimental_generateSpeech({ model, text, voice, outputFormat, instructions, speed, language, providerOptions, maxRetries: maxRetriesArg, abortSignal, headers, }: {
    /**
     The speech model to use.
     */
    model: SpeechModelV2;
    /**
     The text to convert to speech.
     */
    text: string;
    /**
     The voice to use for speech generation.
     */
    voice?: string;
    /**
     * The desired output format for the audio e.g. "mp3", "wav", etc.
     */
    outputFormat?: 'mp3' | 'wav' | (string & {});
    /**
     Instructions for the speech generation e.g. "Speak in a slow and steady tone".
     */
    instructions?: string;
    /**
     The speed of the speech generation.
     */
    speed?: number;
    /**
     The language for speech generation. This should be an ISO 639-1 language code (e.g. "en", "es", "fr")
     or "auto" for automatic language detection. Provider support varies.
     */
    language?: string;
    /**
     Additional provider-specific options that are passed through to the provider
     as body parameters.

     The outer record is keyed by the provider name, and the inner
     record is keyed by the provider-specific metadata key.
     ```ts
     {
     "openai": {}
     }
     ```
     */
    providerOptions?: ProviderOptions;
    /**
     Maximum number of retries per speech model call. Set to 0 to disable retries.

     @default 2
     */
    maxRetries?: number;
    /**
     Abort signal.
     */
    abortSignal?: AbortSignal;
    /**
     Additional headers to include in the request.
     Only applicable for HTTP-based providers.
     */
    headers?: Record<string, string>;
}): Promise<Experimental_SpeechResult>;

/**
 * Infer the UI message type of an agent.
 */
export declare type Experimental_InferAgentUIMessage<AGENT> = UIMessage<never, never, InferUITools<InferAgentTools<AGENT>>>;

export declare type Experimental_LogWarningsFunction = (warnings: Experimental_Warning[]) => void;

/**
 The result of a `generateSpeech` call.
 It contains the audio data and additional information.
 */
export declare interface Experimental_SpeechResult {
    /**
     * The audio data as a base64 encoded string or binary data.
     */
    readonly audio: GeneratedAudioFile;
    /**
     Warnings for the call, e.g. unsupported settings.
     */
    readonly warnings: Array<SpeechWarning>;
    /**
     Response metadata from the provider. There may be multiple responses if we made multiple calls to the model.
     */
    readonly responses: Array<SpeechModelResponseMetadata>;
    /**
     Provider metadata from the provider.
     */
    readonly providerMetadata: Record<string, Record<string, JSONValue_2>>;
}

/**
 Generates transcripts using a transcription model.

 @param model - The transcription model to use.
 @param audio - The audio data to transcribe as DataContent (string | Uint8Array | ArrayBuffer | Buffer) or a URL.
 @param providerOptions - Additional provider-specific options that are passed through to the provider
 as body parameters.
 @param maxRetries - Maximum number of retries. Set to 0 to disable retries. Default: 2.
 @param abortSignal - An optional abort signal that can be used to cancel the call.
 @param headers - Additional HTTP headers to be sent with the request. Only applicable for HTTP-based providers.

 @returns A result object that contains the generated transcript.
 */
export declare function experimental_transcribe({ model, audio, providerOptions, maxRetries: maxRetriesArg, abortSignal, headers, }: {
    /**
     The transcription model to use.
     */
    model: TranscriptionModelV2;
    /**
     The audio data to transcribe.
     */
    audio: DataContent | URL;
    /**
     Additional provider-specific options that are passed through to the provider
     as body parameters.

     The outer record is keyed by the provider name, and the inner
     record is keyed by the provider-specific metadata key.
     ```ts
     {
     "openai": {
     "temperature": 0
     }
     }
     ```
     */
    providerOptions?: ProviderOptions;
    /**
     Maximum number of retries per transcript model call. Set to 0 to disable retries.

     @default 2
     */
    maxRetries?: number;
    /**
     Abort signal.
     */
    abortSignal?: AbortSignal;
    /**
     Additional headers to include in the request.
     Only applicable for HTTP-based providers.
     */
    headers?: Record<string, string>;
}): Promise<Experimental_TranscriptionResult>;

/**
 The result of a `transcribe` call.
 It contains the transcript and additional information.
 */
export declare interface Experimental_TranscriptionResult {
    /**
     * The complete transcribed text from the audio.
     */
    readonly text: string;
    /**
     * Array of transcript segments with timing information.
     * Each segment represents a portion of the transcribed text with start and end times.
     */
    readonly segments: Array<{
        /**
         * The text content of this segment.
         */
        readonly text: string;
        /**
         * The start time of this segment in seconds.
         */
        readonly startSecond: number;
        /**
         * The end time of this segment in seconds.
         */
        readonly endSecond: number;
    }>;
    /**
     * The detected language of the audio content, as an ISO-639-1 code (e.g., 'en' for English).
     * May be undefined if the language couldn't be detected.
     */
    readonly language: string | undefined;
    /**
     * The total duration of the audio file in seconds.
     * May be undefined if the duration couldn't be determined.
     */
    readonly durationInSeconds: number | undefined;
    /**
     Warnings for the call, e.g. unsupported settings.
     */
    readonly warnings: Array<TranscriptionWarning>;
    /**
     Response metadata from the provider. There may be multiple responses if we made multiple calls to the model.
     */
    readonly responses: Array<TranscriptionModelResponseMetadata>;
    /**
     Provider metadata from the provider.
     */
    readonly providerMetadata: Record<string, Record<string, JSONValue_2>>;
}

export declare type Experimental_Warning = LanguageModelV2CallWarning | ImageModelV2CallWarning | SpeechModelV2CallWarning | TranscriptionModelV2CallWarning;

declare type ExtractLiteralUnion<T> = T extends string ? string extends T ? never : T : never;

declare type ExtractModelId<MODELS extends Record<string, unknown>> = Extract<keyof MODELS, string>;

/**
 * Extract an XML-tagged reasoning section from the generated text and exposes it
 * as a `reasoning` property on the result.
 *
 * @param tagName - The name of the XML tag to extract reasoning from.
 * @param separator - The separator to use between reasoning and text sections.
 * @param startWithReasoning - Whether to start with reasoning tokens.
 */
export declare function extractReasoningMiddleware({ tagName, separator, startWithReasoning, }: {
    tagName: string;
    separator?: string;
    startWithReasoning?: boolean;
}): LanguageModelMiddleware;

/**
 Extracts the headers from a response object and returns them as a key-value object.

 @param response - The response object to extract headers from.
 @returns The headers as a key-value object.
 */
declare function extractResponseHeaders(response: Response): {
    [k: string]: string;
};

/**
 * Fetch function type (standardizes the version of fetch used).
 */
declare type FetchFunction = typeof globalThis.fetch;

/**
 File content part of a prompt. It contains a file.
 */
export declare interface FilePart {
    type: 'file';
    /**
     File data. Can either be:

     - data: a base64-encoded string, a Uint8Array, an ArrayBuffer, or a Buffer
     - URL: a URL that points to the image
     */
    data: DataContent | URL;
    /**
     Optional filename of the file.
     */
    filename?: string;
    /**
     IANA media type of the file.

     @see https://www.iana.org/assignments/media-types/media-types.xhtml
     */
    mediaType: string;
    /**
     Additional provider-specific metadata. They are passed through
     to the provider from the AI SDK and enable provider-specific
     functionality that can be fully encapsulated in the provider.
     */
    providerOptions?: ProviderOptions;
}

/**
 * A file part of a message.
 */
export declare type FileUIPart = {
    type: 'file';
    /**
     * IANA media type of the file.
     *
     * @see https://www.iana.org/assignments/media-types/media-types.xhtml
     */
    mediaType: string;
    /**
     * Optional filename of the file.
     */
    filename?: string;
    /**
     * The URL of the file.
     * It can either be a URL to a hosted file or a [Data URL](https://developer.mozilla.org/en-US/docs/Web/HTTP/Basics_of_HTTP/Data_URLs).
     */
    url: string;
    /**
     * The provider metadata.
     */
    providerMetadata?: ProviderMetadata;
};

/**
 Reason why a language model finished generating a response.

 Can be one of the following:
 - `stop`: model generated stop sequence
 - `length`: model generated maximum number of tokens
 - `content-filter`: content filter violation stopped the model
 - `tool-calls`: model triggered tool calls
 - `error`: model stopped because of an error
 - `other`: model stopped for other reasons
 */
export declare type FinishReason = LanguageModelV2FinishReason;

declare type FlexibleSchema<SCHEMA> = z4.core.$ZodType<SCHEMA, any> | z3.Schema<SCHEMA, z3.ZodTypeDef, any> | Schema<SCHEMA> | LazySchema<SCHEMA>;

declare type FlexibleValidator<OBJECT> = Validator<OBJECT> | LazyValidator<OBJECT> | StandardSchemaV1<unknown, OBJECT>;

export declare const gateway: GatewayProvider;

declare interface GatewayCreditsResponse {
    /** The remaining gateway credit balance available for API usage */
    balance: string;
    /** The total amount of gateway credits that have been consumed */
    totalUsed: string;
}

declare type GatewayEmbeddingModelId = 'amazon/titan-embed-text-v2' | 'cohere/embed-v4.0' | 'google/gemini-embedding-001' | 'google/text-embedding-005' | 'google/text-multilingual-embedding-002' | 'mistral/codestral-embed' | 'mistral/mistral-embed' | 'openai/text-embedding-3-large' | 'openai/text-embedding-3-small' | 'openai/text-embedding-ada-002' | 'voyage/voyage-3-large' | 'voyage/voyage-3.5' | 'voyage/voyage-3.5-lite' | 'voyage/voyage-code-3' | 'voyage/voyage-finance-2' | 'voyage/voyage-law-2' | 'voyage/voyage-code-2' | (string & {});

declare interface GatewayFetchMetadataResponse {
    models: GatewayLanguageModelEntry[];
}

declare type GatewayImageModelId = 'google/imagen-4.0-generate' | 'bfl/flux-kontext-max' | 'bfl/flux-kontext-pro' | 'bfl/flux-pro-1.0-fill' | 'bfl/flux-pro-1.1' | 'bfl/flux-pro-1.1-ultra' | (string & {});

declare interface GatewayLanguageModelEntry {
    /**
     * The model id used by the remote provider in model settings and for specifying the
     * intended model for text generation.
     */
    id: string;
    /**
     * The display name of the model for presentation in user-facing contexts.
     */
    name: string;
    /**
     * Optional description of the model.
     */
    description?: string | null;
    /**
     * Optional pricing information for the model.
     */
    pricing?: {
        /**
         * Cost per input token in USD.
         */
        input: string;
        /**
         * Cost per output token in USD.
         */
        output: string;
        /**
         * Cost per cached input token in USD.
         * Only present for providers/models that support prompt caching.
         */
        cachedInputTokens?: string;
        /**
         * Cost per input token to create/write cache entries in USD.
         * Only present for providers/models that support prompt caching.
         */
        cacheCreationInputTokens?: string;
    } | null;
    /**
     * Additional AI SDK language model specifications for the model.
     */
    specification: GatewayLanguageModelSpecification;
    /**
     * Optional field to differentiate between model types.
     */
    modelType?: 'language' | 'embedding' | 'image' | null;
}

declare type GatewayLanguageModelSpecification = Pick<LanguageModelV2, 'specificationVersion' | 'provider' | 'modelId'>;

export declare type GatewayModelId = 'alibaba/qwen-3-14b' | 'alibaba/qwen-3-235b' | 'alibaba/qwen-3-30b' | 'alibaba/qwen-3-32b' | 'alibaba/qwen3-235b-a22b-thinking' | 'alibaba/qwen3-coder' | 'alibaba/qwen3-coder-30b-a3b' | 'alibaba/qwen3-coder-plus' | 'alibaba/qwen3-max' | 'alibaba/qwen3-max-preview' | 'alibaba/qwen3-next-80b-a3b-instruct' | 'alibaba/qwen3-next-80b-a3b-thinking' | 'alibaba/qwen3-vl-instruct' | 'alibaba/qwen3-vl-thinking' | 'amazon/nova-lite' | 'amazon/nova-micro' | 'amazon/nova-pro' | 'anthropic/claude-3-haiku' | 'anthropic/claude-3-opus' | 'anthropic/claude-3.5-haiku' | 'anthropic/claude-3.5-sonnet' | 'anthropic/claude-3.5-sonnet-20240620' | 'anthropic/claude-3.7-sonnet' | 'anthropic/claude-haiku-4.5' | 'anthropic/claude-opus-4' | 'anthropic/claude-opus-4.1' | 'anthropic/claude-opus-4.5' | 'anthropic/claude-sonnet-4' | 'anthropic/claude-sonnet-4.5' | 'arcee-ai/trinity-mini' | 'cohere/command-a' | 'deepseek/deepseek-r1' | 'deepseek/deepseek-v3' | 'deepseek/deepseek-v3.1' | 'deepseek/deepseek-v3.1-terminus' | 'deepseek/deepseek-v3.2-exp' | 'deepseek/deepseek-v3.2-exp-thinking' | 'google/gemini-2.0-flash' | 'google/gemini-2.0-flash-lite' | 'google/gemini-2.5-flash' | 'google/gemini-2.5-flash-image' | 'google/gemini-2.5-flash-image-preview' | 'google/gemini-2.5-flash-lite' | 'google/gemini-2.5-flash-lite-preview-09-2025' | 'google/gemini-2.5-flash-preview-09-2025' | 'google/gemini-2.5-pro' | 'google/gemini-3-pro-preview' | 'google/gemini-3-pro-image' | 'inception/mercury-coder-small' | 'meituan/longcat-flash-chat' | 'meituan/longcat-flash-thinking' | 'meta/llama-3.1-70b' | 'meta/llama-3.1-8b' | 'meta/llama-3.2-11b' | 'meta/llama-3.2-1b' | 'meta/llama-3.2-3b' | 'meta/llama-3.2-90b' | 'meta/llama-3.3-70b' | 'meta/llama-4-maverick' | 'meta/llama-4-scout' | 'minimax/minimax-m2' | 'mistral/codestral' | 'mistral/devstral-small' | 'mistral/magistral-medium' | 'mistral/magistral-medium-2506' | 'mistral/magistral-small' | 'mistral/magistral-small-2506' | 'mistral/ministral-3b' | 'mistral/ministral-8b' | 'mistral/mistral-large' | 'mistral/mistral-medium' | 'mistral/mistral-small' | 'mistral/mixtral-8x22b-instruct' | 'mistral/pixtral-12b' | 'mistral/pixtral-large' | 'moonshotai/kimi-k2' | 'moonshotai/kimi-k2-0905' | 'moonshotai/kimi-k2-thinking' | 'moonshotai/kimi-k2-thinking-turbo' | 'moonshotai/kimi-k2-turbo' | 'morph/morph-v3-fast' | 'morph/morph-v3-large' | 'openai/gpt-3.5-turbo' | 'openai/gpt-3.5-turbo-instruct' | 'openai/gpt-4-turbo' | 'openai/gpt-4.1' | 'openai/gpt-4.1-mini' | 'openai/gpt-4.1-nano' | 'openai/gpt-4o' | 'openai/gpt-4o-mini' | 'openai/gpt-5' | 'openai/gpt-5-chat' | 'openai/gpt-5-codex' | 'openai/gpt-5-mini' | 'openai/gpt-5-nano' | 'openai/gpt-5-pro' | 'openai/gpt-5.1-codex' | 'openai/gpt-5.1-codex-mini' | 'openai/gpt-5.1-instant' | 'openai/gpt-5.1-thinking' | 'openai/gpt-5.2' | 'openai/gpt-5.2-chat-latest' | 'openai/gpt-5.2-pro' | 'openai/gpt-oss-120b' | 'openai/gpt-oss-20b' | 'openai/gpt-oss-safeguard-20b' | 'openai/o1' | 'openai/o3' | 'openai/o3-deep-research' | 'openai/o3-mini' | 'openai/o4-mini' | 'perplexity/sonar' | 'perplexity/sonar-pro' | 'perplexity/sonar-reasoning' | 'perplexity/sonar-reasoning-pro' | 'prime-intellect/intellect-3' | 'stealth/sonoma-dusk-alpha' | 'stealth/sonoma-sky-alpha' | 'vercel/v0-1.0-md' | 'vercel/v0-1.5-md' | 'xai/grok-2' | 'xai/grok-2-vision' | 'xai/grok-3' | 'xai/grok-3-fast' | 'xai/grok-3-mini' | 'xai/grok-3-mini-fast' | 'xai/grok-4' | 'xai/grok-4-fast-non-reasoning' | 'xai/grok-4-fast-reasoning' | 'xai/grok-4.1-fast-reasoning' | 'xai/grok-4.1-fast-non-reasoning' | 'xai/grok-code-fast-1' | 'zai/glm-4.5' | 'zai/glm-4.5-air' | 'zai/glm-4.5v' | 'zai/glm-4.6' | (string & {});

declare interface GatewayProvider extends ProviderV2 {
    (modelId: GatewayModelId): LanguageModelV2;
    /**
     Creates a model for text generation.
     */
    languageModel(modelId: GatewayModelId): LanguageModelV2;
    /**
     Returns available providers and models for use with the remote provider.
     */
    getAvailableModels(): Promise<GatewayFetchMetadataResponse>;
    /**
     Returns credit information for the authenticated user.
     */
    getCredits(): Promise<GatewayCreditsResponse>;
    /**
     Creates a model for generating text embeddings.
     */
    textEmbeddingModel(modelId: GatewayEmbeddingModelId): EmbeddingModelV2<string>;
    /**
     Creates a model for generating images.
     */
    imageModel(modelId: GatewayImageModelId): ImageModelV2;
}

declare interface GatewayProviderSettings {
    /**
     The base URL prefix for API calls. Defaults to `https://ai-gateway.vercel.sh/v1/ai`.
     */
    baseURL?: string;
    /**
     API key that is being sent using the `Authorization` header.
     */
    apiKey?: string;
    /**
     Custom headers to include in the requests.
     */
    headers?: Record<string, string>;
    /**
     Custom fetch implementation. You can use it as a middleware to intercept requests,
     or to provide a custom fetch implementation for e.g. testing.
     */
    fetch?: FetchFunction;
    /**
     How frequently to refresh the metadata cache in milliseconds.
     */
    metadataCacheRefreshMillis?: number;
}

/**
 * A generated audio file.
 */
export declare interface GeneratedAudioFile extends GeneratedFile {
    /**
     * Audio format of the file (e.g., 'mp3', 'wav', etc.)
     */
    readonly format: string;
}

/**
 * A generated file.
 */
declare interface GeneratedFile {
    /**
     File as a base64 encoded string.
     */
    readonly base64: string;
    /**
     File as a Uint8Array.
     */
    readonly uint8Array: Uint8Array;
    /**
     The IANA media type of the file.

     @see https://www.iana.org/assignments/media-types/media-types.xhtml
     */
    readonly mediaType: string;
}
export { GeneratedFile as Experimental_GeneratedImage }
export { GeneratedFile }

/**
 Generates a 16-character random string to use for IDs.
 Not cryptographically secure.
 */
export declare const generateId: IdGenerator;

/**
 Generate a structured, typed object for a given prompt and schema using a language model.

 This function does not stream the output. If you want to stream the output, use `streamObject` instead.

 @param model - The language model to use.
 @param tools - Tools that are accessible to and can be called by the model. The model needs to support calling tools.

 @param system - A system message that will be part of the prompt.
 @param prompt - A simple text prompt. You can either use `prompt` or `messages` but not both.
 @param messages - A list of messages. You can either use `prompt` or `messages` but not both.

 @param maxOutputTokens - Maximum number of tokens to generate.
 @param temperature - Temperature setting.
 The value is passed through to the provider. The range depends on the provider and model.
 It is recommended to set either `temperature` or `topP`, but not both.
 @param topP - Nucleus sampling.
 The value is passed through to the provider. The range depends on the provider and model.
 It is recommended to set either `temperature` or `topP`, but not both.
 @param topK - Only sample from the top K options for each subsequent token.
 Used to remove "long tail" low probability responses.
 Recommended for advanced use cases only. You usually only need to use temperature.
 @param presencePenalty - Presence penalty setting.
 It affects the likelihood of the model to repeat information that is already in the prompt.
 The value is passed through to the provider. The range depends on the provider and model.
 @param frequencyPenalty - Frequency penalty setting.
 It affects the likelihood of the model to repeatedly use the same words or phrases.
 The value is passed through to the provider. The range depends on the provider and model.
 @param stopSequences - Stop sequences.
 If set, the model will stop generating text when one of the stop sequences is generated.
 @param seed - The seed (integer) to use for random sampling.
 If set and supported by the model, calls will generate deterministic results.

 @param maxRetries - Maximum number of retries. Set to 0 to disable retries. Default: 2.
 @param abortSignal - An optional abort signal that can be used to cancel the call.
 @param headers - Additional HTTP headers to be sent with the request. Only applicable for HTTP-based providers.

 @param schema - The schema of the object that the model should generate.
 @param schemaName - Optional name of the output that should be generated.
 Used by some providers for additional LLM guidance, e.g.
 via tool or schema name.
 @param schemaDescription - Optional description of the output that should be generated.
 Used by some providers for additional LLM guidance, e.g.
 via tool or schema description.

 @param output - The type of the output.

 - 'object': The output is an object.
 - 'array': The output is an array.
 - 'enum': The output is an enum.
 - 'no-schema': The output is not a schema.

 @param experimental_repairText - A function that attempts to repair the raw output of the model
 to enable JSON parsing.

 @param experimental_telemetry - Optional telemetry configuration (experimental).

 @param providerOptions - Additional provider-specific options. They are passed through
 to the provider from the AI SDK and enable provider-specific
 functionality that can be fully encapsulated in the provider.

 @returns
 A result object that contains the generated object, the finish reason, the token usage, and additional information.
 */
export declare function generateObject<SCHEMA extends FlexibleSchema<unknown> = FlexibleSchema<JSONValue_2>, OUTPUT extends 'object' | 'array' | 'enum' | 'no-schema' = InferSchema<SCHEMA> extends string ? 'enum' : 'object', RESULT = OUTPUT extends 'array' ? Array<InferSchema<SCHEMA>> : InferSchema<SCHEMA>>(options: Omit<CallSettings, 'stopSequences'> & Prompt & (OUTPUT extends 'enum' ? {
    /**
     The enum values that the model should use.
     */
    enum: Array<RESULT>;
    mode?: 'json';
    output: 'enum';
} : OUTPUT extends 'no-schema' ? {} : {
    /**
     The schema of the object that the model should generate.
     */
    schema: SCHEMA;
    /**
     Optional name of the output that should be generated.
     Used by some providers for additional LLM guidance, e.g.
     via tool or schema name.
     */
    schemaName?: string;
    /**
     Optional description of the output that should be generated.
     Used by some providers for additional LLM guidance, e.g.
     via tool or schema description.
     */
    schemaDescription?: string;
    /**
     The mode to use for object generation.

     The schema is converted into a JSON schema and used in one of the following ways

     - 'auto': The provider will choose the best mode for the model.
     - 'tool': A tool with the JSON schema as parameters is provided and the provider is instructed to use it.
     - 'json': The JSON schema and an instruction are injected into the prompt. If the provider supports JSON mode, it is enabled. If the provider supports JSON grammars, the grammar is used.

     Please note that most providers do not support all modes.

     Default and recommended: 'auto' (best mode for the model).
     */
    mode?: 'auto' | 'json' | 'tool';
}) & {
    output?: OUTPUT;
    /**
     The language model to use.
     */
    model: LanguageModel;
    /**
     A function that attempts to repair the raw output of the model
     to enable JSON parsing.
     */
    experimental_repairText?: RepairTextFunction;
    /**
     Optional telemetry configuration (experimental).
     */
    experimental_telemetry?: TelemetrySettings;
    /**
     Custom download function to use for URLs.

     By default, files are downloaded if the model does not support the URL for the given media type.
     */
    experimental_download?: Experimental_DownloadFunction | undefined;
    /**
     Additional provider-specific options. They are passed through
     to the provider from the AI SDK and enable provider-specific
     functionality that can be fully encapsulated in the provider.
     */
    providerOptions?: ProviderOptions;
    /**
     * Internal. For test use only. May change without notice.
     */
    _internal?: {
        generateId?: () => string;
        currentDate?: () => Date;
    };
}): Promise<GenerateObjectResult<RESULT>>;

/**
 The result of a `generateObject` call.
 */
export declare interface GenerateObjectResult<OBJECT> {
    /**
     The generated object (typed according to the schema).
     */
    readonly object: OBJECT;
    /**
     * The reasoning that was used to generate the object.
     * Concatenated from all reasoning parts.
     */
    readonly reasoning: string | undefined;
    /**
     The reason why the generation finished.
     */
    readonly finishReason: FinishReason;
    /**
     The token usage of the generated text.
     */
    readonly usage: LanguageModelUsage;
    /**
     Warnings from the model provider (e.g. unsupported settings).
     */
    readonly warnings: CallWarning[] | undefined;
    /**
     Additional request information.
     */
    readonly request: LanguageModelRequestMetadata;
    /**
     Additional response information.
     */
    readonly response: LanguageModelResponseMetadata & {
        /**
         Response body (available only for providers that use HTTP requests).
         */
        body?: unknown;
    };
    /**
     Additional provider-specific metadata. They are passed through
     from the provider to the AI SDK and enable provider-specific
     results that can be fully encapsulated in the provider.
     */
    readonly providerMetadata: ProviderMetadata | undefined;
    /**
     Converts the object to a JSON response.
     The response will have a status code of 200 and a content type of `application/json; charset=utf-8`.
     */
    toJsonResponse(init?: ResponseInit): Response;
}

/**
 Generate a text and call tools for a given prompt using a language model.

 This function does not stream the output. If you want to stream the output, use `streamText` instead.

 @param model - The language model to use.

 @param tools - Tools that are accessible to and can be called by the model. The model needs to support calling tools.
 @param toolChoice - The tool choice strategy. Default: 'auto'.

 @param system - A system message that will be part of the prompt.
 @param prompt - A simple text prompt. You can either use `prompt` or `messages` but not both.
 @param messages - A list of messages. You can either use `prompt` or `messages` but not both.

 @param maxOutputTokens - Maximum number of tokens to generate.
 @param temperature - Temperature setting.
 The value is passed through to the provider. The range depends on the provider and model.
 It is recommended to set either `temperature` or `topP`, but not both.
 @param topP - Nucleus sampling.
 The value is passed through to the provider. The range depends on the provider and model.
 It is recommended to set either `temperature` or `topP`, but not both.
 @param topK - Only sample from the top K options for each subsequent token.
 Used to remove "long tail" low probability responses.
 Recommended for advanced use cases only. You usually only need to use temperature.
 @param presencePenalty - Presence penalty setting.
 It affects the likelihood of the model to repeat information that is already in the prompt.
 The value is passed through to the provider. The range depends on the provider and model.
 @param frequencyPenalty - Frequency penalty setting.
 It affects the likelihood of the model to repeatedly use the same words or phrases.
 The value is passed through to the provider. The range depends on the provider and model.
 @param stopSequences - Stop sequences.
 If set, the model will stop generating text when one of the stop sequences is generated.
 @param seed - The seed (integer) to use for random sampling.
 If set and supported by the model, calls will generate deterministic results.

 @param maxRetries - Maximum number of retries. Set to 0 to disable retries. Default: 2.
 @param abortSignal - An optional abort signal that can be used to cancel the call.
 @param headers - Additional HTTP headers to be sent with the request. Only applicable for HTTP-based providers.

 @param experimental_generateMessageId - Generate a unique ID for each message.

 @param onStepFinish - Callback that is called when each step (LLM call) is finished, including intermediate steps.

 @returns
 A result object that contains the generated text, the results of the tool calls, and additional information.
 */
export declare function generateText<TOOLS extends ToolSet, OUTPUT = never, OUTPUT_PARTIAL = never>({ model: modelArg, tools, toolChoice, system, prompt, messages, maxRetries: maxRetriesArg, abortSignal, headers, stopWhen, experimental_output: output, experimental_telemetry: telemetry, providerOptions, experimental_activeTools, activeTools, experimental_prepareStep, prepareStep, experimental_repairToolCall: repairToolCall, experimental_download: download, experimental_context, _internal: { generateId, currentDate, }, onStepFinish, ...settings }: CallSettings & Prompt & {
    /**
     The language model to use.
     */
    model: LanguageModel;
    /**
     The tools that the model can call. The model needs to support calling tools.
     */
    tools?: TOOLS;
    /**
     The tool choice strategy. Default: 'auto'.
     */
    toolChoice?: ToolChoice<NoInfer<TOOLS>>;
    /**
     Condition for stopping the generation when there are tool results in the last step.
     When the condition is an array, any of the conditions can be met to stop the generation.

     @default stepCountIs(1)
     */
    stopWhen?: StopCondition<NoInfer<TOOLS>> | Array<StopCondition<NoInfer<TOOLS>>>;
    /**
     Optional telemetry configuration (experimental).
     */
    experimental_telemetry?: TelemetrySettings;
    /**
     Additional provider-specific options. They are passed through
     to the provider from the AI SDK and enable provider-specific
     functionality that can be fully encapsulated in the provider.
     */
    providerOptions?: ProviderOptions;
    /**
     * @deprecated Use `activeTools` instead.
     */
    experimental_activeTools?: Array<keyof NoInfer<TOOLS>>;
    /**
     Limits the tools that are available for the model to call without
     changing the tool call and result types in the result.
     */
    activeTools?: Array<keyof NoInfer<TOOLS>>;
    /**
     Optional specification for parsing structured outputs from the LLM response.
     */
    experimental_output?: Output_2<OUTPUT, OUTPUT_PARTIAL>;
    /**
     Custom download function to use for URLs.

     By default, files are downloaded if the model does not support the URL for the given media type.
     */
    experimental_download?: Experimental_DownloadFunction | undefined;
    /**
     * @deprecated Use `prepareStep` instead.
     */
    experimental_prepareStep?: PrepareStepFunction<NoInfer<TOOLS>>;
    /**
     Optional function that you can use to provide different settings for a step.
     */
    prepareStep?: PrepareStepFunction<NoInfer<TOOLS>>;
    /**
     A function that attempts to repair a tool call that failed to parse.
     */
    experimental_repairToolCall?: ToolCallRepairFunction<NoInfer<TOOLS>>;
    /**
     Callback that is called when each step (LLM call) is finished, including intermediate steps.
     */
    onStepFinish?: GenerateTextOnStepFinishCallback<NoInfer<TOOLS>>;
    /**
     * Context that is passed into tool execution.
     *
     * Experimental (can break in patch releases).
     *
     * @default undefined
     */
    experimental_context?: unknown;
    /**
     * Internal. For test use only. May change without notice.
     */
    _internal?: {
        generateId?: IdGenerator;
        currentDate?: () => Date;
    };
}): Promise<GenerateTextResult<TOOLS, OUTPUT>>;

/**
 Callback that is set using the `onStepFinish` option.

 @param stepResult - The result of the step.
 */
export declare type GenerateTextOnStepFinishCallback<TOOLS extends ToolSet> = (stepResult: StepResult<TOOLS>) => Promise<void> | void;

/**
 The result of a `generateText` call.
 It contains the generated text, the tool calls that were made during the generation, and the results of the tool calls.
 */
export declare interface GenerateTextResult<TOOLS extends ToolSet, OUTPUT> {
    /**
     The content that was generated in the last step.
     */
    readonly content: Array<ContentPart<TOOLS>>;
    /**
     The text that was generated in the last step.
     */
    readonly text: string;
    /**
     The full reasoning that the model has generated in the last step.
     */
    readonly reasoning: Array<ReasoningOutput>;
    /**
     The reasoning text that the model has generated in the last step. Can be undefined if the model
     has only generated text.
     */
    readonly reasoningText: string | undefined;
    /**
     The files that were generated in the last step.
     Empty array if no files were generated.
     */
    readonly files: Array<GeneratedFile>;
    /**
     Sources that have been used as references in the last step.
     */
    readonly sources: Array<Source>;
    /**
     The tool calls that were made in the last step.
     */
    readonly toolCalls: Array<TypedToolCall<TOOLS>>;
    /**
     The static tool calls that were made in the last step.
     */
    readonly staticToolCalls: Array<StaticToolCall<TOOLS>>;
    /**
     The dynamic tool calls that were made in the last step.
     */
    readonly dynamicToolCalls: Array<DynamicToolCall>;
    /**
     The results of the tool calls from the last step.
     */
    readonly toolResults: Array<TypedToolResult<TOOLS>>;
    /**
     The static tool results that were made in the last step.
     */
    readonly staticToolResults: Array<StaticToolResult<TOOLS>>;
    /**
     The dynamic tool results that were made in the last step.
     */
    readonly dynamicToolResults: Array<DynamicToolResult>;
    /**
     The reason why the generation finished.
     */
    readonly finishReason: FinishReason;
    /**
     The token usage of the last step.
     */
    readonly usage: LanguageModelUsage;
    /**
     The total token usage of all steps.
     When there are multiple steps, the usage is the sum of all step usages.
     */
    readonly totalUsage: LanguageModelUsage;
    /**
     Warnings from the model provider (e.g. unsupported settings)
     */
    readonly warnings: CallWarning[] | undefined;
    /**
     Additional request information.
     */
    readonly request: LanguageModelRequestMetadata;
    /**
     Additional response information.
     */
    readonly response: LanguageModelResponseMetadata & {
        /**
         The response messages that were generated during the call. It consists of an assistant message,
         potentially containing tool calls.

         When there are tool results, there is an additional tool message with the tool results that are available.
         If there are tools that do not have execute functions, they are not included in the tool results and
         need to be added separately.
         */
        messages: Array<ResponseMessage>;
        /**
         Response body (available only for providers that use HTTP requests).
         */
        body?: unknown;
    };
    /**
     Additional provider-specific metadata. They are passed through
     from the provider to the AI SDK and enable provider-specific
     results that can be fully encapsulated in the provider.
     */
    readonly providerMetadata: ProviderMetadata | undefined;
    /**
     Details for all steps.
     You can use this to get information about intermediate steps,
     such as the tool calls or the response headers.
     */
    readonly steps: Array<StepResult<TOOLS>>;
    /**
     The generated structured output. It uses the `experimental_output` specification.
     */
    readonly experimental_output: OUTPUT;
}

declare function getErrorMessage(error: unknown | undefined): string;

declare function getErrorMessage_2(error: unknown | undefined): string;

declare const getFromApi: <T>({ url, headers, successfulResponseHandler, failedResponseHandler, abortSignal, fetch, }: {
    url: string;
    headers?: Record<string, string | undefined>;
    failedResponseHandler: ResponseHandler<Error>;
    successfulResponseHandler: ResponseHandler<T>;
    abortSignal?: AbortSignal;
    fetch?: FetchFunction;
}) => Promise<{
    value: T;
    rawValue?: unknown;
    responseHeaders?: Record<string, string>;
}>;

declare type GetMaxImagesPerCallFunction = (options: {
    modelId: string;
}) => PromiseLike<number | undefined> | number | undefined;

declare const getOriginalFetch: () => typeof fetch;

declare function getRuntimeEnvironmentUserAgent(globalThisAny?: any): string;

/**
 * Converts a data URL of type text/* to a text string.
 */
export declare function getTextFromDataUrl(dataUrl: string): string;

export declare function getToolName<TOOLS extends UITools>(part: ToolUIPart<TOOLS>): keyof TOOLS;

export declare function getToolOrDynamicToolName(part: ToolUIPart<UITools> | DynamicToolUIPart): string;

/**
 * Global provider model ID type that defaults to GatewayModelId but can be augmented
 * by third-party packages via declaration merging.
 */
declare type GlobalProviderModelId = [keyof RegisteredProviderModels] extends [
never
] ? GatewayModelId : keyof RegisteredProviderModels | RegisteredProviderModels[keyof RegisteredProviderModels];

export declare function hasToolCall(toolName: string): StopCondition<any>;

/**
 * Defines High-Resolution Time.
 *
 * The first number, HrTime[0], is UNIX Epoch time in seconds since 00:00:00 UTC on 1 January 1970.
 * The second number, HrTime[1], represents the partial second elapsed since Unix Epoch time represented by first number in nanoseconds.
 * For example, 2021-01-01T12:30:10.150Z in UNIX Epoch time in milliseconds is represented as 1609504210150.
 * The first number is calculated by converting and truncating the Epoch time in milliseconds to seconds:
 * HrTime[0] = Math.trunc(1609504210150 / 1000) = 1609504210.
 * The second number is calculated by converting the digits after the decimal point of the subtraction, (1609504210150 / 1000) - HrTime[0], to nanoseconds:
 * HrTime[1] = Number((1609504210.150 - HrTime[0]).toFixed(9)) * 1e9 = 150000000.
 * This is represented in HrTime format as [1609504210, 150000000].
 */
declare type HrTime = [number, number];

export declare abstract class HttpChatTransport<UI_MESSAGE extends UIMessage> implements ChatTransport<UI_MESSAGE> {
    protected api: string;
    protected credentials: HttpChatTransportInitOptions<UI_MESSAGE>['credentials'];
    protected headers: HttpChatTransportInitOptions<UI_MESSAGE>['headers'];
    protected body: HttpChatTransportInitOptions<UI_MESSAGE>['body'];
    protected fetch?: FetchFunction;
    protected prepareSendMessagesRequest?: PrepareSendMessagesRequest<UI_MESSAGE>;
    protected prepareReconnectToStreamRequest?: PrepareReconnectToStreamRequest;
    constructor({ api, credentials, headers, body, fetch, prepareSendMessagesRequest, prepareReconnectToStreamRequest, }: HttpChatTransportInitOptions<UI_MESSAGE>);
    sendMessages({ abortSignal, ...options }: Parameters<ChatTransport<UI_MESSAGE>['sendMessages']>[0]): Promise<ReadableStream<UIMessageChunk>>;
    reconnectToStream(options: Parameters<ChatTransport<UI_MESSAGE>['reconnectToStream']>[0]): Promise<ReadableStream<UIMessageChunk> | null>;
    protected abstract processResponseStream(stream: ReadableStream<Uint8Array<ArrayBufferLike>>): ReadableStream<UIMessageChunk>;
}

/**
 * Options for the `HttpChatTransport` class.
 *
 * @param UI_MESSAGE - The type of message to be used in the chat.
 */
export declare type HttpChatTransportInitOptions<UI_MESSAGE extends UIMessage> = {
    /**
     * The API URL to be used for the chat transport.
     * Defaults to '/api/chat'.
     */
    api?: string;
    /**
     * The credentials mode to be used for the fetch request.
     * Possible values are: 'omit', 'same-origin', 'include'.
     * Defaults to 'same-origin'.
     */
    credentials?: Resolvable<RequestCredentials>;
    /**
     * HTTP headers to be sent with the API request.
     */
    headers?: Resolvable<Record<string, string> | Headers>;
    /**
     * Extra body object to be sent with the API request.
     * @example
     * Send a `sessionId` to the API along with the messages.
     * ```js
     * useChat({
     *   body: {
     *     sessionId: '123',
     *   }
     * })
     * ```
     */
    body?: Resolvable<object>;
    /**
     Custom fetch implementation. You can use it as a middleware to intercept requests,
     or to provide a custom fetch implementation for e.g. testing.
     */
    fetch?: FetchFunction;
    /**
     * When a function is provided, it will be used
     * to prepare the request body for the chat API. This can be useful for
     * customizing the request body based on the messages and data in the chat.
     *
     * @param id The id of the chat.
     * @param messages The current messages in the chat.
     * @param requestBody The request body object passed in the chat request.
     */
    prepareSendMessagesRequest?: PrepareSendMessagesRequest<UI_MESSAGE>;
    /**
     * When a function is provided, it will be used
     * to prepare the request body for the chat API. This can be useful for
     * customizing the request body based on the messages and data in the chat.
     *
     * @param id The id of the chat.
     * @param messages The current messages in the chat.
     * @param requestBody The request body object passed in the chat request.
     */
    prepareReconnectToStreamRequest?: PrepareReconnectToStreamRequest;
};

/**
 A function that generates an ID.
 */
export declare type IdGenerator = () => string;

/**
 Image model that is used by the AI SDK Core functions.
 */
export declare type ImageModel = string | ImageModelV2;

/**
 Warning from the model provider for this call. The call will proceed, but e.g.
 some settings might not be supported, which can lead to suboptimal results.
 */
export declare type ImageModelCallWarning = ImageModelV2CallWarning;

/**
 Metadata from the model provider for this call
 */
export declare type ImageModelProviderMetadata = ImageModelV2ProviderMetadata;

export declare type ImageModelResponseMetadata = {
    /**
     Timestamp for the start of the generated response.
     */
    timestamp: Date;
    /**
     The ID of the response model that was used to generate the response.
     */
    modelId: string;
    /**
     Response headers.
     */
    headers?: Record<string, string>;
};

/**
 Image generation model specification version 2.
 */
declare type ImageModelV2 = {
    /**
     The image model must specify which image model interface
     version it implements. This will allow us to evolve the image
     model interface and retain backwards compatibility. The different
     implementation versions can be handled as a discriminated union
     on our side.
     */
    readonly specificationVersion: 'v2';
    /**
     Name of the provider for logging purposes.
     */
    readonly provider: string;
    /**
     Provider-specific model ID for logging purposes.
     */
    readonly modelId: string;
    /**
     Limit of how many images can be generated in a single API call.
     Can be set to a number for a fixed limit, to undefined to use
     the global limit, or a function that returns a number or undefined,
     optionally as a promise.
     */
    readonly maxImagesPerCall: number | undefined | GetMaxImagesPerCallFunction;
    /**
     Generates an array of images.
     */
    doGenerate(options: ImageModelV2CallOptions): PromiseLike<{
        /**
         Generated images as base64 encoded strings or binary data.
         The images should be returned without any unnecessary conversion.
         If the API returns base64 encoded strings, the images should be returned
         as base64 encoded strings. If the API returns binary data, the images should
         be returned as binary data.
         */
        images: Array<string> | Array<Uint8Array>;
        /**
         Warnings for the call, e.g. unsupported settings.
         */
        warnings: Array<ImageModelV2CallWarning>;
        /**
         Additional provider-specific metadata. They are passed through
         from the provider to the AI SDK and enable provider-specific
         results that can be fully encapsulated in the provider.

         The outer record is keyed by the provider name, and the inner
         record is provider-specific metadata. It always includes an
         `images` key with image-specific metadata

         ```ts
         {
         "openai": {
         "images": ["revisedPrompt": "Revised prompt here."]
         }
         }
         ```
         */
        providerMetadata?: ImageModelV2ProviderMetadata;
        /**
         Response information for telemetry and debugging purposes.
         */
        response: {
            /**
             Timestamp for the start of the generated response.
             */
            timestamp: Date;
            /**
             The ID of the response model that was used to generate the response.
             */
            modelId: string;
            /**
             Response headers.
             */
            headers: Record<string, string> | undefined;
        };
    }>;
};

declare type ImageModelV2CallOptions = {
    /**
     Prompt for the image generation.
     */
    prompt: string;
    /**
     Number of images to generate.
     */
    n: number;
    /**
     Size of the images to generate.
     Must have the format `{width}x{height}`.
     `undefined` will use the provider's default size.
     */
    size: `${number}x${number}` | undefined;
    /**
     Aspect ratio of the images to generate.
     Must have the format `{width}:{height}`.
     `undefined` will use the provider's default aspect ratio.
     */
    aspectRatio: `${number}:${number}` | undefined;
    /**
     Seed for the image generation.
     `undefined` will use the provider's default seed.
     */
    seed: number | undefined;
    /**
     Additional provider-specific options that are passed through to the provider
     as body parameters.

     The outer record is keyed by the provider name, and the inner
     record is keyed by the provider-specific metadata key.
     ```ts
     {
     "openai": {
     "style": "vivid"
     }
     }
     ```
     */
    providerOptions: SharedV2ProviderOptions;
    /**
     Abort signal for cancelling the operation.
     */
    abortSignal?: AbortSignal;
    /**
     Additional HTTP headers to be sent with the request.
     Only applicable for HTTP-based providers.
     */
    headers?: Record<string, string | undefined>;
};

/**
 Warning from the model provider for this call. The call will proceed, but e.g.
 some settings might not be supported, which can lead to suboptimal results.
 */
declare type ImageModelV2CallWarning = {
    type: 'unsupported-setting';
    setting: keyof ImageModelV2CallOptions;
    details?: string;
} | {
    type: 'other';
    message: string;
};

declare type ImageModelV2ProviderMetadata = Record<string, {
    images: JSONArray;
} & JSONValue_2>;

/**
 Image content part of a prompt. It contains an image.
 */
export declare interface ImagePart {
    type: 'image';
    /**
     Image data. Can either be:

     - data: a base64-encoded string, a Uint8Array, an ArrayBuffer, or a Buffer
     - URL: a URL that points to the image
     */
    image: DataContent | URL;
    /**
     Optional IANA media type of the image.

     @see https://www.iana.org/assignments/media-types/media-types.xhtml
     */
    mediaType?: string;
    /**
     Additional provider-specific metadata. They are passed through
     to the provider from the AI SDK and enable provider-specific
     functionality that can be fully encapsulated in the provider.
     */
    providerOptions?: ProviderOptions;
}

declare type InferAgentTools<AGENT> = AGENT extends Experimental_Agent<infer TOOLS, any, any> ? TOOLS : never;

declare type InferSchema<SCHEMA> = SCHEMA extends z3.Schema ? z3.infer<SCHEMA> : SCHEMA extends z4.core.$ZodType ? z4.infer<SCHEMA> : SCHEMA extends LazySchema<infer T> ? T : SCHEMA extends Schema<infer T> ? T : never;

/**
 * Infer the input type of a tool.
 */
export declare type InferToolInput<TOOL extends Tool> = TOOL extends Tool<infer INPUT, any> ? INPUT : never;

/**
 * Infer the output type of a tool.
 */
export declare type InferToolOutput<TOOL extends Tool> = TOOL extends Tool<any, infer OUTPUT> ? OUTPUT : never;

export declare type InferUIDataParts<T extends UIDataPartSchemas> = {
    [K in keyof T]: T[K] extends Validator<infer U> ? U : T[K] extends StandardSchemaV1<infer U> ? U : unknown;
};

export declare type InferUIMessageChunk<T extends UIMessage> = UIMessageChunk<InferUIMessageMetadata<T>, InferUIMessageData<T>>;

declare type InferUIMessageData<T extends UIMessage> = T extends UIMessage<unknown, infer DATA_TYPES> ? DATA_TYPES : UIDataTypes;

declare type InferUIMessageMetadata<T extends UIMessage> = T extends UIMessage<infer METADATA> ? METADATA : unknown;

declare type InferUIMessageToolCall<UI_MESSAGE extends UIMessage> = ValueOf<{
    [NAME in keyof InferUIMessageTools<UI_MESSAGE>]: ToolCall<NAME & string, InferUIMessageTools<UI_MESSAGE>[NAME] extends {
        input: infer INPUT;
    } ? INPUT : never> & {
        dynamic?: false;
    };
}> | (ToolCall<string, unknown> & {
    dynamic: true;
});

declare type InferUIMessageTools<T extends UIMessage> = T extends UIMessage<unknown, UIDataTypes, infer TOOLS> ? TOOLS : UITools;

/**
 * Infer the input and output types of a tool so it can be used as a UI tool.
 */
export declare type InferUITool<TOOL extends Tool> = {
    input: InferToolInput<TOOL>;
    output: InferToolOutput<TOOL>;
};

/**
 * Infer the input and output types of a tool set so it can be used as a UI tool set.
 */
export declare type InferUITools<TOOLS extends ToolSet> = {
    [NAME in keyof TOOLS & string]: InferUITool<TOOLS[NAME]>;
};

declare type InferValidator<SCHEMA> = SCHEMA extends StandardSchemaV1<unknown, infer T> ? T : SCHEMA extends LazyValidator<infer T> ? T : SCHEMA extends Validator<infer T> ? T : never;

declare function injectJsonInstructionIntoMessages({ messages, schema, schemaPrefix, schemaSuffix, }: {
    messages: LanguageModelV2Prompt;
    schema?: JSONSchema7;
    schemaPrefix?: string;
    schemaSuffix?: string;
}): LanguageModelV2Prompt;

export declare class InvalidArgumentError extends AISDKError {
    private readonly [symbol$c_2];
    readonly parameter: string;
    readonly value: unknown;
    constructor({ parameter, value, message, }: {
        parameter: string;
        value: unknown;
        message: string;
    });
    static isInstance(error: unknown): error is InvalidArgumentError;
}

/**
 * A function argument is invalid.
 */
declare class InvalidArgumentError_2 extends AISDKError {
    private readonly [symbol$a_2];
    readonly argument: string;
    constructor({ message, cause, argument, }: {
        argument: string;
        message: string;
        cause?: unknown;
    });
    static isInstance(error: unknown): error is InvalidArgumentError_2;
}

export declare class InvalidDataContentError extends AISDKError {
    private readonly [symbol$5_2];
    readonly content: unknown;
    constructor({ content, cause, message, }: {
        content: unknown;
        cause?: unknown;
        message?: string;
    });
    static isInstance(error: unknown): error is InvalidDataContentError;
}

export declare class InvalidMessageRoleError extends AISDKError {
    private readonly [symbol$4_2];
    readonly role: string;
    constructor({ role, message, }: {
        role: string;
        message?: string;
    });
    static isInstance(error: unknown): error is InvalidMessageRoleError;
}

/**
 * A prompt is invalid. This error should be thrown by providers when they cannot
 * process a prompt.
 */
export declare class InvalidPromptError extends AISDKError {
    private readonly [symbol$9];
    readonly prompt: unknown;
    constructor({ prompt, message, cause, }: {
        prompt: unknown;
        message: string;
        cause?: unknown;
    });
    static isInstance(error: unknown): error is InvalidPromptError;
}

/**
 * Server returned a response with invalid data content.
 * This should be thrown by providers when they cannot parse the response from the API.
 */
export declare class InvalidResponseDataError extends AISDKError {
    private readonly [symbol$8];
    readonly data: unknown;
    constructor({ data, message, }: {
        data: unknown;
        message?: string;
    });
    static isInstance(error: unknown): error is InvalidResponseDataError;
}

export declare class InvalidStreamPartError extends AISDKError {
    private readonly [symbol$b_2];
    readonly chunk: SingleRequestTextStreamPart<any>;
    constructor({ chunk, message, }: {
        chunk: SingleRequestTextStreamPart<any>;
        message: string;
    });
    static isInstance(error: unknown): error is InvalidStreamPartError;
}

export declare class InvalidToolInputError extends AISDKError {
    private readonly [symbol$e];
    readonly toolName: string;
    readonly toolInput: string;
    constructor({ toolInput, toolName, cause, message, }: {
        message?: string;
        toolInput: string;
        toolName: string;
        cause: unknown;
    });
    static isInstance(error: unknown): error is InvalidToolInputError;
}

declare function isAbortError(error: unknown): error is Error;

/**
 * Check if a message part is a data part.
 */
export declare function isDataUIPart<DATA_TYPES extends UIDataTypes>(part: UIMessagePart<DATA_TYPES, UITools>): part is DataUIPart<DATA_TYPES>;

/**
 * Performs a deep-equal comparison of two parsed JSON objects.
 *
 * @param {any} obj1 - The first object to compare.
 * @param {any} obj2 - The second object to compare.
 * @returns {boolean} - Returns true if the two objects are deeply equal, false otherwise.
 */
export declare function isDeepEqualData(obj1: any, obj2: any): boolean;

/**
 * Type guard to check if a message part is a file part.
 */
export declare function isFileUIPart(part: UIMessagePart<UIDataTypes, UITools>): part is FileUIPart;

declare function isJSONArray(value: unknown): value is JSONArray;

declare function isJSONObject(value: unknown): value is JSONObject;

declare function isJSONValue(value: unknown): value is JSONValue_2;

declare function isParsableJson(input: string): boolean;

/**
 * Type guard to check if a message part is a reasoning part.
 */
export declare function isReasoningUIPart(part: UIMessagePart<UIDataTypes, UITools>): part is ReasoningUIPart;

/**
 * Type guard to check if a message part is a text part.
 */
export declare function isTextUIPart(part: UIMessagePart<UIDataTypes, UITools>): part is TextUIPart;

export declare function isToolOrDynamicToolUIPart<TOOLS extends UITools>(part: UIMessagePart<UIDataTypes, TOOLS>): part is ToolUIPart<TOOLS> | DynamicToolUIPart;

export declare function isToolUIPart<TOOLS extends UITools>(part: UIMessagePart<UIDataTypes, TOOLS>): part is ToolUIPart<TOOLS>;

/**
 * Checks if the given URL is supported natively by the model.
 *
 * @param mediaType - The media type of the URL. Case-sensitive.
 * @param url - The URL to check.
 * @param supportedUrls - A record where keys are case-sensitive media types (or '*')
 *                        and values are arrays of RegExp patterns for URLs.
 *
 * @returns `true` if the URL matches a pattern under the specific media type
 *          or the wildcard '*', `false` otherwise.
 */
declare function isUrlSupported({ mediaType, url, supportedUrls, }: {
    mediaType: string;
    url: string;
    supportedUrls: Record<string, RegExp[]>;
}): boolean;

declare function isValidator(value: unknown): value is Validator;

declare type Job = () => Promise<void>;

declare type JSONArray = JSONValue_2[];

declare type JSONObject = {
    [key: string]: JSONValue_2;
};

export declare class JSONParseError extends AISDKError {
    private readonly [symbol$7];
    readonly text: string;
    constructor({ text, cause }: {
        text: string;
        cause: unknown;
    });
    static isInstance(error: unknown): error is JSONParseError;
}

/**
 * Create a schema using a JSON Schema.
 *
 * @param jsonSchema The JSON Schema for the schema.
 * @param options.validate Optional. A validation function for the schema.
 */
export declare function jsonSchema<OBJECT = unknown>(jsonSchema: JSONSchema7 | (() => JSONSchema7), { validate, }?: {
    validate?: (value: unknown) => ValidationResult<OBJECT> | PromiseLike<ValidationResult<OBJECT>>;
}): Schema<OBJECT>;

export declare interface JSONSchema7 {
    $id?: string | undefined;
    $ref?: string | undefined;
    $schema?: JSONSchema7Version | undefined;
    $comment?: string | undefined;

    /**
     * @see https://datatracker.ietf.org/doc/html/draft-bhutton-json-schema-00#section-8.2.4
     * @see https://datatracker.ietf.org/doc/html/draft-bhutton-json-schema-validation-00#appendix-A
     */
    $defs?: {
        [key: string]: JSONSchema7Definition;
    } | undefined;

    /**
     * @see https://tools.ietf.org/html/draft-handrews-json-schema-validation-01#section-6.1
     */
    type?: JSONSchema7TypeName | JSONSchema7TypeName[] | undefined;
    enum?: JSONSchema7Type[] | undefined;
    const?: JSONSchema7Type | undefined;

    /**
     * @see https://tools.ietf.org/html/draft-handrews-json-schema-validation-01#section-6.2
     */
    multipleOf?: number | undefined;
    maximum?: number | undefined;
    exclusiveMaximum?: number | undefined;
    minimum?: number | undefined;
    exclusiveMinimum?: number | undefined;

    /**
     * @see https://tools.ietf.org/html/draft-handrews-json-schema-validation-01#section-6.3
     */
    maxLength?: number | undefined;
    minLength?: number | undefined;
    pattern?: string | undefined;

    /**
     * @see https://tools.ietf.org/html/draft-handrews-json-schema-validation-01#section-6.4
     */
    items?: JSONSchema7Definition | JSONSchema7Definition[] | undefined;
    additionalItems?: JSONSchema7Definition | undefined;
    maxItems?: number | undefined;
    minItems?: number | undefined;
    uniqueItems?: boolean | undefined;
    contains?: JSONSchema7Definition | undefined;

    /**
     * @see https://tools.ietf.org/html/draft-handrews-json-schema-validation-01#section-6.5
     */
    maxProperties?: number | undefined;
    minProperties?: number | undefined;
    required?: string[] | undefined;
    properties?: {
        [key: string]: JSONSchema7Definition;
    } | undefined;
    patternProperties?: {
        [key: string]: JSONSchema7Definition;
    } | undefined;
    additionalProperties?: JSONSchema7Definition | undefined;
    dependencies?: {
        [key: string]: JSONSchema7Definition | string[];
    } | undefined;
    propertyNames?: JSONSchema7Definition | undefined;

    /**
     * @see https://tools.ietf.org/html/draft-handrews-json-schema-validation-01#section-6.6
     */
    if?: JSONSchema7Definition | undefined;
    then?: JSONSchema7Definition | undefined;
    else?: JSONSchema7Definition | undefined;

    /**
     * @see https://tools.ietf.org/html/draft-handrews-json-schema-validation-01#section-6.7
     */
    allOf?: JSONSchema7Definition[] | undefined;
    anyOf?: JSONSchema7Definition[] | undefined;
    oneOf?: JSONSchema7Definition[] | undefined;
    not?: JSONSchema7Definition | undefined;

    /**
     * @see https://tools.ietf.org/html/draft-handrews-json-schema-validation-01#section-7
     */
    format?: string | undefined;

    /**
     * @see https://tools.ietf.org/html/draft-handrews-json-schema-validation-01#section-8
     */
    contentMediaType?: string | undefined;
    contentEncoding?: string | undefined;

    /**
     * @see https://tools.ietf.org/html/draft-handrews-json-schema-validation-01#section-9
     */
    definitions?: {
        [key: string]: JSONSchema7Definition;
    } | undefined;

    /**
     * @see https://tools.ietf.org/html/draft-handrews-json-schema-validation-01#section-10
     */
    title?: string | undefined;
    description?: string | undefined;
    default?: JSONSchema7Type | undefined;
    readOnly?: boolean | undefined;
    writeOnly?: boolean | undefined;
    examples?: JSONSchema7Type | undefined;
}

declare interface JSONSchema7Array extends Array<JSONSchema7Type> {}

/**
 * JSON Schema v7
 * @see https://tools.ietf.org/html/draft-handrews-json-schema-validation-01
 */
declare type JSONSchema7Definition = JSONSchema7 | boolean;

declare interface JSONSchema7Object {
    [key: string]: JSONSchema7Type;
}

/**
 * Primitive type
 * @see https://tools.ietf.org/html/draft-handrews-json-schema-validation-01#section-6.1.1
 */
declare type JSONSchema7Type =
| string //
| number
| boolean
| JSONSchema7Object
| JSONSchema7Array
| null;

/**
 * Primitive type
 * @see https://tools.ietf.org/html/draft-handrews-json-schema-validation-01#section-6.1.1
 */
declare type JSONSchema7TypeName =
| "string" //
| "number"
| "integer"
| "boolean"
| "object"
| "array"
| "null";

/**
 * Meta schema
 *
 * Recommended values:
 * - 'http://json-schema.org/schema#'
 * - 'http://json-schema.org/hyper-schema#'
 * - 'http://json-schema.org/draft-07/schema#'
 * - 'http://json-schema.org/draft-07/hyper-schema#'
 *
 * @see https://tools.ietf.org/html/draft-handrews-json-schema-validation-01#section-5
 */
declare type JSONSchema7Version = string;

export declare class JsonToSseTransformStream extends TransformStream<unknown, string> {
    constructor();
}

export declare type JSONValue = JSONValue_2;

/**
 A JSON value can be a string, number, boolean, object, array, or null.
 JSON values can be serialized and deserialized by the JSON.stringify and JSON.parse methods.
 */
declare type JSONValue_2 = null | string | number | boolean | JSONObject | JSONArray;

/**
 Language model that is used by the AI SDK Core functions.
 */
export declare type LanguageModel = GlobalProviderModelId | LanguageModelV2;

export declare type LanguageModelMiddleware = LanguageModelV2Middleware;

export declare type LanguageModelRequestMetadata = {
    /**
     Request HTTP body that was sent to the provider API.
     */
    body?: unknown;
};

export declare type LanguageModelResponseMetadata = {
    /**
     ID for the generated response.
     */
    id: string;
    /**
     Timestamp for the start of the generated response.
     */
    timestamp: Date;
    /**
     The ID of the response model that was used to generate the response.
     */
    modelId: string;
    /**
     Response headers (available only for providers that use HTTP requests).
     */
    headers?: Record<string, string>;
};

/**
 Represents the number of tokens used in a prompt and completion.
 */
export declare type LanguageModelUsage = LanguageModelV2Usage;

/**
 Specification for a language model that implements the language model interface version 2.
 */
declare type LanguageModelV2 = {
    /**
     The language model must specify which language model interface version it implements.
     */
    readonly specificationVersion: 'v2';
    /**
     Name of the provider for logging purposes.
     */
    readonly provider: string;
    /**
     Provider-specific model ID for logging purposes.
     */
    readonly modelId: string;
    /**
     Supported URL patterns by media type for the provider.

     The keys are media type patterns or full media types (e.g. `*\/*` for everything, `audio/*`, `video/*`, or `application/pdf`).
     and the values are arrays of regular expressions that match the URL paths.

     The matching should be against lower-case URLs.

     Matched URLs are supported natively by the model and are not downloaded.

     @returns A map of supported URL patterns by media type (as a promise or a plain object).
     */
    supportedUrls: PromiseLike<Record<string, RegExp[]>> | Record<string, RegExp[]>;
    /**
     Generates a language model output (non-streaming).

     Naming: "do" prefix to prevent accidental direct usage of the method
     by the user.
     */
    doGenerate(options: LanguageModelV2CallOptions): PromiseLike<{
        /**
         Ordered content that the model has generated.
         */
        content: Array<LanguageModelV2Content>;
        /**
         Finish reason.
         */
        finishReason: LanguageModelV2FinishReason;
        /**
         Usage information.
         */
        usage: LanguageModelV2Usage;
        /**
         Additional provider-specific metadata. They are passed through
         from the provider to the AI SDK and enable provider-specific
         results that can be fully encapsulated in the provider.
         */
        providerMetadata?: SharedV2ProviderMetadata;
        /**
         Optional request information for telemetry and debugging purposes.
         */
        request?: {
            /**
             Request HTTP body that was sent to the provider API.
             */
            body?: unknown;
        };
        /**
         Optional response information for telemetry and debugging purposes.
         */
        response?: LanguageModelV2ResponseMetadata & {
            /**
             Response headers.
             */
            headers?: SharedV2Headers;
            /**
             Response HTTP body.
             */
            body?: unknown;
        };
        /**
         Warnings for the call, e.g. unsupported settings.
         */
        warnings: Array<LanguageModelV2CallWarning>;
    }>;
    /**
     Generates a language model output (streaming).

     Naming: "do" prefix to prevent accidental direct usage of the method
     by the user.
     *
     @return A stream of higher-level language model output parts.
     */
    doStream(options: LanguageModelV2CallOptions): PromiseLike<{
        stream: ReadableStream<LanguageModelV2StreamPart>;
        /**
         Optional request information for telemetry and debugging purposes.
         */
        request?: {
            /**
             Request HTTP body that was sent to the provider API.
             */
            body?: unknown;
        };
        /**
         Optional response data.
         */
        response?: {
            /**
             Response headers.
             */
            headers?: SharedV2Headers;
        };
    }>;
};

declare type LanguageModelV2CallOptions = {
    /**
     A language mode prompt is a standardized prompt type.

     Note: This is **not** the user-facing prompt. The AI SDK methods will map the
     user-facing prompt types such as chat or instruction prompts to this format.
     That approach allows us to evolve the user  facing prompts without breaking
     the language model interface.
     */
    prompt: LanguageModelV2Prompt;
    /**
     Maximum number of tokens to generate.
     */
    maxOutputTokens?: number;
    /**
     Temperature setting. The range depends on the provider and model.
     */
    temperature?: number;
    /**
     Stop sequences.
     If set, the model will stop generating text when one of the stop sequences is generated.
     Providers may have limits on the number of stop sequences.
     */
    stopSequences?: string[];
    /**
     Nucleus sampling.
     */
    topP?: number;
    /**
     Only sample from the top K options for each subsequent token.

     Used to remove "long tail" low probability responses.
     Recommended for advanced use cases only. You usually only need to use temperature.
     */
    topK?: number;
    /**
     Presence penalty setting. It affects the likelihood of the model to
     repeat information that is already in the prompt.
     */
    presencePenalty?: number;
    /**
     Frequency penalty setting. It affects the likelihood of the model
     to repeatedly use the same words or phrases.
     */
    frequencyPenalty?: number;
    /**
     Response format. The output can either be text or JSON. Default is text.

     If JSON is selected, a schema can optionally be provided to guide the LLM.
     */
    responseFormat?: {
        type: 'text';
    } | {
        type: 'json';
        /**
         * JSON schema that the generated output should conform to.
         */
        schema?: JSONSchema7;
        /**
         * Name of output that should be generated. Used by some providers for additional LLM guidance.
         */
        name?: string;
        /**
         * Description of the output that should be generated. Used by some providers for additional LLM guidance.
         */
        description?: string;
    };
    /**
     The seed (integer) to use for random sampling. If set and supported
     by the model, calls will generate deterministic results.
     */
    seed?: number;
    /**
     The tools that are available for the model.
     */
    tools?: Array<LanguageModelV2FunctionTool | LanguageModelV2ProviderDefinedTool>;
    /**
     Specifies how the tool should be selected. Defaults to 'auto'.
     */
    toolChoice?: LanguageModelV2ToolChoice;
    /**
     Include raw chunks in the stream. Only applicable for streaming calls.
     */
    includeRawChunks?: boolean;
    /**
     Abort signal for cancelling the operation.
     */
    abortSignal?: AbortSignal;
    /**
     Additional HTTP headers to be sent with the request.
     Only applicable for HTTP-based providers.
     */
    headers?: Record<string, string | undefined>;
    /**
     * Additional provider-specific options. They are passed through
     * to the provider from the AI SDK and enable provider-specific
     * functionality that can be fully encapsulated in the provider.
     */
    providerOptions?: SharedV2ProviderOptions;
};

/**
 Warning from the model provider for this call. The call will proceed, but e.g.
 some settings might not be supported, which can lead to suboptimal results.
 */
declare type LanguageModelV2CallWarning = {
    type: 'unsupported-setting';
    setting: Omit<keyof LanguageModelV2CallOptions, 'prompt'>;
    details?: string;
} | {
    type: 'unsupported-tool';
    tool: LanguageModelV2FunctionTool | LanguageModelV2ProviderDefinedTool;
    details?: string;
} | {
    type: 'other';
    message: string;
};

declare type LanguageModelV2Content = LanguageModelV2Text | LanguageModelV2Reasoning | LanguageModelV2File | LanguageModelV2Source | LanguageModelV2ToolCall | LanguageModelV2ToolResult;

/**
 Data content. Can be a Uint8Array, base64 encoded data as a string or a URL.
 */
declare type LanguageModelV2DataContent = Uint8Array | string | URL;

/**
 A file that has been generated by the model.
 Generated files as base64 encoded strings or binary data.
 The files should be returned without any unnecessary conversion.
 */
declare type LanguageModelV2File = {
    type: 'file';
    /**
     The IANA media type of the file, e.g. `image/png` or `audio/mp3`.

     @see https://www.iana.org/assignments/media-types/media-types.xhtml
     */
    mediaType: string;
    /**
     Generated file data as base64 encoded strings or binary data.

     The file data should be returned without any unnecessary conversion.
     If the API returns base64 encoded strings, the file data should be returned
     as base64 encoded strings. If the API returns binary data, the file data should
     be returned as binary data.
     */
    data: string | Uint8Array;
};

/**
 File content part of a prompt. It contains a file.
 */
declare interface LanguageModelV2FilePart {
    type: 'file';
    /**
     * Optional filename of the file.
     */
    filename?: string;
    /**
     File data. Can be a Uint8Array, base64 encoded data as a string or a URL.
     */
    data: LanguageModelV2DataContent;
    /**
     IANA media type of the file.

     Can support wildcards, e.g. `image/*` (in which case the provider needs to take appropriate action).

     @see https://www.iana.org/assignments/media-types/media-types.xhtml
     */
    mediaType: string;
    /**
     * Additional provider-specific options. They are passed through
     * to the provider from the AI SDK and enable provider-specific
     * functionality that can be fully encapsulated in the provider.
     */
    providerOptions?: SharedV2ProviderOptions;
}

/**
 Reason why a language model finished generating a response.

 Can be one of the following:
 - `stop`: model generated stop sequence
 - `length`: model generated maximum number of tokens
 - `content-filter`: content filter violation stopped the model
 - `tool-calls`: model triggered tool calls
 - `error`: model stopped because of an error
 - `other`: model stopped for other reasons
 - `unknown`: the model has not transmitted a finish reason
 */
declare type LanguageModelV2FinishReason = 'stop' | 'length' | 'content-filter' | 'tool-calls' | 'error' | 'other' | 'unknown';

/**
 A tool has a name, a description, and a set of parameters.

 Note: this is **not** the user-facing tool definition. The AI SDK methods will
 map the user-facing tool definitions to this format.
 */
declare type LanguageModelV2FunctionTool = {
    /**
     The type of the tool (always 'function').
     */
    type: 'function';
    /**
     The name of the tool. Unique within this model call.
     */
    name: string;
    /**
     A description of the tool. The language model uses this to understand the
     tool's purpose and to provide better completion suggestions.
     */
    description?: string;
    /**
     The parameters that the tool expects. The language model uses this to
     understand the tool's input requirements and to provide matching suggestions.
     */
    inputSchema: JSONSchema7;
    /**
     The provider-specific options for the tool.
     */
    providerOptions?: SharedV2ProviderOptions;
};

declare type LanguageModelV2Message = ({
    role: 'system';
    content: string;
} | {
    role: 'user';
    content: Array<LanguageModelV2TextPart | LanguageModelV2FilePart>;
} | {
    role: 'assistant';
    content: Array<LanguageModelV2TextPart | LanguageModelV2FilePart | LanguageModelV2ReasoningPart | LanguageModelV2ToolCallPart | LanguageModelV2ToolResultPart>;
} | {
    role: 'tool';
    content: Array<LanguageModelV2ToolResultPart>;
}) & {
    /**
     * Additional provider-specific options. They are passed through
     * to the provider from the AI SDK and enable provider-specific
     * functionality that can be fully encapsulated in the provider.
     */
    providerOptions?: SharedV2ProviderOptions;
};

/**
 * Experimental middleware for LanguageModelV2.
 * This type defines the structure for middleware that can be used to modify
 * the behavior of LanguageModelV2 operations.
 */
declare type LanguageModelV2Middleware = {
    /**
     * Middleware specification version. Use `v2` for the current version.
     */
    middlewareVersion?: 'v2' | undefined;
    /**
     * Override the provider name if desired.
     * @param options.model - The language model instance.
     */
    overrideProvider?: (options: {
        model: LanguageModelV2;
    }) => string;
    /**
     * Override the model ID if desired.
     * @param options.model - The language model instance.
     */
    overrideModelId?: (options: {
        model: LanguageModelV2;
    }) => string;
    /**
     * Override the supported URLs if desired.
     * @param options.model - The language model instance.
     */
    overrideSupportedUrls?: (options: {
        model: LanguageModelV2;
    }) => PromiseLike<Record<string, RegExp[]>> | Record<string, RegExp[]>;
    /**
     * Transforms the parameters before they are passed to the language model.
     * @param options - Object containing the type of operation and the parameters.
     * @param options.type - The type of operation ('generate' or 'stream').
     * @param options.params - The original parameters for the language model call.
     * @returns A promise that resolves to the transformed parameters.
     */
    transformParams?: (options: {
        type: 'generate' | 'stream';
        params: LanguageModelV2CallOptions;
        model: LanguageModelV2;
    }) => PromiseLike<LanguageModelV2CallOptions>;
    /**
     * Wraps the generate operation of the language model.
     * @param options - Object containing the generate function, parameters, and model.
     * @param options.doGenerate - The original generate function.
     * @param options.doStream - The original stream function.
     * @param options.params - The parameters for the generate call. If the
     * `transformParams` middleware is used, this will be the transformed parameters.
     * @param options.model - The language model instance.
     * @returns A promise that resolves to the result of the generate operation.
     */
    wrapGenerate?: (options: {
        doGenerate: () => ReturnType<LanguageModelV2['doGenerate']>;
        doStream: () => ReturnType<LanguageModelV2['doStream']>;
        params: LanguageModelV2CallOptions;
        model: LanguageModelV2;
    }) => Promise<Awaited<ReturnType<LanguageModelV2['doGenerate']>>>;
    /**
     * Wraps the stream operation of the language model.
     *
     * @param options - Object containing the stream function, parameters, and model.
     * @param options.doGenerate - The original generate function.
     * @param options.doStream - The original stream function.
     * @param options.params - The parameters for the stream call. If the
     * `transformParams` middleware is used, this will be the transformed parameters.
     * @param options.model - The language model instance.
     * @returns A promise that resolves to the result of the stream operation.
     */
    wrapStream?: (options: {
        doGenerate: () => ReturnType<LanguageModelV2['doGenerate']>;
        doStream: () => ReturnType<LanguageModelV2['doStream']>;
        params: LanguageModelV2CallOptions;
        model: LanguageModelV2;
    }) => PromiseLike<Awaited<ReturnType<LanguageModelV2['doStream']>>>;
};

/**
 A prompt is a list of messages.

 Note: Not all models and prompt formats support multi-modal inputs and
 tool calls. The validation happens at runtime.

 Note: This is not a user-facing prompt. The AI SDK methods will map the
 user-facing prompt types such as chat or instruction prompts to this format.
 */
declare type LanguageModelV2Prompt = Array<LanguageModelV2Message>;

/**
 The configuration of a tool that is defined by the provider.
 */
declare type LanguageModelV2ProviderDefinedTool = {
    /**
     The type of the tool (always 'provider-defined').
     */
    type: 'provider-defined';
    /**
     The ID of the tool. Should follow the format `<provider-name>.<unique-tool-name>`.
     */
    id: `${string}.${string}`;
    /**
     The name of the tool that the user must use in the tool set.
     */
    name: string;
    /**
     The arguments for configuring the tool. Must match the expected arguments defined by the provider for this tool.
     */
    args: Record<string, unknown>;
};

/**
 Reasoning that the model has generated.
 */
declare type LanguageModelV2Reasoning = {
    type: 'reasoning';
    text: string;
    /**
     * Optional provider-specific metadata for the reasoning part.
     */
    providerMetadata?: SharedV2ProviderMetadata;
};

/**
 Reasoning content part of a prompt. It contains a string of reasoning text.
 */
declare interface LanguageModelV2ReasoningPart {
    type: 'reasoning';
    /**
     The reasoning text.
     */
    text: string;
    /**
     * Additional provider-specific options. They are passed through
     * to the provider from the AI SDK and enable provider-specific
     * functionality that can be fully encapsulated in the provider.
     */
    providerOptions?: SharedV2ProviderOptions;
}

declare interface LanguageModelV2ResponseMetadata {
    /**
     ID for the generated response, if the provider sends one.
     */
    id?: string;
    /**
     Timestamp for the start of the generated response, if the provider sends one.
     */
    timestamp?: Date;
    /**
     The ID of the response model that was used to generate the response, if the provider sends one.
     */
    modelId?: string;
}

/**
 A source that has been used as input to generate the response.
 */
declare type LanguageModelV2Source = {
    type: 'source';
    /**
     * The type of source - URL sources reference web content.
     */
    sourceType: 'url';
    /**
     * The ID of the source.
     */
    id: string;
    /**
     * The URL of the source.
     */
    url: string;
    /**
     * The title of the source.
     */
    title?: string;
    /**
     * Additional provider metadata for the source.
     */
    providerMetadata?: SharedV2ProviderMetadata;
} | {
    type: 'source';
    /**
     * The type of source - document sources reference files/documents.
     */
    sourceType: 'document';
    /**
     * The ID of the source.
     */
    id: string;
    /**
     * IANA media type of the document (e.g., 'application/pdf').
     */
    mediaType: string;
    /**
     * The title of the document.
     */
    title: string;
    /**
     * Optional filename of the document.
     */
    filename?: string;
    /**
     * Additional provider metadata for the source.
     */
    providerMetadata?: SharedV2ProviderMetadata;
};

declare type LanguageModelV2StreamPart = {
    type: 'text-start';
    providerMetadata?: SharedV2ProviderMetadata;
    id: string;
} | {
    type: 'text-delta';
    id: string;
    providerMetadata?: SharedV2ProviderMetadata;
    delta: string;
} | {
    type: 'text-end';
    providerMetadata?: SharedV2ProviderMetadata;
    id: string;
} | {
    type: 'reasoning-start';
    providerMetadata?: SharedV2ProviderMetadata;
    id: string;
} | {
    type: 'reasoning-delta';
    id: string;
    providerMetadata?: SharedV2ProviderMetadata;
    delta: string;
} | {
    type: 'reasoning-end';
    id: string;
    providerMetadata?: SharedV2ProviderMetadata;
} | {
    type: 'tool-input-start';
    id: string;
    toolName: string;
    providerMetadata?: SharedV2ProviderMetadata;
    providerExecuted?: boolean;
} | {
    type: 'tool-input-delta';
    id: string;
    delta: string;
    providerMetadata?: SharedV2ProviderMetadata;
} | {
    type: 'tool-input-end';
    id: string;
    providerMetadata?: SharedV2ProviderMetadata;
} | LanguageModelV2ToolCall | LanguageModelV2ToolResult | LanguageModelV2File | LanguageModelV2Source | {
    type: 'stream-start';
    warnings: Array<LanguageModelV2CallWarning>;
} | ({
    type: 'response-metadata';
} & LanguageModelV2ResponseMetadata) | {
    type: 'finish';
    usage: LanguageModelV2Usage;
    finishReason: LanguageModelV2FinishReason;
    providerMetadata?: SharedV2ProviderMetadata;
} | {
    type: 'raw';
    rawValue: unknown;
} | {
    type: 'error';
    error: unknown;
};

/**
 Text that the model has generated.
 */
declare type LanguageModelV2Text = {
    type: 'text';
    /**
     The text content.
     */
    text: string;
    providerMetadata?: SharedV2ProviderMetadata;
};

/**
 Text content part of a prompt. It contains a string of text.
 */
declare interface LanguageModelV2TextPart {
    type: 'text';
    /**
     The text content.
     */
    text: string;
    /**
     * Additional provider-specific options. They are passed through
     * to the provider from the AI SDK and enable provider-specific
     * functionality that can be fully encapsulated in the provider.
     */
    providerOptions?: SharedV2ProviderOptions;
}

/**
 Tool calls that the model has generated.
 */
declare type LanguageModelV2ToolCall = {
    type: 'tool-call';
    toolCallId: string;
    toolName: string;
    /**
     Stringified JSON object with the tool call arguments. Must match the
     parameters schema of the tool.
     */
    input: string;
    /**
     * Whether the tool call will be executed by the provider.
     * If this flag is not set or is false, the tool call will be executed by the client.
     */
    providerExecuted?: boolean;
    /**
     * Additional provider-specific metadata for the tool call.
     */
    providerMetadata?: SharedV2ProviderMetadata;
};

/**
 Tool call content part of a prompt. It contains a tool call (usually generated by the AI model).
 */
declare interface LanguageModelV2ToolCallPart {
    type: 'tool-call';
    /**
     ID of the tool call. This ID is used to match the tool call with the tool result.
     */
    toolCallId: string;
    /**
     Name of the tool that is being called.
     */
    toolName: string;
    /**
     Arguments of the tool call. This is a JSON-serializable object that matches the tool's input schema.
     */
    input: unknown;
    /**
     * Whether the tool call will be executed by the provider.
     * If this flag is not set or is false, the tool call will be executed by the client.
     */
    providerExecuted?: boolean;
    /**
     * Additional provider-specific options. They are passed through
     * to the provider from the AI SDK and enable provider-specific
     * functionality that can be fully encapsulated in the provider.
     */
    providerOptions?: SharedV2ProviderOptions;
}

declare type LanguageModelV2ToolChoice = {
    type: 'auto';
} | {
    type: 'none';
} | {
    type: 'required';
} | {
    type: 'tool';
    toolName: string;
};

/**
 Result of a tool call that has been executed by the provider.
 */
declare type LanguageModelV2ToolResult = {
    type: 'tool-result';
    /**
     * The ID of the tool call that this result is associated with.
     */
    toolCallId: string;
    /**
     * Name of the tool that generated this result.
     */
    toolName: string;
    /**
     * Result of the tool call. This is a JSON-serializable object.
     */
    result: unknown;
    /**
     * Optional flag if the result is an error or an error message.
     */
    isError?: boolean;
    /**
     * Whether the tool result was generated by the provider.
     * If this flag is set to true, the tool result was generated by the provider.
     * If this flag is not set or is false, the tool result was generated by the client.
     */
    providerExecuted?: boolean;
    /**
     * Additional provider-specific metadata for the tool result.
     */
    providerMetadata?: SharedV2ProviderMetadata;
};

declare type LanguageModelV2ToolResultOutput = {
    type: 'text';
    value: string;
} | {
    type: 'json';
    value: JSONValue_2;
} | {
    type: 'error-text';
    value: string;
} | {
    type: 'error-json';
    value: JSONValue_2;
} | {
    type: 'content';
    value: Array<{
        type: 'text';
        /**
         Text content.
         */
        text: string;
    } | {
        type: 'media';
        /**
         Base-64 encoded media data.
         */
        data: string;
        /**
         IANA media type.
         @see https://www.iana.org/assignments/media-types/media-types.xhtml
         */
        mediaType: string;
    }>;
};

/**
 Tool result content part of a prompt. It contains the result of the tool call with the matching ID.
 */
declare interface LanguageModelV2ToolResultPart {
    type: 'tool-result';
    /**
     ID of the tool call that this result is associated with.
     */
    toolCallId: string;
    /**
     Name of the tool that generated this result.
     */
    toolName: string;
    /**
     Result of the tool call.
     */
    output: LanguageModelV2ToolResultOutput;
    /**
     * Additional provider-specific options. They are passed through
     * to the provider from the AI SDK and enable provider-specific
     * functionality that can be fully encapsulated in the provider.
     */
    providerOptions?: SharedV2ProviderOptions;
}

/**
 Usage information for a language model call.

 If your API return additional usage information, you can add it to the
 provider metadata under your provider's key.
 */
declare type LanguageModelV2Usage = {
    /**
     The number of input (prompt) tokens used.
     */
    inputTokens: number | undefined;
    /**
     The number of output (completion) tokens used.
     */
    outputTokens: number | undefined;
    /**
     The total number of tokens as reported by the provider.
     This number might be different from the sum of `inputTokens` and `outputTokens`
     and e.g. include reasoning tokens or other overhead.
     */
    totalTokens: number | undefined;
    /**
     The number of reasoning tokens used.
     */
    reasoningTokens?: number | undefined;
    /**
     The number of cached input tokens.
     */
    cachedInputTokens?: number | undefined;
};

/**
 Check if the message is an assistant message with completed tool calls.
 The last step of the message must have at least one tool invocation and
 all tool invocations must have a result.
 */
export declare function lastAssistantMessageIsCompleteWithToolCalls({ messages, }: {
    messages: UIMessage[];
}): boolean;

declare type LazySchema<SCHEMA> = () => Schema<SCHEMA>;

/**
 * Creates a schema with deferred creation.
 * This is important to reduce the startup time of the library
 * and to avoid initializing unused validators.
 *
 * @param createValidator A function that creates a schema.
 * @returns A function that returns a schema.
 */
declare function lazySchema<SCHEMA>(createSchema: () => Schema<SCHEMA>): LazySchema<SCHEMA>;

declare type LazyValidator<OBJECT> = () => Validator<OBJECT>;

/**
 * Creates a validator with deferred creation.
 * This is important to reduce the startup time of the library
 * and to avoid initializing unused validators.
 *
 * @param createValidator A function that creates a validator.
 * @returns A function that returns a validator.
 */
declare function lazyValidator<OBJECT>(createValidator: () => Validator<OBJECT>): LazyValidator<OBJECT>;

/**
 * A pointer from the current {@link Span} to another span in the same trace or
 * in a different trace.
 * Few examples of Link usage.
 * 1. Batch Processing: A batch of elements may contain elements associated
 *    with one or more traces/spans. Since there can only be one parent
 *    SpanContext, Link is used to keep reference to SpanContext of all
 *    elements in the batch.
 * 2. Public Endpoint: A SpanContext in incoming client request on a public
 *    endpoint is untrusted from service provider perspective. In such case it
 *    is advisable to start a new trace with appropriate sampling decision.
 *    However, it is desirable to associate incoming SpanContext to new trace
 *    initiated on service provider side so two traces (from Client and from
 *    Service Provider) can be correlated.
 */
declare interface Link {
    /** The {@link SpanContext} of a linked span. */
    context: SpanContext;
    /** A set of {@link SpanAttributes} on the link. */
    attributes?: SpanAttributes;
    /** Count of attributes of the link that were dropped due to collection limits */
    droppedAttributesCount?: number;
}

declare function loadApiKey({ apiKey, environmentVariableName, apiKeyParameterName, description, }: {
    apiKey: string | undefined;
    environmentVariableName: string;
    apiKeyParameterName?: string;
    description: string;
}): string;

export declare class LoadAPIKeyError extends AISDKError {
    private readonly [symbol$6];
    constructor({ message }: {
        message: string;
    });
    static isInstance(error: unknown): error is LoadAPIKeyError;
}

/**
 * Loads an optional `string` setting from the environment or a parameter.
 *
 * @param settingValue - The setting value.
 * @param environmentVariableName - The environment variable name.
 * @returns The setting value.
 */
declare function loadOptionalSetting({ settingValue, environmentVariableName, }: {
    settingValue: string | undefined;
    environmentVariableName: string;
}): string | undefined;

/**
 * Loads a `string` setting from the environment or a parameter.
 *
 * @param settingValue - The setting value.
 * @param environmentVariableName - The environment variable name.
 * @param settingName - The setting name.
 * @param description - The description of the setting.
 * @returns The setting value.
 */
declare function loadSetting({ settingValue, environmentVariableName, settingName, description, }: {
    settingValue: string | undefined;
    environmentVariableName: string;
    settingName: string;
    description: string;
}): string;

export declare class LoadSettingError extends AISDKError {
    private readonly [symbol$5];
    constructor({ message }: {
        message: string;
    });
    static isInstance(error: unknown): error is LoadSettingError;
}

/**
 * Maps a media type to its corresponding file extension.
 * It was originally introduced to set a filename for audio file uploads
 * in https://github.com/vercel/ai/pull/8159.
 *
 * @param mediaType The media type to map.
 * @returns The corresponding file extension
 * @see https://developer.mozilla.org/en-US/docs/Web/HTTP/Guides/MIME_types/Common_types
 */
declare function mediaTypeToExtension(mediaType: string): string;

export declare class MessageConversionError extends AISDKError {
    private readonly [symbol$3_2];
    readonly originalMessage: Omit<UIMessage, 'id'>;
    constructor({ originalMessage, message, }: {
        originalMessage: Omit<UIMessage, 'id'>;
        message: string;
    });
    static isInstance(error: unknown): error is MessageConversionError;
}

/**
 A message that can be used in the `messages` field of a prompt.
 It can be a user message, an assistant message, or a tool message.
 */
export declare type ModelMessage = SystemModelMessage | UserModelMessage | AssistantModelMessage | ToolModelMessage;

export declare const modelMessageSchema: z.ZodType<ModelMessage>;

declare type NeverOptional<N, T> = 0 extends 1 & N ? Partial<T> : [N] extends [never] ? Partial<Record<keyof T, undefined>> : T;

/**
 Thrown when the AI provider fails to generate any content.
 */
export declare class NoContentGeneratedError extends AISDKError {
    private readonly [symbol$4];
    constructor({ message, }?: {
        message?: string;
    });
    static isInstance(error: unknown): error is NoContentGeneratedError;
}

/**
 Thrown when no image could be generated. This can have multiple causes:

 - The model failed to generate a response.
 - The model generated a response that could not be parsed.
 */
export declare class NoImageGeneratedError extends AISDKError {
    private readonly [symbol$a];
    /**
     The response metadata for each call.
     */
    readonly responses: Array<ImageModelResponseMetadata> | undefined;
    constructor({ message, cause, responses, }: {
        message?: string;
        cause?: Error;
        responses?: Array<ImageModelResponseMetadata>;
    });
    static isInstance(error: unknown): error is NoImageGeneratedError;
}

/**
 Thrown when no object could be generated. This can have several causes:

 - The model failed to generate a response.
 - The model generated a response that could not be parsed.
 - The model generated a response that could not be validated against the schema.

 The error contains the following properties:

 - `text`: The text that was generated by the model. This can be the raw text or the tool call text, depending on the model.
 */
export declare class NoObjectGeneratedError extends AISDKError {
    private readonly [symbol$9_2];
    /**
     The text that was generated by the model. This can be the raw text or the tool call text, depending on the model.
     */
    readonly text: string | undefined;
    /**
     The response metadata.
     */
    readonly response: LanguageModelResponseMetadata | undefined;
    /**
     The usage of the model.
     */
    readonly usage: LanguageModelUsage | undefined;
    /**
     Reason why the model finished generating a response.
     */
    readonly finishReason: FinishReason | undefined;
    constructor({ message, cause, text, response, usage, finishReason, }: {
        message?: string;
        cause?: Error;
        text?: string;
        response: LanguageModelResponseMetadata;
        usage: LanguageModelUsage;
        finishReason: FinishReason;
    });
    static isInstance(error: unknown): error is NoObjectGeneratedError;
}

/**
 Thrown when no LLM output was generated, e.g. because of errors.
 */
export declare class NoOutputGeneratedError extends AISDKError {
    private readonly [symbol$8_2];
    constructor({ message, cause, }?: {
        message?: string;
        cause?: Error;
    });
    static isInstance(error: unknown): error is NoOutputGeneratedError;
}

/**
 Thrown when no output type is specified and output-related methods are called.
 */
export declare class NoOutputSpecifiedError extends AISDKError {
    private readonly [symbol$7_2];
    constructor({ message }?: {
        message?: string;
    });
    static isInstance(error: unknown): error is NoOutputSpecifiedError;
}

/**
 * Normalizes different header inputs into a plain record with lower-case keys.
 * Entries with `undefined` or `null` values are removed.
 *
 * @param headers - Input headers (`Headers`, tuples array, plain record) to normalize.
 * @returns A record containing the normalized header entries.
 */
declare function normalizeHeaders(headers: HeadersInit | Record<string, string | undefined> | Array<[string, string | undefined]> | undefined): Record<string, string>;

/**
 Error that is thrown when no speech audio was generated.
 */
export declare class NoSpeechGeneratedError extends AISDKError {
    readonly responses: Array<SpeechModelResponseMetadata>;
    constructor(options: {
        responses: Array<SpeechModelResponseMetadata>;
    });
}

export declare class NoSuchModelError extends AISDKError {
    private readonly [symbol$3];
    readonly modelId: string;
    readonly modelType: 'languageModel' | 'textEmbeddingModel' | 'imageModel' | 'transcriptionModel' | 'speechModel';
    constructor({ errorName, modelId, modelType, message, }: {
        errorName?: string;
        modelId: string;
        modelType: 'languageModel' | 'textEmbeddingModel' | 'imageModel' | 'transcriptionModel' | 'speechModel';
        message?: string;
    });
    static isInstance(error: unknown): error is NoSuchModelError;
}

export declare class NoSuchProviderError extends NoSuchModelError {
    private readonly [symbol_2];
    readonly providerId: string;
    readonly availableProviders: string[];
    constructor({ modelId, modelType, providerId, availableProviders, message, }: {
        modelId: string;
        modelType: 'languageModel' | 'textEmbeddingModel' | 'imageModel' | 'transcriptionModel' | 'speechModel';
        providerId: string;
        availableProviders: string[];
        message?: string;
    });
    static isInstance(error: unknown): error is NoSuchProviderError;
}

export declare class NoSuchToolError extends AISDKError {
    private readonly [symbol$d_2];
    readonly toolName: string;
    readonly availableTools: string[] | undefined;
    constructor({ toolName, availableTools, message, }: {
        toolName: string;
        availableTools?: string[] | undefined;
        message?: string;
    });
    static isInstance(error: unknown): error is NoSuchToolError;
}

export declare type ObjectStreamPart<PARTIAL> = {
    type: 'object';
    object: PARTIAL;
} | {
    type: 'text-delta';
    textDelta: string;
} | {
    type: 'error';
    error: unknown;
} | {
    type: 'finish';
    finishReason: FinishReason;
    usage: LanguageModelUsage;
    response: LanguageModelResponseMetadata;
    providerMetadata?: ProviderMetadata;
};

declare interface Output_2<OUTPUT, PARTIAL> {
    readonly type: 'object' | 'text';
    responseFormat: LanguageModelV2CallOptions['responseFormat'];
    parsePartial(options: {
        text: string;
    }): Promise<{
        partial: PARTIAL;
    } | undefined>;
    parseOutput(options: {
        text: string;
    }, context: {
        response: LanguageModelResponseMetadata;
        usage: LanguageModelUsage;
        finishReason: FinishReason;
    }): Promise<OUTPUT>;
}

/**
 * Parses a JSON string into an unknown object.
 *
 * @param text - The JSON string to parse.
 * @returns {JSONValue} - The parsed JSON object.
 */
declare function parseJSON(options: {
    text: string;
    schema?: undefined;
}): Promise<JSONValue_2>;

/**
 * Parses a JSON string into a strongly-typed object using the provided schema.
 *
 * @template T - The type of the object to parse the JSON into.
 * @param {string} text - The JSON string to parse.
 * @param {Validator<T>} schema - The schema to use for parsing the JSON.
 * @returns {Promise<T>} - The parsed object.
 */
declare function parseJSON<T>(options: {
    text: string;
    schema: FlexibleValidator<T>;
}): Promise<T>;

/**
 * Parses a JSON event stream into a stream of parsed JSON objects.
 */
export declare function parseJsonEventStream<T>({ stream, schema, }: {
    stream: ReadableStream<Uint8Array>;
    schema: FlexibleValidator<T>;
}): ReadableStream<ParseResult<T>>;

export declare function parsePartialJson(jsonText: string | undefined): Promise<{
    value: JSONValue_2 | undefined;
    state: 'undefined-input' | 'successful-parse' | 'repaired-parse' | 'failed-parse';
}>;

declare function parseProviderOptions<OPTIONS>({ provider, providerOptions, schema, }: {
    provider: string;
    providerOptions: Record<string, unknown> | undefined;
    schema: FlexibleValidator<OPTIONS>;
}): Promise<OPTIONS | undefined>;

declare type ParseResult<T> = {
    success: true;
    value: T;
    rawValue: unknown;
} | {
    success: false;
    error: JSONParseError | TypeValidationError;
    rawValue: unknown;
};

declare type PartialMap<KeyType, ValueType> = {} & Map<DeepPartialInternal<KeyType>, DeepPartialInternal<ValueType>>;

declare type PartialObject<ObjectType extends object> = {
    [KeyType in keyof ObjectType]?: DeepPartialInternal<ObjectType[KeyType]>;
};

declare type PartialReadonlyMap<KeyType, ValueType> = {} & ReadonlyMap<DeepPartialInternal<KeyType>, DeepPartialInternal<ValueType>>;

declare type PartialReadonlySet<T> = {} & ReadonlySet<DeepPartialInternal<T>>;

declare type PartialSet<T> = {} & Set<DeepPartialInternal<T>>;

export declare function pipeTextStreamToResponse({ response, status, statusText, headers, textStream, }: {
    response: ServerResponse;
    textStream: ReadableStream<string>;
} & ResponseInit): void;

export declare function pipeUIMessageStreamToResponse({ response, status, statusText, headers, stream, consumeSseStream, }: {
    response: ServerResponse;
    stream: ReadableStream<UIMessageChunk>;
} & UIMessageStreamResponseInit): void;

declare const postFormDataToApi: <T>({ url, headers, formData, failedResponseHandler, successfulResponseHandler, abortSignal, fetch, }: {
    url: string;
    headers?: Record<string, string | undefined>;
    formData: FormData;
    failedResponseHandler: ResponseHandler<APICallError>;
    successfulResponseHandler: ResponseHandler<T>;
    abortSignal?: AbortSignal;
    fetch?: FetchFunction;
}) => Promise<{
    value: T;
    rawValue?: unknown;
    responseHeaders?: Record<string, string>;
}>;

declare const postJsonToApi: <T>({ url, headers, body, failedResponseHandler, successfulResponseHandler, abortSignal, fetch, }: {
    url: string;
    headers?: Record<string, string | undefined>;
    body: unknown;
    failedResponseHandler: ResponseHandler<APICallError>;
    successfulResponseHandler: ResponseHandler<T>;
    abortSignal?: AbortSignal;
    fetch?: FetchFunction;
}) => Promise<{
    value: T;
    rawValue?: unknown;
    responseHeaders?: Record<string, string>;
}>;

declare const postToApi: <T>({ url, headers, body, successfulResponseHandler, failedResponseHandler, abortSignal, fetch, }: {
    url: string;
    headers?: Record<string, string | undefined>;
    body: {
        content: string | FormData | Uint8Array;
        values: unknown;
    };
    failedResponseHandler: ResponseHandler<Error>;
    successfulResponseHandler: ResponseHandler<T>;
    abortSignal?: AbortSignal;
    fetch?: FetchFunction;
}) => Promise<{
    value: T;
    rawValue?: unknown;
    responseHeaders?: Record<string, string>;
}>;

export declare type PrepareReconnectToStreamRequest = (options: {
    id: string;
    requestMetadata: unknown;
    body: Record<string, any> | undefined;
    credentials: RequestCredentials | undefined;
    headers: HeadersInit | undefined;
    api: string;
}) => {
    headers?: HeadersInit;
    credentials?: RequestCredentials;
    api?: string;
} | PromiseLike<{
    headers?: HeadersInit;
    credentials?: RequestCredentials;
    api?: string;
}>;

export declare type PrepareSendMessagesRequest<UI_MESSAGE extends UIMessage> = (options: {
    id: string;
    messages: UI_MESSAGE[];
    requestMetadata: unknown;
    body: Record<string, any> | undefined;
    credentials: RequestCredentials | undefined;
    headers: HeadersInit | undefined;
    api: string;
} & {
    trigger: 'submit-message' | 'regenerate-message';
    messageId: string | undefined;
}) => {
    body: object;
    headers?: HeadersInit;
    credentials?: RequestCredentials;
    api?: string;
} | PromiseLike<{
    body: object;
    headers?: HeadersInit;
    credentials?: RequestCredentials;
    api?: string;
}>;

/**
 Function that you can use to provide different settings for a step.

 @param options - The options for the step.
 @param options.steps - The steps that have been executed so far.
 @param options.stepNumber - The number of the step that is being executed.
 @param options.model - The model that is being used.

 @returns An object that contains the settings for the step.
 If you return undefined (or for undefined settings), the settings from the outer level will be used.
 */
export declare type PrepareStepFunction<TOOLS extends Record<string, Tool> = Record<string, Tool>> = (options: {
    steps: Array<StepResult<NoInfer<TOOLS>>>;
    stepNumber: number;
    model: LanguageModel;
    messages: Array<ModelMessage>;
}) => PromiseLike<PrepareStepResult<TOOLS>> | PrepareStepResult<TOOLS>;

export declare type PrepareStepResult<TOOLS extends Record<string, Tool> = Record<string, Tool>> = {
    model?: LanguageModel;
    toolChoice?: ToolChoice<NoInfer<TOOLS>>;
    activeTools?: Array<keyof NoInfer<TOOLS>>;
    system?: string;
    messages?: Array<ModelMessage>;
} | undefined;

/**
 Prompt part of the AI function options.
 It contains a system message, a simple text prompt, or a list of messages.
 */
export declare type Prompt = {
    /**
     System message to include in the prompt. Can be used with `prompt` or `messages`.
     */
    system?: string;
} & ({
    /**
     A prompt. It can be either a text prompt or a list of messages.

     You can either use `prompt` or `messages` but not both.
     */
    prompt: string | Array<ModelMessage>;
    /**
     A list of messages.

     You can either use `prompt` or `messages` but not both.
     */
    messages?: never;
} | {
    /**
     A list of messages.

     You can either use `prompt` or `messages` but not both.
     */
    messages: Array<ModelMessage>;
    /**
     A prompt. It can be either a text prompt or a list of messages.

     You can either use `prompt` or `messages` but not both.
     */
    prompt?: never;
});

/**
 * Provider for language, text embedding, and image models.
 */
export declare type Provider = {
    /**
     Returns the language model with the given id.
     The model id is then passed to the provider function to get the model.

     @param {string} id - The id of the model to return.

     @returns {LanguageModel} The language model associated with the id

     @throws {NoSuchModelError} If no such model exists.
     */
    languageModel(modelId: string): LanguageModel;
    /**
     Returns the text embedding model with the given id.
     The model id is then passed to the provider function to get the model.

     @param {string} id - The id of the model to return.

     @returns {LanguageModel} The language model associated with the id

     @throws {NoSuchModelError} If no such model exists.
     */
    textEmbeddingModel(modelId: string): EmbeddingModel<string>;
    /**
     Returns the image model with the given id.
     The model id is then passed to the provider function to get the model.

     @param {string} id - The id of the model to return.

     @returns {ImageModel} The image model associated with the id
     */
    imageModel(modelId: string): ImageModel;
};

declare type ProviderDefinedToolFactory<INPUT, ARGS extends object> = <OUTPUT>(options: ARGS & {
    execute?: ToolExecuteFunction<INPUT, OUTPUT>;
    toModelOutput?: Tool<INPUT, OUTPUT>['toModelOutput'];
    onInputStart?: Tool<INPUT, OUTPUT>['onInputStart'];
    onInputDelta?: Tool<INPUT, OUTPUT>['onInputDelta'];
    onInputAvailable?: Tool<INPUT, OUTPUT>['onInputAvailable'];
}) => Tool<INPUT, OUTPUT>;

declare type ProviderDefinedToolFactoryWithOutputSchema<INPUT, OUTPUT, ARGS extends object> = (options: ARGS & {
    execute?: ToolExecuteFunction<INPUT, OUTPUT>;
    toModelOutput?: Tool<INPUT, OUTPUT>['toModelOutput'];
    onInputStart?: Tool<INPUT, OUTPUT>['onInputStart'];
    onInputDelta?: Tool<INPUT, OUTPUT>['onInputDelta'];
    onInputAvailable?: Tool<INPUT, OUTPUT>['onInputAvailable'];
}) => Tool<INPUT, OUTPUT>;

/**
 Additional provider-specific metadata that is returned from the provider.

 This is needed to enable provider-specific functionality that can be
 fully encapsulated in the provider.
 */
export declare type ProviderMetadata = SharedV2ProviderMetadata;

/**
 Additional provider-specific options.

 They are passed through to the provider from the AI SDK and enable
 provider-specific functionality that can be fully encapsulated in the provider.
 */
declare type ProviderOptions = SharedV2ProviderOptions;

export declare interface ProviderRegistryProvider<PROVIDERS extends Record<string, ProviderV2> = Record<string, ProviderV2>, SEPARATOR extends string = ':'> {
    languageModel<KEY extends keyof PROVIDERS>(id: KEY extends string ? `${KEY & string}${SEPARATOR}${ExtractLiteralUnion<Parameters<NonNullable<PROVIDERS[KEY]['languageModel']>>[0]>}` : never): LanguageModelV2;
    languageModel<KEY extends keyof PROVIDERS>(id: KEY extends string ? `${KEY & string}${SEPARATOR}${string}` : never): LanguageModelV2;
    textEmbeddingModel<KEY extends keyof PROVIDERS>(id: KEY extends string ? `${KEY & string}${SEPARATOR}${ExtractLiteralUnion<Parameters<NonNullable<PROVIDERS[KEY]['textEmbeddingModel']>>[0]>}` : never): EmbeddingModelV2<string>;
    textEmbeddingModel<KEY extends keyof PROVIDERS>(id: KEY extends string ? `${KEY & string}${SEPARATOR}${string}` : never): EmbeddingModelV2<string>;
    imageModel<KEY extends keyof PROVIDERS>(id: KEY extends string ? `${KEY & string}${SEPARATOR}${ExtractLiteralUnion<Parameters<NonNullable<PROVIDERS[KEY]['imageModel']>>[0]>}` : never): ImageModelV2;
    imageModel<KEY extends keyof PROVIDERS>(id: KEY extends string ? `${KEY & string}${SEPARATOR}${string}` : never): ImageModelV2;
    transcriptionModel<KEY extends keyof PROVIDERS>(id: KEY extends string ? `${KEY & string}${SEPARATOR}${ExtractLiteralUnion<Parameters<NonNullable<PROVIDERS[KEY]['transcriptionModel']>>[0]>}` : never): TranscriptionModelV2;
    transcriptionModel<KEY extends keyof PROVIDERS>(id: KEY extends string ? `${KEY & string}${SEPARATOR}${string}` : never): TranscriptionModelV2;
    speechModel<KEY extends keyof PROVIDERS>(id: KEY extends string ? `${KEY & string}${SEPARATOR}${ExtractLiteralUnion<Parameters<NonNullable<PROVIDERS[KEY]['speechModel']>>[0]>}` : never): SpeechModelV2;
    speechModel<KEY extends keyof PROVIDERS>(id: KEY extends string ? `${KEY & string}${SEPARATOR}${string}` : never): SpeechModelV2;
}

/**
 * Provider for language, text embedding, and image generation models.
 */
declare interface ProviderV2 {
    /**
     Returns the language model with the given id.
     The model id is then passed to the provider function to get the model.

     @param {string} modelId - The id of the model to return.

     @returns {LanguageModel} The language model associated with the id

     @throws {NoSuchModelError} If no such model exists.
     */
    languageModel(modelId: string): LanguageModelV2;
    /**
     Returns the text embedding model with the given id.
     The model id is then passed to the provider function to get the model.

     @param {string} modelId - The id of the model to return.

     @returns {LanguageModel} The language model associated with the id

     @throws {NoSuchModelError} If no such model exists.
     */
    textEmbeddingModel(modelId: string): EmbeddingModelV2<string>;
    /**
     Returns the image model with the given id.
     The model id is then passed to the provider function to get the model.

     @param {string} modelId - The id of the model to return.

     @returns {ImageModel} The image model associated with the id
     */
    imageModel(modelId: string): ImageModelV2;
    /**
     Returns the transcription model with the given id.
     The model id is then passed to the provider function to get the model.

     @param {string} modelId - The id of the model to return.

     @returns {TranscriptionModel} The transcription model associated with the id
     */
    transcriptionModel?(modelId: string): TranscriptionModelV2;
    /**
     Returns the speech model with the given id.
     The model id is then passed to the provider function to get the model.

     @param {string} modelId - The id of the model to return.

     @returns {SpeechModel} The speech model associated with the id
     */
    speechModel?(modelId: string): SpeechModelV2;
}

/**
 * Prunes model messages from a list of model messages.
 *
 * @param messages - The list of model messages to prune.
 * @param reasoning - How to remove reasoning content from assistant messages. Default is `'none'`.
 * @param toolCalls - How to prune tool call/results/approval content. Default is `[]`.
 * @param emptyMessages - Whether to keep or remove messages whose content is empty after pruning. Default is `'remove'`.
 *
 * @returns The pruned list of model messages.
 */
export declare function pruneMessages({ messages, reasoning, toolCalls, emptyMessages, }: {
    messages: ModelMessage[];
    reasoning?: 'all' | 'before-last-message' | 'none';
    toolCalls?: 'all' | 'before-last-message' | `before-last-${number}-messages` | 'none' | Array<{
        type: 'all' | 'before-last-message' | `before-last-${number}-messages`;
        tools?: string[];
    }>;
    emptyMessages?: 'keep' | 'remove';
}): ModelMessage[];

/**
 * Transforms a stream of `UIMessageChunk`s into an `AsyncIterableStream` of `UIMessage`s.
 *
 * @param options.message - The last assistant message to use as a starting point when the conversation is resumed. Otherwise undefined.
 * @param options.stream - The stream of `UIMessageChunk`s to read.
 * @param options.terminateOnError - Whether to terminate the stream if an error occurs.
 * @param options.onError - A function that is called when an error occurs.
 *
 * @returns An `AsyncIterableStream` of `UIMessage`s. Each stream part is a different state of the same message
 * as it is being completed.
 */
export declare function readUIMessageStream<UI_MESSAGE extends UIMessage>({ message, stream, onError, terminateOnError, }: {
    message?: UI_MESSAGE;
    stream: ReadableStream<UIMessageChunk>;
    onError?: (error: unknown) => void;
    terminateOnError?: boolean;
}): AsyncIterableStream<UI_MESSAGE>;

/**
 * Reasoning output of a text generation. It contains a reasoning.
 */
export declare interface ReasoningOutput {
    type: 'reasoning';
    /**
     * The reasoning text.
     */
    text: string;
    /**
     * Additional provider-specific metadata. They are passed through
     * to the provider from the AI SDK and enable provider-specific
     * functionality that can be fully encapsulated in the provider.
     */
    providerMetadata?: ProviderMetadata;
}

/**
 * Reasoning content part of a prompt. It contains a reasoning.
 */
declare interface ReasoningPart {
    type: 'reasoning';
    /**
     The reasoning text.
     */
    text: string;
    /**
     Additional provider-specific metadata. They are passed through
     to the provider from the AI SDK and enable provider-specific
     functionality that can be fully encapsulated in the provider.
     */
    providerOptions?: ProviderOptions;
}

/**
 * A reasoning part of a message.
 */
export declare type ReasoningUIPart = {
    type: 'reasoning';
    /**
     * The reasoning text.
     */
    text: string;
    /**
     * The state of the reasoning part.
     */
    state?: 'streaming' | 'done';
    /**
     * The provider metadata.
     */
    providerMetadata?: ProviderMetadata;
};

/**
 * Removes entries from a record where the value is null or undefined.
 * @param record - The input object whose entries may be null or undefined.
 * @returns A new object containing only entries with non-null and non-undefined values.
 */
declare function removeUndefinedEntries<T>(record: Record<string, T | undefined>): Record<string, T>;

/**
 A function that attempts to repair the raw output of the model
 to enable JSON parsing.

 Should return the repaired text or null if the text cannot be repaired.
 */
export declare type RepairTextFunction = (options: {
    text: string;
    error: JSONParseError | TypeValidationError;
}) => Promise<string | null>;

declare type Resolvable<T> = T | Promise<T> | (() => T) | (() => Promise<T>);

/**
 * Resolves a value that could be a raw value, a Promise, a function returning a value,
 * or a function returning a Promise.
 */
declare function resolve<T>(value: Resolvable<T>): Promise<T>;

declare type ResponseHandler<RETURN_TYPE> = (options: {
    url: string;
    requestBodyValues: unknown;
    response: Response;
}) => PromiseLike<{
    value: RETURN_TYPE;
    rawValue?: unknown;
    responseHeaders?: Record<string, string>;
}>;

/**
 A message that was generated during the generation process.
 It can be either an assistant message or a tool message.
 */
declare type ResponseMessage = AssistantModelMessage | ToolModelMessage;

export declare class RetryError extends AISDKError {
    private readonly [symbol$1_2];
    readonly reason: RetryErrorReason;
    readonly lastError: unknown;
    readonly errors: Array<unknown>;
    constructor({ message, reason, errors, }: {
        message: string;
        reason: RetryErrorReason;
        errors: Array<unknown>;
    });
    static isInstance(error: unknown): error is RetryError;
}

declare type RetryErrorReason = 'maxRetriesExceeded' | 'errorNotRetryable' | 'abort';

/**
 * Safely parses a JSON string and returns the result as an object of type `unknown`.
 *
 * @param text - The JSON string to parse.
 * @returns {Promise<object>} Either an object with `success: true` and the parsed data, or an object with `success: false` and the error that occurred.
 */
declare function safeParseJSON(options: {
    text: string;
    schema?: undefined;
}): Promise<ParseResult<JSONValue_2>>;

/**
 * Safely parses a JSON string into a strongly-typed object, using a provided schema to validate the object.
 *
 * @template T - The type of the object to parse the JSON into.
 * @param {string} text - The JSON string to parse.
 * @param {Validator<T>} schema - The schema to use for parsing the JSON.
 * @returns An object with either a `success` flag and the parsed and typed data, or a `success` flag and an error object.
 */
declare function safeParseJSON<T>(options: {
    text: string;
    schema: FlexibleValidator<T>;
}): Promise<ParseResult<T>>;

/**
 * Safely validates the types of an unknown object using a schema and
 * return a strongly-typed object.
 *
 * @template T - The type of the object to validate.
 * @param {string} options.value - The JSON object to validate.
 * @param {Validator<T>} options.schema - The schema to use for validating the JSON.
 * @returns An object with either a `success` flag and the parsed and typed data, or a `success` flag and an error object.
 */
declare function safeValidateTypes<OBJECT>({ value, schema, }: {
    value: unknown;
    schema: FlexibleValidator<OBJECT>;
}): Promise<{
    success: true;
    value: OBJECT;
    rawValue: unknown;
} | {
    success: false;
    error: TypeValidationError;
    rawValue: unknown;
}>;

/**
 * Validates a list of UI messages like `validateUIMessages`,
 * but instead of throwing it returns `{ success: true, data }`
 * or `{ success: false, error }`.
 */
export declare function safeValidateUIMessages<UI_MESSAGE extends UIMessage>({ messages, metadataSchema, dataSchemas, tools, }: {
    messages: unknown;
    metadataSchema?: Validator<UIMessage['metadata']> | StandardSchemaV1<unknown, UI_MESSAGE['metadata']>;
    dataSchemas?: {
        [NAME in keyof InferUIMessageData<UI_MESSAGE> & string]?: Validator<InferUIMessageData<UI_MESSAGE>[NAME]> | StandardSchemaV1<unknown, InferUIMessageData<UI_MESSAGE>[NAME]>;
    };
    tools?: {
        [NAME in keyof InferUIMessageTools<UI_MESSAGE> & string]?: Tool<InferUIMessageTools<UI_MESSAGE>[NAME]['input'], InferUIMessageTools<UI_MESSAGE>[NAME]['output']>;
    };
}): Promise<SafeValidateUIMessagesResult<UI_MESSAGE>>;

export declare type SafeValidateUIMessagesResult<UI_MESSAGE extends UIMessage> = {
    success: true;
    data: Array<UI_MESSAGE>;
} | {
    success: false;
    error: Error;
};

export declare type Schema<OBJECT = unknown> = Validator<OBJECT> & {
    /**
     * Used to mark schemas so we can support both Zod and custom schemas.
     */
    [schemaSymbol]: true;
    /**
     * Schema type for inference.
     */
    _type: OBJECT;
    /**
     * The JSON Schema for the schema. It is passed to the providers.
     */
    readonly jsonSchema: JSONSchema7;
};

/**
 * Used to mark schemas so we can support both Zod and custom schemas.
 */
declare const schemaSymbol: unique symbol;

export declare class SerialJobExecutor {
    private queue;
    private isProcessing;
    private processQueue;
    run(job: Job): Promise<void>;
}

declare type SharedV2Headers = Record<string, string>;

/**
 * Additional provider-specific metadata.
 * Metadata are additional outputs from the provider.
 * They are passed through to the provider from the AI SDK
 * and enable provider-specific functionality
 * that can be fully encapsulated in the provider.
 *
 * This enables us to quickly ship provider-specific functionality
 * without affecting the core AI SDK.
 *
 * The outer record is keyed by the provider name, and the inner
 * record is keyed by the provider-specific metadata key.
 *
 * ```ts
 * {
 *   "anthropic": {
 *     "cacheControl": { "type": "ephemeral" }
 *   }
 * }
 * ```
 */
declare type SharedV2ProviderMetadata = Record<string, Record<string, JSONValue_2>>;

/**
 * Additional provider-specific options.
 * Options are additional input to the provider.
 * They are passed through to the provider from the AI SDK
 * and enable provider-specific functionality
 * that can be fully encapsulated in the provider.
 *
 * This enables us to quickly ship provider-specific functionality
 * without affecting the core AI SDK.
 *
 * The outer record is keyed by the provider name, and the inner
 * record is keyed by the provider-specific metadata key.
 *
 * ```ts
 * {
 *   "anthropic": {
 *     "cacheControl": { "type": "ephemeral" }
 *   }
 * }
 * ```
 */
declare type SharedV2ProviderOptions = Record<string, Record<string, JSONValue_2>>;

/**
 * Creates a ReadableStream that emits the provided values with an optional delay between each value.
 *
 * @param options - The configuration options
 * @param options.chunks - Array of values to be emitted by the stream
 * @param options.initialDelayInMs - Optional initial delay in milliseconds before emitting the first value (default: 0). Can be set to `null` to skip the initial delay. The difference between `initialDelayInMs: null` and `initialDelayInMs: 0` is that `initialDelayInMs: null` will emit the values without any delay, while `initialDelayInMs: 0` will emit the values with a delay of 0 milliseconds.
 * @param options.chunkDelayInMs - Optional delay in milliseconds between emitting each value (default: 0). Can be set to `null` to skip the delay. The difference between `chunkDelayInMs: null` and `chunkDelayInMs: 0` is that `chunkDelayInMs: null` will emit the values without any delay, while `chunkDelayInMs: 0` will emit the values with a delay of 0 milliseconds.
 * @returns A ReadableStream that emits the provided values
 */
export declare function simulateReadableStream<T>({ chunks, initialDelayInMs, chunkDelayInMs, _internal, }: {
    chunks: T[];
    initialDelayInMs?: number | null;
    chunkDelayInMs?: number | null;
    _internal?: {
        delay?: (ms: number | null) => Promise<void>;
    };
}): ReadableStream<T>;

/**
 * Simulates streaming chunks with the response from a generate call.
 */
export declare function simulateStreamingMiddleware(): LanguageModelMiddleware;

declare type SingleRequestTextStreamPart<TOOLS extends ToolSet> = {
    type: 'text-start';
    providerMetadata?: ProviderMetadata;
    id: string;
} | {
    type: 'text-delta';
    id: string;
    providerMetadata?: ProviderMetadata;
    delta: string;
} | {
    type: 'text-end';
    providerMetadata?: ProviderMetadata;
    id: string;
} | {
    type: 'reasoning-start';
    providerMetadata?: ProviderMetadata;
    id: string;
} | {
    type: 'reasoning-delta';
    id: string;
    providerMetadata?: ProviderMetadata;
    delta: string;
} | {
    type: 'reasoning-end';
    id: string;
    providerMetadata?: ProviderMetadata;
} | {
    type: 'tool-input-start';
    id: string;
    toolName: string;
    providerMetadata?: ProviderMetadata;
} | {
    type: 'tool-input-delta';
    id: string;
    delta: string;
    providerMetadata?: ProviderMetadata;
} | {
    type: 'tool-input-end';
    id: string;
    providerMetadata?: ProviderMetadata;
} | ({
    type: 'source';
} & Source) | {
    type: 'file';
    file: GeneratedFile;
} | ({
    type: 'tool-call';
} & TypedToolCall<TOOLS>) | ({
    type: 'tool-result';
} & TypedToolResult<TOOLS>) | ({
    type: 'tool-error';
} & TypedToolError<TOOLS>) | {
    type: 'file';
    file: GeneratedFile;
} | {
    type: 'stream-start';
    warnings: LanguageModelV2CallWarning[];
} | {
    type: 'response-metadata';
    id?: string;
    timestamp?: Date;
    modelId?: string;
} | {
    type: 'finish';
    finishReason: FinishReason;
    usage: LanguageModelUsage;
    providerMetadata?: ProviderMetadata;
} | {
    type: 'error';
    error: unknown;
} | {
    type: 'raw';
    rawValue: unknown;
};

/**
 * Smooths text streaming output.
 *
 * @param delayInMs - The delay in milliseconds between each chunk. Defaults to 10ms. Can be set to `null` to skip the delay.
 * @param chunking - Controls how the text is chunked for streaming. Use "word" to stream word by word (default), "line" to stream line by line, or provide a custom RegExp pattern for custom chunking.
 *
 * @returns A transform stream that smooths text streaming output.
 */
export declare function smoothStream<TOOLS extends ToolSet>({ delayInMs, chunking, _internal: { delay }, }?: {
    delayInMs?: number | null;
    chunking?: 'word' | 'line' | RegExp | ChunkDetector;
    /**
     * Internal. For test use only. May change without notice.
     */
    _internal?: {
        delay?: (delayInMs: number | null) => Promise<void>;
    };
}): (options: {
    tools: TOOLS;
}) => TransformStream<TextStreamPart<TOOLS>, TextStreamPart<TOOLS>>;

/**
 A source that has been used as input to generate the response.
 */
declare type Source = LanguageModelV2Source;

/**
 * A document source part of a message.
 */
export declare type SourceDocumentUIPart = {
    type: 'source-document';
    sourceId: string;
    mediaType: string;
    title: string;
    filename?: string;
    providerMetadata?: ProviderMetadata;
};

/**
 * A source part of a message.
 */
export declare type SourceUrlUIPart = {
    type: 'source-url';
    sourceId: string;
    url: string;
    title?: string;
    providerMetadata?: ProviderMetadata;
};

/**
 * An interface that represents a span. A span represents a single operation
 * within a trace. Examples of span might include remote procedure calls or a
 * in-process function calls to sub-components. A Trace has a single, top-level
 * "root" Span that in turn may have zero or more child Spans, which in turn
 * may have children.
 *
 * Spans are created by the {@link Tracer.startSpan} method.
 */
declare interface Span {
    /**
     * Returns the {@link SpanContext} object associated with this Span.
     *
     * Get an immutable, serializable identifier for this span that can be used
     * to create new child spans. Returned SpanContext is usable even after the
     * span ends.
     *
     * @returns the SpanContext object associated with this Span.
     */
    spanContext(): SpanContext;
    /**
     * Sets an attribute to the span.
     *
     * Sets a single Attribute with the key and value passed as arguments.
     *
     * @param key the key for this attribute.
     * @param value the value for this attribute. Setting a value null or
     *              undefined is invalid and will result in undefined behavior.
     */
    setAttribute(key: string, value: SpanAttributeValue): this;
    /**
     * Sets attributes to the span.
     *
     * @param attributes the attributes that will be added.
     *                   null or undefined attribute values
     *                   are invalid and will result in undefined behavior.
     */
    setAttributes(attributes: SpanAttributes): this;
    /**
     * Adds an event to the Span.
     *
     * @param name the name of the event.
     * @param [attributesOrStartTime] the attributes that will be added; these are
     *     associated with this event. Can be also a start time
     *     if type is {@type TimeInput} and 3rd param is undefined
     * @param [startTime] start time of the event.
     */
    addEvent(name: string, attributesOrStartTime?: SpanAttributes | TimeInput, startTime?: TimeInput): this;
    /**
     * Adds a single link to the span.
     *
     * Links added after the creation will not affect the sampling decision.
     * It is preferred span links be added at span creation.
     *
     * @param link the link to add.
     */
    addLink(link: Link): this;
    /**
     * Adds multiple links to the span.
     *
     * Links added after the creation will not affect the sampling decision.
     * It is preferred span links be added at span creation.
     *
     * @param links the links to add.
     */
    addLinks(links: Link[]): this;
    /**
     * Sets a status to the span. If used, this will override the default Span
     * status. Default is {@link SpanStatusCode.UNSET}. SetStatus overrides the value
     * of previous calls to SetStatus on the Span.
     *
     * @param status the SpanStatus to set.
     */
    setStatus(status: SpanStatus): this;
    /**
     * Updates the Span name.
     *
     * This will override the name provided via {@link Tracer.startSpan}.
     *
     * Upon this update, any sampling behavior based on Span name will depend on
     * the implementation.
     *
     * @param name the Span name.
     */
    updateName(name: string): this;
    /**
     * Marks the end of Span execution.
     *
     * Call to End of a Span MUST not have any effects on child spans. Those may
     * still be running and can be ended later.
     *
     * Do not return `this`. The Span generally should not be used after it
     * is ended so chaining is not desired in this context.
     *
     * @param [endTime] the time to set as Span's end time. If not provided,
     *     use the current time as the span's end time.
     */
    end(endTime?: TimeInput): void;
    /**
     * Returns the flag whether this span will be recorded.
     *
     * @returns true if this Span is active and recording information like events
     *     with the `AddEvent` operation and attributes using `setAttributes`.
     */
    isRecording(): boolean;
    /**
     * Sets exception as a span event
     * @param exception the exception the only accepted values are string or Error
     * @param [time] the time to set as Span's event time. If not provided,
     *     use the current time.
     */
    recordException(exception: Exception, time?: TimeInput): void;
}

/**
 * @deprecated please use {@link Attributes}
 */
declare type SpanAttributes = Attributes;

/**
 * @deprecated please use {@link AttributeValue}
 */
declare type SpanAttributeValue = AttributeValue;

/**
 * A SpanContext represents the portion of a {@link Span} which must be
 * serialized and propagated along side of a {@link Baggage}.
 */
declare interface SpanContext {
    /**
     * The ID of the trace that this span belongs to. It is worldwide unique
     * with practically sufficient probability by being made as 16 randomly
     * generated bytes, encoded as a 32 lowercase hex characters corresponding to
     * 128 bits.
     */
    traceId: string;
    /**
     * The ID of the Span. It is globally unique with practically sufficient
     * probability by being made as 8 randomly generated bytes, encoded as a 16
     * lowercase hex characters corresponding to 64 bits.
     */
    spanId: string;
    /**
     * Only true if the SpanContext was propagated from a remote parent.
     */
    isRemote?: boolean;
    /**
     * Trace flags to propagate.
     *
     * It is represented as 1 byte (bitmap). Bit to represent whether trace is
     * sampled or not. When set, the least significant bit documents that the
     * caller may have recorded trace data. A caller who does not record trace
     * data out-of-band leaves this flag unset.
     *
     * see {@link TraceFlags} for valid flag values.
     */
    traceFlags: number;
    /**
     * Tracing-system-specific info to propagate.
     *
     * The tracestate field value is a `list` as defined below. The `list` is a
     * series of `list-members` separated by commas `,`, and a list-member is a
     * key/value pair separated by an equals sign `=`. Spaces and horizontal tabs
     * surrounding `list-members` are ignored. There can be a maximum of 32
     * `list-members` in a `list`.
     * More Info: https://www.w3.org/TR/trace-context/#tracestate-field
     *
     * Examples:
     *     Single tracing system (generic format):
     *         tracestate: rojo=00f067aa0ba902b7
     *     Multiple tracing systems (with different formatting):
     *         tracestate: rojo=00f067aa0ba902b7,congo=t61rcWkgMzE
     */
    traceState?: TraceState;
}

declare enum SpanKind {
    /** Default value. Indicates that the span is used internally. */
    INTERNAL = 0,
    /**
     * Indicates that the span covers server-side handling of an RPC or other
     * remote request.
     */
    SERVER = 1,
    /**
     * Indicates that the span covers the client-side wrapper around an RPC or
     * other remote request.
     */
    CLIENT = 2,
    /**
     * Indicates that the span describes producer sending a message to a
     * broker. Unlike client and server, there is no direct critical path latency
     * relationship between producer and consumer spans.
     */
    PRODUCER = 3,
    /**
     * Indicates that the span describes consumer receiving a message from a
     * broker. Unlike client and server, there is no direct critical path latency
     * relationship between producer and consumer spans.
     */
    CONSUMER = 4
}

/**
 * Options needed for span creation
 */
declare interface SpanOptions {
    /**
     * The SpanKind of a span
     * @default {@link SpanKind.INTERNAL}
     */
    kind?: SpanKind;
    /** A span's attributes */
    attributes?: SpanAttributes;
    /** {@link Link}s span to other spans */
    links?: Link[];
    /** A manually specified start time for the created `Span` object. */
    startTime?: TimeInput;
    /** The new span should be a root span. (Ignore parent from context). */
    root?: boolean;
}

declare interface SpanStatus {
    /** The status code of this message. */
    code: SpanStatusCode;
    /** A developer-facing error message. */
    message?: string;
}

/**
 * An enumeration of status codes.
 */
declare enum SpanStatusCode {
    /**
     * The default status.
     */
    UNSET = 0,
    /**
     * The operation has been validated by an Application developer or
     * Operator to have completed successfully.
     */
    OK = 1,
    /**
     * The operation contains an error.
     */
    ERROR = 2
}

/**
 Speech model that is used by the AI SDK Core functions.
 */
export declare type SpeechModel = SpeechModelV2;

export declare type SpeechModelResponseMetadata = {
    /**
     Timestamp for the start of the generated response.
     */
    timestamp: Date;
    /**
     The ID of the response model that was used to generate the response.
     */
    modelId: string;
    /**
     Response headers.
     */
    headers?: Record<string, string>;
    /**
     Response body.
     */
    body?: unknown;
};

/**
 * Speech model specification version 2.
 */
declare type SpeechModelV2 = {
    /**
     * The speech model must specify which speech model interface
     * version it implements. This will allow us to evolve the speech
     * model interface and retain backwards compatibility. The different
     * implementation versions can be handled as a discriminated union
     * on our side.
     */
    readonly specificationVersion: 'v2';
    /**
     * Name of the provider for logging purposes.
     */
    readonly provider: string;
    /**
     * Provider-specific model ID for logging purposes.
     */
    readonly modelId: string;
    /**
     * Generates speech audio from text.
     */
    doGenerate(options: SpeechModelV2CallOptions): PromiseLike<{
        /**
         * Generated audio as an ArrayBuffer.
         * The audio should be returned without any unnecessary conversion.
         * If the API returns base64 encoded strings, the audio should be returned
         * as base64 encoded strings. If the API returns binary data, the audio
         * should be returned as binary data.
         */
        audio: string | Uint8Array;
        /**
         * Warnings for the call, e.g. unsupported settings.
         */
        warnings: Array<SpeechModelV2CallWarning>;
        /**
         * Optional request information for telemetry and debugging purposes.
         */
        request?: {
            /**
             * Response body (available only for providers that use HTTP requests).
             */
            body?: unknown;
        };
        /**
         * Response information for telemetry and debugging purposes.
         */
        response: {
            /**
             * Timestamp for the start of the generated response.
             */
            timestamp: Date;
            /**
             * The ID of the response model that was used to generate the response.
             */
            modelId: string;
            /**
             * Response headers.
             */
            headers?: SharedV2Headers;
            /**
             * Response body.
             */
            body?: unknown;
        };
        /**
         * Additional provider-specific metadata. They are passed through
         * from the provider to the AI SDK and enable provider-specific
         * results that can be fully encapsulated in the provider.
         */
        providerMetadata?: Record<string, Record<string, JSONValue_2>>;
    }>;
};

declare type SpeechModelV2CallOptions = {
    /**
     * Text to convert to speech.
     */
    text: string;
    /**
     * The voice to use for speech synthesis.
     * This is provider-specific and may be a voice ID, name, or other identifier.
     */
    voice?: string;
    /**
     * The desired output format for the audio e.g. "mp3", "wav", etc.
     */
    outputFormat?: string;
    /**
     * Instructions for the speech generation e.g. "Speak in a slow and steady tone".
     */
    instructions?: string;
    /**
     * The speed of the speech generation.
     */
    speed?: number;
    /**
     * The language for speech generation. This should be an ISO 639-1 language code (e.g. "en", "es", "fr")
     * or "auto" for automatic language detection. Provider support varies.
     */
    language?: string;
    /**
     * Additional provider-specific options that are passed through to the provider
     * as body parameters.
     *
     * The outer record is keyed by the provider name, and the inner
     * record is keyed by the provider-specific metadata key.
     * ```ts
     * {
     *   "openai": {}
     * }
     * ```
     */
    providerOptions?: SpeechModelV2ProviderOptions;
    /**
     * Abort signal for cancelling the operation.
     */
    abortSignal?: AbortSignal;
    /**
     * Additional HTTP headers to be sent with the request.
     * Only applicable for HTTP-based providers.
     */
    headers?: Record<string, string | undefined>;
};

/**
 * Warning from the model provider for this call. The call will proceed, but e.g.
 * some settings might not be supported, which can lead to suboptimal results.
 */
declare type SpeechModelV2CallWarning = {
    type: 'unsupported-setting';
    setting: keyof SpeechModelV2CallOptions;
    details?: string;
} | {
    type: 'other';
    message: string;
};

declare type SpeechModelV2ProviderOptions = Record<string, Record<string, JSONValue_2>>;

/**
 Warning from the model provider for this call. The call will proceed, but e.g.
 some settings might not be supported, which can lead to suboptimal results.
 */
export declare type SpeechWarning = SpeechModelV2CallWarning;

/** The Standard JSON Schema interface. */
declare interface StandardJSONSchemaV1<Input = unknown, Output = Input> {
    /** The Standard JSON Schema properties. */
    readonly "~standard": StandardJSONSchemaV1.Props<Input, Output>;
}

declare namespace StandardJSONSchemaV1 {
    /** The Standard JSON Schema properties interface. */
    interface Props<Input = unknown, Output = Input> extends StandardTypedV1.Props<Input, Output> {
        /** Methods for generating the input/output JSON Schema. */
        readonly jsonSchema: StandardJSONSchemaV1.Converter;
    }
    /** The Standard JSON Schema converter interface. */
    interface Converter {
        /** Converts the input type to JSON Schema. May throw if conversion is not supported. */
        readonly input: (options: StandardJSONSchemaV1.Options) => Record<string, unknown>;
        /** Converts the output type to JSON Schema. May throw if conversion is not supported. */
        readonly output: (options: StandardJSONSchemaV1.Options) => Record<string, unknown>;
    }
    /**
     * The target version of the generated JSON Schema.
     *
     * It is *strongly recommended* that implementers support `"draft-2020-12"` and `"draft-07"`, as they are both in wide use. All other targets can be implemented on a best-effort basis. Libraries should throw if they don't support a specified target.
     *
     * The `"openapi-3.0"` target is intended as a standardized specifier for OpenAPI 3.0 which is a superset of JSON Schema `"draft-04"`.
     */
    type Target = "draft-2020-12" | "draft-07" | "openapi-3.0" | ({} & string);
    /** The options for the input/output methods. */
    interface Options {
        /** Specifies the target version of the generated JSON Schema. Support for all versions is on a best-effort basis. If a given version is not supported, the library should throw. */
        readonly target: Target;
        /** Explicit support for additional vendor-specific parameters, if needed. */
        readonly libraryOptions?: Record<string, unknown> | undefined;
    }
    /** The Standard types interface. */
    interface Types<Input = unknown, Output = Input> extends StandardTypedV1.Types<Input, Output> {
    }
    /** Infers the input type of a Standard. */
    type InferInput<Schema extends StandardTypedV1> = StandardTypedV1.InferInput<Schema>;
    /** Infers the output type of a Standard. */
    type InferOutput<Schema extends StandardTypedV1> = StandardTypedV1.InferOutput<Schema>;
}

/** The Standard Schema interface. */
declare interface StandardSchemaV1<Input = unknown, Output = Input> {
    /** The Standard Schema properties. */
    readonly "~standard": StandardSchemaV1.Props<Input, Output>;
}

declare namespace StandardSchemaV1 {
    /** The Standard Schema properties interface. */
    interface Props<Input = unknown, Output = Input> extends StandardTypedV1.Props<Input, Output> {
        /** Validates unknown input values. */
        readonly validate: (value: unknown, options?: StandardSchemaV1.Options | undefined) => Result<Output> | Promise<Result<Output>>;
    }
    /** The result interface of the validate function. */
    type Result<Output> = SuccessResult<Output> | FailureResult;
    /** The result interface if validation succeeds. */
    interface SuccessResult<Output> {
        /** The typed output value. */
        readonly value: Output;
        /** A falsy value for `issues` indicates success. */
        readonly issues?: undefined;
    }
    interface Options {
        /** Explicit support for additional vendor-specific parameters, if needed. */
        readonly libraryOptions?: Record<string, unknown> | undefined;
    }
    /** The result interface if validation fails. */
    interface FailureResult {
        /** The issues of failed validation. */
        readonly issues: ReadonlyArray<Issue>;
    }
    /** The issue interface of the failure output. */
    interface Issue {
        /** The error message of the issue. */
        readonly message: string;
        /** The path of the issue, if any. */
        readonly path?: ReadonlyArray<PropertyKey | PathSegment> | undefined;
    }
    /** The path segment interface of the issue. */
    interface PathSegment {
        /** The key representing a path segment. */
        readonly key: PropertyKey;
    }
    /** The Standard types interface. */
    interface Types<Input = unknown, Output = Input> extends StandardTypedV1.Types<Input, Output> {
    }
    /** Infers the input type of a Standard. */
    type InferInput<Schema extends StandardTypedV1> = StandardTypedV1.InferInput<Schema>;
    /** Infers the output type of a Standard. */
    type InferOutput<Schema extends StandardTypedV1> = StandardTypedV1.InferOutput<Schema>;
}

declare function standardSchemaValidator<OBJECT>(standardSchema: StandardSchemaV1<unknown, OBJECT>): Validator<OBJECT>;

/** The Standard Typed interface. This is a base type extended by other specs. */
declare interface StandardTypedV1<Input = unknown, Output = Input> {
    /** The Standard properties. */
    readonly "~standard": StandardTypedV1.Props<Input, Output>;
}

declare namespace StandardTypedV1 {
    /** The Standard Typed properties interface. */
    interface Props<Input = unknown, Output = Input> {
        /** The version number of the standard. */
        readonly version: 1;
        /** The vendor name of the schema library. */
        readonly vendor: string;
        /** Inferred types associated with the schema. */
        readonly types?: Types<Input, Output> | undefined;
    }
    /** The Standard Typed types interface. */
    interface Types<Input = unknown, Output = Input> {
        /** The input type of the schema. */
        readonly input: Input;
        /** The output type of the schema. */
        readonly output: Output;
    }
    /** Infers the input type of a Standard Typed. */
    type InferInput<Schema extends StandardTypedV1> = NonNullable<Schema["~standard"]["types"]>["input"];
    /** Infers the output type of a Standard Typed. */
    type InferOutput<Schema extends StandardTypedV1> = NonNullable<Schema["~standard"]["types"]>["output"];
}

export declare type StaticToolCall<TOOLS extends ToolSet> = ValueOf<{
    [NAME in keyof TOOLS]: {
        type: 'tool-call';
        toolCallId: string;
        toolName: NAME & string;
        input: TOOLS[NAME] extends Tool<infer PARAMETERS> ? PARAMETERS : never;
        providerExecuted?: boolean;
        dynamic?: false | undefined;
        invalid?: false | undefined;
        error?: never;
        providerMetadata?: ProviderMetadata;
    };
}>;

export declare type StaticToolError<TOOLS extends ToolSet> = ValueOf<{
    [NAME in keyof TOOLS]: {
        type: 'tool-error';
        toolCallId: string;
        toolName: NAME & string;
        input: InferToolInput<TOOLS[NAME]>;
        error: unknown;
        providerExecuted?: boolean;
        providerMetadata?: ProviderMetadata;
        dynamic?: false | undefined;
    };
}>;

export declare type StaticToolResult<TOOLS extends ToolSet> = ValueOf<{
    [NAME in keyof TOOLS]: {
        type: 'tool-result';
        toolCallId: string;
        toolName: NAME & string;
        input: InferToolInput<TOOLS[NAME]>;
        output: InferToolOutput<TOOLS[NAME]>;
        providerExecuted?: boolean;
        providerMetadata?: ProviderMetadata;
        dynamic?: false | undefined;
        preliminary?: boolean;
    };
}>;

export declare function stepCountIs(stepCount: number): StopCondition<any>;

/**
 * The result of a single step in the generation process.
 */
export declare type StepResult<TOOLS extends ToolSet> = {
    /**
     The content that was generated in the last step.
     */
    readonly content: Array<ContentPart<TOOLS>>;
    /**
     The generated text.
     */
    readonly text: string;
    /**
     The reasoning that was generated during the generation.
     */
    readonly reasoning: Array<ReasoningPart>;
    /**
     The reasoning text that was generated during the generation.
     */
    readonly reasoningText: string | undefined;
    /**
     The files that were generated during the generation.
     */
    readonly files: Array<GeneratedFile>;
    /**
     The sources that were used to generate the text.
     */
    readonly sources: Array<Source>;
    /**
     The tool calls that were made during the generation.
     */
    readonly toolCalls: Array<TypedToolCall<TOOLS>>;
    /**
     The static tool calls that were made in the last step.
     */
    readonly staticToolCalls: Array<StaticToolCall<TOOLS>>;
    /**
     The dynamic tool calls that were made in the last step.
     */
    readonly dynamicToolCalls: Array<DynamicToolCall>;
    /**
     The results of the tool calls.
     */
    readonly toolResults: Array<TypedToolResult<TOOLS>>;
    /**
     The static tool results that were made in the last step.
     */
    readonly staticToolResults: Array<StaticToolResult<TOOLS>>;
    /**
     The dynamic tool results that were made in the last step.
     */
    readonly dynamicToolResults: Array<DynamicToolResult>;
    /**
     The reason why the generation finished.
     */
    readonly finishReason: FinishReason;
    /**
     The token usage of the generated text.
     */
    readonly usage: LanguageModelUsage;
    /**
     Warnings from the model provider (e.g. unsupported settings).
     */
    readonly warnings: CallWarning[] | undefined;
    /**
     Additional request information.
     */
    readonly request: LanguageModelRequestMetadata;
    /**
     Additional response information.
     */
    readonly response: LanguageModelResponseMetadata & {
        /**
         The response messages that were generated during the call.
         Response messages can be either assistant messages or tool messages.
         They contain a generated id.
         */
        readonly messages: Array<ResponseMessage>;
        /**
         Response body (available only for providers that use HTTP requests).
         */
        body?: unknown;
    };
    /**
     Additional provider-specific metadata. They are passed through
     from the provider to the AI SDK and enable provider-specific
     results that can be fully encapsulated in the provider.
     */
    readonly providerMetadata: ProviderMetadata | undefined;
};

/**
 * A step boundary part of a message.
 */
export declare type StepStartUIPart = {
    type: 'step-start';
};

export declare type StopCondition<TOOLS extends ToolSet> = (options: {
    steps: Array<StepResult<TOOLS>>;
}) => PromiseLike<boolean> | boolean;

/**
 Generate a structured, typed object for a given prompt and schema using a language model.

 This function streams the output. If you do not want to stream the output, use `generateObject` instead.

 @param model - The language model to use.
 @param tools - Tools that are accessible to and can be called by the model. The model needs to support calling tools.

 @param system - A system message that will be part of the prompt.
 @param prompt - A simple text prompt. You can either use `prompt` or `messages` but not both.
 @param messages - A list of messages. You can either use `prompt` or `messages` but not both.

 @param maxOutputTokens - Maximum number of tokens to generate.
 @param temperature - Temperature setting.
 The value is passed through to the provider. The range depends on the provider and model.
 It is recommended to set either `temperature` or `topP`, but not both.
 @param topP - Nucleus sampling.
 The value is passed through to the provider. The range depends on the provider and model.
 It is recommended to set either `temperature` or `topP`, but not both.
 @param topK - Only sample from the top K options for each subsequent token.
 Used to remove "long tail" low probability responses.
 Recommended for advanced use cases only. You usually only need to use temperature.
 @param presencePenalty - Presence penalty setting.
 It affects the likelihood of the model to repeat information that is already in the prompt.
 The value is passed through to the provider. The range depends on the provider and model.
 @param frequencyPenalty - Frequency penalty setting.
 It affects the likelihood of the model to repeatedly use the same words or phrases.
 The value is passed through to the provider. The range depends on the provider and model.
 @param stopSequences - Stop sequences.
 If set, the model will stop generating text when one of the stop sequences is generated.
 @param seed - The seed (integer) to use for random sampling.
 If set and supported by the model, calls will generate deterministic results.

 @param maxRetries - Maximum number of retries. Set to 0 to disable retries. Default: 2.
 @param abortSignal - An optional abort signal that can be used to cancel the call.
 @param headers - Additional HTTP headers to be sent with the request. Only applicable for HTTP-based providers.

 @param schema - The schema of the object that the model should generate.
 @param schemaName - Optional name of the output that should be generated.
 Used by some providers for additional LLM guidance, e.g.
 via tool or schema name.
 @param schemaDescription - Optional description of the output that should be generated.
 Used by some providers for additional LLM guidance, e.g.
 via tool or schema description.

 @param output - The type of the output.

 - 'object': The output is an object.
 - 'array': The output is an array.
 - 'enum': The output is an enum.
 - 'no-schema': The output is not a schema.

 @param experimental_telemetry - Optional telemetry configuration (experimental).

 @param providerOptions - Additional provider-specific options. They are passed through
 to the provider from the AI SDK and enable provider-specific
 functionality that can be fully encapsulated in the provider.

 @returns
 A result object for accessing the partial object stream and additional information.
 */
export declare function streamObject<SCHEMA extends FlexibleSchema<unknown> = FlexibleSchema<JSONValue_2>, OUTPUT extends 'object' | 'array' | 'enum' | 'no-schema' = InferSchema<SCHEMA> extends string ? 'enum' : 'object', RESULT = OUTPUT extends 'array' ? Array<InferSchema<SCHEMA>> : InferSchema<SCHEMA>>(options: Omit<CallSettings, 'stopSequences'> & Prompt & (OUTPUT extends 'enum' ? {
    /**
     The enum values that the model should use.
     */
    enum: Array<RESULT>;
    mode?: 'json';
    output: 'enum';
} : OUTPUT extends 'no-schema' ? {} : {
    /**
     The schema of the object that the model should generate.
     */
    schema: SCHEMA;
    /**
     Optional name of the output that should be generated.
     Used by some providers for additional LLM guidance, e.g.
     via tool or schema name.
     */
    schemaName?: string;
    /**
     Optional description of the output that should be generated.
     Used by some providers for additional LLM guidance, e.g.
     via tool or schema description.
     */
    schemaDescription?: string;
    /**
     The mode to use for object generation.

     The schema is converted into a JSON schema and used in one of the following ways

     - 'auto': The provider will choose the best mode for the model.
     - 'tool': A tool with the JSON schema as parameters is provided and the provider is instructed to use it.
     - 'json': The JSON schema and an instruction are injected into the prompt. If the provider supports JSON mode, it is enabled. If the provider supports JSON grammars, the grammar is used.

     Please note that most providers do not support all modes.

     Default and recommended: 'auto' (best mode for the model).
     */
    mode?: 'auto' | 'json' | 'tool';
}) & {
    output?: OUTPUT;
    /**
     The language model to use.
     */
    model: LanguageModel;
    /**
     A function that attempts to repair the raw output of the model
     to enable JSON parsing.
     */
    experimental_repairText?: RepairTextFunction;
    /**
     Optional telemetry configuration (experimental).
     */
    experimental_telemetry?: TelemetrySettings;
    /**
     Custom download function to use for URLs.

     By default, files are downloaded if the model does not support the URL for the given media type.
     */
    experimental_download?: Experimental_DownloadFunction | undefined;
    /**
     Additional provider-specific options. They are passed through
     to the provider from the AI SDK and enable provider-specific
     functionality that can be fully encapsulated in the provider.
     */
    providerOptions?: ProviderOptions;
    /**
     Callback that is invoked when an error occurs during streaming.
     You can use it to log errors.
     The stream processing will pause until the callback promise is resolved.
     */
    onError?: StreamObjectOnErrorCallback;
    /**
     Callback that is called when the LLM response and the final object validation are finished.
     */
    onFinish?: StreamObjectOnFinishCallback<RESULT>;
    /**
     * Internal. For test use only. May change without notice.
     */
    _internal?: {
        generateId?: () => string;
        currentDate?: () => Date;
        now?: () => number;
    };
}): StreamObjectResult<OUTPUT extends 'enum' ? string : OUTPUT extends 'array' ? RESULT : DeepPartial<RESULT>, OUTPUT extends 'array' ? RESULT : RESULT, OUTPUT extends 'array' ? RESULT extends Array<infer U> ? AsyncIterableStream<U> : never : never>;

/**
 Callback that is set using the `onError` option.

 @param event - The event that is passed to the callback.
 */
declare type StreamObjectOnErrorCallback = (event: {
    error: unknown;
}) => Promise<void> | void;

/**
 Callback that is set using the `onFinish` option.

 @param event - The event that is passed to the callback.
 */
export declare type StreamObjectOnFinishCallback<RESULT> = (event: {
    /**
     The token usage of the generated response.
     */
    usage: LanguageModelUsage;
    /**
     The generated object. Can be undefined if the final object does not match the schema.
     */
    object: RESULT | undefined;
    /**
     Optional error object. This is e.g. a TypeValidationError when the final object does not match the schema.
     */
    error: unknown | undefined;
    /**
     Response metadata.
     */
    response: LanguageModelResponseMetadata;
    /**
     Warnings from the model provider (e.g. unsupported settings).
     */
    warnings?: CallWarning[];
    /**
     Additional provider-specific metadata. They are passed through
     to the provider from the AI SDK and enable provider-specific
     functionality that can be fully encapsulated in the provider.
     */
    providerMetadata: ProviderMetadata | undefined;
}) => Promise<void> | void;

/**
 The result of a `streamObject` call that contains the partial object stream and additional information.
 */
export declare interface StreamObjectResult<PARTIAL, RESULT, ELEMENT_STREAM> {
    /**
     Warnings from the model provider (e.g. unsupported settings)
     */
    readonly warnings: Promise<CallWarning[] | undefined>;
    /**
     The token usage of the generated response. Resolved when the response is finished.
     */
    readonly usage: Promise<LanguageModelUsage>;
    /**
     Additional provider-specific metadata. They are passed through
     from the provider to the AI SDK and enable provider-specific
     results that can be fully encapsulated in the provider.
     */
    readonly providerMetadata: Promise<ProviderMetadata | undefined>;
    /**
     Additional request information from the last step.
     */
    readonly request: Promise<LanguageModelRequestMetadata>;
    /**
     Additional response information.
     */
    readonly response: Promise<LanguageModelResponseMetadata>;
    /**
     The reason why the generation finished. Taken from the last step.

     Resolved when the response is finished.
     */
    readonly finishReason: Promise<FinishReason>;
    /**
     The generated object (typed according to the schema). Resolved when the response is finished.
     */
    readonly object: Promise<RESULT>;
    /**
     Stream of partial objects. It gets more complete as the stream progresses.

     Note that the partial object is not validated.
     If you want to be certain that the actual content matches your schema, you need to implement your own validation for partial results.
     */
    readonly partialObjectStream: AsyncIterableStream<PARTIAL>;
    /**
     * Stream over complete array elements. Only available if the output strategy is set to `array`.
     */
    readonly elementStream: ELEMENT_STREAM;
    /**
     Text stream of the JSON representation of the generated object. It contains text chunks.
     When the stream is finished, the object is valid JSON that can be parsed.
     */
    readonly textStream: AsyncIterableStream<string>;
    /**
     Stream of different types of events, including partial objects, errors, and finish events.
     Only errors that stop the stream, such as network errors, are thrown.
     */
    readonly fullStream: AsyncIterableStream<ObjectStreamPart<PARTIAL>>;
    /**
     Writes text delta output to a Node.js response-like object.
     It sets a `Content-Type` header to `text/plain; charset=utf-8` and
     writes each text delta as a separate chunk.

     @param response A Node.js response-like object (ServerResponse).
     @param init Optional headers, status code, and status text.
     */
    pipeTextStreamToResponse(response: ServerResponse_2, init?: ResponseInit): void;
    /**
     Creates a simple text stream response.
     The response has a `Content-Type` header set to `text/plain; charset=utf-8`.
     Each text delta is encoded as UTF-8 and sent as a separate chunk.
     Non-text-delta events are ignored.

     @param init Optional headers, status code, and status text.
     */
    toTextStreamResponse(init?: ResponseInit): Response;
}

/**
 * Options for the EventSourceParserStream.
 *
 * @public
 */
declare interface StreamOptions {
    /**
     * Behavior when a parsing error occurs.
     *
     * - A custom function can be provided to handle the error.
     * - `'terminate'` will error the stream and stop parsing.
     * - Any other value will ignore the error and continue parsing.
     *
     * @defaultValue `undefined`
     */
    onError?: ('terminate' | ((error: Error) => void)) | undefined
    /**
     * Callback for when a reconnection interval is sent from the server.
     *
     * @param retry - The number of milliseconds to wait before reconnecting.
     */
    onRetry?: ((retry: number) => void) | undefined
    /**
     * Callback for when a comment is encountered in the stream.
     *
     * @param comment - The comment encountered in the stream.
     */
    onComment?: ((comment: string) => void) | undefined
}

/**
 Generate a text and call tools for a given prompt using a language model.

 This function streams the output. If you do not want to stream the output, use `generateText` instead.

 @param model - The language model to use.
 @param tools - Tools that are accessible to and can be called by the model. The model needs to support calling tools.

 @param system - A system message that will be part of the prompt.
 @param prompt - A simple text prompt. You can either use `prompt` or `messages` but not both.
 @param messages - A list of messages. You can either use `prompt` or `messages` but not both.

 @param maxOutputTokens - Maximum number of tokens to generate.
 @param temperature - Temperature setting.
 The value is passed through to the provider. The range depends on the provider and model.
 It is recommended to set either `temperature` or `topP`, but not both.
 @param topP - Nucleus sampling.
 The value is passed through to the provider. The range depends on the provider and model.
 It is recommended to set either `temperature` or `topP`, but not both.
 @param topK - Only sample from the top K options for each subsequent token.
 Used to remove "long tail" low probability responses.
 Recommended for advanced use cases only. You usually only need to use temperature.
 @param presencePenalty - Presence penalty setting.
 It affects the likelihood of the model to repeat information that is already in the prompt.
 The value is passed through to the provider. The range depends on the provider and model.
 @param frequencyPenalty - Frequency penalty setting.
 It affects the likelihood of the model to repeatedly use the same words or phrases.
 The value is passed through to the provider. The range depends on the provider and model.
 @param stopSequences - Stop sequences.
 If set, the model will stop generating text when one of the stop sequences is generated.
 @param seed - The seed (integer) to use for random sampling.
 If set and supported by the model, calls will generate deterministic results.

 @param maxRetries - Maximum number of retries. Set to 0 to disable retries. Default: 2.
 @param abortSignal - An optional abort signal that can be used to cancel the call.
 @param headers - Additional HTTP headers to be sent with the request. Only applicable for HTTP-based providers.

 @param maxSteps - Maximum number of sequential LLM calls (steps), e.g. when you use tool calls.

 @param onChunk - Callback that is called for each chunk of the stream. The stream processing will pause until the callback promise is resolved.
 @param onError - Callback that is called when an error occurs during streaming. You can use it to log errors.
 @param onStepFinish - Callback that is called when each step (LLM call) is finished, including intermediate steps.
 @param onFinish - Callback that is called when the LLM response and all request tool executions
 (for tools that have an `execute` function) are finished.

 @return
 A result object for accessing different stream types and additional information.
 */
export declare function streamText<TOOLS extends ToolSet, OUTPUT = never, PARTIAL_OUTPUT = never>({ model, tools, toolChoice, system, prompt, messages, maxRetries, abortSignal, headers, stopWhen, experimental_output: output, experimental_telemetry: telemetry, prepareStep, providerOptions, experimental_activeTools, activeTools, experimental_repairToolCall: repairToolCall, experimental_transform: transform, experimental_download: download, includeRawChunks, onChunk, onError, onFinish, onAbort, onStepFinish, experimental_context, _internal: { now, generateId, currentDate, }, ...settings }: CallSettings & Prompt & {
    /**
     The language model to use.
     */
    model: LanguageModel;
    /**
     The tools that the model can call. The model needs to support calling tools.
     */
    tools?: TOOLS;
    /**
     The tool choice strategy. Default: 'auto'.
     */
    toolChoice?: ToolChoice<TOOLS>;
    /**
     Condition for stopping the generation when there are tool results in the last step.
     When the condition is an array, any of the conditions can be met to stop the generation.

     @default stepCountIs(1)
     */
    stopWhen?: StopCondition<NoInfer<TOOLS>> | Array<StopCondition<NoInfer<TOOLS>>>;
    /**
     Optional telemetry configuration (experimental).
     */
    experimental_telemetry?: TelemetrySettings;
    /**
     Additional provider-specific options. They are passed through
     to the provider from the AI SDK and enable provider-specific
     functionality that can be fully encapsulated in the provider.
     */
    providerOptions?: ProviderOptions;
    /**
     * @deprecated Use `activeTools` instead.
     */
    experimental_activeTools?: Array<keyof NoInfer<TOOLS>>;
    /**
     Limits the tools that are available for the model to call without
     changing the tool call and result types in the result.
     */
    activeTools?: Array<keyof NoInfer<TOOLS>>;
    /**
     Optional specification for parsing structured outputs from the LLM response.
     */
    experimental_output?: Output_2<OUTPUT, PARTIAL_OUTPUT>;
    /**
     Optional function that you can use to provide different settings for a step.

     @param options - The options for the step.
     @param options.steps - The steps that have been executed so far.
     @param options.stepNumber - The number of the step that is being executed.
     @param options.model - The model that is being used.

     @returns An object that contains the settings for the step.
     If you return undefined (or for undefined settings), the settings from the outer level will be used.
     */
    prepareStep?: PrepareStepFunction<NoInfer<TOOLS>>;
    /**
     A function that attempts to repair a tool call that failed to parse.
     */
    experimental_repairToolCall?: ToolCallRepairFunction<TOOLS>;
    /**
     Optional stream transformations.
     They are applied in the order they are provided.
     The stream transformations must maintain the stream structure for streamText to work correctly.
     */
    experimental_transform?: StreamTextTransform<TOOLS> | Array<StreamTextTransform<TOOLS>>;
    /**
     Custom download function to use for URLs.

     By default, files are downloaded if the model does not support the URL for the given media type.
     */
    experimental_download?: Experimental_DownloadFunction | undefined;
    /**
     Whether to include raw chunks from the provider in the stream.
     When enabled, you will receive raw chunks with type 'raw' that contain the unprocessed data from the provider.
     This allows access to cutting-edge provider features not yet wrapped by the AI SDK.
     Defaults to false.
     */
    includeRawChunks?: boolean;
    /**
     Callback that is called for each chunk of the stream.
     The stream processing will pause until the callback promise is resolved.
     */
    onChunk?: StreamTextOnChunkCallback<TOOLS>;
    /**
     Callback that is invoked when an error occurs during streaming.
     You can use it to log errors.
     The stream processing will pause until the callback promise is resolved.
     */
    onError?: StreamTextOnErrorCallback;
    /**
     Callback that is called when the LLM response and all request tool executions
     (for tools that have an `execute` function) are finished.

     The usage is the combined usage of all steps.
     */
    onFinish?: StreamTextOnFinishCallback<TOOLS>;
    onAbort?: StreamTextOnAbortCallback<TOOLS>;
    /**
     Callback that is called when each step (LLM call) is finished, including intermediate steps.
     */
    onStepFinish?: StreamTextOnStepFinishCallback<TOOLS>;
    /**
     * Context that is passed into tool execution.
     *
     * Experimental (can break in patch releases).
     *
     * @default undefined
     */
    experimental_context?: unknown;
    /**
     Internal. For test use only. May change without notice.
     */
    _internal?: {
        now?: () => number;
        generateId?: IdGenerator;
        currentDate?: () => Date;
    };
}): StreamTextResult<TOOLS, PARTIAL_OUTPUT>;

/**
 Callback that is set using the `onAbort` option.

 @param event - The event that is passed to the callback.
 */
declare type StreamTextOnAbortCallback<TOOLS extends ToolSet> = (event: {
    /**
     Details for all previously finished steps.
     */
    readonly steps: StepResult<TOOLS>[];
}) => PromiseLike<void> | void;

/**
 Callback that is set using the `onChunk` option.

 @param event - The event that is passed to the callback.
 */
export declare type StreamTextOnChunkCallback<TOOLS extends ToolSet> = (event: {
    chunk: Extract<TextStreamPart<TOOLS>, {
        type: 'text-delta' | 'reasoning-delta' | 'source' | 'tool-call' | 'tool-input-start' | 'tool-input-delta' | 'tool-result' | 'raw';
    }>;
}) => PromiseLike<void> | void;

/**
 Callback that is set using the `onError` option.

 @param event - The event that is passed to the callback.
 */
export declare type StreamTextOnErrorCallback = (event: {
    error: unknown;
}) => PromiseLike<void> | void;

/**
 Callback that is set using the `onFinish` option.

 @param event - The event that is passed to the callback.
 */
export declare type StreamTextOnFinishCallback<TOOLS extends ToolSet> = (event: StepResult<TOOLS> & {
    /**
     Details for all steps.
     */
    readonly steps: StepResult<TOOLS>[];
    /**
     Total usage for all steps. This is the sum of the usage of all steps.
     */
    readonly totalUsage: LanguageModelUsage;
}) => PromiseLike<void> | void;

/**
 Callback that is set using the `onStepFinish` option.

 @param stepResult - The result of the step.
 */
export declare type StreamTextOnStepFinishCallback<TOOLS extends ToolSet> = (stepResult: StepResult<TOOLS>) => PromiseLike<void> | void;

/**
 A result object for accessing different stream types and additional information.
 */
export declare interface StreamTextResult<TOOLS extends ToolSet, PARTIAL_OUTPUT> {
    /**
     The content that was generated in the last step.

     Automatically consumes the stream.
     */
    readonly content: Promise<Array<ContentPart<TOOLS>>>;
    /**
     The full text that has been generated by the last step.

     Automatically consumes the stream.
     */
    readonly text: Promise<string>;
    /**
     The full reasoning that the model has generated.

     Automatically consumes the stream.
     */
    readonly reasoning: Promise<Array<ReasoningOutput>>;
    /**
     The reasoning that has been generated by the last step.

     Automatically consumes the stream.
     */
    readonly reasoningText: Promise<string | undefined>;
    /**
     Files that have been generated by the model in the last step.

     Automatically consumes the stream.
     */
    readonly files: Promise<GeneratedFile[]>;
    /**
     Sources that have been used as references in the last step.

     Automatically consumes the stream.
     */
    readonly sources: Promise<Source[]>;
    /**
     The tool calls that have been executed in the last step.

     Automatically consumes the stream.
     */
    readonly toolCalls: Promise<TypedToolCall<TOOLS>[]>;
    /**
     The static tool calls that have been executed in the last step.

     Automatically consumes the stream.
     */
    readonly staticToolCalls: Promise<StaticToolCall<TOOLS>[]>;
    /**
     The dynamic tool calls that have been executed in the last step.

     Automatically consumes the stream.
     */
    readonly dynamicToolCalls: Promise<DynamicToolCall[]>;
    /**
     The static tool results that have been generated in the last step.

     Automatically consumes the stream.
     */
    readonly staticToolResults: Promise<StaticToolResult<TOOLS>[]>;
    /**
     The dynamic tool results that have been generated in the last step.

     Automatically consumes the stream.
     */
    readonly dynamicToolResults: Promise<DynamicToolResult[]>;
    /**
     The tool results that have been generated in the last step.

     Automatically consumes the stream.
     */
    readonly toolResults: Promise<TypedToolResult<TOOLS>[]>;
    /**
     The reason why the generation finished. Taken from the last step.

     Automatically consumes the stream.
     */
    readonly finishReason: Promise<FinishReason>;
    /**
     The token usage of the last step.

     Automatically consumes the stream.
     */
    readonly usage: Promise<LanguageModelUsage>;
    /**
     The total token usage of the generated response.
     When there are multiple steps, the usage is the sum of all step usages.

     Automatically consumes the stream.
     */
    readonly totalUsage: Promise<LanguageModelUsage>;
    /**
     Warnings from the model provider (e.g. unsupported settings) for the first step.

     Automatically consumes the stream.
     */
    readonly warnings: Promise<CallWarning[] | undefined>;
    /**
     Details for all steps.
     You can use this to get information about intermediate steps,
     such as the tool calls or the response headers.

     Automatically consumes the stream.
     */
    readonly steps: Promise<Array<StepResult<TOOLS>>>;
    /**
     Additional request information from the last step.

     Automatically consumes the stream.
     */
    readonly request: Promise<LanguageModelRequestMetadata>;
    /**
     Additional response information from the last step.

     Automatically consumes the stream.
     */
    readonly response: Promise<LanguageModelResponseMetadata & {
        /**
         The response messages that were generated during the call. It consists of an assistant message,
         potentially containing tool calls.

         When there are tool results, there is an additional tool message with the tool results that are available.
         If there are tools that do not have execute functions, they are not included in the tool results and
         need to be added separately.
         */
        messages: Array<ResponseMessage>;
    }>;
    /**
     Additional provider-specific metadata from the last step.
     Metadata is passed through from the provider to the AI SDK and
     enables provider-specific results that can be fully encapsulated in the provider.
     */
    readonly providerMetadata: Promise<ProviderMetadata | undefined>;
    /**
     A text stream that returns only the generated text deltas. You can use it
     as either an AsyncIterable or a ReadableStream. When an error occurs, the
     stream will throw the error.
     */
    readonly textStream: AsyncIterableStream<string>;
    /**
     A stream with all events, including text deltas, tool calls, tool results, and
     errors.
     You can use it as either an AsyncIterable or a ReadableStream.
     Only errors that stop the stream, such as network errors, are thrown.
     */
    readonly fullStream: AsyncIterableStream<TextStreamPart<TOOLS>>;
    /**
     A stream of partial outputs. It uses the `experimental_output` specification.
     */
    readonly experimental_partialOutputStream: AsyncIterableStream<PARTIAL_OUTPUT>;
    /**
     Consumes the stream without processing the parts.
     This is useful to force the stream to finish.
     It effectively removes the backpressure and allows the stream to finish,
     triggering the `onFinish` callback and the promise resolution.

     If an error occurs, it is passed to the optional `onError` callback.
     */
    consumeStream(options?: ConsumeStreamOptions): Promise<void>;
    /**
     Converts the result to a UI message stream.

     @return A UI message stream.
     */
    toUIMessageStream<UI_MESSAGE extends UIMessage>(options?: UIMessageStreamOptions<UI_MESSAGE>): AsyncIterableStream<InferUIMessageChunk<UI_MESSAGE>>;
    /**
     *Writes UI message stream output to a Node.js response-like object.
     */
    pipeUIMessageStreamToResponse<UI_MESSAGE extends UIMessage>(response: ServerResponse, options?: UIMessageStreamResponseInit & UIMessageStreamOptions<UI_MESSAGE>): void;
    /**
     Writes text delta output to a Node.js response-like object.
     It sets a `Content-Type` header to `text/plain; charset=utf-8` and
     writes each text delta as a separate chunk.

     @param response A Node.js response-like object (ServerResponse).
     @param init Optional headers, status code, and status text.
     */
    pipeTextStreamToResponse(response: ServerResponse, init?: ResponseInit): void;
    /**
     Converts the result to a streamed response object with a stream data part stream.

     @return A response object.
     */
    toUIMessageStreamResponse<UI_MESSAGE extends UIMessage>(options?: UIMessageStreamResponseInit & UIMessageStreamOptions<UI_MESSAGE>): Response;
    /**
     Creates a simple text stream response.
     Each text delta is encoded as UTF-8 and sent as a separate chunk.
     Non-text-delta events are ignored.
     @param init Optional headers, status code, and status text.
     */
    toTextStreamResponse(init?: ResponseInit): Response;
}

/**
 A transformation that is applied to the stream.

 @param stopStream - A function that stops the source stream.
 @param tools - The tools that are accessible to and can be called by the model. The model needs to support calling tools.
 */
export declare type StreamTextTransform<TOOLS extends ToolSet> = (options: {
    tools: TOOLS;
    stopStream: () => void;
}) => TransformStream<TextStreamPart<TOOLS>, TextStreamPart<TOOLS>>;

declare const symbol$1: unique symbol;

declare const symbol$1_2: unique symbol;

declare const symbol$2: unique symbol;

declare const symbol$2_2: unique symbol;

declare const symbol$3: unique symbol;

declare const symbol$3_2: unique symbol;

declare const symbol$4: unique symbol;

declare const symbol$4_2: unique symbol;

declare const symbol$5: unique symbol;

declare const symbol$5_2: unique symbol;

declare const symbol$6: unique symbol;

declare const symbol$6_2: unique symbol;

declare const symbol$7: unique symbol;

declare const symbol$7_2: unique symbol;

declare const symbol$8: unique symbol;

declare const symbol$8_2: unique symbol;

declare const symbol$9: unique symbol;

declare const symbol$9_2: unique symbol;

declare const symbol$a: unique symbol;

declare const symbol$a_2: unique symbol;

declare const symbol$b: unique symbol;

declare const symbol$b_2: unique symbol;

declare const symbol$c: unique symbol;

declare const symbol$c_2: unique symbol;

declare const symbol$d: unique symbol;

declare const symbol$d_2: unique symbol;

declare const symbol$e: unique symbol;

declare const symbol: unique symbol;

declare const symbol_2: unique symbol;

/**
 A system message. It can contain system information.

 Note: using the "system" part of the prompt is strongly preferred
 to increase the resilience against prompt injection attacks,
 and because not all providers support several system messages.
 */
export declare type SystemModelMessage = {
    role: 'system';
    content: string;
    /**
     Additional provider-specific metadata. They are passed through
     to the provider from the AI SDK and enable provider-specific
     functionality that can be fully encapsulated in the provider.
     */
    providerOptions?: ProviderOptions;
};

export declare const systemModelMessageSchema: z.ZodType<SystemModelMessage>;

/**
 * Telemetry configuration.
 */
export declare type TelemetrySettings = {
    /**
     * Enable or disable telemetry. Disabled by default while experimental.
     */
    isEnabled?: boolean;
    /**
     * Enable or disable input recording. Enabled by default.
     *
     * You might want to disable input recording to avoid recording sensitive
     * information, to reduce data transfers, or to increase performance.
     */
    recordInputs?: boolean;
    /**
     * Enable or disable output recording. Enabled by default.
     *
     * You might want to disable output recording to avoid recording sensitive
     * information, to reduce data transfers, or to increase performance.
     */
    recordOutputs?: boolean;
    /**
     * Identifier for this function. Used to group telemetry data by function.
     */
    functionId?: string;
    /**
     * Additional information to include in the telemetry data.
     */
    metadata?: Record<string, AttributeValue>;
    /**
     * A custom tracer to use for the telemetry data.
     */
    tracer?: Tracer;
};

/**
 Text content part of a prompt. It contains a string of text.
 */
export declare interface TextPart {
    type: 'text';
    /**
     The text content.
     */
    text: string;
    /**
     Additional provider-specific metadata. They are passed through
     to the provider from the AI SDK and enable provider-specific
     functionality that can be fully encapsulated in the provider.
     */
    providerOptions?: ProviderOptions;
}

export declare class TextStreamChatTransport<UI_MESSAGE extends UIMessage> extends HttpChatTransport<UI_MESSAGE> {
    constructor(options?: HttpChatTransportInitOptions<UI_MESSAGE>);
    protected processResponseStream(stream: ReadableStream<Uint8Array<ArrayBufferLike>>): ReadableStream<UIMessageChunk>;
}

export declare type TextStreamPart<TOOLS extends ToolSet> = {
    type: 'text-start';
    id: string;
    providerMetadata?: ProviderMetadata;
} | {
    type: 'text-end';
    id: string;
    providerMetadata?: ProviderMetadata;
} | {
    type: 'text-delta';
    id: string;
    providerMetadata?: ProviderMetadata;
    text: string;
} | {
    type: 'reasoning-start';
    id: string;
    providerMetadata?: ProviderMetadata;
} | {
    type: 'reasoning-end';
    id: string;
    providerMetadata?: ProviderMetadata;
} | {
    type: 'reasoning-delta';
    providerMetadata?: ProviderMetadata;
    id: string;
    text: string;
} | {
    type: 'tool-input-start';
    id: string;
    toolName: string;
    providerMetadata?: ProviderMetadata;
    providerExecuted?: boolean;
    dynamic?: boolean;
} | {
    type: 'tool-input-end';
    id: string;
    providerMetadata?: ProviderMetadata;
} | {
    type: 'tool-input-delta';
    id: string;
    delta: string;
    providerMetadata?: ProviderMetadata;
} | ({
    type: 'source';
} & Source) | {
    type: 'file';
    file: GeneratedFile;
} | ({
    type: 'tool-call';
} & TypedToolCall<TOOLS>) | ({
    type: 'tool-result';
} & TypedToolResult<TOOLS>) | ({
    type: 'tool-error';
} & TypedToolError<TOOLS>) | {
    type: 'start-step';
    request: LanguageModelRequestMetadata;
    warnings: CallWarning[];
} | {
    type: 'finish-step';
    response: LanguageModelResponseMetadata;
    usage: LanguageModelUsage;
    finishReason: FinishReason;
    providerMetadata: ProviderMetadata | undefined;
} | {
    type: 'start';
} | {
    type: 'finish';
    finishReason: FinishReason;
    totalUsage: LanguageModelUsage;
} | {
    type: 'abort';
} | {
    type: 'error';
    error: unknown;
} | {
    type: 'raw';
    rawValue: unknown;
};

/**
 * A text part of a message.
 */
export declare type TextUIPart = {
    type: 'text';
    /**
     * The text content.
     */
    text: string;
    /**
     * The state of the text part.
     */
    state?: 'streaming' | 'done';
    /**
     * The provider metadata.
     */
    providerMetadata?: ProviderMetadata;
};

/**
 * Defines TimeInput.
 *
 * hrtime, epoch milliseconds, performance.now() or Date
 */
declare type TimeInput = HrTime | number | Date;

/**
 A tool contains the description and the schema of the input that the tool expects.
 This enables the language model to generate the input.

 The tool can also contain an optional execute function for the actual execution function of the tool.
 */
export declare type Tool<INPUT extends JSONValue_2 | unknown | never = any, OUTPUT extends JSONValue_2 | unknown | never = any> = {
    /**
     An optional description of what the tool does.
     Will be used by the language model to decide whether to use the tool.
     Not used for provider-defined tools.
     */
    description?: string;
    /**
     Additional provider-specific metadata. They are passed through
     to the provider from the AI SDK and enable provider-specific
     functionality that can be fully encapsulated in the provider.
     */
    providerOptions?: ProviderOptions;
    /**
     The schema of the input that the tool expects. The language model will use this to generate the input.
     It is also used to validate the output of the language model.
     Use descriptions to make the input understandable for the language model.
     */
    inputSchema: FlexibleSchema<INPUT>;
    /**
     * Optional function that is called when the argument streaming starts.
     * Only called when the tool is used in a streaming context.
     */
    onInputStart?: (options: ToolCallOptions) => void | PromiseLike<void>;
    /**
     * Optional function that is called when an argument streaming delta is available.
     * Only called when the tool is used in a streaming context.
     */
    onInputDelta?: (options: {
        inputTextDelta: string;
    } & ToolCallOptions) => void | PromiseLike<void>;
    /**
     * Optional function that is called when a tool call can be started,
     * even if the execute function is not provided.
     */
    onInputAvailable?: (options: {
        input: [INPUT] extends [never] ? undefined : INPUT;
    } & ToolCallOptions) => void | PromiseLike<void>;
} & ToolOutputProperties<INPUT, OUTPUT> & {
    /**
     Optional conversion function that maps the tool result to an output that can be used by the language model.

     If not provided, the tool result will be sent as a JSON object.
     */
    toModelOutput?: (output: 0 extends 1 & OUTPUT ? any : [OUTPUT] extends [never] ? any : NoInfer<OUTPUT>) => LanguageModelV2ToolResultPart['output'];
} & ({
    /**
     Tool with user-defined input and output schemas.
     */
    type?: undefined | 'function';
} | {
    /**
     Tool that is defined at runtime (e.g. an MCP tool).
     The types of input and output are not known at development time.
     */
    type: 'dynamic';
} | {
    /**
     Tool with provider-defined input and output schemas.
     */
    type: 'provider-defined';
    /**
     The ID of the tool. Should follow the format `<provider-name>.<unique-tool-name>`.
     */
    id: `${string}.${string}`;
    /**
     The name of the tool that the user must use in the tool set.
     */
    name: string;
    /**
     The arguments for configuring the tool. Must match the expected arguments defined by the provider for this tool.
     */
    args: Record<string, unknown>;
});

/**
 Helper function for inferring the execute args of a tool.
 */
export declare function tool<INPUT, OUTPUT>(tool: Tool<INPUT, OUTPUT>): Tool<INPUT, OUTPUT>;

export declare function tool<INPUT>(tool: Tool<INPUT, never>): Tool<INPUT, never>;

export declare function tool<OUTPUT>(tool: Tool<never, OUTPUT>): Tool<never, OUTPUT>;

export declare function tool(tool: Tool<never, never>): Tool<never, never>;

/**
 Typed tool call that is returned by generateText and streamText.
 It contains the tool call ID, the tool name, and the tool arguments.
 */
declare interface ToolCall<NAME extends string, INPUT> {
    /**
     ID of the tool call. This ID is used to match the tool call with the tool result.
     */
    toolCallId: string;
    /**
     Name of the tool that is being called.
     */
    toolName: NAME;
    /**
     Arguments of the tool call. This is a JSON-serializable object that matches the tool's input schema.
     */
    input: INPUT;
    /**
     * Whether the tool call will be executed by the provider.
     * If this flag is not set or is false, the tool call will be executed by the client.
     */
    providerExecuted?: boolean;
    /**
     * Whether the tool is dynamic.
     */
    dynamic?: boolean;
}

/**
 * Additional options that are sent into each tool call.
 */
export declare interface ToolCallOptions {
    /**
     * The ID of the tool call. You can use it e.g. when sending tool-call related information with stream data.
     */
    toolCallId: string;
    /**
     * Messages that were sent to the language model to initiate the response that contained the tool call.
     * The messages **do not** include the system prompt nor the assistant response that contained the tool call.
     */
    messages: ModelMessage[];
    /**
     * An optional abort signal that indicates that the overall operation should be aborted.
     */
    abortSignal?: AbortSignal;
    /**
     * Additional context.
     *
     * Experimental (can break in patch releases).
     */
    experimental_context?: unknown;
}

/**
 Tool call content part of a prompt. It contains a tool call (usually generated by the AI model).
 */
export declare interface ToolCallPart {
    type: 'tool-call';
    /**
     ID of the tool call. This ID is used to match the tool call with the tool result.
     */
    toolCallId: string;
    /**
     Name of the tool that is being called.
     */
    toolName: string;
    /**
     Arguments of the tool call. This is a JSON-serializable object that matches the tool's input schema.
     */
    input: unknown;
    /**
     Additional provider-specific metadata. They are passed through
     to the provider from the AI SDK and enable provider-specific
     functionality that can be fully encapsulated in the provider.
     */
    providerOptions?: ProviderOptions;
    /**
     Whether the tool call was executed by the provider.
     */
    providerExecuted?: boolean;
}

export declare class ToolCallRepairError extends AISDKError {
    private readonly [symbol$6_2];
    readonly originalError: NoSuchToolError | InvalidToolInputError;
    constructor({ cause, originalError, message, }: {
        message?: string;
        cause: unknown;
        originalError: NoSuchToolError | InvalidToolInputError;
    });
    static isInstance(error: unknown): error is ToolCallRepairError;
}

/**
 * A function that attempts to repair a tool call that failed to parse.
 *
 * It receives the error and the context as arguments and returns the repair
 * tool call JSON as text.
 *
 * @param options.system - The system prompt.
 * @param options.messages - The messages in the current generation step.
 * @param options.toolCall - The tool call that failed to parse.
 * @param options.tools - The tools that are available.
 * @param options.inputSchema - A function that returns the JSON Schema for a tool.
 * @param options.error - The error that occurred while parsing the tool call.
 */
export declare type ToolCallRepairFunction<TOOLS extends ToolSet> = (options: {
    system: string | undefined;
    messages: ModelMessage[];
    toolCall: LanguageModelV2ToolCall;
    tools: TOOLS;
    inputSchema: (options: {
        toolName: string;
    }) => JSONSchema7;
    error: NoSuchToolError | InvalidToolInputError;
}) => Promise<LanguageModelV2ToolCall | null>;

/**
 Tool choice for the generation. It supports the following settings:

 - `auto` (default): the model can choose whether and which tools to call.
 - `required`: the model must call a tool. It can choose which tool to call.
 - `none`: the model must not call tools
 - `{ type: 'tool', toolName: string (typed) }`: the model must call the specified tool
 */
export declare type ToolChoice<TOOLS extends Record<string, unknown>> = 'auto' | 'none' | 'required' | {
    type: 'tool';
    toolName: Extract<keyof TOOLS, string>;
};

/**
 Content of a tool message. It is an array of tool result parts.
 */
export declare type ToolContent = Array<ToolResultPart>;

export declare type ToolExecuteFunction<INPUT, OUTPUT> = (input: INPUT, options: ToolCallOptions) => AsyncIterable<OUTPUT> | PromiseLike<OUTPUT> | OUTPUT;

/**
 A tool message. It contains the result of one or more tool calls.
 */
export declare type ToolModelMessage = {
    role: 'tool';
    content: ToolContent;
    /**
     Additional provider-specific metadata. They are passed through
     to the provider from the AI SDK and enable provider-specific
     functionality that can be fully encapsulated in the provider.
     */
    providerOptions?: ProviderOptions;
};

export declare const toolModelMessageSchema: z.ZodType<ToolModelMessage>;

declare type ToolOutputProperties<INPUT, OUTPUT> = NeverOptional<OUTPUT, {
    /**
     An async function that is called with the arguments from the tool call and produces a result.
     If not provided, the tool will not be executed automatically.

     @args is the input of the tool call.
     @options.abortSignal is a signal that can be used to abort the tool call.
     */
    execute: ToolExecuteFunction<INPUT, OUTPUT>;
    outputSchema?: FlexibleSchema<OUTPUT>;
} | {
    outputSchema: FlexibleSchema<OUTPUT>;
    execute?: never;
}>;

/**
 Typed tool result that is returned by `generateText` and `streamText`.
 It contains the tool call ID, the tool name, the tool arguments, and the tool result.
 */
declare interface ToolResult<NAME extends string, INPUT, OUTPUT> {
    /**
     ID of the tool call. This ID is used to match the tool call with the tool result.
     */
    toolCallId: string;
    /**
     Name of the tool that was called.
     */
    toolName: NAME;
    /**
     Arguments of the tool call. This is a JSON-serializable object that matches the tool's input schema.
     */
    input: INPUT;
    /**
     Result of the tool call. This is the result of the tool's execution.
     */
    output: OUTPUT;
    /**
     * Whether the tool result has been executed by the provider.
     */
    providerExecuted?: boolean;
    /**
     * Whether the tool is dynamic.
     */
    dynamic?: boolean;
}

/**
 Tool result content part of a prompt. It contains the result of the tool call with the matching ID.
 */
export declare interface ToolResultPart {
    type: 'tool-result';
    /**
     ID of the tool call that this result is associated with.
     */
    toolCallId: string;
    /**
     Name of the tool that generated this result.
     */
    toolName: string;
    /**
     Result of the tool call. This is a JSON-serializable object.
     */
    output: LanguageModelV2ToolResultOutput;
    /**
     Additional provider-specific metadata. They are passed through
     to the provider from the AI SDK and enable provider-specific
     functionality that can be fully encapsulated in the provider.
     */
    providerOptions?: ProviderOptions;
}

export declare type ToolSet = Record<string, (Tool<never, never> | Tool<any, any> | Tool<any, never> | Tool<never, any>) & Pick<Tool<any, any>, 'execute' | 'onInputAvailable' | 'onInputStart' | 'onInputDelta'>>;

export declare type ToolUIPart<TOOLS extends UITools = UITools> = ValueOf<{
    [NAME in keyof TOOLS & string]: {
        type: `tool-${NAME}`;
    } & UIToolInvocation<TOOLS[NAME]>;
}>;

export declare class TooManyEmbeddingValuesForCallError extends AISDKError {
    private readonly [symbol$2];
    readonly provider: string;
    readonly modelId: string;
    readonly maxEmbeddingsPerCall: number;
    readonly values: Array<unknown>;
    constructor(options: {
        provider: string;
        modelId: string;
        maxEmbeddingsPerCall: number;
        values: Array<unknown>;
    });
    static isInstance(error: unknown): error is TooManyEmbeddingValuesForCallError;
}

/**
 * Tracer provides an interface for creating {@link Span}s.
 */
declare interface Tracer {
    /**
     * Starts a new {@link Span}. Start the span without setting it on context.
     *
     * This method do NOT modify the current Context.
     *
     * @param name The name of the span
     * @param [options] SpanOptions used for span creation
     * @param [context] Context to use to extract parent
     * @returns Span The newly created span
     * @example
     *     const span = tracer.startSpan('op');
     *     span.setAttribute('key', 'value');
     *     span.end();
     */
    startSpan(name: string, options?: SpanOptions, context?: Context): Span;
    /**
     * Starts a new {@link Span} and calls the given function passing it the
     * created span as first argument.
     * Additionally the new span gets set in context and this context is activated
     * for the duration of the function call.
     *
     * @param name The name of the span
     * @param [options] SpanOptions used for span creation
     * @param [context] Context to use to extract parent
     * @param fn function called in the context of the span and receives the newly created span as an argument
     * @returns return value of fn
     * @example
     *     const something = tracer.startActiveSpan('op', span => {
     *       try {
     *         do some work
     *         span.setStatus({code: SpanStatusCode.OK});
     *         return something;
     *       } catch (err) {
     *         span.setStatus({
     *           code: SpanStatusCode.ERROR,
     *           message: err.message,
     *         });
     *         throw err;
     *       } finally {
     *         span.end();
     *       }
     *     });
     *
     * @example
     *     const span = tracer.startActiveSpan('op', span => {
     *       try {
     *         do some work
     *         return span;
     *       } catch (err) {
     *         span.setStatus({
     *           code: SpanStatusCode.ERROR,
     *           message: err.message,
     *         });
     *         throw err;
     *       }
     *     });
     *     do some more work
     *     span.end();
     */
    startActiveSpan<F extends (span: Span) => unknown>(name: string, fn: F): ReturnType<F>;
    startActiveSpan<F extends (span: Span) => unknown>(name: string, options: SpanOptions, fn: F): ReturnType<F>;
    startActiveSpan<F extends (span: Span) => unknown>(name: string, options: SpanOptions, context: Context, fn: F): ReturnType<F>;
}

declare interface TraceState {
    /**
     * Create a new TraceState which inherits from this TraceState and has the
     * given key set.
     * The new entry will always be added in the front of the list of states.
     *
     * @param key key of the TraceState entry.
     * @param value value of the TraceState entry.
     */
    set(key: string, value: string): TraceState;
    /**
     * Return a new TraceState which inherits from this TraceState but does not
     * contain the given key.
     *
     * @param key the key for the TraceState entry to be removed.
     */
    unset(key: string): TraceState;
    /**
     * Returns the value to which the specified key is mapped, or `undefined` if
     * this map contains no mapping for the key.
     *
     * @param key with which the specified value is to be associated.
     * @returns the value to which the specified key is mapped, or `undefined` if
     *     this map contains no mapping for the key.
     */
    get(key: string): string | undefined;
    /**
     * Serializes the TraceState to a `list` as defined below. The `list` is a
     * series of `list-members` separated by commas `,`, and a list-member is a
     * key/value pair separated by an equals sign `=`. Spaces and horizontal tabs
     * surrounding `list-members` are ignored. There can be a maximum of 32
     * `list-members` in a `list`.
     *
     * @returns the serialized string.
     */
    serialize(): string;
}

/**
 Transcription model that is used by the AI SDK Core functions.
 */
export declare type TranscriptionModel = TranscriptionModelV2;

export declare type TranscriptionModelResponseMetadata = {
    /**
     Timestamp for the start of the generated response.
     */
    timestamp: Date;
    /**
     The ID of the response model that was used to generate the response.
     */
    modelId: string;
    /**
     Response headers.
     */
    headers?: Record<string, string>;
};

/**
 Transcription model specification version 2.
 */
declare type TranscriptionModelV2 = {
    /**
     The transcription model must specify which transcription model interface
     version it implements. This will allow us to evolve the transcription
     model interface and retain backwards compatibility. The different
     implementation versions can be handled as a discriminated union
     on our side.
     */
    readonly specificationVersion: 'v2';
    /**
     Name of the provider for logging purposes.
     */
    readonly provider: string;
    /**
     Provider-specific model ID for logging purposes.
     */
    readonly modelId: string;
    /**
     Generates a transcript.
     */
    doGenerate(options: TranscriptionModelV2CallOptions): PromiseLike<{
        /**
         * The complete transcribed text from the audio.
         */
        text: string;
        /**
         * Array of transcript segments with timing information.
         * Each segment represents a portion of the transcribed text with start and end times.
         */
        segments: Array<{
            /**
             * The text content of this segment.
             */
            text: string;
            /**
             * The start time of this segment in seconds.
             */
            startSecond: number;
            /**
             * The end time of this segment in seconds.
             */
            endSecond: number;
        }>;
        /**
         * The detected language of the audio content, as an ISO-639-1 code (e.g., 'en' for English).
         * May be undefined if the language couldn't be detected.
         */
        language: string | undefined;
        /**
         * The total duration of the audio file in seconds.
         * May be undefined if the duration couldn't be determined.
         */
        durationInSeconds: number | undefined;
        /**
         Warnings for the call, e.g. unsupported settings.
         */
        warnings: Array<TranscriptionModelV2CallWarning>;
        /**
         Optional request information for telemetry and debugging purposes.
         */
        request?: {
            /**
             Raw request HTTP body that was sent to the provider API as a string (JSON should be stringified).
             Non-HTTP(s) providers should not set this.
             */
            body?: string;
        };
        /**
         Response information for telemetry and debugging purposes.
         */
        response: {
            /**
             Timestamp for the start of the generated response.
             */
            timestamp: Date;
            /**
             The ID of the response model that was used to generate the response.
             */
            modelId: string;
            /**
             Response headers.
             */
            headers?: SharedV2Headers;
            /**
             Response body.
             */
            body?: unknown;
        };
        /**
         Additional provider-specific metadata. They are passed through
         from the provider to the AI SDK and enable provider-specific
         results that can be fully encapsulated in the provider.
         */
        providerMetadata?: Record<string, Record<string, JSONValue_2>>;
    }>;
};

declare type TranscriptionModelV2CallOptions = {
    /**
     Audio data to transcribe.
     Accepts a `Uint8Array` or `string`, where `string` is a base64 encoded audio file.
     */
    audio: Uint8Array | string;
    /**
     The IANA media type of the audio data.

     @see https://www.iana.org/assignments/media-types/media-types.xhtml
     */
    mediaType: string;
    /**
     Additional provider-specific options that are passed through to the provider
     as body parameters.

     The outer record is keyed by the provider name, and the inner
     record is keyed by the provider-specific metadata key.
     ```ts
     {
     "openai": {
     "timestampGranularities": ["word"]
     }
     }
     ```
     */
    providerOptions?: TranscriptionModelV2ProviderOptions;
    /**
     Abort signal for cancelling the operation.
     */
    abortSignal?: AbortSignal;
    /**
     Additional HTTP headers to be sent with the request.
     Only applicable for HTTP-based providers.
     */
    headers?: Record<string, string | undefined>;
};

/**
 Warning from the model provider for this call. The call will proceed, but e.g.
 some settings might not be supported, which can lead to suboptimal results.
 */
declare type TranscriptionModelV2CallWarning = {
    type: 'unsupported-setting';
    setting: keyof TranscriptionModelV2CallOptions;
    details?: string;
} | {
    type: 'other';
    message: string;
};

declare type TranscriptionModelV2ProviderOptions = Record<string, Record<string, JSONValue_2>>;

/**
 Warning from the model provider for this call. The call will proceed, but e.g.
 some settings might not be supported, which can lead to suboptimal results.
 */
export declare type TranscriptionWarning = TranscriptionModelV2CallWarning;

export declare type TypedToolCall<TOOLS extends ToolSet> = StaticToolCall<TOOLS> | DynamicToolCall;

export declare type TypedToolError<TOOLS extends ToolSet> = StaticToolError<TOOLS> | DynamicToolError;

export declare type TypedToolResult<TOOLS extends ToolSet> = StaticToolResult<TOOLS> | DynamicToolResult;

export declare class TypeValidationError extends AISDKError {
    private readonly [symbol$1];
    readonly value: unknown;
    constructor({ value, cause }: {
        value: unknown;
        cause: unknown;
    });
    static isInstance(error: unknown): error is TypeValidationError;
    /**
     * Wraps an error into a TypeValidationError.
     * If the cause is already a TypeValidationError with the same value, it returns the cause.
     * Otherwise, it creates a new TypeValidationError.
     *
     * @param {Object} params - The parameters for wrapping the error.
     * @param {unknown} params.value - The value that failed validation.
     * @param {unknown} params.cause - The original error or cause of the validation failure.
     * @returns {TypeValidationError} A TypeValidationError instance.
     */
    static wrap({ value, cause, }: {
        value: unknown;
        cause: unknown;
    }): TypeValidationError;
}

export declare const UI_MESSAGE_STREAM_HEADERS: {
    'content-type': string;
    'cache-control': string;
    connection: string;
    'x-vercel-ai-ui-message-stream': string;
    'x-accel-buffering': string;
};

export declare type UIDataPartSchemas = Record<string, Validator<any> | StandardSchemaV1<any>>;

/**
 The data types that can be used in the UI message for the UI message data parts.
 */
export declare type UIDataTypes = Record<string, unknown>;

declare type UIDataTypesToSchemas<T extends UIDataTypes> = {
    [K in keyof T]: Validator<T[K]> | StandardSchemaV1<T[K]>;
};

/**
 AI SDK UI Messages. They are used in the client and to communicate between the frontend and the API routes.
 */
export declare interface UIMessage<METADATA = unknown, DATA_PARTS extends UIDataTypes = UIDataTypes, TOOLS extends UITools = UITools> {
    /**
     A unique identifier for the message.
     */
    id: string;
    /**
     The role of the message.
     */
    role: 'system' | 'user' | 'assistant';
    /**
     The metadata of the message.
     */
    metadata?: METADATA;
    /**
     The parts of the message. Use this for rendering the message in the UI.

     System messages should be avoided (set the system prompt on the server instead).
     They can have text parts.

     User messages can have text parts and file parts.

     Assistant messages can have text, reasoning, tool invocation, and file parts.
     */
    parts: Array<UIMessagePart<DATA_PARTS, TOOLS>>;
}

export declare type UIMessageChunk<METADATA = unknown, DATA_TYPES extends UIDataTypes = UIDataTypes> = {
    type: 'text-start';
    id: string;
    providerMetadata?: ProviderMetadata;
} | {
    type: 'text-delta';
    delta: string;
    id: string;
    providerMetadata?: ProviderMetadata;
} | {
    type: 'text-end';
    id: string;
    providerMetadata?: ProviderMetadata;
} | {
    type: 'reasoning-start';
    id: string;
    providerMetadata?: ProviderMetadata;
} | {
    type: 'reasoning-delta';
    id: string;
    delta: string;
    providerMetadata?: ProviderMetadata;
} | {
    type: 'reasoning-end';
    id: string;
    providerMetadata?: ProviderMetadata;
} | {
    type: 'error';
    errorText: string;
} | {
    type: 'tool-input-available';
    toolCallId: string;
    toolName: string;
    input: unknown;
    providerExecuted?: boolean;
    providerMetadata?: ProviderMetadata;
    dynamic?: boolean;
} | {
    type: 'tool-input-error';
    toolCallId: string;
    toolName: string;
    input: unknown;
    providerExecuted?: boolean;
    providerMetadata?: ProviderMetadata;
    dynamic?: boolean;
    errorText: string;
} | {
    type: 'tool-output-available';
    toolCallId: string;
    output: unknown;
    providerExecuted?: boolean;
    dynamic?: boolean;
    preliminary?: boolean;
} | {
    type: 'tool-output-error';
    toolCallId: string;
    errorText: string;
    providerExecuted?: boolean;
    dynamic?: boolean;
} | {
    type: 'tool-input-start';
    toolCallId: string;
    toolName: string;
    providerExecuted?: boolean;
    dynamic?: boolean;
} | {
    type: 'tool-input-delta';
    toolCallId: string;
    inputTextDelta: string;
} | {
    type: 'source-url';
    sourceId: string;
    url: string;
    title?: string;
    providerMetadata?: ProviderMetadata;
} | {
    type: 'source-document';
    sourceId: string;
    mediaType: string;
    title: string;
    filename?: string;
    providerMetadata?: ProviderMetadata;
} | {
    type: 'file';
    url: string;
    mediaType: string;
    providerMetadata?: ProviderMetadata;
} | DataUIMessageChunk<DATA_TYPES> | {
    type: 'start-step';
} | {
    type: 'finish-step';
} | {
    type: 'start';
    messageId?: string;
    messageMetadata?: METADATA;
} | {
    type: 'finish';
    finishReason?: FinishReason;
    messageMetadata?: METADATA;
} | {
    type: 'abort';
} | {
    type: 'message-metadata';
    messageMetadata: METADATA;
};

export declare const uiMessageChunkSchema: _ai_sdk_provider_utils.LazyValidator<{
    type: "text-start";
    id: string;
    providerMetadata?: _ai_sdk_provider.SharedV2ProviderMetadata | undefined;
} | {
    type: "text-delta";
    id: string;
    delta: string;
    providerMetadata?: _ai_sdk_provider.SharedV2ProviderMetadata | undefined;
} | {
    type: "text-end";
    id: string;
    providerMetadata?: _ai_sdk_provider.SharedV2ProviderMetadata | undefined;
} | {
    type: "error";
    errorText: string;
} | {
    type: "tool-input-start";
    toolCallId: string;
    toolName: string;
    providerExecuted?: boolean | undefined;
    dynamic?: boolean | undefined;
} | {
    type: "tool-input-delta";
    toolCallId: string;
    inputTextDelta: string;
} | {
    type: "tool-input-available";
    toolCallId: string;
    toolName: string;
    input: unknown;
    providerExecuted?: boolean | undefined;
    providerMetadata?: _ai_sdk_provider.SharedV2ProviderMetadata | undefined;
    dynamic?: boolean | undefined;
} | {
    type: "tool-input-error";
    toolCallId: string;
    toolName: string;
    input: unknown;
    errorText: string;
    providerExecuted?: boolean | undefined;
    providerMetadata?: _ai_sdk_provider.SharedV2ProviderMetadata | undefined;
    dynamic?: boolean | undefined;
} | {
    type: "tool-output-available";
    toolCallId: string;
    output: unknown;
    providerExecuted?: boolean | undefined;
    dynamic?: boolean | undefined;
    preliminary?: boolean | undefined;
} | {
    type: "tool-output-error";
    toolCallId: string;
    errorText: string;
    providerExecuted?: boolean | undefined;
    dynamic?: boolean | undefined;
} | {
    type: "reasoning-start";
    id: string;
    providerMetadata?: _ai_sdk_provider.SharedV2ProviderMetadata | undefined;
} | {
    type: "reasoning-delta";
    id: string;
    delta: string;
    providerMetadata?: _ai_sdk_provider.SharedV2ProviderMetadata | undefined;
} | {
    type: "reasoning-end";
    id: string;
    providerMetadata?: _ai_sdk_provider.SharedV2ProviderMetadata | undefined;
} | {
    type: "source-url";
    sourceId: string;
    url: string;
    title?: string | undefined;
    providerMetadata?: _ai_sdk_provider.SharedV2ProviderMetadata | undefined;
} | {
    type: "source-document";
    sourceId: string;
    mediaType: string;
    title: string;
    filename?: string | undefined;
    providerMetadata?: _ai_sdk_provider.SharedV2ProviderMetadata | undefined;
} | {
    type: "file";
    url: string;
    mediaType: string;
    providerMetadata?: _ai_sdk_provider.SharedV2ProviderMetadata | undefined;
} | {
    type: `data-${string}`;
    data: unknown;
    id?: string | undefined;
    transient?: boolean | undefined;
} | {
    type: "start-step";
} | {
    type: "finish-step";
} | {
    type: "start";
    messageId?: string | undefined;
    messageMetadata?: unknown;
} | {
    type: "finish";
    finishReason?: "other" | "length" | "unknown" | "error" | "stop" | "content-filter" | "tool-calls" | undefined;
    messageMetadata?: unknown;
} | {
    type: "abort";
} | {
    type: "message-metadata";
    messageMetadata: unknown;
}>;

export declare type UIMessagePart<DATA_TYPES extends UIDataTypes, TOOLS extends UITools> = TextUIPart | ReasoningUIPart | ToolUIPart<TOOLS> | DynamicToolUIPart | SourceUrlUIPart | SourceDocumentUIPart | FileUIPart | DataUIPart<DATA_TYPES> | StepStartUIPart;

export declare type UIMessageStreamOnFinishCallback<UI_MESSAGE extends UIMessage> = (event: {
    /**
     * The updated list of UI messages.
     */
    messages: UI_MESSAGE[];
    /**
     * Indicates whether the response message is a continuation of the last original message,
     * or if a new message was created.
     */
    isContinuation: boolean;
    /**
     * Indicates whether the stream was aborted.
     */
    isAborted: boolean;
    /**
     * The message that was sent to the client as a response
     * (including the original message if it was extended).
     */
    responseMessage: UI_MESSAGE;
    /**
     * The reason why the generation finished.
     */
    finishReason?: FinishReason;
}) => PromiseLike<void> | void;

export declare type UIMessageStreamOptions<UI_MESSAGE extends UIMessage> = {
    /**
     * The original messages. If they are provided, persistence mode is assumed,
     * and a message ID is provided for the response message.
     */
    originalMessages?: UI_MESSAGE[];
    /**
     * Generate a message ID for the response message.
     *
     * If not provided, no message ID will be set for the response message (unless
     * the original messages are provided and the last message is an assistant message).
     */
    generateMessageId?: IdGenerator;
    onFinish?: UIMessageStreamOnFinishCallback<UI_MESSAGE>;
    /**
     * Extracts message metadata that will be send to the client.
     *
     * Called on `start` and `finish` events.
     */
    messageMetadata?: (options: {
        part: TextStreamPart<ToolSet>;
    }) => InferUIMessageMetadata<UI_MESSAGE> | undefined;
    /**
     * Send reasoning parts to the client.
     * Default to true.
     */
    sendReasoning?: boolean;
    /**
     * Send source parts to the client.
     * Default to false.
     */
    sendSources?: boolean;
    /**
     * Send the finish event to the client.
     * Set to false if you are using additional streamText calls
     * that send additional data.
     * Default to true.
     */
    sendFinish?: boolean;
    /**
     * Send the message start event to the client.
     * Set to false if you are using additional streamText calls
     * and the message start event has already been sent.
     * Default to true.
     */
    sendStart?: boolean;
    /**
     * Process an error, e.g. to log it. Default to `() => 'An error occurred.'`.
     *
     * @return error message to include in the data stream.
     */
    onError?: (error: unknown) => string;
};

declare type UIMessageStreamResponseInit = ResponseInit & {
    consumeSseStream?: (options: {
        stream: ReadableStream<string>;
    }) => PromiseLike<void> | void;
};

export declare interface UIMessageStreamWriter<UI_MESSAGE extends UIMessage = UIMessage> {
    /**
     * Appends a data stream part to the stream.
     */
    write(part: InferUIMessageChunk<UI_MESSAGE>): void;
    /**
     * Merges the contents of another stream to this stream.
     */
    merge(stream: ReadableStream<InferUIMessageChunk<UI_MESSAGE>>): void;
    /**
     * Error handler that is used by the data stream writer.
     * This is intended for forwarding when merging streams
     * to prevent duplicated error masking.
     */
    onError: ErrorHandler | undefined;
}

export declare type UITool = {
    input: unknown;
    output: unknown | undefined;
};

/**
 * A UI tool invocation contains all the information needed to render a tool invocation in the UI.
 * It can be derived from a tool without knowing the tool name, and can be used to define
 * UI components for the tool.
 */
export declare type UIToolInvocation<TOOL extends UITool | Tool> = {
    /**
     * ID of the tool call.
     */
    toolCallId: string;
    /**
     * Whether the tool call was executed by the provider.
     */
    providerExecuted?: boolean;
} & ({
    state: 'input-streaming';
    input: DeepPartial<asUITool<TOOL>['input']> | undefined;
    providerExecuted?: boolean;
    output?: never;
    errorText?: never;
} | {
    state: 'input-available';
    input: asUITool<TOOL>['input'];
    providerExecuted?: boolean;
    output?: never;
    errorText?: never;
    callProviderMetadata?: ProviderMetadata;
} | {
    state: 'output-available';
    input: asUITool<TOOL>['input'];
    output: asUITool<TOOL>['output'];
    errorText?: never;
    providerExecuted?: boolean;
    callProviderMetadata?: ProviderMetadata;
    preliminary?: boolean;
} | {
    state: 'output-error';
    input: asUITool<TOOL>['input'] | undefined;
    rawInput?: unknown;
    output?: never;
    errorText: string;
    providerExecuted?: boolean;
    callProviderMetadata?: ProviderMetadata;
});

export declare type UITools = Record<string, UITool>;

export declare class UnsupportedFunctionalityError extends AISDKError {
    private readonly [symbol];
    readonly functionality: string;
    constructor({ functionality, message, }: {
        functionality: string;
        message?: string;
    });
    static isInstance(error: unknown): error is UnsupportedFunctionalityError;
}

/**
 Error that is thrown when a model with an unsupported version is used.
 */
export declare class UnsupportedModelVersionError extends AISDKError {
    readonly version: string;
    readonly provider: string;
    readonly modelId: string;
    constructor(options: {
        version: string;
        provider: string;
        modelId: string;
    });
}

export declare type UseCompletionOptions = {
    /**
     * The API endpoint that accepts a `{ prompt: string }` object and returns
     * a stream of tokens of the AI completion response. Defaults to `/api/completion`.
     */
    api?: string;
    /**
     * An unique identifier for the chat. If not provided, a random one will be
     * generated. When provided, the `useChat` hook with the same `id` will
     * have shared states across components.
     */
    id?: string;
    /**
     * Initial prompt input of the completion.
     */
    initialInput?: string;
    /**
     * Initial completion result. Useful to load an existing history.
     */
    initialCompletion?: string;
    /**
     * Callback function to be called when the completion is finished streaming.
     */
    onFinish?: (prompt: string, completion: string) => void;
    /**
     * Callback function to be called when an error is encountered.
     */
    onError?: (error: Error) => void;
    /**
     * The credentials mode to be used for the fetch request.
     * Possible values are: 'omit', 'same-origin', 'include'.
     * Defaults to 'same-origin'.
     */
    credentials?: RequestCredentials;
    /**
     * HTTP headers to be sent with the API request.
     */
    headers?: Record<string, string> | Headers;
    /**
     * Extra body object to be sent with the API request.
     * @example
     * Send a `sessionId` to the API along with the prompt.
     * ```js
     * useChat({
     *   body: {
     *     sessionId: '123',
     *   }
     * })
     * ```
     */
    body?: object;
    /**
     Streaming protocol that is used. Defaults to `data`.
     */
    streamProtocol?: 'data' | 'text';
    /**
     Custom fetch implementation. You can use it as a middleware to intercept requests,
     or to provide a custom fetch implementation for e.g. testing.
     */
    fetch?: FetchFunction;
};

/**
 Content of a user message. It can be a string or an array of text and image parts.
 */
export declare type UserContent = string | Array<TextPart | ImagePart | FilePart>;

/**
 A user message. It can contain text or a combination of text and images.
 */
export declare type UserModelMessage = {
    role: 'user';
    content: UserContent;
    /**
     Additional provider-specific metadata. They are passed through
     to the provider from the AI SDK and enable provider-specific
     functionality that can be fully encapsulated in the provider.
     */
    providerOptions?: ProviderOptions;
};

export declare const userModelMessageSchema: z.ZodType<UserModelMessage>;

/**
 * Validates the types of an unknown object using a schema and
 * return a strongly-typed object.
 *
 * @template T - The type of the object to validate.
 * @param {string} options.value - The object to validate.
 * @param {Validator<T>} options.schema - The schema to use for validating the JSON.
 * @returns {Promise<T>} - The typed object.
 */
declare function validateTypes<OBJECT>({ value, schema, }: {
    value: unknown;
    schema: FlexibleValidator<OBJECT>;
}): Promise<OBJECT>;

/**
 * Validates a list of UI messages.
 *
 * Metadata, data parts, and generic tool call structures are only validated if
 * the corresponding schemas are provided. Otherwise, they are assumed to be
 * valid.
 */
export declare function validateUIMessages<UI_MESSAGE extends UIMessage>({ messages, metadataSchema, dataSchemas, tools, }: {
    messages: unknown;
    metadataSchema?: Validator<UIMessage['metadata']> | StandardSchemaV1<unknown, UI_MESSAGE['metadata']>;
    dataSchemas?: {
        [NAME in keyof InferUIMessageData<UI_MESSAGE> & string]?: Validator<InferUIMessageData<UI_MESSAGE>[NAME]> | StandardSchemaV1<unknown, InferUIMessageData<UI_MESSAGE>[NAME]>;
    };
    tools?: {
        [NAME in keyof InferUIMessageTools<UI_MESSAGE> & string]?: Tool<InferUIMessageTools<UI_MESSAGE>[NAME]['input'], InferUIMessageTools<UI_MESSAGE>[NAME]['output']>;
    };
}): Promise<Array<UI_MESSAGE>>;

declare type ValidationResult<OBJECT> = {
    success: true;
    value: OBJECT;
} | {
    success: false;
    error: Error;
};

declare type Validator<OBJECT = unknown> = {
    /**
     * Used to mark validator functions so we can support both Zod and custom schemas.
     */
    [validatorSymbol]: true;
    /**
     * Optional. Validates that the structure of a value matches this schema,
     * and returns a typed version of the value if it does.
     */
    readonly validate?: (value: unknown) => ValidationResult<OBJECT> | PromiseLike<ValidationResult<OBJECT>>;
};

/**
 * Create a validator.
 *
 * @param validate A validation function for the schema.
 */
declare function validator<OBJECT>(validate?: undefined | ((value: unknown) => ValidationResult<OBJECT> | PromiseLike<ValidationResult<OBJECT>>)): Validator<OBJECT>;

/**
 * Used to mark validator functions so we can support both Zod and custom schemas.
 */
declare const validatorSymbol: unique symbol;

/**
 Create a union of the given object's values, and optionally specify which keys to get the values from.

 Please upvote [this issue](https://github.com/microsoft/TypeScript/issues/31438) if you want to have this type as a built-in in TypeScript.

 @example
 ```
 // data.json
 {
 'foo': 1,
 'bar': 2,
 'biz': 3
 }

 // main.ts
 import type {ValueOf} from 'type-fest';
 import data = require('./data.json');

 export function getData(name: string): ValueOf<typeof data> {
 return data[name];
 }

 export function onlyBar(name: string): ValueOf<typeof data, 'bar'> {
 return data[name];
 }

 // file.ts
 import {getData, onlyBar} from './main';

 getData('foo');
 //=> 1

 onlyBar('foo');
 //=> TypeError ...

 onlyBar('bar');
 //=> 2
 ```
 * @see https://github.com/sindresorhus/type-fest/blob/main/source/value-of.d.ts
 */
declare type ValueOf<ObjectType, ValueType extends keyof ObjectType = keyof ObjectType> = ObjectType[ValueType];

declare const VERSION: string;

declare function withoutTrailingSlash(url: string | undefined): string | undefined;

/**
 * Appends suffix parts to the `user-agent` header.
 * If a `user-agent` header already exists, the suffix parts are appended to it.
 * If no `user-agent` header exists, a new one is created with the suffix parts.
 * Automatically removes undefined entries from the headers.
 *
 * @param headers - The original headers.
 * @param userAgentSuffixParts - The parts to append to the `user-agent` header.
 * @returns The new headers with the `user-agent` header set or updated.
 */
declare function withUserAgentSuffix(headers: HeadersInit | Record<string, string | undefined> | undefined, ...userAgentSuffixParts: string[]): Record<string, string>;

/**
 * Wraps a LanguageModelV2 instance with middleware functionality.
 * This function allows you to apply middleware to transform parameters,
 * wrap generate operations, and wrap stream operations of a language model.
 *
 * @param options - Configuration options for wrapping the language model.
 * @param options.model - The original LanguageModelV2 instance to be wrapped.
 * @param options.middleware - The middleware to be applied to the language model. When multiple middlewares are provided, the first middleware will transform the input first, and the last middleware will be wrapped directly around the model.
 * @param options.modelId - Optional custom model ID to override the original model's ID.
 * @param options.providerId - Optional custom provider ID to override the original model's provider ID.
 * @returns A new LanguageModelV2 instance with middleware applied.
 */
export declare const wrapLanguageModel: ({ model, middleware: middlewareArg, modelId, providerId, }: {
    model: LanguageModelV2;
    middleware: LanguageModelMiddleware | LanguageModelMiddleware[];
    modelId?: string;
    providerId?: string;
}) => LanguageModelV2;

/**
 * Wraps a ProviderV2 instance with middleware functionality.
 * This function allows you to apply middleware to all language models
 * from the provider, enabling you to transform parameters, wrap generate
 * operations, and wrap stream operations for every language model.
 *
 * @param options - Configuration options for wrapping the provider.
 * @param options.provider - The original ProviderV2 instance to be wrapped.
 * @param options.languageModelMiddleware - The middleware to be applied to all language models from the provider. When multiple middlewares are provided, the first middleware will transform the input first, and the last middleware will be wrapped directly around the model.
 * @returns A new ProviderV2 instance with middleware applied to all language models.
 */
export declare function wrapProvider({ provider, languageModelMiddleware, }: {
    provider: ProviderV2;
    languageModelMiddleware: LanguageModelMiddleware | LanguageModelMiddleware[];
}): ProviderV2;

export declare function zodSchema<OBJECT>(zodSchema: z4.core.$ZodType<OBJECT, any> | z3.Schema<OBJECT, z3.ZodTypeDef, any>, options?: {
    /**
     * Enables support for references in the schema.
     * This is required for recursive schemas, e.g. with `z.lazy`.
     * However, not all language models and providers support such references.
     * Defaults to `false`.
     */
    useReferences?: boolean;
}): Schema<OBJECT>;

export { }
export { GatewayProviderSettings as GatewayProviderSettings, GatewayProvider as GatewayProvider, ParseResult as ParseResult, FlexibleValidator as FlexibleValidator, ValidationResult as ValidationResult, FlexibleSchema as FlexibleSchema, LanguageModelV2ToolResultOutput as LanguageModelV2ToolResultOutput, ProviderOptions as ProviderOptions, ReasoningPart as ReasoningPart, ToolOutputProperties as ToolOutputProperties, LanguageModelV2ToolResultPart as LanguageModelV2ToolResultPart, JSONSchema7Version as JSONSchema7Version, JSONSchema7Definition as JSONSchema7Definition, JSONSchema7TypeName as JSONSchema7TypeName, JSONSchema7Type as JSONSchema7Type, AttributeValue as AttributeValue, Tracer as Tracer, EmbeddingModelV2Embedding as EmbeddingModelV2Embedding, ImageModelV2ProviderMetadata as ImageModelV2ProviderMetadata, GlobalProviderModelId as GlobalProviderModelId, LanguageModelV2FinishReason as LanguageModelV2FinishReason, LanguageModelV2CallWarning as LanguageModelV2CallWarning, LanguageModelV2Middleware as LanguageModelV2Middleware, SharedV2ProviderMetadata as SharedV2ProviderMetadata, LanguageModelV2Usage as LanguageModelV2Usage, ContentPart as ContentPart, Source as Source, ResponseMessage as ResponseMessage, DeepPartialInternal as DeepPartialInternal, LanguageModelV2ToolCall as LanguageModelV2ToolCall, StreamTextOnAbortCallback as StreamTextOnAbortCallback, ValueOf as ValueOf, asUITool as asUITool, _ai_sdk_provider_utils as _ai_sdk_provider_utils, _ai_sdk_provider as _ai_sdk_provider, DataUIMessageChunk as DataUIMessageChunk, ConsumeStreamOptions as ConsumeStreamOptions, Output_2 as Output_2, InferAgentTools as InferAgentTools, SingleRequestTextStreamPart as SingleRequestTextStreamPart, RetryErrorReason as RetryErrorReason, InferSchema as InferSchema, Job as Job, StreamObjectOnErrorCallback as StreamObjectOnErrorCallback, JSONValue_2 as JSONValue_2, ImageModelV2CallWarning as ImageModelV2CallWarning, SpeechModelV2CallWarning as SpeechModelV2CallWarning, TranscriptionModelV2CallWarning as TranscriptionModelV2CallWarning, LanguageModelV2CallOptions as LanguageModelV2CallOptions, LanguageModelV2 as LanguageModelV2, EmbeddingModelV2 as EmbeddingModelV2, ImageModelV2 as ImageModelV2, TranscriptionModelV2 as TranscriptionModelV2, SpeechModelV2 as SpeechModelV2, ExtractModelId as ExtractModelId, ExtractLiteralUnion as ExtractLiteralUnion, ProviderV2 as ProviderV2, getOriginalFetch as getOriginalFetch, UIMessageStreamResponseInit as UIMessageStreamResponseInit, InferUIMessageToolCall as InferUIMessageToolCall, Validator as Validator, StandardSchemaV1 as StandardSchemaV1, UIDataTypesToSchemas as UIDataTypesToSchemas, InferUIMessageData as InferUIMessageData, InferUIMessageMetadata as InferUIMessageMetadata, InferUIMessageTools as InferUIMessageTools, Resolvable as Resolvable, FetchFunction as FetchFunction };

export namespace Output {
        export { output_Output as Output, output_object as object, output_text as text };
}

export { schemaSymbol, symbol$1, symbol$1_2, symbol$2, symbol$2_2, symbol$3, symbol$3_2, symbol$4, symbol$4_2, symbol$5, symbol$5_2, symbol$6, symbol$6_2, symbol$7, symbol$7_2, symbol$8, symbol$8_2, symbol$9, symbol$9_2, symbol$a, symbol$a_2, symbol$b, symbol$b_2, symbol$c, symbol$c_2, symbol$d, symbol$d_2, symbol$e, symbol, symbol_2, validatorSymbol };
