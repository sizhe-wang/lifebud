{"version":3,"sources":["../../../node_modules/.pnpm/@vercel+oidc@3.0.5/node_modules/@vercel/oidc/dist/get-context.js","../../../node_modules/.pnpm/@vercel+oidc@3.0.5/node_modules/@vercel/oidc/dist/get-vercel-oidc-token.js","../../../node_modules/.pnpm/@vercel+oidc@3.0.5/node_modules/@vercel/oidc/dist/index.js","../../../node_modules/.pnpm/@ai-sdk+gateway@2.0.15_zod@3.25.76/node_modules/@ai-sdk/gateway/src/vercel-environment.ts","../../../node_modules/.pnpm/@ai-sdk+gateway@2.0.15_zod@3.25.76/node_modules/@ai-sdk/gateway/src/errors/gateway-error.ts","../../../node_modules/.pnpm/@ai-sdk+gateway@2.0.15_zod@3.25.76/node_modules/@ai-sdk/gateway/src/errors/gateway-authentication-error.ts","../../../node_modules/.pnpm/@ai-sdk+gateway@2.0.15_zod@3.25.76/node_modules/@ai-sdk/gateway/src/errors/gateway-invalid-request-error.ts","../../../node_modules/.pnpm/@ai-sdk+gateway@2.0.15_zod@3.25.76/node_modules/@ai-sdk/gateway/src/errors/gateway-rate-limit-error.ts","../../../node_modules/.pnpm/@ai-sdk+gateway@2.0.15_zod@3.25.76/node_modules/@ai-sdk/gateway/src/errors/gateway-model-not-found-error.ts","../../../node_modules/.pnpm/@ai-sdk+gateway@2.0.15_zod@3.25.76/node_modules/@ai-sdk/gateway/src/errors/gateway-internal-server-error.ts","../../../node_modules/.pnpm/@ai-sdk+gateway@2.0.15_zod@3.25.76/node_modules/@ai-sdk/gateway/src/errors/gateway-response-error.ts","../../../node_modules/.pnpm/@ai-sdk+gateway@2.0.15_zod@3.25.76/node_modules/@ai-sdk/gateway/src/errors/create-gateway-error.ts","../../../node_modules/.pnpm/@ai-sdk+gateway@2.0.15_zod@3.25.76/node_modules/@ai-sdk/gateway/src/errors/as-gateway-error.ts","../../../node_modules/.pnpm/@ai-sdk+gateway@2.0.15_zod@3.25.76/node_modules/@ai-sdk/gateway/src/errors/extract-api-call-response.ts","../../../node_modules/.pnpm/@ai-sdk+gateway@2.0.15_zod@3.25.76/node_modules/@ai-sdk/gateway/src/errors/parse-auth-method.ts","../../../node_modules/.pnpm/@ai-sdk+gateway@2.0.15_zod@3.25.76/node_modules/@ai-sdk/gateway/src/gateway-fetch-metadata.ts","../../../node_modules/.pnpm/@ai-sdk+gateway@2.0.15_zod@3.25.76/node_modules/@ai-sdk/gateway/src/gateway-language-model.ts","../../../node_modules/.pnpm/@ai-sdk+gateway@2.0.15_zod@3.25.76/node_modules/@ai-sdk/gateway/src/gateway-embedding-model.ts","../../../node_modules/.pnpm/@ai-sdk+gateway@2.0.15_zod@3.25.76/node_modules/@ai-sdk/gateway/src/gateway-image-model.ts","../../../node_modules/.pnpm/@ai-sdk+gateway@2.0.15_zod@3.25.76/node_modules/@ai-sdk/gateway/src/version.ts","../../../node_modules/.pnpm/@ai-sdk+gateway@2.0.15_zod@3.25.76/node_modules/@ai-sdk/gateway/src/gateway-provider.ts","../../../node_modules/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/src/platform/node/globalThis.ts","../../../node_modules/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/src/version.ts","../../../node_modules/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/src/internal/semver.ts","../../../node_modules/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/src/internal/global-utils.ts","../../../node_modules/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/src/diag/ComponentLogger.ts","../../../node_modules/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/src/diag/types.ts","../../../node_modules/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/src/diag/internal/logLevelLogger.ts","../../../node_modules/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/src/api/diag.ts","../../../node_modules/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/src/context/context.ts","../../../node_modules/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/src/context/NoopContextManager.ts","../../../node_modules/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/src/api/context.ts","../../../node_modules/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/src/trace/trace_flags.ts","../../../node_modules/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/src/trace/invalid-span-constants.ts","../../../node_modules/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/src/trace/NonRecordingSpan.ts","../../../node_modules/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/src/trace/context-utils.ts","../../../node_modules/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/src/trace/spancontext-utils.ts","../../../node_modules/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/src/trace/NoopTracer.ts","../../../node_modules/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/src/trace/ProxyTracer.ts","../../../node_modules/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/src/trace/NoopTracerProvider.ts","../../../node_modules/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/src/trace/ProxyTracerProvider.ts","../../../node_modules/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/src/trace/status.ts","../../../node_modules/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/src/api/trace.ts","../../../node_modules/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/src/trace-api.ts","../../../node_modules/.pnpm/ai@5.0.101_zod@3.25.76/node_modules/ai/src/logger/log-warnings.ts","../../../node_modules/.pnpm/ai@5.0.101_zod@3.25.76/node_modules/ai/src/error/invalid-argument-error.ts","../../../node_modules/.pnpm/ai@5.0.101_zod@3.25.76/node_modules/ai/src/error/no-object-generated-error.ts","../../../node_modules/.pnpm/ai@5.0.101_zod@3.25.76/node_modules/ai/src/error/no-speech-generated-error.ts","../../../node_modules/.pnpm/ai@5.0.101_zod@3.25.76/node_modules/ai/src/error/unsupported-model-version-error.ts","../../../node_modules/.pnpm/ai@5.0.101_zod@3.25.76/node_modules/ai/src/prompt/invalid-data-content-error.ts","../../../node_modules/.pnpm/ai@5.0.101_zod@3.25.76/node_modules/ai/src/prompt/message-conversion-error.ts","../../../node_modules/.pnpm/ai@5.0.101_zod@3.25.76/node_modules/ai/src/util/download/download-error.ts","../../../node_modules/.pnpm/ai@5.0.101_zod@3.25.76/node_modules/ai/src/util/retry-error.ts","../../../node_modules/.pnpm/ai@5.0.101_zod@3.25.76/node_modules/ai/src/model/resolve-model.ts","../../../node_modules/.pnpm/ai@5.0.101_zod@3.25.76/node_modules/ai/src/util/detect-media-type.ts","../../../node_modules/.pnpm/ai@5.0.101_zod@3.25.76/node_modules/ai/src/version.ts","../../../node_modules/.pnpm/ai@5.0.101_zod@3.25.76/node_modules/ai/src/util/download/download.ts","../../../node_modules/.pnpm/ai@5.0.101_zod@3.25.76/node_modules/ai/src/prompt/data-content.ts","../../../node_modules/.pnpm/ai@5.0.101_zod@3.25.76/node_modules/ai/src/types/json-value.ts","../../../node_modules/.pnpm/ai@5.0.101_zod@3.25.76/node_modules/ai/src/types/provider-metadata.ts","../../../node_modules/.pnpm/ai@5.0.101_zod@3.25.76/node_modules/ai/src/prompt/content-part.ts","../../../node_modules/.pnpm/ai@5.0.101_zod@3.25.76/node_modules/ai/src/prompt/message.ts","../../../node_modules/.pnpm/ai@5.0.101_zod@3.25.76/node_modules/ai/src/telemetry/assemble-operation-name.ts","../../../node_modules/.pnpm/ai@5.0.101_zod@3.25.76/node_modules/ai/src/telemetry/get-base-telemetry-attributes.ts","../../../node_modules/.pnpm/ai@5.0.101_zod@3.25.76/node_modules/ai/src/telemetry/noop-tracer.ts","../../../node_modules/.pnpm/ai@5.0.101_zod@3.25.76/node_modules/ai/src/telemetry/get-tracer.ts","../../../node_modules/.pnpm/ai@5.0.101_zod@3.25.76/node_modules/ai/src/telemetry/record-span.ts","../../../node_modules/.pnpm/ai@5.0.101_zod@3.25.76/node_modules/ai/src/telemetry/select-telemetry-attributes.ts","../../../node_modules/.pnpm/ai@5.0.101_zod@3.25.76/node_modules/ai/src/util/retry-with-exponential-backoff.ts","../../../node_modules/.pnpm/ai@5.0.101_zod@3.25.76/node_modules/ai/src/util/prepare-retries.ts","../../../node_modules/.pnpm/ai@5.0.101_zod@3.25.76/node_modules/ai/src/generate-text/generated-file.ts","../../../node_modules/.pnpm/ai@5.0.101_zod@3.25.76/node_modules/ai/src/generate-text/stop-condition.ts","../../../node_modules/.pnpm/ai@5.0.101_zod@3.25.76/node_modules/ai/src/prompt/create-tool-model-output.ts","../../../node_modules/.pnpm/ai@5.0.101_zod@3.25.76/node_modules/ai/src/generate-text/generate-text.ts","../../../node_modules/.pnpm/ai@5.0.101_zod@3.25.76/node_modules/ai/src/ui-message-stream/ui-message-chunks.ts","../../../node_modules/.pnpm/ai@5.0.101_zod@3.25.76/node_modules/ai/src/util/fix-json.ts","../../../node_modules/.pnpm/ai@5.0.101_zod@3.25.76/node_modules/ai/src/util/parse-partial-json.ts","../../../node_modules/.pnpm/ai@5.0.101_zod@3.25.76/node_modules/ai/src/ui/ui-messages.ts","../../../node_modules/.pnpm/ai@5.0.101_zod@3.25.76/node_modules/ai/src/generate-text/stream-text.ts","../../../node_modules/.pnpm/ai@5.0.101_zod@3.25.76/node_modules/ai/src/ui/convert-to-model-messages.ts","../../../node_modules/.pnpm/ai@5.0.101_zod@3.25.76/node_modules/ai/src/embed/embed.ts","../../../node_modules/.pnpm/ai@5.0.101_zod@3.25.76/node_modules/ai/src/generate-object/generate-object.ts","../../../node_modules/.pnpm/ai@5.0.101_zod@3.25.76/node_modules/ai/src/util/is-deep-equal-data.ts","../../../node_modules/.pnpm/ai@5.0.101_zod@3.25.76/node_modules/ai/src/generate-object/stream-object.ts","../../../node_modules/.pnpm/ai@5.0.101_zod@3.25.76/node_modules/ai/src/generate-speech/generated-audio-file.ts","../../../node_modules/.pnpm/ai@5.0.101_zod@3.25.76/node_modules/ai/src/generate-speech/generate-speech.ts","../../../node_modules/.pnpm/ai@5.0.101_zod@3.25.76/node_modules/ai/src/generate-text/output.ts","../../../node_modules/.pnpm/ai@5.0.101_zod@3.25.76/node_modules/ai/src/error/no-transcript-generated-error.ts","../../../node_modules/.pnpm/ai@5.0.101_zod@3.25.76/node_modules/ai/src/transcribe/transcribe.ts","../../../node_modules/.pnpm/ai@5.0.101_zod@3.25.76/node_modules/ai/src/ui/validate-ui-messages.ts"],"names":["__commonJS","__defProp","__export","name","getContext","getVercelOidcToken","getVercelOidcTokenSync","require_token_error","__toESM","import_oidc","marker","symbol","_a","_b","lazyValidator","zodSchema","z","safeValidateTypes","APICallError","getFromApi","resolve","createJsonResponseHandler","createJsonErrorResponseHandler","postJsonToApi","combineHeaders","createEventSourceResponseHandler","withoutTrailingSlash","withUserAgentSuffix","loadOptionalSetting","now","VERSION","isCompatible","DiagComponentLogger","DiagLogLevel","DiagAPI","__spreadArray","__read","BaseContext","NoopContextManager","API_NAME","ContextAPI","TraceFlags","NonRecordingSpan","NoopTracer","ProxyTracer","NoopTracerProvider","ProxyTracerProvider","SpanStatusCode","TraceAPI","InvalidArgumentError","AISDKError","text","convertBase64ToUint8Array","getRuntimeEnvironmentUserAgent","attributes","isAbortError","getErrorMessage","delay","convertUint8ArrayToBase64","tool","createIdGenerator","safeParseJSON","processBlock","embedding","usage","asSchema"],"mappings":";;;;;;AAAA,IAAA,sBAAAA,4BAAA,CAAA;AAAA,EAAA,8FAAA,CAAA,SAAA,MAAA,EAAA;AACA,IAAA,IAAIC,aAAY,MAAA,CAAO,cAAA;AACvB,IAAA,IAAI,mBAAmB,MAAA,CAAO,wBAAA;AAC9B,IAAA,IAAI,oBAAoB,MAAA,CAAO,mBAAA;AAC/B,IAAA,IAAI,YAAA,GAAe,OAAO,SAAA,CAAU,cAAA;AACpC,IAAA,IAAIC,SAAAA,GAAW,CAAC,MAAA,EAAQ,GAAA,KAAQ;AAC9B,MAAA,KAAA,IAASC,MAAAA,IAAQ,GAAA;AACfF,QAAAA,UAAAA,CAAU,MAAA,EAAQE,QAAM,EAAE,GAAA,EAAK,IAAIA,MAAI,CAAA,EAAG,UAAA,EAAY,IAAA,EAAM,CAAA;AAChE,IAAA,CAAA;AACA,IAAA,IAAI,WAAA,GAAc,CAAC,EAAA,EAAI,IAAA,EAAM,QAAQ,IAAA,KAAS;AAC5C,MAAA,IAAI,QAAQ,OAAO,IAAA,KAAS,QAAA,IAAY,OAAO,SAAS,UAAA,EAAY;AAClE,QAAA,KAAA,IAAS,GAAA,IAAO,kBAAkB,IAAI,CAAA;AACpC,UAAA,IAAI,CAAC,YAAA,CAAa,IAAA,CAAK,EAAA,EAAI,GAAG,KAAK,GAAA,KAAQ,MAAA;AACzCF,YAAAA,UAAAA,CAAU,IAAI,GAAA,EAAK,EAAE,GAAA,EAAK,MAAM,KAAK,GAAG,CAAA,EAAG,UAAA,EAAY,EAAE,OAAO,gBAAA,CAAiB,IAAA,EAAM,GAAG,CAAA,CAAA,IAAM,IAAA,CAAK,YAAY,CAAA;AACvH,MAAA;AACA,MAAA,OAAO,EAAA;AACT,IAAA,CAAA;AACA,IAAA,IAAI,YAAA,GAAe,CAAC,GAAA,KAAQ,WAAA,CAAYA,UAAAA,CAAU,EAAA,EAAI,YAAA,EAAc,EAAE,KAAA,EAAO,IAAA,EAAM,GAAG,GAAG,CAAA;AACzF,IAAA,IAAI,sBAAsB,EAAA;AAC1BC,IAAAA,SAAAA,CAAS,mBAAA,EAAqB;AAC5B,MAAA,sBAAA,EAAwB,MAAM,sBAAA;AAC9B,MAAA,UAAA,EAAY,MAAME;KACnB,CAAA;AACD,IAAA,MAAA,CAAO,OAAA,GAAU,aAAa,mBAAmB,CAAA;AACjD,IAAA,IAAM,sBAAA,mBAAyB,MAAA,CAAO,GAAA,CAAI,yBAAyB,CAAA;AACnE,IAAA,SAASA,WAAAA,GAAa;AACpB,MAAA,MAAM,UAAA,GAAa,UAAA;AACnB,MAAA,OAAO,UAAA,CAAW,sBAAsB,CAAA,EAAG,GAAA,QAAW,EAAA;AACxD,IAAA;AAAA,EAAA;AAAA,CAAA,CAAA;AC5BA,IAAA,gCAAAJ,4BAAA,CAAA;AAAA,EAAA,wGAAA,CAAA,SAAA,MAAA,EAAA;AAEA,IAAA,IAAIC,aAAY,MAAA,CAAO,cAAA;AACvB,IAAA,IAAI,mBAAmB,MAAA,CAAO,wBAAA;AAC9B,IAAA,IAAI,oBAAoB,MAAA,CAAO,mBAAA;AAE/B,IAAA,IAAI,YAAA,GAAe,OAAO,SAAA,CAAU,cAAA;AACpC,IAAA,IAAIC,SAAAA,GAAW,CAAC,MAAA,EAAQ,GAAA,KAAQ;AAC9B,MAAA,KAAA,IAASC,MAAAA,IAAQ,GAAA;AACfF,QAAAA,UAAAA,CAAU,MAAA,EAAQE,QAAM,EAAE,GAAA,EAAK,IAAIA,MAAI,CAAA,EAAG,UAAA,EAAY,IAAA,EAAM,CAAA;AAChE,IAAA,CAAA;AACA,IAAA,IAAI,WAAA,GAAc,CAAC,EAAA,EAAI,IAAA,EAAM,QAAQ,IAAA,KAAS;AAC5C,MAAA,IAAI,QAAQ,OAAO,IAAA,KAAS,QAAA,IAAY,OAAO,SAAS,UAAA,EAAY;AAClE,QAAA,KAAA,IAAS,GAAA,IAAO,kBAAkB,IAAI,CAAA;AACpC,UAAA,IAAI,CAAC,YAAA,CAAa,IAAA,CAAK,EAAA,EAAI,GAAG,KAAK,GAAA,KAAQ,MAAA;AACzCF,YAAAA,UAAAA,CAAU,IAAI,GAAA,EAAK,EAAE,GAAA,EAAK,MAAM,KAAK,GAAG,CAAA,EAAG,UAAA,EAAY,EAAE,OAAO,gBAAA,CAAiB,IAAA,EAAM,GAAG,CAAA,CAAA,IAAM,IAAA,CAAK,YAAY,CAAA;AACvH,MAAA;AACA,MAAA,OAAO,EAAA;AACT,IAAA,CAAA;AASA,IAAA,IAAI,YAAA,GAAe,CAAC,GAAA,KAAQ,WAAA,CAAYA,UAAAA,CAAU,EAAA,EAAI,YAAA,EAAc,EAAE,KAAA,EAAO,IAAA,EAAM,GAAG,GAAG,CAAA;AACzF,IAAA,IAAI,gCAAgC,EAAA;AACpCC,IAAAA,SAAAA,CAAS,6BAAA,EAA+B;AACtC,MAAA,kBAAA,EAAoB,MAAMG,mBAAAA;AAC1B,MAAA,sBAAA,EAAwB,MAAMC;KAC/B,CAAA;AACD,IAAA,MAAA,CAAO,OAAA,GAAU,aAAa,6BAA6B,CAAA;AAC3D,IAAA,IAAI,qBAAqB,mBAAA,EAAA;AACzB,IAAA,IAAI,qBAAqBC,qCAAA,EAAA;AACzB,IAAA,eAAeF,mBAAAA,GAAqB;AAClC,MAAA,IAAI,KAAA,GAAQ,EAAA;AACZ,MAAA,IAAI,GAAA;AACJ,MAAA,IAAI;AACF,QAAA,KAAA,GAAQC,uBAAAA,EAAAA;AACV,MAAA,CAAA,CAAA,OAAS,KAAA,EAAO;AACd,QAAA,GAAA,GAAM,KAAA;AACR,MAAA;AACA,MAAA,IAAI;AACF,QAAA,MAAM,CAAC,EAAE,eAAA,EAAiB,SAAA,EAAA,EAAa,EAAE,YAAA,EAAc,CAAA,GAAI,MAAM,OAAA,CAAQ,GAAA,CAAI;AAC3E,UAAA,MAAM,OAAO,oCAAiB,CAAA;AAC9B,UAAA,MAAM,OAAO,+BAAY;SAC1B,CAAA;AACD,QAAA,IAAI,CAAC,KAAA,IAAS,SAAA,CAAU,eAAA,CAAgB,KAAK,CAAC,CAAA,EAAG;AAC/C,UAAA,MAAM,YAAA,EAAA;AACN,UAAA,KAAA,GAAQA,uBAAAA,EAAAA;AACV,QAAA;AACF,MAAA,CAAA,CAAA,OAAS,KAAA,EAAO;AACd,QAAA,IAAI,GAAA,EAAK,OAAA,IAAW,KAAA,YAAiB,KAAA,EAAO;AAC1C,UAAA,KAAA,CAAM,OAAA,GAAU,CAAA,EAAG,GAAA,CAAI,OAAO;AAClC,EAAA,KAAA,CAAM,OAAO,CAAA,CAAA;AACX,QAAA;AACA,QAAA,MAAM,IAAI,kBAAA,CAAmB,oBAAA,CAAqB,CAAA,4BAAA,CAAA,EAAgC,KAAK,CAAA;AACzF,MAAA;AACA,MAAA,OAAO,KAAA;AACT,IAAA;AACA,IAAA,SAASA,uBAAAA,GAAyB;AAChC,MAAA,MAAM,KAAA,GAAA,IAAY,kBAAA,CAAmB,UAAA,IAAc,OAAA,GAAU,qBAAqB,CAAA,IAAK,OAAA,CAAQ,GAAA,CAAI,iBAAA;AACnG,MAAA,IAAI,CAAC,KAAA,EAAO;AACV,QAAA,MAAM,IAAI,KAAA;AACR,UAAA,CAAA,iIAAA;AAAA,SAAA;AAEJ,MAAA;AACA,MAAA,OAAO,KAAA;AACT,IAAA;AAAA,EAAA;AAAA,CAAA,CAAA;ACtEA,IAAA,eAAAN,4BAAA,CAAA;AAAA,EAAA,wFAAA,CAAA,SAAA,MAAA,EAAA;AACA,IAAA,IAAIC,aAAY,MAAA,CAAO,cAAA;AACvB,IAAA,IAAI,mBAAmB,MAAA,CAAO,wBAAA;AAC9B,IAAA,IAAI,oBAAoB,MAAA,CAAO,mBAAA;AAC/B,IAAA,IAAI,YAAA,GAAe,OAAO,SAAA,CAAU,cAAA;AACpC,IAAA,IAAIC,SAAAA,GAAW,CAAC,MAAA,EAAQ,GAAA,KAAQ;AAC9B,MAAA,KAAA,IAASC,MAAAA,IAAQ,GAAA;AACfF,QAAAA,UAAAA,CAAU,MAAA,EAAQE,QAAM,EAAE,GAAA,EAAK,IAAIA,MAAI,CAAA,EAAG,UAAA,EAAY,IAAA,EAAM,CAAA;AAChE,IAAA,CAAA;AACA,IAAA,IAAI,WAAA,GAAc,CAAC,EAAA,EAAI,IAAA,EAAM,QAAQ,IAAA,KAAS;AAC5C,MAAA,IAAI,QAAQ,OAAO,IAAA,KAAS,QAAA,IAAY,OAAO,SAAS,UAAA,EAAY;AAClE,QAAA,KAAA,IAAS,GAAA,IAAO,kBAAkB,IAAI,CAAA;AACpC,UAAA,IAAI,CAAC,YAAA,CAAa,IAAA,CAAK,EAAA,EAAI,GAAG,KAAK,GAAA,KAAQ,MAAA;AACzCF,YAAAA,UAAAA,CAAU,IAAI,GAAA,EAAK,EAAE,GAAA,EAAK,MAAM,KAAK,GAAG,CAAA,EAAG,UAAA,EAAY,EAAE,OAAO,gBAAA,CAAiB,IAAA,EAAM,GAAG,CAAA,CAAA,IAAM,IAAA,CAAK,YAAY,CAAA;AACvH,MAAA;AACA,MAAA,OAAO,EAAA;AACT,IAAA,CAAA;AACA,IAAA,IAAI,YAAA,GAAe,CAAC,GAAA,KAAQ,WAAA,CAAYA,UAAAA,CAAU,EAAA,EAAI,YAAA,EAAc,EAAE,KAAA,EAAO,IAAA,EAAM,GAAG,GAAG,CAAA;AACzF,IAAA,IAAI,cAAc,EAAA;AAClBC,IAAAA,SAAAA,CAAS,WAAA,EAAa;AACpB,MAAA,UAAA,EAAY,MAAM,kBAAA,CAAmB,UAAA;AACrC,MAAA,kBAAA,EAAoB,MAAM,4BAAA,CAA6B,kBAAA;AACvD,MAAA,sBAAA,EAAwB,MAAM,4BAAA,CAA6B;KAC5D,CAAA;AACD,IAAA,MAAA,CAAO,OAAA,GAAU,aAAa,WAAW,CAAA;AACzC,IAAA,IAAI,+BAA+B,6BAAA,EAAA;AACnC,IAAA,IAAI,qBAAqB,mBAAA,EAAA;AAAA,EAAA;AAAA,CAAA,CAAA;AC1BzB,IAAA,WAAA,GAA2BM,yBAAA,CAAA,YAAA,EAAA,EAAA,CAAA,CAAA;AAC3B,IAAAC,YAAAA,GAAmCD,yBAAA,CAAA,YAAA,EAAA,EAAA,CAAA,CAAA;ACDnC,IAAM,MAAA,GAAS,yBAAA;AACf,IAAM,MAAA,GAAS,MAAA,CAAO,GAAA,CAAI,MAAM,CAAA;AADhC,IAAA,EAAA;AAAA,IAAA,EAAA;AAGO,IAAe,eAAf,MAAe,aAAA,UAAqB,KAAA,KAAA,EACvB,EAAA,GAAA,QADuB,EAAA,EAAM;EAQ/C,WAAA,CAAY;AACV,IAAA,OAAA;IACA,UAAA,GAAa,GAAA;AACb,IAAA;AAKC,GAAA,EAAA;AACD,IAAA,KAAA,CAAM,OAAO,CAAA;AAhBf,IAAA,IAAA,CAAkB,EAAA,CAAA,GAAU,IAAA;AAiB1B,IAAA,IAAA,CAAK,UAAA,GAAa,UAAA;AAClB,IAAA,IAAA,CAAK,KAAA,GAAQ,KAAA;AACf,EAAA;;;;;;AAOA,EAAA,OAAO,WAAW,KAAA,EAAuC;AACvD,IAAA,OAAO,aAAA,CAAa,UAAU,KAAK,CAAA;AACrC,EAAA;AAEA,EAAA,OAAO,UAAU,KAAA,EAAuC;AACtD,IAAA,OACE,OAAO,UAAU,QAAA,IACjB,KAAA,KAAU,QACV,MAAA,IAAU,KAAA,IACT,KAAA,CAAc,MAAM,CAAA,KAAM,IAAA;AAE/B,EAAA;AACF,CAAA;ACxCA,IAAM,IAAA,GAAO,4BAAA;AACb,IAAME,OAAAA,GAAS,2BAA2B,IAAI,CAAA,CAAA;AAC9C,IAAMC,OAAAA,GAAS,MAAA,CAAO,GAAA,CAAID,OAAM,CAAA;AAJhC,IAAAE,GAAAA;AAAA,IAAAC,GAAAA;AASO,IAAM,6BAAN,MAAM,2BAAA,UAAmCA,MAAA,YAAA,EAC5BD,GAAAA,GAAAD,SAD4BE,GAAAA,EAAa;EAM3D,WAAA,CAAY;IACV,OAAA,GAAU,uBAAA;IACV,UAAA,GAAa,GAAA;AACb,IAAA;AACF,GAAA,GAII,EAAA,EAAI;AACN,IAAA,KAAA,CAAM,EAAE,OAAA,EAAS,UAAA,EAAY,KAAA,EAAO,CAAA;AAdtC,IAAA,IAAA,CAAkBD,GAAAA,CAAAA,GAAU,IAAA;AAE5B,IAAA,IAAA,CAAS,IAAA,GAAO,IAAA;AAChB,IAAA,IAAA,CAAS,IAAA,GAAO,sBAAA;AAYhB,EAAA;AAEA,EAAA,OAAO,WAAW,KAAA,EAAqD;AACrE,IAAA,OAAO,YAAA,CAAa,SAAA,CAAU,KAAK,CAAA,IAAKD,OAAAA,IAAU,KAAA;AACpD,EAAA;;;;AAKA,EAAA,OAAO,qBAAA,CAAsB;AAC3B,IAAA,cAAA;AACA,IAAA,iBAAA;IACA,OAAA,GAAU,uBAAA;IACV,UAAA,GAAa,GAAA;AACb,IAAA;AAO6B,GAAA,EAAA;AAC7B,IAAA,IAAI,iBAAA;AAEJ,IAAA,IAAI,cAAA,EAAgB;AAClB,MAAA,iBAAA,GAAoB,CAAA;;;;;AAKtB,IAAA,CAAA,MAAA,IAAW,iBAAA,EAAmB;AAC5B,MAAA,iBAAA,GAAoB,CAAA;;;;;IAKtB,CAAA,MAAO;AACL,MAAA,iBAAA,GAAoB,CAAA;;;;;;;;AAQtB,IAAA;AAEA,IAAA,OAAO,IAAI,2BAAA,CAA2B;MACpC,OAAA,EAAS,iBAAA;AACT,MAAA,UAAA;AACA,MAAA;AACD,KAAA,CAAA;AACH,EAAA;AACF,CAAA;AC5EA,IAAMR,KAAAA,GAAO,4BAAA;AACb,IAAMO,OAAAA,GAAS,2BAA2BP,KAAI,CAAA,CAAA;AAC9C,IAAMQ,OAAAA,GAAS,MAAA,CAAO,GAAA,CAAID,OAAM,CAAA;AAJhC,IAAAE,GAAAA;AAAA,IAAAC,GAAAA;AASO,IAAM,6BAAN,eAAyCA,GAAAA,GAAA,YAAA,EAC5BD,GAAAA,GAAAD,SAD4BE,GAAAA,EAAa;EAM3D,WAAA,CAAY;IACV,OAAA,GAAU,iBAAA;IACV,UAAA,GAAa,GAAA;AACb,IAAA;AACF,GAAA,GAII,EAAA,EAAI;AACN,IAAA,KAAA,CAAM,EAAE,OAAA,EAAS,UAAA,EAAY,KAAA,EAAO,CAAA;AAdtC,IAAA,IAAA,CAAkBD,GAAAA,CAAAA,GAAU,IAAA;AAE5B,IAAA,IAAA,CAAS,IAAA,GAAOT,KAAAA;AAChB,IAAA,IAAA,CAAS,IAAA,GAAO,uBAAA;AAYhB,EAAA;AAEA,EAAA,OAAO,WAAW,KAAA,EAAqD;AACrE,IAAA,OAAO,YAAA,CAAa,SAAA,CAAU,KAAK,CAAA,IAAKQ,OAAAA,IAAU,KAAA;AACpD,EAAA;AACF,CAAA;AC5BA,IAAMR,KAAAA,GAAO,uBAAA;AACb,IAAMO,OAAAA,GAAS,2BAA2BP,KAAI,CAAA,CAAA;AAC9C,IAAMQ,OAAAA,GAAS,MAAA,CAAO,GAAA,CAAID,OAAM,CAAA;AAJhC,IAAAE,GAAAA;AAAA,IAAAC,GAAAA;AASO,IAAM,wBAAN,eAAoCA,GAAAA,GAAA,YAAA,EACvBD,GAAAA,GAAAD,SADuBE,GAAAA,EAAa;EAMtD,WAAA,CAAY;IACV,OAAA,GAAU,qBAAA;IACV,UAAA,GAAa,GAAA;AACb,IAAA;AACF,GAAA,GAII,EAAA,EAAI;AACN,IAAA,KAAA,CAAM,EAAE,OAAA,EAAS,UAAA,EAAY,KAAA,EAAO,CAAA;AAdtC,IAAA,IAAA,CAAkBD,GAAAA,CAAAA,GAAU,IAAA;AAE5B,IAAA,IAAA,CAAS,IAAA,GAAOT,KAAAA;AAChB,IAAA,IAAA,CAAS,IAAA,GAAO,qBAAA;AAYhB,EAAA;AAEA,EAAA,OAAO,WAAW,KAAA,EAAgD;AAChE,IAAA,OAAO,YAAA,CAAa,SAAA,CAAU,KAAK,CAAA,IAAKQ,OAAAA,IAAU,KAAA;AACpD,EAAA;AACF,CAAA;AC1BA,IAAMR,KAAAA,GAAO,2BAAA;AACb,IAAMO,OAAAA,GAAS,2BAA2BP,KAAI,CAAA,CAAA;AAC9C,IAAMQ,OAAAA,GAAS,MAAA,CAAO,GAAA,CAAID,OAAM,CAAA;AAEzB,IAAM,wBAAA,GAA2BI,+BAAA;EAAc,MACpDC,2BAAA;AACE,IAAAC,IAAA,CAAE,MAAA,CAAO;AACP,MAAA,OAAA,EAASA,KAAE,MAAA;AACZ,KAAA;AACH;AACF,CAAA;AAdA,IAAAJ,GAAAA;AAAA,IAAAC,GAAAA;AAmBO,IAAM,4BAAN,eAAwCA,GAAAA,GAAA,YAAA,EAC3BD,GAAAA,GAAAD,SAD2BE,GAAAA,EAAa;EAO1D,WAAA,CAAY;IACV,OAAA,GAAU,iBAAA;IACV,UAAA,GAAa,GAAA;AACb,IAAA,OAAA;AACA,IAAA;AACF,GAAA,GAKI,EAAA,EAAI;AACN,IAAA,KAAA,CAAM,EAAE,OAAA,EAAS,UAAA,EAAY,KAAA,EAAO,CAAA;AAjBtC,IAAA,IAAA,CAAkBD,GAAAA,CAAAA,GAAU,IAAA;AAE5B,IAAA,IAAA,CAAS,IAAA,GAAOT,KAAAA;AAChB,IAAA,IAAA,CAAS,IAAA,GAAO,iBAAA;AAed,IAAA,IAAA,CAAK,OAAA,GAAU,OAAA;AACjB,EAAA;AAEA,EAAA,OAAO,WAAW,KAAA,EAAoD;AACpE,IAAA,OAAO,YAAA,CAAa,SAAA,CAAU,KAAK,CAAA,IAAKQ,OAAAA,IAAU,KAAA;AACpD,EAAA;AACF,CAAA;AC1CA,IAAMR,KAAAA,GAAO,4BAAA;AACb,IAAMO,OAAAA,GAAS,2BAA2BP,KAAI,CAAA,CAAA;AAC9C,IAAMQ,OAAAA,GAAS,MAAA,CAAO,GAAA,CAAID,OAAM,CAAA;AAJhC,IAAAE,GAAAA;AAAA,IAAAC,GAAAA;AASO,IAAM,6BAAN,eAAyCA,GAAAA,GAAA,YAAA,EAC5BD,GAAAA,GAAAD,SAD4BE,GAAAA,EAAa;EAM3D,WAAA,CAAY;IACV,OAAA,GAAU,uBAAA;IACV,UAAA,GAAa,GAAA;AACb,IAAA;AACF,GAAA,GAII,EAAA,EAAI;AACN,IAAA,KAAA,CAAM,EAAE,OAAA,EAAS,UAAA,EAAY,KAAA,EAAO,CAAA;AAdtC,IAAA,IAAA,CAAkBD,GAAAA,CAAAA,GAAU,IAAA;AAE5B,IAAA,IAAA,CAAS,IAAA,GAAOT,KAAAA;AAChB,IAAA,IAAA,CAAS,IAAA,GAAO,uBAAA;AAYhB,EAAA;AAEA,EAAA,OAAO,WAAW,KAAA,EAAqD;AACrE,IAAA,OAAO,YAAA,CAAa,SAAA,CAAU,KAAK,CAAA,IAAKQ,OAAAA,IAAU,KAAA;AACpD,EAAA;AACF,CAAA;AC3BA,IAAMR,KAAAA,GAAO,sBAAA;AACb,IAAMO,OAAAA,GAAS,2BAA2BP,KAAI,CAAA,CAAA;AAC9C,IAAMQ,OAAAA,GAAS,MAAA,CAAO,GAAA,CAAID,OAAM,CAAA;AALhC,IAAAE,GAAAA;AAAA,IAAAC,GAAAA;AAUO,IAAM,uBAAN,eAAmCA,GAAAA,GAAA,YAAA,EACtBD,GAAAA,GAAAD,SADsBE,GAAAA,EAAa;EAQrD,WAAA,CAAY;IACV,OAAA,GAAU,+BAAA;IACV,UAAA,GAAa,GAAA;AACb,IAAA,QAAA;AACA,IAAA,eAAA;AACA,IAAA;AACF,GAAA,GAMI,EAAA,EAAI;AACN,IAAA,KAAA,CAAM,EAAE,OAAA,EAAS,UAAA,EAAY,KAAA,EAAO,CAAA;AApBtC,IAAA,IAAA,CAAkBD,GAAAA,CAAAA,GAAU,IAAA;AAE5B,IAAA,IAAA,CAAS,IAAA,GAAOT,KAAAA;AAChB,IAAA,IAAA,CAAS,IAAA,GAAO,gBAAA;AAkBd,IAAA,IAAA,CAAK,QAAA,GAAW,QAAA;AAChB,IAAA,IAAA,CAAK,eAAA,GAAkB,eAAA;AACzB,EAAA;AAEA,EAAA,OAAO,WAAW,KAAA,EAA+C;AAC/D,IAAA,OAAO,YAAA,CAAa,SAAA,CAAU,KAAK,CAAA,IAAKQ,OAAAA,IAAU,KAAA;AACpD,EAAA;AACF,CAAA;ACpBA,eAAsB,8BAAA,CAA+B;AACnD,EAAA,QAAA;AACA,EAAA,UAAA;EACA,cAAA,GAAiB,wBAAA;AACjB,EAAA,KAAA;AACA,EAAA;AACF,CAAA,EAM0B;AACxB,EAAA,MAAM,WAAA,GAAc,MAAMM,mCAAA,CAAkB;IAC1C,KAAA,EAAO,QAAA;IACP,MAAA,EAAQ;AACT,GAAA,CAAA;AAED,EAAA,IAAI,CAAC,YAAY,OAAA,EAAS;AACxB,IAAA,OAAO,IAAI,oBAAA,CAAqB;AAC9B,MAAA,OAAA,EAAS,kCAAkC,cAAc,CAAA,CAAA;AACzD,MAAA,UAAA;AACA,MAAA,QAAA;AACA,MAAA,eAAA,EAAiB,WAAA,CAAY,KAAA;AAC7B,MAAA;AACD,KAAA,CAAA;AACH,EAAA;AAEA,EAAA,MAAM,oBAA0C,WAAA,CAAY,KAAA;AAC5D,EAAA,MAAM,SAAA,GAAY,kBAAkB,KAAA,CAAM,IAAA;AAC1C,EAAA,MAAM,OAAA,GAAU,kBAAkB,KAAA,CAAM,OAAA;AAExC,EAAA,QAAQ,SAAA;IACN,KAAK,sBAAA;AACH,MAAA,OAAO,2BAA2B,qBAAA,CAAsB;AACtD,QAAA,cAAA,EAAgB,UAAA,KAAe,SAAA;AAC/B,QAAA,iBAAA,EAAmB,UAAA,KAAe,MAAA;AAClC,QAAA,UAAA;AACA,QAAA;AACD,OAAA,CAAA;IACH,KAAK,uBAAA;AACH,MAAA,OAAO,IAAI,0BAAA,CAA2B,EAAE,OAAA,EAAS,UAAA,EAAY,OAAO,CAAA;IACtE,KAAK,qBAAA;AACH,MAAA,OAAO,IAAI,qBAAA,CAAsB,EAAE,OAAA,EAAS,UAAA,EAAY,OAAO,CAAA;AACjE,IAAA,KAAK,iBAAA,EAAmB;AACtB,MAAA,MAAM,WAAA,GAAc,MAAMA,mCAAA,CAAkB;AAC1C,QAAA,KAAA,EAAO,kBAAkB,KAAA,CAAM,KAAA;QAC/B,MAAA,EAAQ;AACT,OAAA,CAAA;AAED,MAAA,OAAO,IAAI,yBAAA,CAA0B;AACnC,QAAA,OAAA;AACA,QAAA,UAAA;AACA,QAAA,OAAA,EAAS,WAAA,CAAY,OAAA,GAAU,WAAA,CAAY,KAAA,CAAM,OAAA,GAAU,MAAA;AAC3D,QAAA;AACD,OAAA,CAAA;AACH,IAAA;IACA,KAAK,uBAAA;AACH,MAAA,OAAO,IAAI,0BAAA,CAA2B,EAAE,OAAA,EAAS,UAAA,EAAY,OAAO,CAAA;AACtE,IAAA;AACE,MAAA,OAAO,IAAI,0BAAA,CAA2B,EAAE,OAAA,EAAS,UAAA,EAAY,OAAO,CAAA;AACxE;AACF;AAEA,IAAM,0BAAA,GAA6BH,+BAAAA;EAAc,MAC/CC,2BAAAA;AACEC,IAAAA,IAAAA,CAAE,MAAA,CAAO;AACP,MAAA,KAAA,EAAOA,KAAE,MAAA,CAAO;AACd,QAAA,OAAA,EAASA,KAAE,MAAA,EAAA;QACX,IAAA,EAAMA,IAAAA,CAAE,MAAA,EAAA,CAAS,OAAA,EAAA;QACjB,KAAA,EAAOA,IAAAA,CAAE,OAAA,EAAA,CAAU,OAAA,EAAA;QACnB,IAAA,EAAMA,IAAAA,CAAE,KAAA,CAAM,CAACA,IAAAA,CAAE,MAAA,EAAA,EAAUA,IAAAA,CAAE,MAAA,EAAQ,CAAC,CAAA,CAAE,OAAA;AACzC,OAAA;AACF,KAAA;AACH;AACF,CAAA;AC1FO,SAAS,cAAA,CACd,OACA,UAAA,EACA;AAPF,EAAA,IAAAJ,IAAAA;AAQE,EAAA,IAAI,YAAA,CAAa,UAAA,CAAW,KAAK,CAAA,EAAG;AAClC,IAAA,OAAO,KAAA;AACT,EAAA;AAEA,EAAA,IAAIM,8BAAA,CAAa,UAAA,CAAW,KAAK,CAAA,EAAG;AAClC,IAAA,OAAO,8BAAA,CAA+B;AACpC,MAAA,QAAA,EAAU,uBAAuB,KAAK,CAAA;AACtC,MAAA,UAAA,EAAA,CAAYN,IAAAA,GAAA,KAAA,CAAM,UAAA,KAAN,IAAA,GAAAA,IAAAA,GAAoB,GAAA;MAChC,cAAA,EAAgB,wBAAA;MAChB,KAAA,EAAO,KAAA;AACP,MAAA;AACD,KAAA,CAAA;AACH,EAAA;AAEA,EAAA,OAAO,8BAAA,CAA+B;AACpC,IAAA,QAAA,EAAU,EAAA;IACV,UAAA,EAAY,GAAA;AACZ,IAAA,cAAA,EACE,KAAA,YAAiB,KAAA,GACb,CAAA,wBAAA,EAA2B,KAAA,CAAM,OAAO,CAAA,CAAA,GACxC,uBAAA;IACN,KAAA,EAAO,KAAA;AACP,IAAA;AACD,GAAA,CAAA;AACH;AC9BO,SAAS,uBAAuB,KAAA,EAA8B;AACnE,EAAA,IAAI,KAAA,CAAM,SAAS,MAAA,EAAW;AAC5B,IAAA,OAAO,KAAA,CAAM,IAAA;AACf,EAAA;AACA,EAAA,IAAI,KAAA,CAAM,gBAAgB,IAAA,EAAM;AAC9B,IAAA,IAAI;AACF,MAAA,OAAO,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,YAAY,CAAA;AACtC,IAAA,CAAA,CAAA,OAAQ,CAAA,EAAA;AACN,MAAA,OAAO,KAAA,CAAM,YAAA;AACf,IAAA;AACF,EAAA;AACA,EAAA,OAAO,EAAA;AACT;ACPO,IAAM,0BAAA,GAA6B,wBAAA;AAE1C,eAAsB,gBACpB,OAAA,EACA;AACA,EAAA,MAAM,MAAA,GAAS,MAAMK,mCAAAA,CAAkB;AACrC,IAAA,KAAA,EAAO,QAAQ,0BAA0B,CAAA;IACzC,MAAA,EAAQ;AACT,GAAA,CAAA;AAED,EAAA,OAAO,MAAA,CAAO,OAAA,GAAU,MAAA,CAAO,KAAA,GAAQ,MAAA;AACzC;AAEA,IAAM,uBAAA,GAA0BH,+BAAAA;AAAc,EAAA,MAC5CC,2BAAAA,CAAUC,IAAAA,CAAE,KAAA,CAAM,CAACA,IAAAA,CAAE,OAAA,CAAQ,SAAS,CAAA,EAAGA,IAAAA,CAAE,OAAA,CAAQ,MAAM,CAAC,CAAC,CAAC;AAC9D,CAAA;ACIO,IAAM,uBAAN,MAA2B;AAChC,EAAA,WAAA,CAA6B,MAAA,EAAoC;AAApC,IAAA,IAAA,CAAA,MAAA,GAAA,MAAA;AAAqC,EAAA;AAElE,EAAA,MAAM,kBAAA,GAA4D;AAChE,IAAA,IAAI;AACF,MAAA,MAAM,EAAE,KAAA,EAAA,GAAU,MAAMG,4BAAA,CAAW;QACjC,GAAA,EAAK,CAAA,EAAG,IAAA,CAAK,MAAA,CAAO,OAAO,CAAA,OAAA,CAAA;AAC3B,QAAA,OAAA,EAAS,MAAMC,yBAAA,CAAQ,IAAA,CAAK,MAAA,CAAO,SAAS,CAAA;QAC5C,yBAAA,EAA2BC,2CAAA;AACzB,UAAA;AACF,SAAA;AACA,QAAA,qBAAA,EAAuBC,gDAAA,CAA+B;AACpD,UAAA,WAAA,EAAaN,KAAE,GAAA,EAAA;AACf,UAAA,cAAA,EAAgB,CAAA,IAAA,KAAQ;AACzB,SAAA,CAAA;AACD,QAAA,KAAA,EAAO,KAAK,MAAA,CAAO;AACpB,OAAA,CAAA;AAED,MAAA,OAAO,KAAA;AACT,IAAA,CAAA,CAAA,OAAS,KAAA,EAAO;AACd,MAAA,MAAM,MAAM,eAAe,KAAK,CAAA;AAClC,IAAA;AACF,EAAA;AAEA,EAAA,MAAM,UAAA,GAA8C;AAClD,IAAA,IAAI;AACF,MAAA,MAAM,OAAA,GAAU,IAAI,GAAA,CAAI,IAAA,CAAK,OAAO,OAAO,CAAA;AAE3C,MAAA,MAAM,EAAE,KAAA,EAAA,GAAU,MAAMG,4BAAA,CAAW;QACjC,GAAA,EAAK,CAAA,EAAG,QAAQ,MAAM,CAAA,WAAA,CAAA;AACtB,QAAA,OAAA,EAAS,MAAMC,yBAAA,CAAQ,IAAA,CAAK,MAAA,CAAO,SAAS,CAAA;QAC5C,yBAAA,EAA2BC,2CAAA;AACzB,UAAA;AACF,SAAA;AACA,QAAA,qBAAA,EAAuBC,gDAAA,CAA+B;AACpD,UAAA,WAAA,EAAaN,KAAE,GAAA,EAAA;AACf,UAAA,cAAA,EAAgB,CAAA,IAAA,KAAQ;AACzB,SAAA,CAAA;AACD,QAAA,KAAA,EAAO,KAAK,MAAA,CAAO;AACpB,OAAA,CAAA;AAED,MAAA,OAAO,KAAA;AACT,IAAA,CAAA,CAAA,OAAS,KAAA,EAAO;AACd,MAAA,MAAM,MAAM,eAAe,KAAK,CAAA;AAClC,IAAA;AACF,EAAA;AACF,CAAA;AAEA,IAAM,oCAAA,GAAuCF,+BAAAA;EAAc,MACzDC,2BAAAA;AACEC,IAAAA,IAAAA,CAAE,MAAA,CAAO;AACP,MAAA,MAAA,EAAQA,IAAAA,CAAE,KAAA;AACRA,QAAAA,IAAAA,CAAE,MAAA,CAAO;AACP,UAAA,EAAA,EAAIA,KAAE,MAAA,EAAA;AACN,UAAA,IAAA,EAAMA,KAAE,MAAA,EAAA;UACR,WAAA,EAAaA,IAAAA,CAAE,MAAA,EAAA,CAAS,OAAA,EAAA;AACxB,UAAA,OAAA,EAASA,KACN,MAAA,CAAO;AACN,YAAA,KAAA,EAAOA,KAAE,MAAA,EAAA;AACT,YAAA,MAAA,EAAQA,KAAE,MAAA,EAAA;YACV,gBAAA,EAAkBA,IAAAA,CAAE,MAAA,EAAA,CAAS,OAAA,EAAA;YAC7B,iBAAA,EAAmBA,IAAAA,CAAE,MAAA,EAAA,CAAS,OAAA;AAChC,WAAC,CAAA,CACA,SAAA;AACC,YAAA,CAAC,EAAE,KAAA,EAAO,MAAA,EAAQ,gBAAA,EAAkB,mBAAA,MAAyB;AAC3D,cAAA,KAAA;AACA,cAAA,MAAA;AACA,cAAA,GAAI,gBAAA,GACA,EAAE,iBAAA,EAAmB,gBAAA,KACrB,EAAA;AACJ,cAAA,GAAI,iBAAA,GACA,EAAE,wBAAA,EAA0B,iBAAA,KAC5B;AACN,aAAA;AACF,WAAA,CACC,OAAA,EAAA;AACH,UAAA,aAAA,EAAeA,KAAE,MAAA,CAAO;YACtB,oBAAA,EAAsBA,IAAAA,CAAE,QAAQ,IAAI,CAAA;AACpC,YAAA,QAAA,EAAUA,KAAE,MAAA,EAAA;AACZ,YAAA,OAAA,EAASA,KAAE,MAAA;AACZ,WAAA,CAAA;UACD,SAAA,EAAWA,IAAAA,CAAE,KAAK,CAAC,UAAA,EAAY,aAAa,OAAO,CAAC,EAAE,OAAA;AACvD,SAAA;AACH;AACD,KAAA;AACH;AACF,CAAA;AAEA,IAAM,4BAAA,GAA+BF,+BAAAA;EAAc,MACjDC,2BAAAA;AACEC,IAAAA,IAAAA,CACG,MAAA,CAAO;AACN,MAAA,OAAA,EAASA,KAAE,MAAA,EAAA;AACX,MAAA,UAAA,EAAYA,KAAE,MAAA;AAChB,KAAC,EACA,SAAA,CAAU,CAAC,EAAE,OAAA,EAAS,YAAA,MAAkB;AACvC,MAAA,OAAA;MACA,SAAA,EAAW;AACX,KAAA,CAAA;AACN;AACF,CAAA;AClGO,IAAM,uBAAN,MAAsD;AAI3D,EAAA,WAAA,CACW,SACQ,MAAA,EACjB;AAFS,IAAA,IAAA,CAAA,OAAA,GAAA,OAAA;AACQ,IAAA,IAAA,CAAA,MAAA,GAAA,MAAA;AALnB,IAAA,IAAA,CAAS,oBAAA,GAAuB,IAAA;AAChC,IAAA,IAAA,CAAS,aAAA,GAAgB,EAAE,KAAA,EAAO,CAAC,IAAI,CAAA,EAAA;AAKpC,EAAA;AAEH,EAAA,IAAI,QAAA,GAAmB;AACrB,IAAA,OAAO,KAAK,MAAA,CAAO,QAAA;AACrB,EAAA;AAEA,EAAA,MAAc,QAAQ,OAAA,EAAuD;AAC3E,IAAA,MAAM,EAAE,WAAA,EAAa,YAAA,EAAc,GAAG,sBAAA,GAAyB,OAAA;AAE/D,IAAA,OAAO;MACL,IAAA,EAAM,IAAA,CAAK,qBAAqB,oBAAoB,CAAA;AACpD,MAAA,QAAA,EAAU;AACZ,KAAA;AACF,EAAA;AAEA,EAAA,MAAM,WACJ,OAAA,EAC6D;AAC7D,IAAA,MAAM,EAAE,IAAA,EAAM,QAAA,KAAa,MAAM,IAAA,CAAK,QAAQ,OAAO,CAAA;AACrD,IAAA,MAAM,EAAE,aAAA,GAAgB,OAAA;AAExB,IAAA,MAAM,kBAAkB,MAAMI,yBAAAA,CAAQ,IAAA,CAAK,MAAA,CAAO,SAAS,CAAA;AAE3D,IAAA,IAAI;AACF,MAAA,MAAM;AACJ,QAAA,eAAA;QACA,KAAA,EAAO,YAAA;QACP,QAAA,EAAU;AACZ,OAAA,GAAI,MAAMG,+BAAA,CAAc;AACtB,QAAA,GAAA,EAAK,KAAK,MAAA,EAAA;QACV,OAAA,EAASC,gCAAA;AACP,UAAA,eAAA;UACA,OAAA,CAAQ,OAAA;UACR,IAAA,CAAK,qBAAA,CAAsB,IAAA,CAAK,OAAA,EAAS,KAAK,CAAA;UAC9C,MAAMJ,yBAAAA,CAAQ,IAAA,CAAK,MAAA,CAAO,WAAW;AACvC,SAAA;QACA,IAAA,EAAM,IAAA;QACN,yBAAA,EAA2BC,2CAAAA,CAA0BL,IAAAA,CAAE,GAAA,EAAK,CAAA;AAC5D,QAAA,qBAAA,EAAuBM,gDAAAA,CAA+B;AACpD,UAAA,WAAA,EAAaN,KAAE,GAAA,EAAA;AACf,UAAA,cAAA,EAAgB,CAAA,IAAA,KAAQ;AACzB,SAAA,CAAA;QACD,GAAI,WAAA,IAAe,EAAE,WAAA,EAAA;AACrB,QAAA,KAAA,EAAO,KAAK,MAAA,CAAO;AACpB,OAAA,CAAA;AAED,MAAA,OAAO;QACL,GAAG,YAAA;QACH,OAAA,EAAS,EAAE,MAAM,IAAA,EAAA;AACjB,QAAA,QAAA,EAAU,EAAE,OAAA,EAAS,eAAA,EAAiB,IAAA,EAAM,WAAA,EAAA;AAC5C,QAAA;AACF,OAAA;AACF,IAAA,CAAA,CAAA,OAAS,KAAA,EAAO;AACd,MAAA,MAAM,MAAM,cAAA,CAAe,KAAA,EAAO,MAAM,eAAA,CAAgB,eAAe,CAAC,CAAA;AAC1E,IAAA;AACF,EAAA;AAEA,EAAA,MAAM,SACJ,OAAA,EAC2D;AAC3D,IAAA,MAAM,EAAE,IAAA,EAAM,QAAA,KAAa,MAAM,IAAA,CAAK,QAAQ,OAAO,CAAA;AACrD,IAAA,MAAM,EAAE,aAAA,GAAgB,OAAA;AAExB,IAAA,MAAM,kBAAkB,MAAMI,yBAAAA,CAAQ,IAAA,CAAK,MAAA,CAAO,SAAS,CAAA;AAE3D,IAAA,IAAI;AACF,MAAA,MAAM,EAAE,KAAA,EAAO,QAAA,EAAU,eAAA,EAAA,GAAoB,MAAMG,+BAAA,CAAc;AAC/D,QAAA,GAAA,EAAK,KAAK,MAAA,EAAA;QACV,OAAA,EAASC,gCAAA;AACP,UAAA,eAAA;UACA,OAAA,CAAQ,OAAA;UACR,IAAA,CAAK,qBAAA,CAAsB,IAAA,CAAK,OAAA,EAAS,IAAI,CAAA;UAC7C,MAAMJ,yBAAAA,CAAQ,IAAA,CAAK,MAAA,CAAO,WAAW;AACvC,SAAA;QACA,IAAA,EAAM,IAAA;QACN,yBAAA,EAA2BK,kDAAA,CAAiCT,IAAAA,CAAE,GAAA,EAAK,CAAA;AACnE,QAAA,qBAAA,EAAuBM,gDAAAA,CAA+B;AACpD,UAAA,WAAA,EAAaN,KAAE,GAAA,EAAA;AACf,UAAA,cAAA,EAAgB,CAAA,IAAA,KAAQ;AACzB,SAAA,CAAA;QACD,GAAI,WAAA,IAAe,EAAE,WAAA,EAAA;AACrB,QAAA,KAAA,EAAO,KAAK,MAAA,CAAO;AACpB,OAAA,CAAA;AAED,MAAA,OAAO;AACL,QAAA,MAAA,EAAQ,QAAA,CAAS,WAAA;AACf,UAAA,IAAI,eAAA,CAGF;AACA,YAAA,KAAA,CAAM,UAAA,EAAY;AAChB,cAAA,IAAI,QAAA,CAAS,SAAS,CAAA,EAAG;AACvB,gBAAA,UAAA,CAAW,OAAA,CAAQ,EAAE,IAAA,EAAM,cAAA,EAAgB,UAAU,CAAA;AACvD,cAAA;AACF,YAAA,CAAA;AACA,YAAA,SAAA,CAAU,OAAO,UAAA,EAAY;AAC3B,cAAA,IAAI,MAAM,OAAA,EAAS;AACjB,gBAAA,MAAM,aAAa,KAAA,CAAM,KAAA;AAIzB,gBAAA,IAAI,UAAA,CAAW,IAAA,KAAS,KAAA,IAAS,CAAC,QAAQ,gBAAA,EAAkB;AAC1D,kBAAA;AACF,gBAAA;AAEA,gBAAA,IACE,UAAA,CAAW,SAAS,mBAAA,IACpB,UAAA,CAAW,aACX,OAAO,UAAA,CAAW,cAAc,QAAA,EAChC;AACA,kBAAA,UAAA,CAAW,SAAA,GAAY,IAAI,IAAA,CAAK,UAAA,CAAW,SAAS,CAAA;AACtD,gBAAA;AAEA,gBAAA,UAAA,CAAW,QAAQ,UAAU,CAAA;cAC/B,CAAA,MAAO;AACL,gBAAA,UAAA,CAAW,KAAA;kBACR,KAAA,CAA6C;AAChD,iBAAA;AACF,cAAA;AACF,YAAA;AACD,WAAA;AACH,SAAA;QACA,OAAA,EAAS,EAAE,MAAM,IAAA,EAAA;QACjB,QAAA,EAAU,EAAE,SAAS,eAAA;AACvB,OAAA;AACF,IAAA,CAAA,CAAA,OAAS,KAAA,EAAO;AACd,MAAA,MAAM,MAAM,cAAA,CAAe,KAAA,EAAO,MAAM,eAAA,CAAgB,eAAe,CAAC,CAAA;AAC1E,IAAA;AACF,EAAA;AAEQ,EAAA,UAAA,CAAW,IAAA,EAAe;AAChC,IAAA,OACE,QAAQ,OAAO,IAAA,KAAS,YAAY,MAAA,IAAU,IAAA,IAAQ,KAAK,IAAA,KAAS,MAAA;AAExE,EAAA;;;;;;;AAQQ,EAAA,oBAAA,CAAqB,OAAA,EAAqC;AAChE,IAAA,KAAA,MAAW,OAAA,IAAW,QAAQ,MAAA,EAAQ;AACpC,MAAA,KAAA,MAAW,IAAA,IAAQ,QAAQ,OAAA,EAAS;AAClC,QAAA,IAAI,IAAA,CAAK,UAAA,CAAW,IAAI,CAAA,EAAG;AACzB,UAAA,MAAM,QAAA,GAAW,IAAA;AAIjB,UAAA,IAAI,QAAA,CAAS,gBAAgB,UAAA,EAAY;AACvC,YAAA,MAAM,MAAA,GAAS,UAAA,CAAW,IAAA,CAAK,QAAA,CAAS,IAAI,CAAA;AAC5C,YAAA,MAAM,aAAa,MAAA,CAAO,IAAA,CAAK,MAAM,CAAA,CAAE,SAAS,QAAQ,CAAA;AACxD,YAAA,QAAA,CAAS,OAAO,IAAI,GAAA;AAClB,cAAA,CAAA,KAAA,EAAQ,QAAA,CAAS,SAAA,IAAa,0BAA0B,CAAA,QAAA,EAAW,UAAU,CAAA;AAC/E,aAAA;AACF,UAAA;AACF,QAAA;AACF,MAAA;AACF,IAAA;AACA,IAAA,OAAO,OAAA;AACT,EAAA;EAEQ,MAAA,GAAS;AACf,IAAA,OAAO,CAAA,EAAG,IAAA,CAAK,MAAA,CAAO,OAAO,CAAA,eAAA,CAAA;AAC/B,EAAA;AAEQ,EAAA,qBAAA,CAAsB,SAAiB,SAAA,EAAoB;AACjE,IAAA,OAAO;MACL,yCAAA,EAA2C,GAAA;MAC3C,sBAAA,EAAwB,OAAA;AACxB,MAAA,6BAAA,EAA+B,OAAO,SAAS;AACjD,KAAA;AACF,EAAA;AACF,CAAA;AC9LO,IAAM,wBAAN,MAAgE;AAKrE,EAAA,WAAA,CACW,SACQ,MAAA,EAIjB;AALS,IAAA,IAAA,CAAA,OAAA,GAAA,OAAA;AACQ,IAAA,IAAA,CAAA,MAAA,GAAA,MAAA;AANnB,IAAA,IAAA,CAAS,oBAAA,GAAuB,IAAA;AAChC,IAAA,IAAA,CAAS,oBAAA,GAAuB,IAAA;AAChC,IAAA,IAAA,CAAS,qBAAA,GAAwB,IAAA;AAQ9B,EAAA;AAEH,EAAA,IAAI,QAAA,GAAmB;AACrB,IAAA,OAAO,KAAK,MAAA,CAAO,QAAA;AACrB,EAAA;AAEA,EAAA,MAAM,OAAA,CAAQ;AACZ,IAAA,MAAA;AACA,IAAA,OAAA;AACA,IAAA,WAAA;AACA,IAAA;AAGA,GAAA,EAAA;AA3CJ,IAAA,IAAAJ,IAAAA;AA4CI,IAAA,MAAM,kBAAkB,MAAMQ,yBAAAA,CAAQ,IAAA,CAAK,MAAA,CAAO,SAAS,CAAA;AAC3D,IAAA,IAAI;AACF,MAAA,MAAM;AACJ,QAAA,eAAA;QACA,KAAA,EAAO,YAAA;AACP,QAAA;AACF,OAAA,GAAI,MAAMG,+BAAAA,CAAc;AACtB,QAAA,GAAA,EAAK,KAAK,MAAA,EAAA;QACV,OAAA,EAASC,gCAAAA;AACP,UAAA,eAAA;UACA,OAAA,IAAA,IAAA,GAAA,UAAW,EAAA;AACX,UAAA,IAAA,CAAK,qBAAA,EAAA;UACL,MAAMJ,yBAAAA,CAAQ,IAAA,CAAK,MAAA,CAAO,WAAW;AACvC,SAAA;QACA,IAAA,EAAM;AACJ,UAAA,KAAA,EAAO,MAAA,CAAO,MAAA,KAAW,CAAA,GAAI,MAAA,CAAO,CAAC,CAAA,GAAI,MAAA;AACzC,UAAA,GAAI,eAAA,GAAkB,EAAE,eAAA,EAAA,GAAoB;AAC9C,SAAA;QACA,yBAAA,EAA2BC,2CAAAA;AACzB,UAAA;AACF,SAAA;AACA,QAAA,qBAAA,EAAuBC,gDAAAA,CAA+B;AACpD,UAAA,WAAA,EAAaN,KAAE,GAAA,EAAA;AACf,UAAA,cAAA,EAAgB,CAAA,IAAA,KAAQ;AACzB,SAAA,CAAA;QACD,GAAI,WAAA,IAAe,EAAE,WAAA,EAAA;AACrB,QAAA,KAAA,EAAO,KAAK,MAAA,CAAO;AACpB,OAAA,CAAA;AAED,MAAA,OAAO;AACL,QAAA,UAAA,EAAY,YAAA,CAAa,UAAA;AACzB,QAAA,KAAA,EAAA,CAAOJ,IAAAA,GAAA,YAAA,CAAa,KAAA,KAAb,IAAA,GAAAA,IAAAA,GAAsB,MAAA;AAC7B,QAAA,gBAAA,EACE,YAAA,CAAa,gBAAA;AACf,QAAA,QAAA,EAAU,EAAE,OAAA,EAAS,eAAA,EAAiB,IAAA,EAAM,QAAA;AAC9C,OAAA;AACF,IAAA,CAAA,CAAA,OAAS,KAAA,EAAO;AACd,MAAA,MAAM,MAAM,cAAA,CAAe,KAAA,EAAO,MAAM,eAAA,CAAgB,eAAe,CAAC,CAAA;AAC1E,IAAA;AACF,EAAA;EAEQ,MAAA,GAAS;AACf,IAAA,OAAO,CAAA,EAAG,IAAA,CAAK,MAAA,CAAO,OAAO,CAAA,gBAAA,CAAA;AAC/B,EAAA;EAEQ,qBAAA,GAAwB;AAC9B,IAAA,OAAO;MACL,0CAAA,EAA4C,GAAA;AAC5C,MAAA,aAAA,EAAe,IAAA,CAAK;AACtB,KAAA;AACF,EAAA;AACF,CAAA;AAEA,IAAM,8BAAA,GAAiCE,+BAAAA;EAAc,MACnDC,2BAAAA;AACEC,IAAAA,IAAAA,CAAE,MAAA,CAAO;AACP,MAAA,UAAA,EAAYA,KAAE,KAAA,CAAMA,IAAAA,CAAE,MAAMA,IAAAA,CAAE,MAAA,EAAQ,CAAC,CAAA;MACvC,KAAA,EAAOA,IAAAA,CAAE,OAAO,EAAE,MAAA,EAAQA,KAAE,MAAA,EAAA,EAAU,CAAA,CAAE,OAAA,EAAA;AACxC,MAAA,gBAAA,EAAkBA,IAAAA,CACf,MAAA,CAAOA,IAAAA,CAAE,MAAA,IAAUA,IAAAA,CAAE,MAAA,CAAOA,IAAAA,CAAE,MAAA,IAAUA,IAAAA,CAAE,OAAA,EAAS,CAAC,EACpD,QAAA;AACJ,KAAA;AACH;AACF,CAAA;ACzFO,IAAM,oBAAN,MAAgD;AAKrD,EAAA,WAAA,CACW,SACQ,MAAA,EAIjB;AALS,IAAA,IAAA,CAAA,OAAA,GAAA,OAAA;AACQ,IAAA,IAAA,CAAA,MAAA,GAAA,MAAA;AANnB,IAAA,IAAA,CAAS,oBAAA,GAAuB,IAAA;AAEhC,IAAA,IAAA,CAAS,mBAAmB,MAAA,CAAO,gBAAA;AAQhC,EAAA;AAEH,EAAA,IAAI,QAAA,GAAmB;AACrB,IAAA,OAAO,KAAK,MAAA,CAAO,QAAA;AACrB,EAAA;AAEA,EAAA,MAAM,UAAA,CAAW;AACf,IAAA,MAAA;AACA,IAAA,CAAA;AACA,IAAA,IAAA;AACA,IAAA,WAAA;AACA,IAAA,IAAA;AACA,IAAA,eAAA;AACA,IAAA,OAAA;AACA,IAAA;AAGA,GAAA,EAAA;AA9CJ,IAAA,IAAAJ,IAAAA;AA+CI,IAAA,MAAM,kBAAkB,MAAMQ,yBAAAA,CAAQ,IAAA,CAAK,MAAA,CAAO,SAAS,CAAA;AAC3D,IAAA,IAAI;AACF,MAAA,MAAM;AACJ,QAAA,eAAA;QACA,KAAA,EAAO;AAET,OAAA,GAAI,MAAMG,+BAAAA,CAAc;AACtB,QAAA,GAAA,EAAK,KAAK,MAAA,EAAA;QACV,OAAA,EAASC,gCAAAA;AACP,UAAA,eAAA;UACA,OAAA,IAAA,IAAA,GAAA,UAAW,EAAA;AACX,UAAA,IAAA,CAAK,qBAAA,EAAA;UACL,MAAMJ,yBAAAA,CAAQ,IAAA,CAAK,MAAA,CAAO,WAAW;AACvC,SAAA;QACA,IAAA,EAAM;AACJ,UAAA,MAAA;AACA,UAAA,CAAA;UACA,GAAI,IAAA,IAAQ,EAAE,IAAA,EAAA;UACd,GAAI,WAAA,IAAe,EAAE,WAAA,EAAA;UACrB,GAAI,IAAA,IAAQ,EAAE,IAAA,EAAA;UACd,GAAI,eAAA,IAAmB,EAAE,eAAA;AAC3B,SAAA;QACA,yBAAA,EAA2BC,2CAAAA;AACzB,UAAA;AACF,SAAA;AACA,QAAA,qBAAA,EAAuBC,gDAAAA,CAA+B;AACpD,UAAA,WAAA,EAAaN,KAAE,GAAA,EAAA;AACf,UAAA,cAAA,EAAgB,CAAA,IAAA,KAAQ;AACzB,SAAA,CAAA;QACD,GAAI,WAAA,IAAe,EAAE,WAAA,EAAA;AACrB,QAAA,KAAA,EAAO,KAAK,MAAA,CAAO;AACpB,OAAA,CAAA;AAED,MAAA,OAAO;AACL,QAAA,MAAA,EAAQ,YAAA,CAAa,MAAA;;AACrB,QAAA,QAAA,EAAA,CAAUJ,IAAAA,GAAA,YAAA,CAAa,QAAA,KAAb,IAAA,GAAAA,OAAyB,EAAA;AACnC,QAAA,gBAAA,EACE,YAAA,CAAa,gBAAA;QACf,QAAA,EAAU;AACR,UAAA,SAAA,sBAAe,IAAA,EAAA;AACf,UAAA,OAAA,EAAS,IAAA,CAAK,OAAA;UACd,OAAA,EAAS;AACX;AACF,OAAA;AACF,IAAA,CAAA,CAAA,OAAS,KAAA,EAAO;AACd,MAAA,MAAM,cAAA,CAAe,KAAA,EAAO,MAAM,eAAA,CAAgB,eAAe,CAAC,CAAA;AACpE,IAAA;AACF,EAAA;EAEQ,MAAA,GAAS;AACf,IAAA,OAAO,CAAA,EAAG,IAAA,CAAK,MAAA,CAAO,OAAO,CAAA,YAAA,CAAA;AAC/B,EAAA;EAEQ,qBAAA,GAAwB;AAC9B,IAAA,OAAO;MACL,sCAAA,EAAwC,GAAA;AACxC,MAAA,aAAA,EAAe,IAAA,CAAK;AACtB,KAAA;AACF,EAAA;AACF,CAAA;AAEA,IAAM,2BAAA,GAA8BI,KACjC,MAAA,CAAO;AACN,EAAA,MAAA,EAAQA,KAAE,KAAA,CAAMA,IAAAA,CAAE,OAAA,EAAS,EAAE,QAAA;AAC/B,CAAC,CAAA,CACA,QAAA,CAASA,IAAAA,CAAE,OAAA,EAAS,CAAA;AAEvB,IAAM,0BAAA,GAA6BA,KAAE,MAAA,CAAO;AAC1C,EAAA,MAAA,EAAQA,IAAAA,CAAE,KAAA,CAAMA,IAAAA,CAAE,MAAA,EAAQ,CAAA;;AAC1B,EAAA,QAAA,EAAUA,IAAAA,CACP,KAAA;AACCA,IAAAA,IAAAA,CAAE,MAAA,CAAO;MACP,IAAA,EAAMA,IAAAA,CAAE,QAAQ,OAAO,CAAA;AACvB,MAAA,OAAA,EAASA,KAAE,MAAA;AACZ,KAAA;AACH,GAAA,CACC,QAAA,EAAA;AACH,EAAA,gBAAA,EAAkBA,KACf,MAAA,CAAOA,IAAAA,CAAE,QAAA,EAAU,2BAA2B,EAC9C,QAAA;AACL,CAAC,CAAA;Af5HD,eAAsB,kBAAA,GAAkD;AAHxE,EAAA,IAAAJ,IAAAA;AAIE,EAAA,OAAA,CAAOA,IAAAA,GAAAA,IAAA,WAAA,CAAA,UAAA,IAAa,OAAA,KAAb,IAAA,GAAA,MAAA,GAAAA,IAAAA,CAAuB,aAAA,CAAA;AAChC;AgBHO,IAAM,OAAA,GAEP,QAAA;AC6FN,IAAM,2BAAA,GAA8B,OAAA;AAK7B,SAAS,qBAAA,CACd,OAAA,GAAmC,EAAA,EAClB;AAxGnB,EAAA,IAAAA,IAAAA,EAAAC,GAAAA;AAyGE,EAAA,IAAI,eAAA,GAAgE,IAAA;AACpE,EAAA,IAAI,aAAA,GAAqD,IAAA;AACzD,EAAA,MAAM,sBACJD,IAAAA,GAAA,OAAA,CAAQ,+BAAR,IAAA,GAAAA,IAAAA,GAAsC,MAAO,EAAA,GAAK,CAAA;AACpD,EAAA,IAAI,aAAA,GAAgB,CAAA;AAEpB,EAAA,MAAM,WACJC,GAAAA,GAAAa,sCAAA,CAAqB,QAAQ,OAAO,CAAA,KAApC,OAAAb,GAAAA,GACA,oCAAA;AAEF,EAAA,MAAM,aAAa,YAAY;AAC7B,IAAA,MAAM,IAAA,GAAO,MAAM,mBAAA,CAAoB,OAAO,CAAA;AAC9C,IAAA,IAAI,IAAA,EAAM;AACR,MAAA,OAAOc,qCAAA;AACL,QAAA;UACE,aAAA,EAAe,CAAA,OAAA,EAAU,KAAK,KAAK,CAAA,CAAA;UACnC,6BAAA,EAA+B,2BAAA;UAC/B,CAAC,0BAA0B,GAAG,IAAA,CAAK,UAAA;AACnC,UAAA,GAAG,OAAA,CAAQ;AACb,SAAA;AACA,QAAA,CAAA,eAAA,EAAkB,OAAO,CAAA;AAC3B,OAAA;AACF,IAAA;AAEA,IAAA,MAAM,2BAA2B,qBAAA,CAAsB;MACrD,cAAA,EAAgB,KAAA;MAChB,iBAAA,EAAmB,KAAA;MACnB,UAAA,EAAY;AACb,KAAA,CAAA;AACH,EAAA,CAAA;AAEA,EAAA,MAAM,oBAAoB,MAAM;AAC9B,IAAA,MAAM,eAAeC,qCAAA,CAAoB;MACvC,YAAA,EAAc,MAAA;MACd,uBAAA,EAAyB;AAC1B,KAAA,CAAA;AACD,IAAA,MAAM,cAAcA,qCAAA,CAAoB;MACtC,YAAA,EAAc,MAAA;MACd,uBAAA,EAAyB;AAC1B,KAAA,CAAA;AACD,IAAA,MAAM,SAASA,qCAAA,CAAoB;MACjC,YAAA,EAAc,MAAA;MACd,uBAAA,EAAyB;AAC1B,KAAA,CAAA;AAED,IAAA,OAAO,YAAY;AACjB,MAAA,MAAM,SAAA,GAAY,MAAM,kBAAA,EAAA;AACxB,MAAA,OAAO;QACL,GAAI,YAAA,IAAgB,EAAE,uBAAA,EAAyB,YAAA,EAAA;QAC/C,GAAI,WAAA,IAAe,EAAE,qBAAA,EAAuB,WAAA,EAAA;QAC5C,GAAI,MAAA,IAAU,EAAE,gBAAA,EAAkB,MAAA,EAAA;QAClC,GAAI,SAAA,IAAa,EAAE,oBAAA,EAAsB,SAAA;AAC3C,OAAA;AACF,IAAA,CAAA;AACF,EAAA,CAAA;AAEA,EAAA,MAAM,mBAAA,GAAsB,CAAC,OAAA,KAA4B;AACvD,IAAA,OAAO,IAAI,qBAAqB,OAAA,EAAS;MACvC,QAAA,EAAU,SAAA;AACV,MAAA,OAAA;MACA,OAAA,EAAS,UAAA;AACT,MAAA,KAAA,EAAO,OAAA,CAAQ,KAAA;AACf,MAAA,WAAA,EAAa,iBAAA;AACd,KAAA,CAAA;AACH,EAAA,CAAA;AAEA,EAAA,MAAM,qBAAqB,YAAY;AA3KzC,IAAA,IAAAhB,MAAAC,GAAAA,EAAA,EAAA;AA4KI,IAAA,MAAMgB,IAAAA,GAAAA,CAAM,MAAAhB,GAAAA,GAAAA,CAAAD,IAAAA,GAAA,QAAQ,SAAA,KAAR,IAAA,GAAA,SAAAA,IAAAA,CAAmB,WAAA,KAAnB,OAAA,MAAA,GAAAC,GAAAA,CAAA,KAAAD,IAAAA,CAAAA,CAAmC,SAAA,KAAnC,IAAA,GAAA,EAAA,GAAgD,IAAA,CAAK,GAAA,EAAA;AACjE,IAAA,IAAI,CAAC,eAAA,IAAmBiB,IAAAA,GAAM,aAAA,GAAgB,kBAAA,EAAoB;AAChE,MAAA,aAAA,GAAgBA,IAAAA;AAEhB,MAAA,eAAA,GAAkB,IAAI,oBAAA,CAAqB;AACzC,QAAA,OAAA;QACA,OAAA,EAAS,UAAA;AACT,QAAA,KAAA,EAAO,OAAA,CAAQ;AACjB,OAAC,CAAA,CACE,kBAAA,EAAA,CACA,IAAA,CAAK,CAAA,QAAA,KAAY;AAChB,QAAA,aAAA,GAAgB,QAAA;AAChB,QAAA,OAAO,QAAA;MACT,CAAC,CAAA,CACA,KAAA,CAAM,OAAO,KAAA,KAAmB;AAC/B,QAAA,MAAM,MAAM,cAAA;AACV,UAAA,KAAA;UACA,MAAM,eAAA,CAAgB,MAAM,UAAA,EAAY;AAC1C,SAAA;MACF,CAAC,CAAA;AACL,IAAA;AAEA,IAAA,OAAO,aAAA,GAAgB,OAAA,CAAQ,OAAA,CAAQ,aAAa,CAAA,GAAI,eAAA;AAC1D,EAAA,CAAA;AAEA,EAAA,MAAM,aAAa,YAAY;AAC7B,IAAA,OAAO,IAAI,oBAAA,CAAqB;AAC9B,MAAA,OAAA;MACA,OAAA,EAAS,UAAA;AACT,MAAA,KAAA,EAAO,OAAA,CAAQ;AACjB,KAAC,CAAA,CACE,UAAA,EAAA,CACA,KAAA,CAAM,OAAO,KAAA,KAAmB;AAC/B,MAAA,MAAM,MAAM,cAAA;AACV,QAAA,KAAA;QACA,MAAM,eAAA,CAAgB,MAAM,UAAA,EAAY;AAC1C,OAAA;IACF,CAAC,CAAA;AACL,EAAA,CAAA;AAEA,EAAA,MAAM,QAAA,GAAW,SAAU,OAAA,EAAyB;AAClD,IAAA,IAAI,GAAA,CAAA,MAAA,EAAY;AACd,MAAA,MAAM,IAAI,KAAA;AACR,QAAA;AACF,OAAA;AACF,IAAA;AAEA,IAAA,OAAO,oBAAoB,OAAO,CAAA;AACpC,EAAA,CAAA;AAEA,EAAA,QAAA,CAAS,kBAAA,GAAqB,kBAAA;AAC9B,EAAA,QAAA,CAAS,UAAA,GAAa,UAAA;AACtB,EAAA,QAAA,CAAS,UAAA,GAAa,CAAC,OAAA,KAAiC;AACtD,IAAA,OAAO,IAAI,kBAAkB,OAAA,EAAS;MACpC,QAAA,EAAU,SAAA;AACV,MAAA,OAAA;MACA,OAAA,EAAS,UAAA;AACT,MAAA,KAAA,EAAO,OAAA,CAAQ,KAAA;AACf,MAAA,WAAA,EAAa,iBAAA;AACd,KAAA,CAAA;AACH,EAAA,CAAA;AACA,EAAA,QAAA,CAAS,aAAA,GAAgB,mBAAA;AACzB,EAAA,QAAA,CAAS,kBAAA,GAAqB,CAAC,OAAA,KAAqC;AAClE,IAAA,OAAO,IAAI,sBAAsB,OAAA,EAAS;MACxC,QAAA,EAAU,SAAA;AACV,MAAA,OAAA;MACA,OAAA,EAAS,UAAA;AACT,MAAA,KAAA,EAAO,OAAA,CAAQ,KAAA;AACf,MAAA,WAAA,EAAa,iBAAA;AACd,KAAA,CAAA;AACH,EAAA,CAAA;AAEA,EAAA,OAAO,QAAA;AACT;AAEO,IAAM,UAAU,qBAAA,EAAA;AAEvB,eAAsB,oBACpB,OAAA,EAIQ;AACR,EAAA,MAAM,SAASD,qCAAA,CAAoB;AACjC,IAAA,YAAA,EAAc,OAAA,CAAQ,MAAA;IACtB,uBAAA,EAAyB;AAC1B,GAAA,CAAA;AAED,EAAA,IAAI,MAAA,EAAQ;AACV,IAAA,OAAO;MACL,KAAA,EAAO,MAAA;MACP,UAAA,EAAY;AACd,KAAA;AACF,EAAA;AAEA,EAAA,IAAI;AACF,IAAA,MAAM,SAAA,GAAY,MAAA,IAAM,YAAA,CAAA,kBAAA,GAAA;AACxB,IAAA,OAAO;MACL,KAAA,EAAO,SAAA;MACP,UAAA,EAAY;AACd,KAAA;AACF,EAAA,CAAA,CAAA,OAAQ,CAAA,EAAA;AACN,IAAA,OAAO,IAAA;AACT,EAAA;AACF;AClQO,IAAM,WAAA,GAAc,OAAO,UAAA,KAAe,QAAA,GAAW,UAAA,GAAa,MAAA;ACDlE,IAAME,QAAAA,GAAU,OAAA;ACCvB,IAAM,EAAA,GAAK,+BAAA;AAkBL,SAAU,wBACd,UAAA,EAAkB;AAElB,EAAA,IAAM,gBAAA,mBAAmB,IAAI,GAAA,CAAY,CAAC,UAAU,CAAC,CAAA;AACrD,EAAA,IAAM,gBAAA,uBAAuB,GAAA,EAAA;AAE7B,EAAA,IAAM,cAAA,GAAiB,UAAA,CAAW,KAAA,CAAM,EAAE,CAAA;AAC1C,EAAA,IAAI,CAAC,cAAA,EAAgB;AAEnB,IAAA,OAAO,WAAA;AAAM,MAAA,OAAA,KAAA;AAAA,IAAA,CAAA;;AAGf,EAAA,IAAM,gBAAA,GAAmB;IACvB,KAAA,EAAO,CAAC,eAAe,CAAC,CAAA;IACxB,KAAA,EAAO,CAAC,eAAe,CAAC,CAAA;IACxB,KAAA,EAAO,CAAC,eAAe,CAAC,CAAA;AACxB,IAAA,UAAA,EAAY,eAAe,CAAC;;AAI9B,EAAA,IAAI,gBAAA,CAAiB,cAAc,IAAA,EAAM;AACvC,IAAA,OAAO,SAAS,aAAa,aAAA,EAAqB;AAChD,MAAA,OAAO,aAAA,KAAkB,UAAA;AAC3B,IAAA,CAAA;;AAGF,EAAA,SAAS,QAAQ,CAAA,EAAS;AACxB,IAAA,gBAAA,CAAiB,IAAI,CAAC,CAAA;AACtB,IAAA,OAAO,KAAA;AACT,EAAA;AAEA,EAAA,SAAS,QAAQ,CAAA,EAAS;AACxB,IAAA,gBAAA,CAAiB,IAAI,CAAC,CAAA;AACtB,IAAA,OAAO,IAAA;AACT,EAAA;AAEA,EAAA,OAAO,SAASC,cAAa,aAAA,EAAqB;AAChD,IAAA,IAAI,gBAAA,CAAiB,GAAA,CAAI,aAAa,CAAA,EAAG;AACvC,MAAA,OAAO,IAAA;;AAGT,IAAA,IAAI,gBAAA,CAAiB,GAAA,CAAI,aAAa,CAAA,EAAG;AACvC,MAAA,OAAO,KAAA;;AAGT,IAAA,IAAM,kBAAA,GAAqB,aAAA,CAAc,KAAA,CAAM,EAAE,CAAA;AACjD,IAAA,IAAI,CAAC,kBAAA,EAAoB;AAGvB,MAAA,OAAO,QAAQ,aAAa,CAAA;;AAG9B,IAAA,IAAM,mBAAA,GAAsB;MAC1B,KAAA,EAAO,CAAC,mBAAmB,CAAC,CAAA;MAC5B,KAAA,EAAO,CAAC,mBAAmB,CAAC,CAAA;MAC5B,KAAA,EAAO,CAAC,mBAAmB,CAAC,CAAA;AAC5B,MAAA,UAAA,EAAY,mBAAmB,CAAC;;AAIlC,IAAA,IAAI,mBAAA,CAAoB,cAAc,IAAA,EAAM;AAC1C,MAAA,OAAO,QAAQ,aAAa,CAAA;;AAI9B,IAAA,IAAI,gBAAA,CAAiB,KAAA,KAAU,mBAAA,CAAoB,KAAA,EAAO;AACxD,MAAA,OAAO,QAAQ,aAAa,CAAA;;AAG9B,IAAA,IAAI,gBAAA,CAAiB,UAAU,CAAA,EAAG;AAChC,MAAA,IACE,iBAAiB,KAAA,KAAU,mBAAA,CAAoB,SAC/C,gBAAA,CAAiB,KAAA,IAAS,oBAAoB,KAAA,EAC9C;AACA,QAAA,OAAO,QAAQ,aAAa,CAAA;;AAG9B,MAAA,OAAO,QAAQ,aAAa,CAAA;;AAG9B,IAAA,IAAI,gBAAA,CAAiB,KAAA,IAAS,mBAAA,CAAoB,KAAA,EAAO;AACvD,MAAA,OAAO,QAAQ,aAAa,CAAA;;AAG9B,IAAA,OAAO,QAAQ,aAAa,CAAA;AAC9B,EAAA,CAAA;AACF;AAiBO,IAAM,YAAA,GAAe,wBAAwBD,QAAO,CAAA;AClH3D,IAAM,KAAA,GAAQA,QAAAA,CAAQ,KAAA,CAAM,GAAG,EAAE,CAAC,CAAA;AAClC,IAAM,4BAAA,mBAA+B,MAAA,CAAO,GAAA,CAC1C,uBAAA,GAAwB,KAAO,CAAA;AAGjC,IAAM,OAAA,GAAU,WAAA;AAEV,SAAU,cAAA,CACd,IAAA,EACA,QAAA,EACA,IAAA,EACA,aAAA,EAAqB;;AAArB,EAAA,IAAA,kBAAA,MAAA,EAAA;AAAA,IAAA,aAAA,GAAA,KAAA;AAAqB,EAAA;AAErB,EAAA,IAAM,GAAA,GAAO,OAAA,CAAQ,4BAA4B,CAAA,GAAA,CAAIlB,IAAAA,GAAA,OAAA,CACnD,4BAA4B,CAAA,MAC7B,IAAA,IAAAA,IAAAA,KAAA,MAAA,GAAAA,IAAAA,GAAI;IACH,OAAA,EAASkB;;AAGX,EAAA,IAAI,CAAC,aAAA,IAAiB,GAAA,CAAI,IAAI,CAAA,EAAG;AAE/B,IAAA,IAAM,GAAA,GAAM,IAAI,KAAA,CACd,+DAAA,GAAgE,IAAM,CAAA;AAExE,IAAA,IAAA,CAAK,KAAA,CAAM,GAAA,CAAI,KAAA,IAAS,GAAA,CAAI,OAAO,CAAA;AACnC,IAAA,OAAO,KAAA;;AAGT,EAAA,IAAI,GAAA,CAAI,YAAYA,QAAAA,EAAS;AAE3B,IAAA,IAAM,GAAA,GAAM,IAAI,KAAA,CACd,+CAAA,GAAgD,IAAI,OAAA,GAAO,OAAA,GAAQ,IAAA,GAAI,6CAAA,GAA8CA,QAAS,CAAA;AAEhI,IAAA,IAAA,CAAK,KAAA,CAAM,GAAA,CAAI,KAAA,IAAS,GAAA,CAAI,OAAO,CAAA;AACnC,IAAA,OAAO,KAAA;;AAGT,EAAA,GAAA,CAAI,IAAI,CAAA,GAAI,QAAA;AACZ,EAAA,IAAA,CAAK,KAAA,CACH,8CAAA,GAA+C,IAAA,GAAI,IAAA,GAAKA,WAAO,GAAG,CAAA;AAGpE,EAAA,OAAO,IAAA;AACT;AAEM,SAAU,UACd,IAAA,EAAU;;AAEV,EAAA,IAAM,aAAA,GAAA,CAAgBlB,OAAA,OAAA,CAAQ,4BAA4B,OAAC,IAAA,IAAAA,IAAAA,KAAA,MAAA,GAAA,MAAA,GAAAA,IAAAA,CAAE,OAAA;AAC7D,EAAA,IAAI,CAAC,aAAA,IAAiB,CAAC,YAAA,CAAa,aAAa,CAAA,EAAG;AAClD,IAAA;;AAEF,EAAA,OAAA,CAAOC,GAAAA,GAAA,QAAQ,4BAA4B,CAAA,MAAC,QAAAA,GAAAA,KAAA,MAAA,GAAA,MAAA,GAAAA,GAAAA,CAAG,IAAI,CAAA;AACrD;AAEM,SAAU,gBAAA,CAAiB,MAA2B,IAAA,EAAgB;AAC1E,EAAA,IAAA,CAAK,KAAA,CACH,iDAAA,GAAkD,IAAA,GAAI,IAAA,GAAKiB,WAAO,GAAG,CAAA;AAEvE,EAAA,IAAM,GAAA,GAAM,QAAQ,4BAA4B,CAAA;AAEhD,EAAA,IAAI,GAAA,EAAK;AACP,IAAA,OAAO,IAAI,IAAI,CAAA;;AAEnB;;;;;;;;;;;;;;;;;;;;;;;;;;;AC7DA,IAAA,mBAAA;;GAAA,WAAA;AAGE,IAAA,SAAAE,qBAAY,KAAA,EAA6B;AACvC,MAAA,IAAA,CAAK,UAAA,GAAa,MAAM,SAAA,IAAa,qBAAA;AACvC,IAAA;AAEOA,IAAAA,oBAAAA,CAAA,SAAA,CAAA,QAAP,WAAA;AAAa,MAAA,IAAA,OAAA,EAAA;AAAA,MAAA,KAAA,IAAA,EAAA,GAAA,CAAA,EAAA,EAAA,GAAA,SAAA,CAAA,QAAA,EAAA,EAAA,EAAc;AAAd,QAAA,IAAA,CAAA,EAAA,CAAA,GAAA,SAAA,CAAA,EAAA,CAAA;;AACX,MAAA,OAAO,QAAA,CAAS,OAAA,EAAS,IAAA,CAAK,UAAA,EAAY,IAAI,CAAA;AAChD,IAAA,CAAA;AAEOA,IAAAA,oBAAAA,CAAA,SAAA,CAAA,QAAP,WAAA;AAAa,MAAA,IAAA,OAAA,EAAA;AAAA,MAAA,KAAA,IAAA,EAAA,GAAA,CAAA,EAAA,EAAA,GAAA,SAAA,CAAA,QAAA,EAAA,EAAA,EAAc;AAAd,QAAA,IAAA,CAAA,EAAA,CAAA,GAAA,SAAA,CAAA,EAAA,CAAA;;AACX,MAAA,OAAO,QAAA,CAAS,OAAA,EAAS,IAAA,CAAK,UAAA,EAAY,IAAI,CAAA;AAChD,IAAA,CAAA;AAEOA,IAAAA,oBAAAA,CAAA,SAAA,CAAA,OAAP,WAAA;AAAY,MAAA,IAAA,OAAA,EAAA;AAAA,MAAA,KAAA,IAAA,EAAA,GAAA,CAAA,EAAA,EAAA,GAAA,SAAA,CAAA,QAAA,EAAA,EAAA,EAAc;AAAd,QAAA,IAAA,CAAA,EAAA,CAAA,GAAA,SAAA,CAAA,EAAA,CAAA;;AACV,MAAA,OAAO,QAAA,CAAS,MAAA,EAAQ,IAAA,CAAK,UAAA,EAAY,IAAI,CAAA;AAC/C,IAAA,CAAA;AAEOA,IAAAA,oBAAAA,CAAA,SAAA,CAAA,OAAP,WAAA;AAAY,MAAA,IAAA,OAAA,EAAA;AAAA,MAAA,KAAA,IAAA,EAAA,GAAA,CAAA,EAAA,EAAA,GAAA,SAAA,CAAA,QAAA,EAAA,EAAA,EAAc;AAAd,QAAA,IAAA,CAAA,EAAA,CAAA,GAAA,SAAA,CAAA,EAAA,CAAA;;AACV,MAAA,OAAO,QAAA,CAAS,MAAA,EAAQ,IAAA,CAAK,UAAA,EAAY,IAAI,CAAA;AAC/C,IAAA,CAAA;AAEOA,IAAAA,oBAAAA,CAAA,SAAA,CAAA,UAAP,WAAA;AAAe,MAAA,IAAA,OAAA,EAAA;AAAA,MAAA,KAAA,IAAA,EAAA,GAAA,CAAA,EAAA,EAAA,GAAA,SAAA,CAAA,QAAA,EAAA,EAAA,EAAc;AAAd,QAAA,IAAA,CAAA,EAAA,CAAA,GAAA,SAAA,CAAA,EAAA,CAAA;;AACb,MAAA,OAAO,QAAA,CAAS,SAAA,EAAW,IAAA,CAAK,UAAA,EAAY,IAAI,CAAA;AAClD,IAAA,CAAA;AACF,IAAA,OAAAA,oBAAAA;EAAA,CAAA;;AAEA,SAAS,QAAA,CACP,QAAA,EACA,SAAA,EACA,IAAA,EAAS;AAET,EAAA,IAAM,MAAA,GAAS,UAAU,MAAM,CAAA;AAE/B,EAAA,IAAI,CAAC,MAAA,EAAQ;AACX,IAAA;;AAGF,EAAA,IAAA,CAAK,QAAQ,SAAS,CAAA;AACtB,EAAA,OAAO,MAAA,CAAO,QAAQ,CAAA,CAAC,KAAA,CAAhB,MAAA,EAAM,aAAA,CAAA,EAAA,EAAA,MAAA,CAAe,IAAoC,CAAA,EAAA,KAAA,CAAA,CAAA;AAClE;ACHA,IAAY,YAAA;AAAZ,CAAA,SAAYC,aAAAA,EAAY;AAEtBA,EAAAA,aAAAA,CAAAA,aAAAA,CAAA,MAAA,CAAA,GAAA,CAAA,CAAA,GAAA,MAAA;AAGAA,EAAAA,aAAAA,CAAAA,aAAAA,CAAA,OAAA,CAAA,GAAA,EAAA,CAAA,GAAA,OAAA;AAGAA,EAAAA,aAAAA,CAAAA,aAAAA,CAAA,MAAA,CAAA,GAAA,EAAA,CAAA,GAAA,MAAA;AAGAA,EAAAA,aAAAA,CAAAA,aAAAA,CAAA,MAAA,CAAA,GAAA,EAAA,CAAA,GAAA,MAAA;AAGAA,EAAAA,aAAAA,CAAAA,aAAAA,CAAA,OAAA,CAAA,GAAA,EAAA,CAAA,GAAA,OAAA;AAMAA,EAAAA,aAAAA,CAAAA,aAAAA,CAAA,SAAA,CAAA,GAAA,EAAA,CAAA,GAAA,SAAA;AAGAA,EAAAA,aAAAA,CAAAA,aAAAA,CAAA,KAAA,CAAA,GAAA,IAAA,CAAA,GAAA,KAAA;AACF,CAAA,EAxBY,YAAA,KAAA,YAAA,GAAY,EAAA,CAAA,CAAA;AChDlB,SAAU,wBAAA,CACd,UACA,MAAA,EAAkB;AAElB,EAAA,IAAI,QAAA,GAAW,aAAa,IAAA,EAAM;AAChC,IAAA,QAAA,GAAW,YAAA,CAAa,IAAA;EACf,CAAA,MAAA,IAAA,QAAA,GAAW,aAAa,GAAA,EAAK;AACtC,IAAA,QAAA,GAAW,YAAA,CAAa,GAAA;;AAI1B,EAAA,MAAA,GAAS,UAAU,EAAA;AAEnB,EAAA,SAAS,WAAA,CACP,UACA,QAAA,EAAsB;AAEtB,IAAA,IAAM,OAAA,GAAU,OAAO,QAAQ,CAAA;AAE/B,IAAA,IAAI,OAAO,OAAA,KAAY,UAAA,IAAc,QAAA,IAAY,QAAA,EAAU;AACzD,MAAA,OAAO,OAAA,CAAQ,KAAK,MAAM,CAAA;;AAE5B,IAAA,OAAO,WAAA;AAAa,IAAA,CAAA;AACtB,EAAA;AAEA,EAAA,OAAO;IACL,KAAA,EAAO,WAAA,CAAY,OAAA,EAAS,YAAA,CAAa,KAAK,CAAA;IAC9C,IAAA,EAAM,WAAA,CAAY,MAAA,EAAQ,YAAA,CAAa,IAAI,CAAA;IAC3C,IAAA,EAAM,WAAA,CAAY,MAAA,EAAQ,YAAA,CAAa,IAAI,CAAA;IAC3C,KAAA,EAAO,WAAA,CAAY,OAAA,EAAS,YAAA,CAAa,KAAK,CAAA;IAC9C,OAAA,EAAS,WAAA,CAAY,SAAA,EAAW,YAAA,CAAa,OAAO;;AAExD;;;;;;;;;;;;;;;;;;;;;;;;;;;ACnBA,IAAM,QAAA,GAAW,MAAA;AAMjB,IAAA,OAAA;;GAAA,WAAA;AAgBE,IAAA,SAAAC,QAAAA,GAAA;AACE,MAAA,SAAS,UAAU,QAAA,EAA0B;AAC3C,QAAA,OAAO,WAAA;AAAU,UAAA,IAAA,OAAA,EAAA;AAAA,UAAA,KAAA,IAAA,EAAA,GAAA,CAAA,EAAA,EAAA,GAAA,SAAA,CAAA,QAAA,EAAA,EAAA,EAAO;AAAP,YAAA,IAAA,CAAA,EAAA,CAAA,GAAA,SAAA,CAAA,EAAA,CAAA;;AACf,UAAA,IAAM,MAAA,GAAS,UAAU,MAAM,CAAA;AAE/B,UAAA,IAAI,CAAC,MAAA;AAAQ,YAAA;AACb,UAAA,OAAO,MAAA,CAAO,QAAQ,CAAA,CAAC,KAAA,CAAhB,MAAA,EAAMC,cAAAA,CAAA,EAAA,EAAAC,OAAAA,CAAc,IAAI,CAAA,EAAA,KAAA,CAAA,CAAA;AACjC,QAAA,CAAA;AACF,MAAA;AAGA,MAAA,IAAM,IAAA,GAAO,IAAA;AAIb,MAAA,IAAM,SAAA,GAAwC,SAC5C,MAAA,EACA,iBAAA,EAAmD;;AAAnD,QAAA,IAAA,sBAAA,MAAA,EAAA;AAAA,UAAA,iBAAA,GAAA,EAAsB,QAAA,EAAU,YAAA,CAAa,IAAA,EAAA;AAAM,QAAA;AAEnD,QAAA,IAAI,WAAW,IAAA,EAAM;AAInB,UAAA,IAAM,GAAA,GAAM,IAAI,KAAA,CACd,oIAAoI,CAAA;AAEtI,UAAA,IAAA,CAAK,KAAA,CAAA,CAAMxB,OAAA,GAAA,CAAI,KAAA,MAAK,QAAAA,IAAAA,KAAA,MAAA,GAAAA,IAAAA,GAAI,GAAA,CAAI,OAAO,CAAA;AACnC,UAAA,OAAO,KAAA;;AAGT,QAAA,IAAI,OAAO,sBAAsB,QAAA,EAAU;AACzC,UAAA,iBAAA,GAAoB;YAClB,QAAA,EAAU;;;AAId,QAAA,IAAM,SAAA,GAAY,UAAU,MAAM,CAAA;AAClC,QAAA,IAAM,SAAA,GAAY,wBAAA,CAAA,CAChBC,GAAAA,GAAA,iBAAA,CAAkB,QAAA,MAAQ,IAAA,IAAAA,GAAAA,KAAA,MAAA,GAAAA,GAAAA,GAAI,YAAA,CAAa,IAAA,EAC3C,MAAM,CAAA;AAGR,QAAA,IAAI,SAAA,IAAa,CAAC,iBAAA,CAAkB,uBAAA,EAAyB;AAC3D,UAAA,IAAM,KAAA,GAAA,CAAQ,KAAA,IAAI,KAAA,GAAQ,KAAA,MAAK,IAAA,IAAA,EAAA,KAAA,MAAA,GAAA,EAAA,GAAI,iCAAA;AACnC,UAAA,SAAA,CAAU,IAAA,CAAK,6CAA2C,KAAO,CAAA;AACjE,UAAA,SAAA,CAAU,IAAA,CACR,+DAA6D,KAAO,CAAA;;AAIxE,QAAA,OAAO,cAAA,CAAe,MAAA,EAAQ,SAAA,EAAW,IAAA,EAAM,IAAI,CAAA;AACrD,MAAA,CAAA;AAEA,MAAA,IAAA,CAAK,SAAA,GAAY,SAAA;AAEjB,MAAA,IAAA,CAAK,UAAU,WAAA;AACb,QAAA,gBAAA,CAAiB,UAAU,IAAI,CAAA;AACjC,MAAA,CAAA;AAEA,MAAA,IAAA,CAAK,qBAAA,GAAwB,SAAC,OAAA,EAA+B;AAC3D,QAAA,OAAO,IAAI,oBAAoB,OAAO,CAAA;AACxC,MAAA,CAAA;AAEA,MAAA,IAAA,CAAK,OAAA,GAAU,UAAU,SAAS,CAAA;AAClC,MAAA,IAAA,CAAK,KAAA,GAAQ,UAAU,OAAO,CAAA;AAC9B,MAAA,IAAA,CAAK,IAAA,GAAO,UAAU,MAAM,CAAA;AAC5B,MAAA,IAAA,CAAK,IAAA,GAAO,UAAU,MAAM,CAAA;AAC5B,MAAA,IAAA,CAAK,KAAA,GAAQ,UAAU,OAAO,CAAA;AAChC,IAAA;AAhFcqB,IAAAA,QAAAA,CAAA,WAAd,WAAA;AACE,MAAA,IAAI,CAAC,KAAK,SAAA,EAAW;AACnB,QAAA,IAAA,CAAK,SAAA,GAAY,IAAIA,QAAAA,EAAAA;;AAGvB,MAAA,OAAO,IAAA,CAAK,SAAA;AACd,IAAA,CAAA;AA+FF,IAAA,OAAAA,QAAAA;EAAA,CAAA;;AC3HM,SAAU,iBAAiB,WAAA,EAAmB;AAOlD,EAAA,OAAO,MAAA,CAAO,IAAI,WAAW,CAAA;AAC/B;AAEA,IAAA,WAAA;;kBAAA,CAAA,WAAA;AAQE,IAAA,SAAAG,aAAY,aAAA,EAAoC;AAE9C,MAAA,IAAM,IAAA,GAAO,IAAA;AAEb,MAAA,IAAA,CAAK,kBAAkB,aAAA,GAAgB,IAAI,IAAI,aAAa,CAAA,uBAAQ,GAAA,EAAA;AAEpE,MAAA,IAAA,CAAK,QAAA,GAAW,SAAC,GAAA,EAAW;AAAK,QAAA,OAAA,IAAA,CAAK,eAAA,CAAgB,GAAA,CAAI,GAAG,CAAA;AAA5B,MAAA,CAAA;AAEjC,MAAA,IAAA,CAAK,QAAA,GAAW,SAAC,GAAA,EAAa,KAAA,EAAc;AAC1C,QAAA,IAAM,OAAA,GAAU,IAAIA,YAAAA,CAAY,IAAA,CAAK,eAAe,CAAA;AACpD,QAAA,OAAA,CAAQ,eAAA,CAAgB,GAAA,CAAI,GAAA,EAAK,KAAK,CAAA;AACtC,QAAA,OAAO,OAAA;AACT,MAAA,CAAA;AAEA,MAAA,IAAA,CAAK,WAAA,GAAc,SAAC,GAAA,EAAW;AAC7B,QAAA,IAAM,OAAA,GAAU,IAAIA,YAAAA,CAAY,IAAA,CAAK,eAAe,CAAA;AACpD,QAAA,OAAA,CAAQ,eAAA,CAAgB,OAAO,GAAG,CAAA;AAClC,QAAA,OAAO,OAAA;AACT,MAAA,CAAA;AACF,IAAA;AAyBF,IAAA,OAAAA,YAAAA;EAAA,CAAA;;AAGO,IAAM,YAAA,GAAwB,IAAI,WAAA,EAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;ACjEzC,IAAA,kBAAA;;GAAA,WAAA;AAAA,IAAA,SAAAC,mBAAAA,GAAA;AAyBA,IAAA;AAxBEA,IAAAA,mBAAAA,CAAA,SAAA,CAAA,SAAA,WAAA;AACE,MAAA,OAAO,YAAA;AACT,IAAA,CAAA;AAEAA,IAAAA,mBAAAA,CAAA,SAAA,CAAA,IAAA,GAAA,SACE,QAAA,EACA,IACA,OAAA,EAA8B;AAC9B,MAAA,IAAA,OAAA,EAAA;AAAA,MAAA,KAAA,IAAA,EAAA,GAAA,CAAA,EAAA,EAAA,GAAA,SAAA,CAAA,QAAA,EAAA,EAAA,EAAU;AAAV,QAAA,IAAA,CAAA,EAAA,GAAA,CAAA,CAAA,GAAA,SAAA,CAAA,EAAA,CAAA;;AAEA,MAAA,OAAO,EAAA,CAAG,IAAA,CAAI,KAAA,CAAP,EAAA,EAAEH,cAAAA,CAAA,CAAM,OAAO,CAAA,EAAAC,OAAAA,CAAK,IAAI,CAAA,EAAA,KAAA,CAAA,CAAA;AACjC,IAAA,CAAA;AAEAE,IAAAA,mBAAAA,CAAA,SAAA,CAAA,IAAA,GAAA,SAAQ,QAAA,EAAyB,MAAA,EAAS;AACxC,MAAA,OAAO,MAAA;AACT,IAAA,CAAA;AAEAA,IAAAA,mBAAAA,CAAA,SAAA,CAAA,SAAA,WAAA;AACE,MAAA,OAAO,IAAA;AACT,IAAA,CAAA;AAEAA,IAAAA,mBAAAA,CAAA,SAAA,CAAA,UAAA,WAAA;AACE,MAAA,OAAO,IAAA;AACT,IAAA,CAAA;AACF,IAAA,OAAAA,mBAAAA;EAAA,CAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACnBA,IAAMC,SAAAA,GAAW,SAAA;AACjB,IAAM,oBAAA,GAAuB,IAAI,kBAAA,EAAA;AAKjC,IAAA,UAAA;;GAAA,WAAA;AAIE,IAAA,SAAAC,WAAAA,GAAA;AAAuB,IAAA;AAGTA,IAAAA,WAAAA,CAAA,cAAd,WAAA;AACE,MAAA,IAAI,CAAC,KAAK,SAAA,EAAW;AACnB,QAAA,IAAA,CAAK,SAAA,GAAY,IAAIA,WAAAA,EAAAA;;AAGvB,MAAA,OAAO,IAAA,CAAK,SAAA;AACd,IAAA,CAAA;AAOOA,IAAAA,WAAAA,CAAA,SAAA,CAAA,uBAAA,GAAP,SAA+B,cAAA,EAA8B;AAC3D,MAAA,OAAO,cAAA,CAAeD,SAAAA,EAAU,cAAA,EAAgB,OAAA,CAAQ,UAAU,CAAA;AACpE,IAAA,CAAA;AAKOC,IAAAA,WAAAA,CAAA,SAAA,CAAA,SAAP,WAAA;AACE,MAAA,OAAO,IAAA,CAAK,kBAAA,EAAA,CAAqB,MAAA,EAAA;AACnC,IAAA,CAAA;AAUOA,IAAAA,WAAAA,CAAA,SAAA,CAAA,IAAA,GAAP,SACE,OAAA,EACA,IACA,OAAA,EAA8B;;AAC9B,MAAA,IAAA,OAAA,EAAA;AAAA,MAAA,KAAA,IAAA,EAAA,GAAA,CAAA,EAAA,EAAA,GAAA,SAAA,CAAA,QAAA,EAAA,EAAA,EAAU;AAAV,QAAA,IAAA,CAAA,EAAA,GAAA,CAAA,CAAA,GAAA,SAAA,CAAA,EAAA,CAAA;;AAEA,MAAA,OAAA,CAAO5B,OAAA,IAAA,CAAK,kBAAA,EAAA,EAAqB,IAAA,CAAI,MAAAA,IAAAA,EAAAuB,cAAAA,CAAA,CAAC,OAAA,EAAS,IAAI,OAAO,CAAA,EAAAC,QAAK,IAAI,CAAA,EAAA,KAAA,CAAA,CAAA;AACrE,IAAA,CAAA;AAQOI,IAAAA,WAAAA,CAAA,SAAA,CAAA,IAAA,GAAP,SAAe,OAAA,EAAkB,MAAA,EAAS;AACxC,MAAA,OAAO,IAAA,CAAK,kBAAA,EAAA,CAAqB,IAAA,CAAK,SAAS,MAAM,CAAA;AACvD,IAAA,CAAA;AAEQA,IAAAA,WAAAA,CAAA,SAAA,CAAA,qBAAR,WAAA;AACE,MAAA,OAAO,SAAA,CAAUD,SAAQ,CAAA,IAAK,oBAAA;AAChC,IAAA,CAAA;AAGOC,IAAAA,WAAAA,CAAA,SAAA,CAAA,UAAP,WAAA;AACE,MAAA,IAAA,CAAK,kBAAA,GAAqB,OAAA,EAAA;AAC1B,MAAA,gBAAA,CAAiBD,SAAAA,EAAU,OAAA,CAAQ,QAAA,EAAU,CAAA;AAC/C,IAAA,CAAA;AACF,IAAA,OAAAC,WAAAA;EAAA,CAAA;;ACnFA,IAAY,UAAA;AAAZ,CAAA,SAAYC,WAAAA,EAAU;AAEpBA,EAAAA,WAAAA,CAAAA,WAAAA,CAAA,MAAA,CAAA,GAAA,CAAA,CAAA,GAAA,MAAA;AAEAA,EAAAA,WAAAA,CAAAA,WAAAA,CAAA,SAAA,CAAA,GAAA,CAAA,CAAA,GAAA,SAAA;AACF,CAAA,EALY,UAAA,KAAA,UAAA,GAAU,EAAA,CAAA,CAAA;ACIf,IAAM,cAAA,GAAiB,kBAAA;AACvB,IAAM,eAAA,GAAkB,kCAAA;AACxB,IAAM,oBAAA,GAAoC;EAC/C,OAAA,EAAS,eAAA;EACT,MAAA,EAAQ,cAAA;AACR,EAAA,UAAA,EAAY,UAAA,CAAW;;ACMzB,IAAA,gBAAA;;GAAA,WAAA;AACE,IAAA,SAAAC,kBACmB,YAAA,EAAgD;AAAhD,MAAA,IAAA,iBAAA,MAAA,EAAA;AAAA,QAAA,YAAA,GAAA,oBAAA;AAAgD,MAAA;AAAhD,MAAA,IAAA,CAAA,YAAA,GAAA,YAAA;AAChB,IAAA;AAGHA,IAAAA,iBAAAA,CAAA,SAAA,CAAA,cAAA,WAAA;AACE,MAAA,OAAO,IAAA,CAAK,YAAA;AACd,IAAA,CAAA;AAGAA,IAAAA,iBAAAA,CAAA,SAAA,CAAA,YAAA,GAAA,SAAa,IAAA,EAAc,MAAA,EAAe;AACxC,MAAA,OAAO,IAAA;AACT,IAAA,CAAA;AAGAA,IAAAA,iBAAAA,CAAA,SAAA,CAAA,aAAA,GAAA,SAAc,WAAA,EAA2B;AACvC,MAAA,OAAO,IAAA;AACT,IAAA,CAAA;AAGAA,IAAAA,iBAAAA,CAAA,SAAA,CAAA,QAAA,GAAA,SAAS,KAAA,EAAe,WAAA,EAA4B;AAClD,MAAA,OAAO,IAAA;AACT,IAAA,CAAA;AAEAA,IAAAA,iBAAAA,CAAA,SAAA,CAAA,OAAA,GAAA,SAAQ,KAAA,EAAW;AACjB,MAAA,OAAO,IAAA;AACT,IAAA,CAAA;AAEAA,IAAAA,iBAAAA,CAAA,SAAA,CAAA,QAAA,GAAA,SAAS,MAAA,EAAc;AACrB,MAAA,OAAO,IAAA;AACT,IAAA,CAAA;AAGAA,IAAAA,iBAAAA,CAAA,SAAA,CAAA,SAAA,GAAA,SAAU,OAAA,EAAmB;AAC3B,MAAA,OAAO,IAAA;AACT,IAAA,CAAA;AAGAA,IAAAA,iBAAAA,CAAA,SAAA,CAAA,UAAA,GAAA,SAAW,KAAA,EAAa;AACtB,MAAA,OAAO,IAAA;AACT,IAAA,CAAA;AAGAA,IAAAA,iBAAAA,CAAA,SAAA,CAAA,GAAA,GAAA,SAAI,QAAA,EAAoB;AAAS,IAAA,CAAA;AAGjCA,IAAAA,iBAAAA,CAAA,SAAA,CAAA,cAAA,WAAA;AACE,MAAA,OAAO,KAAA;AACT,IAAA,CAAA;AAGAA,IAAAA,iBAAAA,CAAA,SAAA,CAAA,eAAA,GAAA,SAAgB,UAAA,EAAuB,KAAA,EAAiB;AAAS,IAAA,CAAA;AACnE,IAAA,OAAAA,iBAAAA;EAAA,CAAA;;ACzDA,IAAM,QAAA,GAAW,iBAAiB,gCAAgC,CAAA;AAO5D,SAAU,QAAQ,OAAA,EAAgB;AACtC,EAAA,OAAQ,OAAA,CAAQ,QAAA,CAAS,QAAQ,CAAA,IAAc,MAAA;AACjD;AAKM,SAAU,aAAA,GAAa;AAC3B,EAAA,OAAO,OAAA,CAAQ,UAAA,CAAW,WAAA,EAAA,CAAc,QAAQ,CAAA;AAClD;AAQM,SAAU,OAAA,CAAQ,SAAkB,IAAA,EAAU;AAClD,EAAA,OAAO,OAAA,CAAQ,QAAA,CAAS,QAAA,EAAU,IAAI,CAAA;AACxC;AAOM,SAAU,WAAW,OAAA,EAAgB;AACzC,EAAA,OAAO,OAAA,CAAQ,YAAY,QAAQ,CAAA;AACrC;AASM,SAAU,cAAA,CACd,SACA,WAAA,EAAwB;AAExB,EAAA,OAAO,OAAA,CAAQ,OAAA,EAAS,IAAI,gBAAA,CAAiB,WAAW,CAAC,CAAA;AAC3D;AAOM,SAAU,eAAe,OAAA,EAAgB;;AAC7C,EAAA,OAAA,CAAO9B,IAAAA,GAAA,QAAQ,OAAO,CAAA,MAAC,QAAAA,IAAAA,KAAA,MAAA,GAAA,MAAA,GAAAA,IAAAA,CAAE,WAAA,EAAA;AAC3B;AChEA,IAAM,mBAAA,GAAsB,mBAAA;AAC5B,IAAM,kBAAA,GAAqB,iBAAA;AAErB,SAAU,eAAe,OAAA,EAAe;AAC5C,EAAA,OAAO,mBAAA,CAAoB,IAAA,CAAK,OAAO,CAAA,IAAK,OAAA,KAAY,eAAA;AAC1D;AAEM,SAAU,cAAc,MAAA,EAAc;AAC1C,EAAA,OAAO,kBAAA,CAAmB,IAAA,CAAK,MAAM,CAAA,IAAK,MAAA,KAAW,cAAA;AACvD;AAMM,SAAU,mBAAmB,WAAA,EAAwB;AACzD,EAAA,OACE,eAAe,WAAA,CAAY,OAAO,CAAA,IAAK,aAAA,CAAc,YAAY,MAAM,CAAA;AAE3E;AAQM,SAAU,gBAAgB,WAAA,EAAwB;AACtD,EAAA,OAAO,IAAI,iBAAiB,WAAW,CAAA;AACzC;ACvBA,IAAM,UAAA,GAAa,WAAW,WAAA,EAAA;AAK9B,IAAA,UAAA;;GAAA,WAAA;AAAA,IAAA,SAAA+B,WAAAA,GAAA;AAoEA,IAAA;AAlEEA,IAAAA,WAAAA,CAAA,SAAA,CAAA,SAAA,GAAA,SACExC,MAAAA,EACA,SACA,OAAA,EAA6B;AAA7B,MAAA,IAAA,YAAA,MAAA,EAAA;AAAA,QAAA,OAAA,GAAU,WAAW,MAAA,EAAA;AAAQ,MAAA;AAE7B,MAAA,IAAM,IAAA,GAAO,QAAQ,OAAA,KAAO,IAAA,IAAP,YAAO,MAAA,GAAA,MAAA,GAAP,QAAS,IAAI,CAAA;AAClC,MAAA,IAAI,IAAA,EAAM;AACR,QAAA,OAAO,IAAI,gBAAA,EAAA;;AAGb,MAAA,IAAM,iBAAA,GAAoB,OAAA,IAAW,cAAA,CAAe,OAAO,CAAA;AAE3D,MAAA,IACE,aAAA,CAAc,iBAAiB,CAAA,IAC/B,kBAAA,CAAmB,iBAAiB,CAAA,EACpC;AACA,QAAA,OAAO,IAAI,iBAAiB,iBAAiB,CAAA;MACxC,CAAA,MAAA;AACL,QAAA,OAAO,IAAI,gBAAA,EAAA;;AAEf,IAAA,CAAA;AAiBAwC,IAAAA,WAAAA,CAAA,UAAA,eAAA,GAAA,SACExC,MAAAA,EACA,IAAA,EACA,MACA,IAAA,EAAQ;AAER,MAAA,IAAI,IAAA;AACJ,MAAA,IAAI,GAAA;AACJ,MAAA,IAAI,EAAA;AAEJ,MAAA,IAAI,SAAA,CAAU,SAAS,CAAA,EAAG;AACxB,QAAA;MACS,CAAA,MAAA,IAAA,SAAA,CAAU,WAAW,CAAA,EAAG;AACjC,QAAA,EAAA,GAAK,IAAA;MACI,CAAA,MAAA,IAAA,SAAA,CAAU,WAAW,CAAA,EAAG;AACjC,QAAA,IAAA,GAAO,IAAA;AACP,QAAA,EAAA,GAAK,IAAA;MACA,CAAA,MAAA;AACL,QAAA,IAAA,GAAO,IAAA;AACP,QAAA,GAAA,GAAM,IAAA;AACN,QAAA,EAAA,GAAK,IAAA;;AAGP,MAAA,IAAM,gBAAgB,GAAA,KAAG,IAAA,IAAH,QAAG,MAAA,GAAH,GAAA,GAAO,WAAW,MAAA,EAAA;AACxC,MAAA,IAAM,IAAA,GAAO,IAAA,CAAK,SAAA,CAAUA,MAAAA,EAAM,MAAM,aAAa,CAAA;AACrD,MAAA,IAAM,kBAAA,GAAqB,OAAA,CAAQ,aAAA,EAAe,IAAI,CAAA;AAEtD,MAAA,OAAO,UAAA,CAAW,IAAA,CAAK,kBAAA,EAAoB,EAAA,EAAI,QAAW,IAAI,CAAA;AAChE,IAAA,CAAA;AACF,IAAA,OAAAwC,WAAAA;EAAA,CAAA;;AAEA,SAAS,cAAc,WAAA,EAAgB;AACrC,EAAA,OACE,OAAO,WAAA,KAAgB,QAAA,IACvB,OAAO,WAAA,CAAY,QAAQ,CAAA,KAAM,QAAA,IACjC,OAAO,WAAA,CAAY,SAAS,CAAA,KAAM,QAAA,IAClC,OAAO,WAAA,CAAY,YAAY,CAAA,KAAM,QAAA;AAEzC;ACrFA,IAAM,WAAA,GAAc,IAAI,UAAA,EAAA;AAKxB,IAAA,WAAA;;GAAA,WAAA;AAIE,IAAA,SAAAC,YAAAA,CACU,SAAA,EACQzC,MAAAA,EACA,OAAA,EACA,OAAA,EAAuB;AAH/B,MAAA,IAAA,CAAA,SAAA,GAAA,SAAA;AACQ,MAAA,IAAA,CAAA,IAAA,GAAAA,MAAAA;AACA,MAAA,IAAA,CAAA,OAAA,GAAA,OAAA;AACA,MAAA,IAAA,CAAA,OAAA,GAAA,OAAA;AACf,IAAA;AAEHyC,IAAAA,YAAAA,CAAA,SAAA,CAAA,SAAA,GAAA,SAAUzC,MAAAA,EAAc,SAAuB,OAAA,EAAiB;AAC9D,MAAA,OAAO,KAAK,UAAA,EAAA,CAAa,SAAA,CAAUA,MAAAA,EAAM,SAAS,OAAO,CAAA;AAC3D,IAAA,CAAA;AAEAyC,IAAAA,YAAAA,CAAA,UAAA,eAAA,GAAA,SACE,KAAA,EACA,QAAA,EACA,UACA,GAAA,EAAO;AAEP,MAAA,IAAM,MAAA,GAAS,KAAK,UAAA,EAAA;AACpB,MAAA,OAAO,OAAA,CAAQ,KAAA,CAAM,MAAA,CAAO,eAAA,EAAiB,QAAQ,SAAS,CAAA;AAChE,IAAA,CAAA;AAMQA,IAAAA,YAAAA,CAAA,SAAA,CAAA,aAAR,WAAA;AACE,MAAA,IAAI,KAAK,SAAA,EAAW;AAClB,QAAA,OAAO,IAAA,CAAK,SAAA;;AAGd,MAAA,IAAM,MAAA,GAAS,KAAK,SAAA,CAAU,iBAAA,CAC5B,KAAK,IAAA,EACL,IAAA,CAAK,OAAA,EACL,IAAA,CAAK,OAAO,CAAA;AAGd,MAAA,IAAI,CAAC,MAAA,EAAQ;AACX,QAAA,OAAO,WAAA;;AAGT,MAAA,IAAA,CAAK,SAAA,GAAY,MAAA;AACjB,MAAA,OAAO,IAAA,CAAK,SAAA;AACd,IAAA,CAAA;AACF,IAAA,OAAAA,YAAAA;EAAA,CAAA;;AChDA,IAAA,kBAAA;;GAAA,WAAA;AAAA,IAAA,SAAAC,mBAAAA,GAAA;AAQA,IAAA;AAPEA,IAAAA,mBAAAA,CAAA,SAAA,CAAA,SAAA,GAAA,SACE,KAAA,EACA,UACA,QAAA,EAAwB;AAExB,MAAA,OAAO,IAAI,UAAA,EAAA;AACb,IAAA,CAAA;AACF,IAAA,OAAAA,mBAAAA;EAAA,CAAA;;ACbA,IAAM,oBAAA,GAAuB,IAAI,kBAAA,EAAA;AAUjC,IAAA,mBAAA;;GAAA,WAAA;AAAA,IAAA,SAAAC,oBAAAA,GAAA;AA+BA,IAAA;AAzBEA,IAAAA,oBAAAA,CAAA,SAAA,CAAA,SAAA,GAAA,SAAU3C,MAAAA,EAAc,SAAkB,OAAA,EAAuB;;AAC/D,MAAA,OAAA,CACES,OAAA,IAAA,CAAK,iBAAA,CAAkBT,MAAAA,EAAM,OAAA,EAAS,OAAO,CAAA,MAAC,IAAA,IAAAS,IAAAA,KAAA,MAAA,GAAAA,OAC9C,IAAI,WAAA,CAAY,IAAA,EAAMT,MAAAA,EAAM,SAAS,OAAO,CAAA;AAEhD,IAAA,CAAA;AAEA2C,IAAAA,oBAAAA,CAAA,SAAA,CAAA,cAAA,WAAA;;AACE,MAAA,OAAA,CAAOlC,OAAA,IAAA,CAAK,SAAA,MAAS,IAAA,IAAAA,IAAAA,KAAA,SAAAA,IAAAA,GAAI,oBAAA;AAC3B,IAAA,CAAA;AAKAkC,IAAAA,oBAAAA,CAAA,SAAA,CAAA,WAAA,GAAA,SAAY,QAAA,EAAwB;AAClC,MAAA,IAAA,CAAK,SAAA,GAAY,QAAA;AACnB,IAAA,CAAA;AAEAA,IAAAA,oBAAAA,CAAA,SAAA,CAAA,iBAAA,GAAA,SACE3C,MAAAA,EACA,SACA,OAAA,EAAuB;;AAEvB,MAAA,OAAA,CAAOS,IAAAA,GAAA,IAAA,CAAK,SAAA,MAAS,IAAA,IAAAA,IAAAA,KAAA,MAAA,GAAA,MAAA,GAAAA,IAAAA,CAAE,SAAA,CAAUT,MAAAA,EAAM,OAAA,EAAS,OAAO,CAAA;AACzD,IAAA,CAAA;AACF,IAAA,OAAA2C,oBAAAA;EAAA,CAAA;;ACtCA,IAAY,cAAA;AAAZ,CAAA,SAAYC,eAAAA,EAAc;AAIxBA,EAAAA,eAAAA,CAAAA,eAAAA,CAAA,OAAA,CAAA,GAAA,CAAA,CAAA,GAAA,OAAA;AAKAA,EAAAA,eAAAA,CAAAA,eAAAA,CAAA,IAAA,CAAA,GAAA,CAAA,CAAA,GAAA,IAAA;AAIAA,EAAAA,eAAAA,CAAAA,eAAAA,CAAA,OAAA,CAAA,GAAA,CAAA,CAAA,GAAA,OAAA;AACF,CAAA,EAdY,cAAA,KAAA,cAAA,GAAc,EAAA,CAAA,CAAA;ACa1B,IAAMR,SAAAA,GAAW,OAAA;AAKjB,IAAA,QAAA;;GAAA,WAAA;AAME,IAAA,SAAAS,SAAAA,GAAA;AAHQ,MAAA,IAAA,CAAA,oBAAA,GAAuB,IAAI,mBAAA,EAAA;AAmD5B,MAAA,IAAA,CAAA,eAAA,GAAkB,eAAA;AAElB,MAAA,IAAA,CAAA,kBAAA,GAAqB,kBAAA;AAErB,MAAA,IAAA,CAAA,UAAA,GAAa,UAAA;AAEb,MAAA,IAAA,CAAA,OAAA,GAAU,OAAA;AAEV,MAAA,IAAA,CAAA,aAAA,GAAgB,aAAA;AAEhB,MAAA,IAAA,CAAA,cAAA,GAAiB,cAAA;AAEjB,MAAA,IAAA,CAAA,OAAA,GAAU,OAAA;AAEV,MAAA,IAAA,CAAA,cAAA,GAAiB,cAAA;AA9DD,IAAA;AAGTA,IAAAA,SAAAA,CAAA,cAAd,WAAA;AACE,MAAA,IAAI,CAAC,KAAK,SAAA,EAAW;AACnB,QAAA,IAAA,CAAK,SAAA,GAAY,IAAIA,SAAAA,EAAAA;;AAGvB,MAAA,OAAO,IAAA,CAAK,SAAA;AACd,IAAA,CAAA;AAOOA,IAAAA,SAAAA,CAAA,SAAA,CAAA,uBAAA,GAAP,SAA+B,QAAA,EAAwB;AACrD,MAAA,IAAM,UAAU,cAAA,CACdT,SAAAA,EACA,KAAK,oBAAA,EACL,OAAA,CAAQ,UAAU,CAAA;AAEpB,MAAA,IAAI,OAAA,EAAS;AACX,QAAA,IAAA,CAAK,oBAAA,CAAqB,YAAY,QAAQ,CAAA;;AAEhD,MAAA,OAAO,OAAA;AACT,IAAA,CAAA;AAKOS,IAAAA,SAAAA,CAAA,SAAA,CAAA,oBAAP,WAAA;AACE,MAAA,OAAO,SAAA,CAAUT,SAAQ,CAAA,IAAK,IAAA,CAAK,oBAAA;AACrC,IAAA,CAAA;AAKOS,IAAAA,SAAAA,CAAA,SAAA,CAAA,SAAA,GAAP,SAAiB7C,MAAAA,EAAc,OAAA,EAAgB;AAC7C,MAAA,OAAO,IAAA,CAAK,iBAAA,EAAA,CAAoB,SAAA,CAAUA,QAAM,OAAO,CAAA;AACzD,IAAA,CAAA;AAGO6C,IAAAA,SAAAA,CAAA,SAAA,CAAA,UAAP,WAAA;AACE,MAAA,gBAAA,CAAiBT,SAAAA,EAAU,OAAA,CAAQ,QAAA,EAAU,CAAA;AAC7C,MAAA,IAAA,CAAK,oBAAA,GAAuB,IAAI,mBAAA,EAAA;AAClC,IAAA,CAAA;AAiBF,IAAA,OAAAS,SAAAA;EAAA,CAAA;;AC5FO,IAAM,KAAA,GAAQ,SAAS,WAAA,EAAA;;;;;;ACF9B,SAAS,cAAc,OAAA,EAA0B;AAC/C,EAAA,MAAM,MAAA,GAAS,iBAAA;AAEf,EAAA,QAAQ,QAAQ,IAAA;AACd,IAAA,KAAK,qBAAA,EAAuB;AAC1B,MAAA,IAAI,OAAA,GAAU,CAAA,EAAG,MAAM,CAAA,MAAA,EAAS,QAAQ,OAAO,CAAA,wCAAA,CAAA;AAC/C,MAAA,IAAI,QAAQ,OAAA,EAAS;AACnB,QAAA,OAAA,IAAW,CAAA,GAAA,EAAM,QAAQ,OAAO,CAAA,CAAA;AAClC,MAAA;AACA,MAAA,OAAO,OAAA;AACT,IAAA;AAEA,IAAA,KAAK,kBAAA,EAAoB;AACvB,MAAA,MAAM,WACJ,MAAA,IAAU,OAAA,CAAQ,IAAA,GAAO,OAAA,CAAQ,KAAK,IAAA,GAAO,cAAA;AAC/C,MAAA,IAAI,OAAA,GAAU,CAAA,EAAG,MAAM,CAAA,WAAA,EAAc,QAAQ,CAAA,gCAAA,CAAA;AAC7C,MAAA,IAAI,QAAQ,OAAA,EAAS;AACnB,QAAA,OAAA,IAAW,CAAA,GAAA,EAAM,QAAQ,OAAO,CAAA,CAAA;AAClC,MAAA;AACA,MAAA,OAAO,OAAA;AACT,IAAA;AAEA,IAAA,KAAK,OAAA,EAAS;AACZ,MAAA,OAAO,CAAA,EAAG,MAAM,CAAA,CAAA,EAAI,OAAA,CAAQ,OAAO,CAAA,CAAA;AACrC,IAAA;IAEA,SAAS;AAEP,MAAA,OAAO,CAAA,EAAG,MAAM,CAAA,CAAA,EAAI,IAAA,CAAK,UAAU,OAAA,EAAS,IAAA,EAAM,CAAC,CAAC,CAAA,CAAA;AACtD,IAAA;AACF;AACF;AAEO,IAAM,0BAAA,GACX,kGAAA;AAEF,IAAI,eAAA,GAAkB,KAAA;AAEf,IAAM,WAAA,GAAmC,CAAA,QAAA,KAAY;AAE1D,EAAA,IAAI,QAAA,CAAS,WAAW,CAAA,EAAG;AACzB,IAAA;AACF,EAAA;AAEA,EAAA,MAAM,SAAS,UAAA,CAAW,mBAAA;AAG1B,EAAA,IAAI,WAAW,KAAA,EAAO;AACpB,IAAA;AACF,EAAA;AAGA,EAAA,IAAI,OAAO,WAAW,UAAA,EAAY;AAChC,IAAA,MAAA,CAAO,QAAQ,CAAA;AACf,IAAA;AACF,EAAA;AAGA,EAAA,IAAI,CAAC,eAAA,EAAiB;AACpB,IAAA,eAAA,GAAkB,IAAA;AAClB,IAAA,OAAA,CAAQ,KAAK,0BAA0B,CAAA;AACzC,EAAA;AAGA,EAAA,KAAA,MAAW,WAAW,QAAA,EAAU;AAC9B,IAAA,OAAA,CAAQ,IAAA,CAAK,aAAA,CAAc,OAAO,CAAC,CAAA;AACrC,EAAA;AACF,CAAA;ACnFA,IAAM7C,MAAAA,GAAO,yBAAA;AACb,IAAMO,QAAAA,GAAS,mBAAmBP,MAAI,CAAA,CAAA;AACtC,IAAMQ,QAAAA,GAAS,MAAA,CAAO,GAAA,CAAID,QAAM,CAAA;AAJhC,IAAAE,IAAAA;AAMO,IAAMqC,qBAAAA,GAAN,cAAmCC,4BAAAA,CAAW;EAMnD,WAAA,CAAY;AACV,IAAA,SAAA;AACA,IAAA,KAAA;AACA,IAAA;AAKC,GAAA,EAAA;AACD,IAAA,KAAA,CAAM;MACJ,IAAA,EAAA/C,MAAAA;MACA,OAAA,EAAS,CAAA,+BAAA,EAAkC,SAAS,CAAA,EAAA,EAAK,OAAO,CAAA;AACjE,KAAA,CAAA;AAjBH,IAAA,IAAA,CAAkBS,IAAAA,CAAAA,GAAU,IAAA;AAmB1B,IAAA,IAAA,CAAK,SAAA,GAAY,SAAA;AACjB,IAAA,IAAA,CAAK,KAAA,GAAQ,KAAA;AACf,EAAA;AAEA,EAAA,OAAO,WAAW,KAAA,EAA+C;AAC/D,IAAA,OAAOsC,4BAAAA,CAAW,SAAA,CAAU,KAAA,EAAOxC,QAAM,CAAA;AAC3C,EAAA;AACF,CAAA;AA1BoBE,IAAAA,GAAAD,QAAAA;ACFpB,IAAMR,MAAAA,GAAO,2BAAA;AACb,IAAMO,QAAAA,GAAS,mBAAmBP,MAAI,CAAA,CAAA;AACtC,IAAMQ,QAAAA,GAAS,MAAA,CAAO,GAAA,CAAID,QAAM,CAAA;AAPhC,IAAAE,IAAAA;AAoBO,IAAM,sBAAA,GAAN,cAAqCsC,4BAAAA,CAAW;EAuBrD,WAAA,CAAY;IACV,OAAA,GAAU,sBAAA;AACV,IAAA,KAAA;IACA,IAAA,EAAAC,KAAAA;AACA,IAAA,QAAA;AACA,IAAA,KAAA;AACA,IAAA;AAQC,GAAA,EAAA;AACD,IAAA,KAAA,CAAM,EAAE,IAAA,EAAAhD,MAAAA,EAAM,OAAA,EAAS,OAAO,CAAA;AArChC,IAAA,IAAA,CAAkBS,IAAAA,CAAAA,GAAU,IAAA;AAuC1B,IAAA,IAAA,CAAK,IAAA,GAAOuC,KAAAA;AACZ,IAAA,IAAA,CAAK,QAAA,GAAW,QAAA;AAChB,IAAA,IAAA,CAAK,KAAA,GAAQ,KAAA;AACb,IAAA,IAAA,CAAK,YAAA,GAAe,YAAA;AACtB,EAAA;AAEA,EAAA,OAAO,WAAW,KAAA,EAAiD;AACjE,IAAA,OAAOD,4BAAAA,CAAW,SAAA,CAAU,KAAA,EAAOxC,QAAM,CAAA;AAC3C,EAAA;AACF,CAAA;AAhDoBE,IAAAA,GAAAD,QAAAA;ACfb,IAAM,sBAAA,GAAN,cAAqCuC,4BAAAA,CAAW;AAGrD,EAAA,WAAA,CAAY,OAAA,EAA4D;AACtE,IAAA,KAAA,CAAM;MACJ,IAAA,EAAM,2BAAA;MACN,OAAA,EAAS;AACV,KAAA,CAAA;AAED,IAAA,IAAA,CAAK,YAAY,OAAA,CAAQ,SAAA;AAC3B,EAAA;AACF,CAAA;ACZO,IAAM,4BAAA,GAAN,cAA2CA,4BAAAA,CAAW;AAK3D,EAAA,WAAA,CAAY,OAAA,EAAiE;AAC3E,IAAA,KAAA,CAAM;MACJ,IAAA,EAAM,iCAAA;MACN,OAAA,EACE,CAAA,0BAAA,EAA6B,QAAQ,OAAO,CAAA,eAAA,EAAkB,QAAQ,QAAQ,CAAA,aAAA,EAAgB,QAAQ,OAAO,CAAA,2EAAA;AAEhH,KAAA,CAAA;AAED,IAAA,IAAA,CAAK,UAAU,OAAA,CAAQ,OAAA;AACvB,IAAA,IAAA,CAAK,WAAW,OAAA,CAAQ,QAAA;AACxB,IAAA,IAAA,CAAK,UAAU,OAAA,CAAQ,OAAA;AACzB,EAAA;AACF,CAAA;ACpBA,IAAM/C,MAAAA,GAAO,4BAAA;AACb,IAAMO,QAAAA,GAAS,mBAAmBP,MAAI,CAAA,CAAA;AACtC,IAAMQ,QAAAA,GAAS,MAAA,CAAO,GAAA,CAAID,QAAM,CAAA;AAJhC,IAAAE,IAAAA;AAMO,IAAM,uBAAA,GAAN,cAAsCsC,4BAAAA,CAAW;EAKtD,WAAA,CAAY;AACV,IAAA,OAAA;AACA,IAAA,KAAA;IACA,OAAA,GAAU,CAAA,4FAAA,EAA+F,OAAO,OAAO,CAAA,CAAA;AAKtH,GAAA,EAAA;AACD,IAAA,KAAA,CAAM,EAAE,IAAA,EAAA/C,MAAAA,EAAM,OAAA,EAAS,OAAO,CAAA;AAbhC,IAAA,IAAA,CAAkBS,IAAAA,CAAAA,GAAU,IAAA;AAe1B,IAAA,IAAA,CAAK,OAAA,GAAU,OAAA;AACjB,EAAA;AAEA,EAAA,OAAO,WAAW,KAAA,EAAkD;AAClE,IAAA,OAAOsC,4BAAAA,CAAW,SAAA,CAAU,KAAA,EAAOxC,QAAM,CAAA;AAC3C,EAAA;AACF,CAAA;AArBoBE,IAAAA,GAAAD,QAAAA;ACJpB,IAAMR,MAAAA,GAAO,2BAAA;AACb,IAAMO,QAAAA,GAAS,mBAAmBP,MAAI,CAAA,CAAA;AACtC,IAAMQ,QAAAA,GAAS,MAAA,CAAO,GAAA,CAAID,QAAM,CAAA;AALhC,IAAAE,IAAAA;AAOO,IAAM,sBAAA,GAAN,cAAqCsC,4BAAAA,CAAW;EAKrD,WAAA,CAAY;AACV,IAAA,eAAA;AACA,IAAA;AAIC,GAAA,EAAA;AACD,IAAA,KAAA,CAAM,EAAE,IAAA,EAAA/C,MAAAA,EAAM,OAAA,EAAS,CAAA;AAXzB,IAAA,IAAA,CAAkBS,IAAAA,CAAAA,GAAU,IAAA;AAa1B,IAAA,IAAA,CAAK,eAAA,GAAkB,eAAA;AACzB,EAAA;AAEA,EAAA,OAAO,WAAW,KAAA,EAAiD;AACjE,IAAA,OAAOsC,4BAAAA,CAAW,SAAA,CAAU,KAAA,EAAOxC,QAAM,CAAA;AAC3C,EAAA;AACF,CAAA;AAnBoBE,IAAAA,GAAAD,QAAAA;ACNpB,IAAMR,MAAAA,GAAO,kBAAA;AACb,IAAMO,QAAAA,GAAS,mBAAmBP,MAAI,CAAA,CAAA;AACtC,IAAMQ,QAAAA,GAAS,MAAA,CAAO,GAAA,CAAID,QAAM,CAAA;AAJhC,IAAAE,IAAAA;AAMO,IAAM,aAAA,GAAN,cAA4BsC,4BAAAA,CAAW;EAO5C,WAAA,CAAY;AACV,IAAA,GAAA;AACA,IAAA,UAAA;AACA,IAAA,UAAA;AACA,IAAA,KAAA;AACA,IAAA,OAAA,GAAU,KAAA,IAAS,IAAA,GACf,CAAA,mBAAA,EAAsB,GAAG,CAAA,EAAA,EAAK,UAAU,CAAA,CAAA,EAAI,UAAU,CAAA,CAAA,GACtD,CAAA,mBAAA,EAAsB,GAAG,CAAA,EAAA,EAAK,KAAK,CAAA;AAOtC,GAAA,EAAA;AACD,IAAA,KAAA,CAAM,EAAE,IAAA,EAAA/C,MAAAA,EAAM,OAAA,EAAS,OAAO,CAAA;AArBhC,IAAA,IAAA,CAAkBS,IAAAA,CAAAA,GAAU,IAAA;AAuB1B,IAAA,IAAA,CAAK,GAAA,GAAM,GAAA;AACX,IAAA,IAAA,CAAK,UAAA,GAAa,UAAA;AAClB,IAAA,IAAA,CAAK,UAAA,GAAa,UAAA;AACpB,EAAA;AAEA,EAAA,OAAO,WAAW,KAAA,EAAwC;AACxD,IAAA,OAAOsC,4BAAAA,CAAW,SAAA,CAAU,KAAA,EAAOxC,QAAM,CAAA;AAC3C,EAAA;AACF,CAAA;AA/BoBE,IAAAA,GAAAD,QAAAA;ACLpB,IAAMR,MAAAA,GAAO,eAAA;AACb,IAAMO,QAAAA,GAAS,mBAAmBP,MAAI,CAAA,CAAA;AACtC,IAAMQ,QAAAA,GAAS,MAAA,CAAO,GAAA,CAAID,QAAM,CAAA;AAJhC,IAAAE,IAAAA;AAWO,IAAM,UAAA,GAAN,cAAyBsC,4BAAAA,CAAW;EAQzC,WAAA,CAAY;AACV,IAAA,OAAA;AACA,IAAA,MAAA;AACA,IAAA;AAKC,GAAA,EAAA;AACD,IAAA,KAAA,CAAM,EAAE,IAAA,EAAA/C,MAAAA,EAAM,OAAA,EAAS,CAAA;AAhBzB,IAAA,IAAA,CAAkBS,IAAAA,CAAAA,GAAU,IAAA;AAkB1B,IAAA,IAAA,CAAK,MAAA,GAAS,MAAA;AACd,IAAA,IAAA,CAAK,MAAA,GAAS,MAAA;AAGd,IAAA,IAAA,CAAK,SAAA,GAAY,MAAA,CAAO,MAAA,CAAO,MAAA,GAAS,CAAC,CAAA;AAC3C,EAAA;AAEA,EAAA,OAAO,WAAW,KAAA,EAAqC;AACrD,IAAA,OAAOsC,4BAAAA,CAAW,SAAA,CAAU,KAAA,EAAOxC,QAAM,CAAA;AAC3C,EAAA;AACF,CAAA;AA5BoBE,IAAAA,GAAAD,QAAAA;ACgBb,SAAS,sBACd,KAAA,EACyB;AACzB,EAAA,IAAI,OAAO,UAAU,QAAA,EAAU;AAC7B,IAAA,IAAI,KAAA,CAAM,yBAAyB,IAAA,EAAM;AACvC,MAAA,MAAM,IAAI,4BAAA,CAA6B;AACrC,QAAA,OAAA,EAAS,KAAA,CAAM,oBAAA;AACf,QAAA,QAAA,EAAU,KAAA,CAAM,QAAA;AAChB,QAAA,OAAA,EAAS,KAAA,CAAM;AAChB,OAAA,CAAA;AACH,IAAA;AAEA,IAAA,OAAO,KAAA;AACT,EAAA;AAGA,EAAA,OAAO,mBAAA,CAAoB,kBAAA;AACzB,IAAA;AACF,GAAA;AACF;AAkBA,SAAS,iBAAA,GAAgC;AAjEzC,EAAA,IAAAC,IAAAA;AAkEE,EAAA,OAAA,CAAOA,IAAAA,GAAA,UAAA,CAAW,uBAAA,KAAX,IAAA,GAAAA,IAAAA,GAAsC,OAAA;AAC/C;ACTO,IAAM,wBAAA,GAA2B;AACtC,EAAA;IACE,SAAA,EAAW,YAAA;IACX,WAAA,EAAa,CAAC,KAAM,GAAI;AAC1B,GAAA;AACA,EAAA;IACE,SAAA,EAAW,YAAA;IACX,WAAA,EAAa,CAAC,KAAM,GAAI;AAC1B,GAAA;AACA,EAAA;IACE,SAAA,EAAW,YAAA;IACX,WAAA,EAAa,CAAC,KAAM,GAAI;AAC1B,GAAA;AACA,EAAA;IACE,SAAA,EAAW,YAAA;IACX,WAAA,EAAa,CAAC,KAAM,GAAI;AAC1B,GAAA;AACA,EAAA;IACE,SAAA,EAAW,YAAA;IACX,WAAA,EAAa,CAAC,KAAM,GAAI;AAC1B,GAAA;AACA,EAAA;IACE,SAAA,EAAW,YAAA;IACX,WAAA,EAAa,CAAC,KAAM,GAAI;AAC1B,GAAA;AACA,EAAA;IACE,SAAA,EAAW,WAAA;IACX,WAAA,EAAa;AACX,MAAA,EAAA;;AACA,MAAA,EAAA;;AACA,MAAA,EAAA;;AACA,MAAA,EAAA;;AACA,MAAA,IAAA;AACA,MAAA,IAAA;AACA,MAAA,IAAA;AACA,MAAA,IAAA;AACA,MAAA,EAAA;;AACA,MAAA,EAAA;;AACA,MAAA,EAAA;;AACA,MAAA;;AACF;AACF,GAAA;AACA,EAAA;IACE,SAAA,EAAW,WAAA;AACX,IAAA,WAAA,EAAa,CAAC,EAAA,EAAM,GAAA,EAAM,GAAA,EAAM,EAAI;AACtC,GAAA;AACA,EAAA;IACE,SAAA,EAAW,YAAA;AACX,IAAA,WAAA,EAAa,CAAC,GAAA,EAAM,EAAA,EAAM,EAAA,EAAM,EAAI;AACtC,GAAA;AACA,EAAA;IACE,SAAA,EAAW,WAAA;AACX,IAAA,WAAA,EAAa,CAAC,EAAA,EAAM,EAAA,EAAM,CAAA,EAAM,CAAI;AACtC,GAAA;AACA,EAAA;IACE,SAAA,EAAW,WAAA;AACX,IAAA,WAAA,EAAa,CAAC,GAAA,EAAM,GAAA,EAAM,GAAA,EAAM,GAAI;AACtC,GAAA;AACA,EAAA;IACE,SAAA,EAAW,YAAA;AACX,IAAA,WAAA,EAAa,CAAC,EAAA,EAAM,EAAA,EAAM,GAAA,EAAM,GAAI;AACtC;AACF,CAAA;AAEA,IAAM,QAAA,GAAW,CAAC,IAAA,KAA8B;AAC9C,EAAA,MAAM,QACJ,OAAO,IAAA,KAAS,QAAA,GAAWwC,2CAAA,CAA0B,IAAI,CAAA,GAAI,IAAA;AAC/D,EAAA,MAAM,WACF,KAAA,CAAM,CAAC,IAAI,GAAA,KAAS,EAAA,GAAA,CACpB,MAAM,CAAC,CAAA,GAAI,GAAA,KAAS,EAAA,GAAA,CACpB,MAAM,CAAC,CAAA,GAAI,QAAS,CAAA,GACrB,KAAA,CAAM,CAAC,CAAA,GAAI,GAAA;AAGd,EAAA,OAAO,KAAA,CAAM,KAAA,CAAM,OAAA,GAAU,EAAE,CAAA;AACjC,CAAA;AAEA,SAAS,sBAAsB,IAAA,EAAgD;AAC7E,EAAA,MAAM,SACH,OAAO,IAAA,KAAS,QAAA,IAAY,IAAA,CAAK,WAAW,MAAM,CAAA,IAClD,OAAO,IAAA,KAAS,YACf,IAAA,CAAK,MAAA,GAAS,EAAA,IACd,IAAA,CAAK,CAAC,CAAA,KAAM,EAAA;AACZ,EAAA,IAAA,CAAK,CAAC,CAAA,KAAM,EAAA;AACZ,EAAA,IAAA,CAAK,CAAC,CAAA,KAAM,EAAA;AAEhB,EAAA,OAAO,MAAA,GAAS,QAAA,CAAS,IAAI,CAAA,GAAI,IAAA;AACnC;AASO,SAAS,eAAA,CAAgB;AAC9B,EAAA,IAAA;AACA,EAAA;AACF,CAAA,EAGyD;AACvD,EAAA,MAAM,aAAA,GAAgB,sBAAsB,IAAI,CAAA;AAGhD,EAAA,MAAM,KAAA,GACJ,OAAO,aAAA,KAAkB,QAAA,GACrBA,2CAAA;AACE,IAAA,aAAA,CAAc,UAAU,CAAA,EAAG,IAAA,CAAK,IAAI,aAAA,CAAc,MAAA,EAAQ,EAAE,CAAC;AAE/D,GAAA,GAAA,aAAA;AAEN,EAAA,KAAA,MAAW,aAAa,UAAA,EAAY;AAClC,IAAA,IACE,MAAM,MAAA,IAAU,SAAA,CAAU,WAAA,CAAY,MAAA,IACtC,UAAU,WAAA,CAAY,KAAA;AACpB,MAAA,CAAC,MAAM,KAAA,KAAU,IAAA,KAAS,IAAA,IAAQ,KAAA,CAAM,KAAK,CAAA,KAAM;AAErD,KAAA,EAAA;AACA,MAAA,OAAO,SAAA,CAAU,SAAA;AACnB,IAAA;AACF,EAAA;AAEA,EAAA,OAAO,MAAA;AACT;ACtLO,IAAMtB,QAAAA,GAEP,SAAA;ACYC,IAAM,QAAA,GAAW,OAAO,EAAE,GAAA,EAAA,KAAwB;AAfzD,EAAA,IAAAlB,IAAAA;AAgBE,EAAA,MAAM,OAAA,GAAU,IAAI,QAAA,EAAA;AACpB,EAAA,IAAI;AACF,IAAA,MAAM,QAAA,GAAW,MAAM,KAAA,CAAM,OAAA,EAAS;MACpC,OAAA,EAASe,qCAAA;QACP,EAAA;AACA,QAAA,CAAA,OAAA,EAAUG,QAAO,CAAA,CAAA;QACjBuB,gDAAA;AACF;AACD,KAAA,CAAA;AAED,IAAA,IAAI,CAAC,SAAS,EAAA,EAAI;AAChB,MAAA,MAAM,IAAI,aAAA,CAAc;QACtB,GAAA,EAAK,OAAA;AACL,QAAA,UAAA,EAAY,QAAA,CAAS,MAAA;AACrB,QAAA,UAAA,EAAY,QAAA,CAAS;AACtB,OAAA,CAAA;AACH,IAAA;AAEA,IAAA,OAAO;AACL,MAAA,IAAA,EAAM,IAAI,UAAA,CAAW,MAAM,QAAA,CAAS,aAAa,CAAA;AACjD,MAAA,SAAA,EAAA,CAAWzC,OAAA,QAAA,CAAS,OAAA,CAAQ,IAAI,cAAc,CAAA,KAAnC,OAAAA,IAAAA,GAAwC;AACrD,KAAA;AACF,EAAA,CAAA,CAAA,OAAS,KAAA,EAAO;AACd,IAAA,IAAI,aAAA,CAAc,UAAA,CAAW,KAAK,CAAA,EAAG;AACnC,MAAA,MAAM,KAAA;AACR,IAAA;AAEA,IAAA,MAAM,IAAI,aAAA,CAAc,EAAE,KAAK,OAAA,EAAS,KAAA,EAAO,OAAO,CAAA;AACxD,EAAA;AACF,CAAA;AChCO,IAAM,iBAAA,GAA4CI,KAAE,KAAA,CAAM;AAC/DA,EAAAA,IAAAA,CAAE,MAAA,EAAA;AACFA,EAAAA,IAAAA,CAAE,WAAW,UAAU,CAAA;AACvBA,EAAAA,IAAAA,CAAE,WAAW,WAAW,CAAA;EACxBA,IAAAA,CAAE,MAAA;;AAEA,IAAA,CAAC,KAAA,KAAiC;AAnBtC,MAAA,IAAAJ,IAAAA,EAAAC,GAAAA;AAoBM,MAAA,OAAA,CAAAA,GAAAA,GAAAA,CAAAD,IAAAA,GAAA,UAAA,CAAW,MAAA,KAAX,IAAA,GAAA,MAAA,GAAAA,IAAAA,CAAmB,QAAA,CAAS,KAAA,CAAA,KAA5B,IAAA,GAAAC,GAAAA,GAAsC,KAAA;AAAA,IAAA,CAAA;AACxC,IAAA,EAAE,SAAS,kBAAA;AACb;AACF,CAAC,CAAA;AAuEM,SAAS,+BACd,OAAA,EACY;AACZ,EAAA,IAAI,mBAAmB,UAAA,EAAY;AACjC,IAAA,OAAO,OAAA;AACT,EAAA;AAEA,EAAA,IAAI,OAAO,YAAY,QAAA,EAAU;AAC/B,IAAA,IAAI;AACF,MAAA,OAAOuC,4CAA0B,OAAO,CAAA;AAC1C,IAAA,CAAA,CAAA,OAAS,KAAA,EAAO;AACd,MAAA,MAAM,IAAI,uBAAA,CAAwB;QAChC,OAAA,EACE,qEAAA;AACF,QAAA,OAAA;QACA,KAAA,EAAO;AACR,OAAA,CAAA;AACH,IAAA;AACF,EAAA;AAEA,EAAA,IAAI,mBAAmB,WAAA,EAAa;AAClC,IAAA,OAAO,IAAI,WAAW,OAAO,CAAA;AAC/B,EAAA;AAEA,EAAA,MAAM,IAAI,uBAAA,CAAwB,EAAE,OAAA,EAAS,CAAA;AAC/C;ACpHO,IAAM,kBAAwCpC,IAAAA,CAAE,IAAA;AAAK,EAAA,MAC1DA,KAAE,KAAA,CAAM;AACNA,IAAAA,IAAAA,CAAE,IAAA,EAAA;AACFA,IAAAA,IAAAA,CAAE,MAAA,EAAA;AACFA,IAAAA,IAAAA,CAAE,MAAA,EAAA;AACFA,IAAAA,IAAAA,CAAE,OAAA,EAAA;AACFA,IAAAA,IAAAA,CAAE,MAAA,CAAOA,IAAAA,CAAE,MAAA,EAAA,EAAU,eAAe,CAAA;AACpCA,IAAAA,IAAAA,CAAE,MAAM,eAAe;AACxB,GAAA;AACH,CAAA;ACAO,IAAM,yBAAsDA,IAAAA,CAAE,MAAA;AACnEA,EAAAA,IAAAA,CAAE,MAAA,EAAA;AACFA,EAAAA,IAAAA,CAAE,MAAA,CAAOA,IAAAA,CAAE,MAAA,EAAA,EAAU,eAAe;AACtC,CAAA;ACEO,IAAM,cAAA,GAAsCA,KAAE,MAAA,CAAO;EAC1D,IAAA,EAAMA,IAAAA,CAAE,QAAQ,MAAM,CAAA;AACtB,EAAA,IAAA,EAAMA,KAAE,MAAA,EAAA;AACR,EAAA,eAAA,EAAiB,uBAAuB,QAAA;AAC1C,CAAC,CAAA;AAKM,IAAM,eAAA,GAAwCA,KAAE,MAAA,CAAO;EAC5D,IAAA,EAAMA,IAAAA,CAAE,QAAQ,OAAO,CAAA;EACvB,KAAA,EAAOA,IAAAA,CAAE,MAAM,CAAC,iBAAA,EAAmBA,KAAE,UAAA,CAAW,GAAG,CAAC,CAAC,CAAA;EACrD,SAAA,EAAWA,IAAAA,CAAE,MAAA,EAAA,CAAS,QAAA,EAAA;AACtB,EAAA,eAAA,EAAiB,uBAAuB,QAAA;AAC1C,CAAC,CAAA;AAKM,IAAM,cAAA,GAAsCA,KAAE,MAAA,CAAO;EAC1D,IAAA,EAAMA,IAAAA,CAAE,QAAQ,MAAM,CAAA;EACtB,IAAA,EAAMA,IAAAA,CAAE,MAAM,CAAC,iBAAA,EAAmBA,KAAE,UAAA,CAAW,GAAG,CAAC,CAAC,CAAA;EACpD,QAAA,EAAUA,IAAAA,CAAE,MAAA,EAAA,CAAS,QAAA,EAAA;AACrB,EAAA,SAAA,EAAWA,KAAE,MAAA,EAAA;AACb,EAAA,eAAA,EAAiB,uBAAuB,QAAA;AAC1C,CAAC,CAAA;AAKM,IAAM,mBAAA,GAAgDA,KAAE,MAAA,CAAO;EACpE,IAAA,EAAMA,IAAAA,CAAE,QAAQ,WAAW,CAAA;AAC3B,EAAA,IAAA,EAAMA,KAAE,MAAA,EAAA;AACR,EAAA,eAAA,EAAiB,uBAAuB,QAAA;AAC1C,CAAC,CAAA;AAkCM,IAAM,kBAAA,GAA8CA,KAAE,MAAA,CAAO;EAClE,IAAA,EAAMA,IAAAA,CAAE,QAAQ,WAAW,CAAA;AAC3B,EAAA,UAAA,EAAYA,KAAE,MAAA,EAAA;AACd,EAAA,QAAA,EAAUA,KAAE,MAAA,EAAA;AACZ,EAAA,KAAA,EAAOA,KAAE,OAAA,EAAA;AACT,EAAA,eAAA,EAAiB,uBAAuB,QAAA,EAAA;EACxC,gBAAA,EAAkBA,IAAAA,CAAE,OAAA,EAAA,CAAU,QAAA;AAChC,CAAC,CAAA;AAKM,IAAM,YAAA,GACXA,IAAAA,CAAE,kBAAA,CAAmB,MAAA,EAAQ;AAC3BA,EAAAA,IAAAA,CAAE,MAAA,CAAO;IACP,IAAA,EAAMA,IAAAA,CAAE,QAAQ,MAAM,CAAA;AACtB,IAAA,KAAA,EAAOA,KAAE,MAAA;AACV,GAAA,CAAA;AACDA,EAAAA,IAAAA,CAAE,MAAA,CAAO;IACP,IAAA,EAAMA,IAAAA,CAAE,QAAQ,MAAM,CAAA;IACtB,KAAA,EAAO;AACR,GAAA,CAAA;AACDA,EAAAA,IAAAA,CAAE,MAAA,CAAO;IACP,IAAA,EAAMA,IAAAA,CAAE,QAAQ,YAAY,CAAA;AAC5B,IAAA,KAAA,EAAOA,KAAE,MAAA;AACV,GAAA,CAAA;AACDA,EAAAA,IAAAA,CAAE,MAAA,CAAO;IACP,IAAA,EAAMA,IAAAA,CAAE,QAAQ,YAAY,CAAA;IAC5B,KAAA,EAAO;AACR,GAAA,CAAA;AACDA,EAAAA,IAAAA,CAAE,MAAA,CAAO;IACP,IAAA,EAAMA,IAAAA,CAAE,QAAQ,SAAS,CAAA;AACzB,IAAA,KAAA,EAAOA,IAAAA,CAAE,KAAA;AACPA,MAAAA,IAAAA,CAAE,KAAA,CAAM;AACNA,QAAAA,IAAAA,CAAE,MAAA,CAAO;UACP,IAAA,EAAMA,IAAAA,CAAE,QAAQ,MAAM,CAAA;AACtB,UAAA,IAAA,EAAMA,KAAE,MAAA;AACT,SAAA,CAAA;AACDA,QAAAA,IAAAA,CAAE,MAAA,CAAO;UACP,IAAA,EAAMA,IAAAA,CAAE,QAAQ,OAAO,CAAA;AACvB,UAAA,IAAA,EAAMA,KAAE,MAAA,EAAA;AACR,UAAA,SAAA,EAAWA,KAAE,MAAA;AACd,SAAA;AACF,OAAA;AACH;AACD,GAAA;AACH,CAAC,CAAA;AAKI,IAAM,oBAAA,GAAkDA,KAAE,MAAA,CAAO;EACtE,IAAA,EAAMA,IAAAA,CAAE,QAAQ,aAAa,CAAA;AAC7B,EAAA,UAAA,EAAYA,KAAE,MAAA,EAAA;AACd,EAAA,QAAA,EAAUA,KAAE,MAAA,EAAA;EACZ,MAAA,EAAQ,YAAA;AACR,EAAA,eAAA,EAAiB,uBAAuB,QAAA;AAC1C,CAAC,CAAA;ACtHM,IAAM,2BAA0DA,IAAAA,CAAE,MAAA;AACvE,EAAA;IACE,IAAA,EAAMA,IAAAA,CAAE,QAAQ,QAAQ,CAAA;AACxB,IAAA,OAAA,EAASA,KAAE,MAAA,EAAA;AACX,IAAA,eAAA,EAAiB,uBAAuB,QAAA;AAC1C;AACF,CAAA;AAcO,IAAM,sBAAA,GAAsDA,KAAE,MAAA,CAAO;EAC1E,IAAA,EAAMA,IAAAA,CAAE,QAAQ,MAAM,CAAA;AACtB,EAAA,OAAA,EAASA,KAAE,KAAA,CAAM;AACfA,IAAAA,IAAAA,CAAE,MAAA,EAAA;IACFA,IAAAA,CAAE,KAAA,CAAMA,KAAE,KAAA,CAAM,CAAC,gBAAgB,eAAA,EAAiB,cAAc,CAAC,CAAC;AACnE,GAAA,CAAA;AACD,EAAA,eAAA,EAAiB,uBAAuB,QAAA;AAC1C,CAAC,CAAA;AAcM,IAAM,2BAAA,GACXA,KAAE,MAAA,CAAO;EACP,IAAA,EAAMA,IAAAA,CAAE,QAAQ,WAAW,CAAA;AAC3B,EAAA,OAAA,EAASA,KAAE,KAAA,CAAM;AACfA,IAAAA,IAAAA,CAAE,MAAA,EAAA;IACFA,IAAAA,CAAE,KAAA;AACAA,MAAAA,IAAAA,CAAE,KAAA,CAAM;AACN,QAAA,cAAA;AACA,QAAA,cAAA;AACA,QAAA,mBAAA;AACA,QAAA,kBAAA;AACA,QAAA;AACD,OAAA;AACH;AACD,GAAA,CAAA;AACD,EAAA,eAAA,EAAiB,uBAAuB,QAAA;AAC1C,CAAC,CAAA;AAcI,IAAM,sBAAA,GAAsDA,KAAE,MAAA,CAAO;EAC1E,IAAA,EAAMA,IAAAA,CAAE,QAAQ,MAAM,CAAA;EACtB,OAAA,EAASA,IAAAA,CAAE,MAAM,oBAAoB,CAAA;AACrC,EAAA,eAAA,EAAiB,uBAAuB,QAAA;AAC1C,CAAC,CAAA;AAc0DA,KAAE,KAAA,CAAM;AACjE,EAAA,wBAAA;AACA,EAAA,sBAAA;AACA,EAAA,2BAAA;AACA,EAAA;AACF,CAAC;ACpHM,SAAS,qBAAA,CAAsB;AACpC,EAAA,WAAA;AACA,EAAA;AACF,CAAA,EAGG;AACD,EAAA,OAAO;;AAEL,IAAA,gBAAA,EAAkB,CAAA,EAAG,WAAW,CAAA,EAAA,CAC9B,SAAA,IAAA,IAAA,GAAA,MAAA,GAAA,SAAA,CAAW,UAAA,KAAc,IAAA,GAAO,CAAA,CAAA,EAAI,SAAA,CAAU,UAAU,KAAK,EAC/D,CAAA,CAAA;IACA,eAAA,EAAiB,SAAA,IAAA,IAAA,GAAA,MAAA,GAAA,SAAA,CAAW,UAAA;;IAG5B,gBAAA,EAAkB,WAAA;IAClB,yBAAA,EAA2B,SAAA,IAAA,IAAA,GAAA,MAAA,GAAA,SAAA,CAAW;AACxC,GAAA;AACF;AChBO,SAAS,0BAAA,CAA2B;AACzC,EAAA,KAAA;AACA,EAAA,QAAA;AACA,EAAA,SAAA;AACA,EAAA;AACF,CAAA,EAKe;AAdf,EAAA,IAAAJ,IAAAA;AAeE,EAAA,OAAO;AACL,IAAA,mBAAA,EAAqB,KAAA,CAAM,QAAA;AAC3B,IAAA,aAAA,EAAe,KAAA,CAAM,OAAA;;IAGrB,GAAG,MAAA,CAAO,OAAA,CAAQ,QAAQ,CAAA,CAAE,MAAA,CAAO,CAAC,UAAA,EAAY,CAAC,GAAA,EAAK,KAAK,CAAA,KAAM;AAC/D,MAAA,UAAA,CAAW,CAAA,YAAA,EAAe,GAAG,CAAA,CAAE,CAAA,GAAI,KAAA;AACnC,MAAA,OAAO,UAAA;AACT,IAAA,CAAA,EAAG,EAAgB,CAAA;;AAGnB,IAAA,GAAG,MAAA,CAAO,OAAA,CAAA,CAAQA,IAAAA,GAAA,SAAA,IAAA,IAAA,GAAA,MAAA,GAAA,SAAA,CAAW,QAAA,KAAX,IAAA,GAAAA,IAAAA,GAAuB,EAAE,CAAA,CAAE,MAAA;AAC3C,MAAA,CAAC,UAAA,EAAY,CAAC,GAAA,EAAK,KAAK,CAAA,KAAM;AAC5B,QAAA,UAAA,CAAW,CAAA,sBAAA,EAAyB,GAAG,CAAA,CAAE,CAAA,GAAI,KAAA;AAC7C,QAAA,OAAO,UAAA;AACT,MAAA,CAAA;MACA;AACF,KAAA;;AAGA,IAAA,GAAG,MAAA,CAAO,OAAA,CAAQ,OAAA,IAAA,IAAA,GAAA,UAAW,EAAE,CAAA,CAAE,MAAA,CAAO,CAAC,UAAA,EAAY,CAAC,GAAA,EAAK,KAAK,CAAA,KAAM;AACpE,MAAA,IAAI,UAAU,MAAA,EAAW;AACvB,QAAA,UAAA,CAAW,CAAA,mBAAA,EAAsB,GAAG,CAAA,CAAE,CAAA,GAAI,KAAA;AAC5C,MAAA;AACA,MAAA,OAAO,UAAA;AACT,IAAA,CAAA,EAAG,EAAgB;AACrB,GAAA;AACF;ACrCO,IAAM,UAAA,GAAqB;EAChC,SAAA,GAAkB;AAChB,IAAA,OAAO,QAAA;AACT,EAAA,CAAA;EAEA,eAAA,CACET,MAAAA,EACA,IAAA,EACA,IAAA,EACA,IAAA,EACiB;AACjB,IAAA,IAAI,OAAO,SAAS,UAAA,EAAY;AAC9B,MAAA,OAAO,KAAK,QAAQ,CAAA;AACtB,IAAA;AACA,IAAA,IAAI,OAAO,SAAS,UAAA,EAAY;AAC9B,MAAA,OAAO,KAAK,QAAQ,CAAA;AACtB,IAAA;AACA,IAAA,IAAI,OAAO,SAAS,UAAA,EAAY;AAC9B,MAAA,OAAO,KAAK,QAAQ,CAAA;AACtB,IAAA;AACF,EAAA;AACF,CAAA;AAEA,IAAM,QAAA,GAAiB;EACrB,WAAA,GAAc;AACZ,IAAA,OAAO,eAAA;AACT,EAAA,CAAA;EACA,YAAA,GAAe;AACb,IAAA,OAAO,IAAA;AACT,EAAA,CAAA;EACA,aAAA,GAAgB;AACd,IAAA,OAAO,IAAA;AACT,EAAA,CAAA;EACA,QAAA,GAAW;AACT,IAAA,OAAO,IAAA;AACT,EAAA,CAAA;EACA,OAAA,GAAU;AACR,IAAA,OAAO,IAAA;AACT,EAAA,CAAA;EACA,QAAA,GAAW;AACT,IAAA,OAAO,IAAA;AACT,EAAA,CAAA;EACA,SAAA,GAAY;AACV,IAAA,OAAO,IAAA;AACT,EAAA,CAAA;EACA,UAAA,GAAa;AACX,IAAA,OAAO,IAAA;AACT,EAAA,CAAA;EACA,GAAA,GAAM;AACJ,IAAA,OAAO,IAAA;AACT,EAAA,CAAA;EACA,WAAA,GAAc;AACZ,IAAA,OAAO,KAAA;AACT,EAAA,CAAA;EACA,eAAA,GAAkB;AAChB,IAAA,OAAO,IAAA;AACT,EAAA;AACF,CAAA;AAEA,IAAM,eAAA,GAA+B;EACnC,OAAA,EAAS,EAAA;EACT,MAAA,EAAQ,EAAA;EACR,UAAA,EAAY;AACd,CAAA;ACjEO,SAAS,SAAA,CAAU;EACxB,SAAA,GAAY,KAAA;AACZ,EAAA;AACF,CAAA,GAGI,EAAA,EAAY;AACd,EAAA,IAAI,CAAC,SAAA,EAAW;AACd,IAAA,OAAO,UAAA;AACT,EAAA;AAEA,EAAA,IAAI,MAAA,EAAQ;AACV,IAAA,OAAO,MAAA;AACT,EAAA;AAEA,EAAA,OAAO,KAAA,CAAM,UAAU,IAAI,CAAA;AAC7B;ACjBO,SAAS,UAAA,CAAc;EAC5B,IAAA,EAAAA,MAAAA;AACA,EAAA,MAAA;AACA,EAAA,UAAA;AACA,EAAA,EAAA;EACA,WAAA,GAAc;AAChB,CAAA,EAMG;AACD,EAAA,OAAO,OAAO,eAAA,CAAgBA,MAAAA,EAAM,EAAE,UAAA,EAAA,EAAc,OAAM,IAAA,KAAQ;AAChE,IAAA,IAAI;AACF,MAAA,MAAM,MAAA,GAAS,MAAM,EAAA,CAAG,IAAI,CAAA;AAE5B,MAAA,IAAI,WAAA,EAAa;AACf,QAAA,IAAA,CAAK,GAAA,EAAA;AACP,MAAA;AAEA,MAAA,OAAO,MAAA;AACT,IAAA,CAAA,CAAA,OAAS,KAAA,EAAO;AACd,MAAA,IAAI;AACF,QAAA,iBAAA,CAAkB,MAAM,KAAK,CAAA;MAC/B,CAAA,SAAA;AAEE,QAAA,IAAA,CAAK,GAAA,EAAA;AACP,MAAA;AAEA,MAAA,MAAM,KAAA;AACR,IAAA;EACF,CAAC,CAAA;AACH;AASO,SAAS,iBAAA,CAAkB,MAAY,KAAA,EAAgB;AAC5D,EAAA,IAAI,iBAAiB,KAAA,EAAO;AAC1B,IAAA,IAAA,CAAK,eAAA,CAAgB;AACnB,MAAA,IAAA,EAAM,KAAA,CAAM,IAAA;AACZ,MAAA,OAAA,EAAS,KAAA,CAAM,OAAA;AACf,MAAA,KAAA,EAAO,KAAA,CAAM;AACd,KAAA,CAAA;AACD,IAAA,IAAA,CAAK,SAAA,CAAU;AACb,MAAA,IAAA,EAAM,cAAA,CAAe,KAAA;AACrB,MAAA,OAAA,EAAS,KAAA,CAAM;AAChB,KAAA,CAAA;EACH,CAAA,MAAO;AACL,IAAA,IAAA,CAAK,SAAA,CAAU,EAAE,IAAA,EAAM,cAAA,CAAe,OAAO,CAAA;AAC/C,EAAA;AACF;ACvDO,SAAS,yBAAA,CAA0B;AACxC,EAAA,SAAA;AACA,EAAA;AACF,CAAA,EASe;AAEb,EAAA,IAAA,CAAI,SAAA,IAAA,IAAA,GAAA,MAAA,GAAA,SAAA,CAAW,eAAc,IAAA,EAAM;AACjC,IAAA,OAAO,EAAA;AACT,EAAA;AAEA,EAAA,OAAO,MAAA,CAAO,OAAA,CAAQ,UAAU,CAAA,CAAE,MAAA,CAAO,CAACmD,WAAAA,EAAY,CAAC,GAAA,EAAK,KAAK,CAAA,KAAM;AACrE,IAAA,IAAI,SAAS,IAAA,EAAM;AACjB,MAAA,OAAOA,WAAAA;AACT,IAAA;AAGA,IAAA,IACE,OAAO,UAAU,QAAA,IACjB,OAAA,IAAW,SACX,OAAO,KAAA,CAAM,UAAU,UAAA,EACvB;AAEA,MAAA,IAAA,CAAI,SAAA,IAAA,IAAA,GAAA,MAAA,GAAA,SAAA,CAAW,kBAAiB,KAAA,EAAO;AACrC,QAAA,OAAOA,WAAAA;AACT,MAAA;AAEA,MAAA,MAAM,MAAA,GAAS,MAAM,KAAA,EAAA;AAErB,MAAA,OAAO,MAAA,IAAU,OAAOA,WAAAA,GAAa,EAAE,GAAGA,WAAAA,EAAY,CAAC,GAAG,GAAG,MAAA,EAAA;AAC/D,IAAA;AAGA,IAAA,IACE,OAAO,UAAU,QAAA,IACjB,QAAA,IAAY,SACZ,OAAO,KAAA,CAAM,WAAW,UAAA,EACxB;AAEA,MAAA,IAAA,CAAI,SAAA,IAAA,IAAA,GAAA,MAAA,GAAA,SAAA,CAAW,mBAAkB,KAAA,EAAO;AACtC,QAAA,OAAOA,WAAAA;AACT,MAAA;AAEA,MAAA,MAAM,MAAA,GAAS,MAAM,MAAA,EAAA;AAErB,MAAA,OAAO,MAAA,IAAU,OAAOA,WAAAA,GAAa,EAAE,GAAGA,WAAAA,EAAY,CAAC,GAAG,GAAG,MAAA,EAAA;AAC/D,IAAA;AAGA,IAAA,OAAO,EAAE,GAAGA,WAAAA,EAAY,CAAC,GAAG,GAAG,KAAA,EAAA;AACjC,EAAA,CAAA,EAAG,EAAE,CAAA;AACP;ACrDA,SAAS,iBAAA,CAAkB;AACzB,EAAA,KAAA;AACA,EAAA;AACF,CAAA,EAGW;AACT,EAAA,MAAM,UAAU,KAAA,CAAM,eAAA;AAEtB,EAAA,IAAI,CAAC,OAAA;AAAS,IAAA,OAAO,uBAAA;AAErB,EAAA,IAAI,EAAA;AAGJ,EAAA,MAAM,YAAA,GAAe,QAAQ,gBAAgB,CAAA;AAC7C,EAAA,IAAI,YAAA,EAAc;AAChB,IAAA,MAAM,SAAA,GAAY,WAAW,YAAY,CAAA;AACzC,IAAA,IAAI,CAAC,MAAA,CAAO,KAAA,CAAM,SAAS,CAAA,EAAG;AAC5B,MAAA,EAAA,GAAK,SAAA;AACP,IAAA;AACF,EAAA;AAGA,EAAA,MAAM,UAAA,GAAa,QAAQ,aAAa,CAAA;AACxC,EAAA,IAAI,UAAA,IAAc,OAAO,MAAA,EAAW;AAClC,IAAA,MAAM,cAAA,GAAiB,WAAW,UAAU,CAAA;AAC5C,IAAA,IAAI,CAAC,MAAA,CAAO,KAAA,CAAM,cAAc,CAAA,EAAG;AACjC,MAAA,EAAA,GAAK,cAAA,GAAiB,GAAA;IACxB,CAAA,MAAO;AACL,MAAA,EAAA,GAAK,IAAA,CAAK,KAAA,CAAM,UAAU,CAAA,GAAI,KAAK,GAAA,EAAA;AACrC,IAAA;AACF,EAAA;AAGA,EAAA,IACE,EAAA,IAAM,IAAA,IACN,CAAC,MAAA,CAAO,KAAA,CAAM,EAAE,CAAA,IAChB,CAAA,IAAK,EAAA,KACJ,EAAA,GAAK,EAAA,GAAK,GAAA,IAAQ,KAAK,uBAAA,CAAA,EACxB;AACA,IAAA,OAAO,EAAA;AACT,EAAA;AAEA,EAAA,OAAO,uBAAA;AACT;AAOO,IAAM,oDACX,CAAC;EACC,UAAA,GAAa,CAAA;EACb,gBAAA,GAAmB,GAAA;EACnB,aAAA,GAAgB,CAAA;AAChB,EAAA;AACF,CAAA,GAKI,EAAA,KACJ,OAAe,CAAA,KACb,6BAA6B,CAAA,EAAG;AAC9B,EAAA,UAAA;EACA,SAAA,EAAW,gBAAA;AACX,EAAA,aAAA;AACA,EAAA;AACF,CAAC,CAAA;AAEL,eAAe,6BACb,CAAA,EACA;AACE,EAAA,UAAA;AACA,EAAA,SAAA;AACA,EAAA,aAAA;AACA,EAAA;AACF,CAAA,EAMA,MAAA,GAAoB,EAAA,EACH;AACjB,EAAA,IAAI;AACF,IAAA,OAAO,MAAM,CAAA,EAAA;AACf,EAAA,CAAA,CAAA,OAAS,KAAA,EAAO;AACd,IAAA,IAAIC,8BAAA,CAAa,KAAK,CAAA,EAAG;AACvB,MAAA,MAAM,KAAA;AACR,IAAA;AAEA,IAAA,IAAI,eAAe,CAAA,EAAG;AACpB,MAAA,MAAM,KAAA;AACR,IAAA;AAEA,IAAA,MAAM,YAAA,GAAeC,mCAAgB,KAAK,CAAA;AAC1C,IAAA,MAAM,SAAA,GAAY,CAAC,GAAG,MAAA,EAAQ,KAAK,CAAA;AACnC,IAAA,MAAM,YAAY,SAAA,CAAU,MAAA;AAE5B,IAAA,IAAI,YAAY,UAAA,EAAY;AAC1B,MAAA,MAAM,IAAI,UAAA,CAAW;QACnB,OAAA,EAAS,CAAA,aAAA,EAAgB,SAAS,CAAA,uBAAA,EAA0B,YAAY,CAAA,CAAA;QACxE,MAAA,EAAQ,oBAAA;QACR,MAAA,EAAQ;AACT,OAAA,CAAA;AACH,IAAA;AAEA,IAAA,IACE,KAAA,YAAiB,KAAA,IACjBtC,8BAAAA,CAAa,UAAA,CAAW,KAAK,KAC7B,KAAA,CAAM,WAAA,KAAgB,IAAA,IACtB,SAAA,IAAa,UAAA,EACb;AACA,MAAA,MAAMuC,uBAAA;QACJ,iBAAA,CAAkB;AAChB,UAAA,KAAA;UACA,uBAAA,EAAyB;AAC1B,SAAA,CAAA;AACD,QAAA,EAAE,WAAA;AACJ,OAAA;AAEA,MAAA,OAAO,4BAAA;AACL,QAAA,CAAA;AACA,QAAA;AACE,UAAA,UAAA;AACA,UAAA,SAAA,EAAW,aAAA,GAAgB,SAAA;AAC3B,UAAA,aAAA;AACA,UAAA;AACF,SAAA;AACA,QAAA;AACF,OAAA;AACF,IAAA;AAEA,IAAA,IAAI,cAAc,CAAA,EAAG;AACnB,MAAA,MAAM,KAAA;AACR,IAAA;AAEA,IAAA,MAAM,IAAI,UAAA,CAAW;MACnB,OAAA,EAAS,CAAA,aAAA,EAAgB,SAAS,CAAA,qCAAA,EAAwC,YAAY,CAAA,CAAA,CAAA;MACtF,MAAA,EAAQ,mBAAA;MACR,MAAA,EAAQ;AACT,KAAA,CAAA;AACH,EAAA;AACF;AChJO,SAAS,cAAA,CAAe;AAC7B,EAAA,UAAA;AACA,EAAA;AACF,CAAA,EAME;AACA,EAAA,IAAI,cAAc,IAAA,EAAM;AACtB,IAAA,IAAI,CAAC,MAAA,CAAO,SAAA,CAAU,UAAU,CAAA,EAAG;AACjC,MAAA,MAAM,IAAIR,qBAAAA,CAAqB;QAC7B,SAAA,EAAW,YAAA;QACX,KAAA,EAAO,UAAA;QACP,OAAA,EAAS;AACV,OAAA,CAAA;AACH,IAAA;AAEA,IAAA,IAAI,aAAa,CAAA,EAAG;AAClB,MAAA,MAAM,IAAIA,qBAAAA,CAAqB;QAC7B,SAAA,EAAW,YAAA;QACX,KAAA,EAAO,UAAA;QACP,OAAA,EAAS;AACV,OAAA,CAAA;AACH,IAAA;AACF,EAAA;AAEA,EAAA,MAAM,gBAAA,GAAmB,UAAA,IAAA,IAAA,GAAA,UAAA,GAAc,CAAA;AAEvC,EAAA,OAAO;IACL,UAAA,EAAY,gBAAA;AACZ,IAAA,KAAA,EAAO,iDAAA,CAAkD;MACvD,UAAA,EAAY,gBAAA;AACZ,MAAA;AACD,KAAA;AACH,GAAA;AACF;ACnBO,IAAM,uBAAN,MAAoD;EAMzD,WAAA,CAAY;AACV,IAAA,IAAA;AACA,IAAA;AAIC,GAAA,EAAA;AACD,IAAA,MAAM,eAAe,IAAA,YAAgB,UAAA;AACrC,IAAA,IAAA,CAAK,UAAA,GAAa,eAAe,MAAA,GAAY,IAAA;AAC7C,IAAA,IAAA,CAAK,cAAA,GAAiB,eAAe,IAAA,GAAO,MAAA;AAC5C,IAAA,IAAA,CAAK,SAAA,GAAY,SAAA;AACnB,EAAA;;AAGA,EAAA,IAAI,MAAA,GAAS;AACX,IAAA,IAAI,IAAA,CAAK,cAAc,IAAA,EAAM;AAC3B,MAAA,IAAA,CAAK,UAAA,GAAaS,2CAAAA,CAA0B,IAAA,CAAK,cAAe,CAAA;AAClE,IAAA;AACA,IAAA,OAAO,IAAA,CAAK,UAAA;AACd,EAAA;;AAGA,EAAA,IAAI,UAAA,GAAa;AACf,IAAA,IAAI,IAAA,CAAK,kBAAkB,IAAA,EAAM;AAC/B,MAAA,IAAA,CAAK,cAAA,GAAiBN,2CAAAA,CAA0B,IAAA,CAAK,UAAW,CAAA;AAClE,IAAA;AACA,IAAA,OAAO,IAAA,CAAK,cAAA;AACd,EAAA;AACF,CAAA;ACtDO,SAAS,YAAY,SAAA,EAAuC;AACjE,EAAA,OAAO,CAAC,EAAE,KAAA,EAAA,KAAY,MAAM,MAAA,KAAW,SAAA;AACzC;ACFO,SAAS,qBAAA,CAAsB;AACpC,EAAA,MAAA;EACA,IAAA,EAAAO,KAAAA;AACA,EAAA;AACF,CAAA,EAIoC;AAClC,EAAA,IAAI,cAAc,MAAA,EAAQ;AACxB,IAAA,OAAO,EAAE,IAAA,EAAM,YAAA,EAAc,KAAA,EAAOH,iCAAAA,CAAgB,MAAM,CAAA,EAAA;AAC5D,EAAA,CAAA,MAAA,IAAW,cAAc,MAAA,EAAQ;AAC/B,IAAA,OAAO,EAAE,IAAA,EAAM,YAAA,EAAc,KAAA,EAAO,WAAA,CAAY,MAAM,CAAA,EAAA;AACxD,EAAA;AAEA,EAAA,IAAIG,KAAAA,IAAA,IAAA,GAAA,MAAA,GAAAA,KAAAA,CAAM,aAAA,EAAe;AACvB,IAAA,OAAOA,KAAAA,CAAK,cAAc,MAAM,CAAA;AAClC,EAAA;AAEA,EAAA,OAAO,OAAO,MAAA,KAAW,QAAA,GACrB,EAAE,MAAM,MAAA,EAAQ,KAAA,EAAO,MAAA,EAAA,GACvB,EAAE,IAAA,EAAM,MAAA,EAAQ,KAAA,EAAO,WAAA,CAAY,MAAM,CAAA,EAAA;AAC/C;AAEA,SAAS,YAAY,KAAA,EAA2B;AAC9C,EAAA,OAAO,KAAA,KAAU,SAAY,IAAA,GAAQ,KAAA;AACvC;AC2B2BC,mCAAA,CAAkB;EAC3C,MAAA,EAAQ,OAAA;EACR,IAAA,EAAM;AACR,CAAC;AChDmC9C,+BAAA;EAAc,MAChDC,2BAAA;AACEC,IAAAA,IAAAA,CAAE,KAAA,CAAM;AACNA,MAAAA,IAAAA,CAAE,YAAA,CAAa;QACb,IAAA,EAAMA,IAAAA,CAAE,QAAQ,YAAY,CAAA;AAC5B,QAAA,EAAA,EAAIA,KAAE,MAAA,EAAA;AACN,QAAA,gBAAA,EAAkB,uBAAuB,QAAA;AAC1C,OAAA,CAAA;AACDA,MAAAA,IAAAA,CAAE,YAAA,CAAa;QACb,IAAA,EAAMA,IAAAA,CAAE,QAAQ,YAAY,CAAA;AAC5B,QAAA,EAAA,EAAIA,KAAE,MAAA,EAAA;AACN,QAAA,KAAA,EAAOA,KAAE,MAAA,EAAA;AACT,QAAA,gBAAA,EAAkB,uBAAuB,QAAA;AAC1C,OAAA,CAAA;AACDA,MAAAA,IAAAA,CAAE,YAAA,CAAa;QACb,IAAA,EAAMA,IAAAA,CAAE,QAAQ,UAAU,CAAA;AAC1B,QAAA,EAAA,EAAIA,KAAE,MAAA,EAAA;AACN,QAAA,gBAAA,EAAkB,uBAAuB,QAAA;AAC1C,OAAA,CAAA;AACDA,MAAAA,IAAAA,CAAE,YAAA,CAAa;QACb,IAAA,EAAMA,IAAAA,CAAE,QAAQ,OAAO,CAAA;AACvB,QAAA,SAAA,EAAWA,KAAE,MAAA;AACd,OAAA,CAAA;AACDA,MAAAA,IAAAA,CAAE,YAAA,CAAa;QACb,IAAA,EAAMA,IAAAA,CAAE,QAAQ,kBAAkB,CAAA;AAClC,QAAA,UAAA,EAAYA,KAAE,MAAA,EAAA;AACd,QAAA,QAAA,EAAUA,KAAE,MAAA,EAAA;QACZ,gBAAA,EAAkBA,IAAAA,CAAE,OAAA,EAAA,CAAU,QAAA,EAAA;QAC9B,OAAA,EAASA,IAAAA,CAAE,OAAA,EAAA,CAAU,QAAA;AACtB,OAAA,CAAA;AACDA,MAAAA,IAAAA,CAAE,YAAA,CAAa;QACb,IAAA,EAAMA,IAAAA,CAAE,QAAQ,kBAAkB,CAAA;AAClC,QAAA,UAAA,EAAYA,KAAE,MAAA,EAAA;AACd,QAAA,cAAA,EAAgBA,KAAE,MAAA;AACnB,OAAA,CAAA;AACDA,MAAAA,IAAAA,CAAE,YAAA,CAAa;QACb,IAAA,EAAMA,IAAAA,CAAE,QAAQ,sBAAsB,CAAA;AACtC,QAAA,UAAA,EAAYA,KAAE,MAAA,EAAA;AACd,QAAA,QAAA,EAAUA,KAAE,MAAA,EAAA;AACZ,QAAA,KAAA,EAAOA,KAAE,OAAA,EAAA;QACT,gBAAA,EAAkBA,IAAAA,CAAE,OAAA,EAAA,CAAU,QAAA,EAAA;AAC9B,QAAA,gBAAA,EAAkB,uBAAuB,QAAA,EAAA;QACzC,OAAA,EAASA,IAAAA,CAAE,OAAA,EAAA,CAAU,QAAA;AACtB,OAAA,CAAA;AACDA,MAAAA,IAAAA,CAAE,YAAA,CAAa;QACb,IAAA,EAAMA,IAAAA,CAAE,QAAQ,kBAAkB,CAAA;AAClC,QAAA,UAAA,EAAYA,KAAE,MAAA,EAAA;AACd,QAAA,QAAA,EAAUA,KAAE,MAAA,EAAA;AACZ,QAAA,KAAA,EAAOA,KAAE,OAAA,EAAA;QACT,gBAAA,EAAkBA,IAAAA,CAAE,OAAA,EAAA,CAAU,QAAA,EAAA;AAC9B,QAAA,gBAAA,EAAkB,uBAAuB,QAAA,EAAA;QACzC,OAAA,EAASA,IAAAA,CAAE,OAAA,EAAA,CAAU,QAAA,EAAA;AACrB,QAAA,SAAA,EAAWA,KAAE,MAAA;AACd,OAAA,CAAA;AACDA,MAAAA,IAAAA,CAAE,YAAA,CAAa;QACb,IAAA,EAAMA,IAAAA,CAAE,QAAQ,uBAAuB,CAAA;AACvC,QAAA,UAAA,EAAYA,KAAE,MAAA,EAAA;AACd,QAAA,MAAA,EAAQA,KAAE,OAAA,EAAA;QACV,gBAAA,EAAkBA,IAAAA,CAAE,OAAA,EAAA,CAAU,QAAA,EAAA;QAC9B,OAAA,EAASA,IAAAA,CAAE,OAAA,EAAA,CAAU,QAAA,EAAA;QACrB,WAAA,EAAaA,IAAAA,CAAE,OAAA,EAAA,CAAU,QAAA;AAC1B,OAAA,CAAA;AACDA,MAAAA,IAAAA,CAAE,YAAA,CAAa;QACb,IAAA,EAAMA,IAAAA,CAAE,QAAQ,mBAAmB,CAAA;AACnC,QAAA,UAAA,EAAYA,KAAE,MAAA,EAAA;AACd,QAAA,SAAA,EAAWA,KAAE,MAAA,EAAA;QACb,gBAAA,EAAkBA,IAAAA,CAAE,OAAA,EAAA,CAAU,QAAA,EAAA;QAC9B,OAAA,EAASA,IAAAA,CAAE,OAAA,EAAA,CAAU,QAAA;AACtB,OAAA,CAAA;AACDA,MAAAA,IAAAA,CAAE,YAAA,CAAa;QACb,IAAA,EAAMA,IAAAA,CAAE,QAAQ,iBAAiB,CAAA;AACjC,QAAA,EAAA,EAAIA,KAAE,MAAA,EAAA;AACN,QAAA,gBAAA,EAAkB,uBAAuB,QAAA;AAC1C,OAAA,CAAA;AACDA,MAAAA,IAAAA,CAAE,YAAA,CAAa;QACb,IAAA,EAAMA,IAAAA,CAAE,QAAQ,iBAAiB,CAAA;AACjC,QAAA,EAAA,EAAIA,KAAE,MAAA,EAAA;AACN,QAAA,KAAA,EAAOA,KAAE,MAAA,EAAA;AACT,QAAA,gBAAA,EAAkB,uBAAuB,QAAA;AAC1C,OAAA,CAAA;AACDA,MAAAA,IAAAA,CAAE,YAAA,CAAa;QACb,IAAA,EAAMA,IAAAA,CAAE,QAAQ,eAAe,CAAA;AAC/B,QAAA,EAAA,EAAIA,KAAE,MAAA,EAAA;AACN,QAAA,gBAAA,EAAkB,uBAAuB,QAAA;AAC1C,OAAA,CAAA;AACDA,MAAAA,IAAAA,CAAE,YAAA,CAAa;QACb,IAAA,EAAMA,IAAAA,CAAE,QAAQ,YAAY,CAAA;AAC5B,QAAA,QAAA,EAAUA,KAAE,MAAA,EAAA;AACZ,QAAA,GAAA,EAAKA,KAAE,MAAA,EAAA;QACP,KAAA,EAAOA,IAAAA,CAAE,MAAA,EAAA,CAAS,QAAA,EAAA;AAClB,QAAA,gBAAA,EAAkB,uBAAuB,QAAA;AAC1C,OAAA,CAAA;AACDA,MAAAA,IAAAA,CAAE,YAAA,CAAa;QACb,IAAA,EAAMA,IAAAA,CAAE,QAAQ,iBAAiB,CAAA;AACjC,QAAA,QAAA,EAAUA,KAAE,MAAA,EAAA;AACZ,QAAA,SAAA,EAAWA,KAAE,MAAA,EAAA;AACb,QAAA,KAAA,EAAOA,KAAE,MAAA,EAAA;QACT,QAAA,EAAUA,IAAAA,CAAE,MAAA,EAAA,CAAS,QAAA,EAAA;AACrB,QAAA,gBAAA,EAAkB,uBAAuB,QAAA;AAC1C,OAAA,CAAA;AACDA,MAAAA,IAAAA,CAAE,YAAA,CAAa;QACb,IAAA,EAAMA,IAAAA,CAAE,QAAQ,MAAM,CAAA;AACtB,QAAA,GAAA,EAAKA,KAAE,MAAA,EAAA;AACP,QAAA,SAAA,EAAWA,KAAE,MAAA,EAAA;AACb,QAAA,gBAAA,EAAkB,uBAAuB,QAAA;AAC1C,OAAA,CAAA;AACDA,MAAAA,IAAAA,CAAE,YAAA,CAAa;AACb,QAAA,IAAA,EAAMA,IAAAA,CAAE,MAAA;AACN,UAAA,CAAC,UACC,OAAO,KAAA,KAAU,QAAA,IAAY,KAAA,CAAM,WAAW,OAAO,CAAA;AACvD,UAAA,EAAE,SAAS,8BAAA;AACb,SAAA;QACA,EAAA,EAAIA,IAAAA,CAAE,MAAA,EAAA,CAAS,QAAA,EAAA;AACf,QAAA,IAAA,EAAMA,KAAE,OAAA,EAAA;QACR,SAAA,EAAWA,IAAAA,CAAE,OAAA,EAAA,CAAU,QAAA;AACxB,OAAA,CAAA;AACDA,MAAAA,IAAAA,CAAE,YAAA,CAAa;QACb,IAAA,EAAMA,IAAAA,CAAE,QAAQ,YAAY;AAC7B,OAAA,CAAA;AACDA,MAAAA,IAAAA,CAAE,YAAA,CAAa;QACb,IAAA,EAAMA,IAAAA,CAAE,QAAQ,aAAa;AAC9B,OAAA,CAAA;AACDA,MAAAA,IAAAA,CAAE,YAAA,CAAa;QACb,IAAA,EAAMA,IAAAA,CAAE,QAAQ,OAAO,CAAA;QACvB,SAAA,EAAWA,IAAAA,CAAE,MAAA,EAAA,CAAS,QAAA,EAAA;QACtB,eAAA,EAAiBA,IAAAA,CAAE,OAAA,EAAA,CAAU,QAAA;AAC9B,OAAA,CAAA;AACDA,MAAAA,IAAAA,CAAE,YAAA,CAAa;QACb,IAAA,EAAMA,IAAAA,CAAE,QAAQ,QAAQ,CAAA;AACxB,QAAA,YAAA,EAAcA,KACX,IAAA,CAAK;AACJ,UAAA,MAAA;AACA,UAAA,QAAA;AACA,UAAA,gBAAA;AACA,UAAA,YAAA;AACA,UAAA,OAAA;AACA,UAAA,OAAA;AACA,UAAA;AACF,SAA4C,EAC3C,QAAA,EAAA;QACH,eAAA,EAAiBA,IAAAA,CAAE,OAAA,EAAA,CAAU,QAAA;AAC9B,OAAA,CAAA;AACDA,MAAAA,IAAAA,CAAE,YAAA,CAAa;QACb,IAAA,EAAMA,IAAAA,CAAE,QAAQ,OAAO;AACxB,OAAA,CAAA;AACDA,MAAAA,IAAAA,CAAE,YAAA,CAAa;QACb,IAAA,EAAMA,IAAAA,CAAE,QAAQ,kBAAkB,CAAA;AAClC,QAAA,eAAA,EAAiBA,KAAE,OAAA;AACpB,OAAA;AACF,KAAA;AACH;AACF;AC5IO,SAAS,QAAQ,KAAA,EAAuB;AAC7C,EAAA,MAAM,KAAA,GAAiB,CAAC,MAAM,CAAA;AAC9B,EAAA,IAAI,cAAA,GAAiB,EAAA;AACrB,EAAA,IAAI,YAAA,GAA8B,IAAA;AAElC,EAAA,SAAS,iBAAA,CAAkB,IAAA,EAAc,CAAA,EAAW,SAAA,EAAkB;AACpE,IAAA;AACE,MAAA,QAAQ,IAAA;AACN,QAAA,KAAK,GAAA,EAAK;AACR,UAAA,cAAA,GAAiB,CAAA;AACjB,UAAA,KAAA,CAAM,GAAA,EAAA;AACN,UAAA,KAAA,CAAM,KAAK,SAAS,CAAA;AACpB,UAAA,KAAA,CAAM,KAAK,eAAe,CAAA;AAC1B,UAAA;AACF,QAAA;QAEA,KAAK,GAAA;QACL,KAAK,GAAA;AACL,QAAA,KAAK,GAAA,EAAK;AACR,UAAA,cAAA,GAAiB,CAAA;AACjB,UAAA,YAAA,GAAe,CAAA;AACf,UAAA,KAAA,CAAM,GAAA,EAAA;AACN,UAAA,KAAA,CAAM,KAAK,SAAS,CAAA;AACpB,UAAA,KAAA,CAAM,KAAK,gBAAgB,CAAA;AAC3B,UAAA;AACF,QAAA;AAEA,QAAA,KAAK,GAAA,EAAK;AACR,UAAA,KAAA,CAAM,GAAA,EAAA;AACN,UAAA,KAAA,CAAM,KAAK,SAAS,CAAA;AACpB,UAAA,KAAA,CAAM,KAAK,eAAe,CAAA;AAC1B,UAAA;AACF,QAAA;QACA,KAAK,GAAA;QACL,KAAK,GAAA;QACL,KAAK,GAAA;QACL,KAAK,GAAA;QACL,KAAK,GAAA;QACL,KAAK,GAAA;QACL,KAAK,GAAA;QACL,KAAK,GAAA;QACL,KAAK,GAAA;AACL,QAAA,KAAK,GAAA,EAAK;AACR,UAAA,cAAA,GAAiB,CAAA;AACjB,UAAA,KAAA,CAAM,GAAA,EAAA;AACN,UAAA,KAAA,CAAM,KAAK,SAAS,CAAA;AACpB,UAAA,KAAA,CAAM,KAAK,eAAe,CAAA;AAC1B,UAAA;AACF,QAAA;AAEA,QAAA,KAAK,GAAA,EAAK;AACR,UAAA,cAAA,GAAiB,CAAA;AACjB,UAAA,KAAA,CAAM,GAAA,EAAA;AACN,UAAA,KAAA,CAAM,KAAK,SAAS,CAAA;AACpB,UAAA,KAAA,CAAM,KAAK,qBAAqB,CAAA;AAChC,UAAA;AACF,QAAA;AAEA,QAAA,KAAK,GAAA,EAAK;AACR,UAAA,cAAA,GAAiB,CAAA;AACjB,UAAA,KAAA,CAAM,GAAA,EAAA;AACN,UAAA,KAAA,CAAM,KAAK,SAAS,CAAA;AACpB,UAAA,KAAA,CAAM,KAAK,oBAAoB,CAAA;AAC/B,UAAA;AACF,QAAA;AACF;AACF,IAAA;AACF,EAAA;AAEA,EAAA,SAAS,uBAAA,CAAwB,MAAc,CAAA,EAAW;AACxD,IAAA,QAAQ,IAAA;AACN,MAAA,KAAK,GAAA,EAAK;AACR,QAAA,KAAA,CAAM,GAAA,EAAA;AACN,QAAA,KAAA,CAAM,KAAK,2BAA2B,CAAA;AACtC,QAAA;AACF,MAAA;AACA,MAAA,KAAK,GAAA,EAAK;AACR,QAAA,cAAA,GAAiB,CAAA;AACjB,QAAA,KAAA,CAAM,GAAA,EAAA;AACN,QAAA;AACF,MAAA;AACF;AACF,EAAA;AAEA,EAAA,SAAS,sBAAA,CAAuB,MAAc,CAAA,EAAW;AACvD,IAAA,QAAQ,IAAA;AACN,MAAA,KAAK,GAAA,EAAK;AACR,QAAA,KAAA,CAAM,GAAA,EAAA;AACN,QAAA,KAAA,CAAM,KAAK,0BAA0B,CAAA;AACrC,QAAA;AACF,MAAA;AACA,MAAA,KAAK,GAAA,EAAK;AACR,QAAA,cAAA,GAAiB,CAAA;AACjB,QAAA,KAAA,CAAM,GAAA,EAAA;AACN,QAAA;AACF,MAAA;AACF;AACF,EAAA;AAEA,EAAA,KAAA,IAAS,CAAA,GAAI,CAAA,EAAG,CAAA,GAAI,KAAA,CAAM,QAAQ,CAAA,EAAA,EAAK;AACrC,IAAA,MAAM,IAAA,GAAO,MAAM,CAAC,CAAA;AACpB,IAAA,MAAM,YAAA,GAAe,KAAA,CAAM,KAAA,CAAM,MAAA,GAAS,CAAC,CAAA;AAE3C,IAAA,QAAQ,YAAA;MACN,KAAK,MAAA;AACH,QAAA,iBAAA,CAAkB,IAAA,EAAM,GAAG,QAAQ,CAAA;AACnC,QAAA;AAEF,MAAA,KAAK,qBAAA,EAAuB;AAC1B,QAAA,QAAQ,IAAA;AACN,UAAA,KAAK,GAAA,EAAK;AACR,YAAA,KAAA,CAAM,GAAA,EAAA;AACN,YAAA,KAAA,CAAM,KAAK,mBAAmB,CAAA;AAC9B,YAAA;AACF,UAAA;AACA,UAAA,KAAK,GAAA,EAAK;AACR,YAAA,cAAA,GAAiB,CAAA;AACjB,YAAA,KAAA,CAAM,GAAA,EAAA;AACN,YAAA;AACF,UAAA;AACF;AACA,QAAA;AACF,MAAA;AAEA,MAAA,KAAK,2BAAA,EAA6B;AAChC,QAAA,QAAQ,IAAA;AACN,UAAA,KAAK,GAAA,EAAK;AACR,YAAA,KAAA,CAAM,GAAA,EAAA;AACN,YAAA,KAAA,CAAM,KAAK,mBAAmB,CAAA;AAC9B,YAAA;AACF,UAAA;AACF;AACA,QAAA;AACF,MAAA;AAEA,MAAA,KAAK,mBAAA,EAAqB;AACxB,QAAA,QAAQ,IAAA;AACN,UAAA,KAAK,GAAA,EAAK;AACR,YAAA,KAAA,CAAM,GAAA,EAAA;AACN,YAAA,KAAA,CAAM,KAAK,yBAAyB,CAAA;AACpC,YAAA;AACF,UAAA;AACF;AACA,QAAA;AACF,MAAA;AAEA,MAAA,KAAK,yBAAA,EAA2B;AAC9B,QAAA,QAAQ,IAAA;AACN,UAAA,KAAK,GAAA,EAAK;AACR,YAAA,KAAA,CAAM,GAAA,EAAA;AACN,YAAA,KAAA,CAAM,KAAK,4BAA4B,CAAA;AAEvC,YAAA;AACF,UAAA;AACF;AACA,QAAA;AACF,MAAA;AAEA,MAAA,KAAK,4BAAA,EAA8B;AACjC,QAAA,iBAAA,CAAkB,IAAA,EAAM,GAAG,2BAA2B,CAAA;AACtD,QAAA;AACF,MAAA;AAEA,MAAA,KAAK,2BAAA,EAA6B;AAChC,QAAA,uBAAA,CAAwB,MAAM,CAAC,CAAA;AAC/B,QAAA;AACF,MAAA;AAEA,MAAA,KAAK,eAAA,EAAiB;AACpB,QAAA,QAAQ,IAAA;AACN,UAAA,KAAK,GAAA,EAAK;AACR,YAAA,KAAA,CAAM,GAAA,EAAA;AACN,YAAA,cAAA,GAAiB,CAAA;AACjB,YAAA;AACF,UAAA;AAEA,UAAA,KAAK,IAAA,EAAM;AACT,YAAA,KAAA,CAAM,KAAK,sBAAsB,CAAA;AACjC,YAAA;AACF,UAAA;UAEA,SAAS;AACP,YAAA,cAAA,GAAiB,CAAA;AACnB,UAAA;AACF;AAEA,QAAA;AACF,MAAA;AAEA,MAAA,KAAK,oBAAA,EAAsB;AACzB,QAAA,QAAQ,IAAA;AACN,UAAA,KAAK,GAAA,EAAK;AACR,YAAA,cAAA,GAAiB,CAAA;AACjB,YAAA,KAAA,CAAM,GAAA,EAAA;AACN,YAAA;AACF,UAAA;UAEA,SAAS;AACP,YAAA,cAAA,GAAiB,CAAA;AACjB,YAAA,iBAAA,CAAkB,IAAA,EAAM,GAAG,0BAA0B,CAAA;AACrD,YAAA;AACF,UAAA;AACF;AACA,QAAA;AACF,MAAA;AAEA,MAAA,KAAK,0BAAA,EAA4B;AAC/B,QAAA,QAAQ,IAAA;AACN,UAAA,KAAK,GAAA,EAAK;AACR,YAAA,KAAA,CAAM,GAAA,EAAA;AACN,YAAA,KAAA,CAAM,KAAK,0BAA0B,CAAA;AACrC,YAAA;AACF,UAAA;AAEA,UAAA,KAAK,GAAA,EAAK;AACR,YAAA,cAAA,GAAiB,CAAA;AACjB,YAAA,KAAA,CAAM,GAAA,EAAA;AACN,YAAA;AACF,UAAA;UAEA,SAAS;AACP,YAAA,cAAA,GAAiB,CAAA;AACjB,YAAA;AACF,UAAA;AACF;AAEA,QAAA;AACF,MAAA;AAEA,MAAA,KAAK,0BAAA,EAA4B;AAC/B,QAAA,iBAAA,CAAkB,IAAA,EAAM,GAAG,0BAA0B,CAAA;AACrD,QAAA;AACF,MAAA;AAEA,MAAA,KAAK,sBAAA,EAAwB;AAC3B,QAAA,KAAA,CAAM,GAAA,EAAA;AACN,QAAA,cAAA,GAAiB,CAAA;AAEjB,QAAA;AACF,MAAA;AAEA,MAAA,KAAK,eAAA,EAAiB;AACpB,QAAA,QAAQ,IAAA;UACN,KAAK,GAAA;UACL,KAAK,GAAA;UACL,KAAK,GAAA;UACL,KAAK,GAAA;UACL,KAAK,GAAA;UACL,KAAK,GAAA;UACL,KAAK,GAAA;UACL,KAAK,GAAA;UACL,KAAK,GAAA;AACL,UAAA,KAAK,GAAA,EAAK;AACR,YAAA,cAAA,GAAiB,CAAA;AACjB,YAAA;AACF,UAAA;UAEA,KAAK,GAAA;UACL,KAAK,GAAA;UACL,KAAK,GAAA;AACL,UAAA,KAAK,GAAA,EAAK;AACR,YAAA;AACF,UAAA;AAEA,UAAA,KAAK,GAAA,EAAK;AACR,YAAA,KAAA,CAAM,GAAA,EAAA;AAEN,YAAA,IAAI,KAAA,CAAM,KAAA,CAAM,MAAA,GAAS,CAAC,MAAM,0BAAA,EAA4B;AAC1D,cAAA,sBAAA,CAAuB,MAAM,CAAC,CAAA;AAChC,YAAA;AAEA,YAAA,IAAI,KAAA,CAAM,KAAA,CAAM,MAAA,GAAS,CAAC,MAAM,2BAAA,EAA6B;AAC3D,cAAA,uBAAA,CAAwB,MAAM,CAAC,CAAA;AACjC,YAAA;AAEA,YAAA;AACF,UAAA;AAEA,UAAA,KAAK,GAAA,EAAK;AACR,YAAA,KAAA,CAAM,GAAA,EAAA;AAEN,YAAA,IAAI,KAAA,CAAM,KAAA,CAAM,MAAA,GAAS,CAAC,MAAM,2BAAA,EAA6B;AAC3D,cAAA,uBAAA,CAAwB,MAAM,CAAC,CAAA;AACjC,YAAA;AAEA,YAAA;AACF,UAAA;AAEA,UAAA,KAAK,GAAA,EAAK;AACR,YAAA,KAAA,CAAM,GAAA,EAAA;AAEN,YAAA,IAAI,KAAA,CAAM,KAAA,CAAM,MAAA,GAAS,CAAC,MAAM,0BAAA,EAA4B;AAC1D,cAAA,sBAAA,CAAuB,MAAM,CAAC,CAAA;AAChC,YAAA;AAEA,YAAA;AACF,UAAA;UAEA,SAAS;AACP,YAAA,KAAA,CAAM,GAAA,EAAA;AACN,YAAA;AACF,UAAA;AACF;AAEA,QAAA;AACF,MAAA;AAEA,MAAA,KAAK,gBAAA,EAAkB;AACrB,QAAA,MAAM,cAAA,GAAiB,KAAA,CAAM,SAAA,CAAU,YAAA,EAAe,IAAI,CAAC,CAAA;AAE3D,QAAA,IACE,CAAC,OAAA,CAAQ,UAAA,CAAW,cAAc,KAClC,CAAC,MAAA,CAAO,UAAA,CAAW,cAAc,CAAA,IACjC,CAAC,MAAA,CAAO,UAAA,CAAW,cAAc,CAAA,EACjC;AACA,UAAA,KAAA,CAAM,GAAA,EAAA;AAEN,UAAA,IAAI,KAAA,CAAM,KAAA,CAAM,MAAA,GAAS,CAAC,MAAM,2BAAA,EAA6B;AAC3D,YAAA,uBAAA,CAAwB,MAAM,CAAC,CAAA;AACjC,UAAA,CAAA,MAAA,IAAW,KAAA,CAAM,KAAA,CAAM,MAAA,GAAS,CAAC,MAAM,0BAAA,EAA4B;AACjE,YAAA,sBAAA,CAAuB,MAAM,CAAC,CAAA;AAChC,UAAA;QACF,CAAA,MAAO;AACL,UAAA,cAAA,GAAiB,CAAA;AACnB,QAAA;AAEA,QAAA;AACF,MAAA;AACF;AACF,EAAA;AAEA,EAAA,IAAI,MAAA,GAAS,KAAA,CAAM,KAAA,CAAM,CAAA,EAAG,iBAAiB,CAAC,CAAA;AAE9C,EAAA,KAAA,IAAS,IAAI,KAAA,CAAM,MAAA,GAAS,CAAA,EAAG,CAAA,IAAK,GAAG,CAAA,EAAA,EAAK;AAC1C,IAAA,MAAM,KAAA,GAAQ,MAAM,CAAC,CAAA;AAErB,IAAA,QAAQ,KAAA;AACN,MAAA,KAAK,eAAA,EAAiB;AACpB,QAAA,MAAA,IAAU,GAAA;AACV,QAAA;AACF,MAAA;MAEA,KAAK,mBAAA;MACL,KAAK,yBAAA;MACL,KAAK,2BAAA;MACL,KAAK,qBAAA;MACL,KAAK,4BAAA;AACL,MAAA,KAAK,2BAAA,EAA6B;AAChC,QAAA,MAAA,IAAU,GAAA;AACV,QAAA;AACF,MAAA;MAEA,KAAK,oBAAA;MACL,KAAK,0BAAA;AACL,MAAA,KAAK,0BAAA,EAA4B;AAC/B,QAAA,MAAA,IAAU,GAAA;AACV,QAAA;AACF,MAAA;AAEA,MAAA,KAAK,gBAAA,EAAkB;AACrB,QAAA,MAAM,cAAA,GAAiB,KAAA,CAAM,SAAA,CAAU,YAAA,EAAe,MAAM,MAAM,CAAA;AAElE,QAAA,IAAI,MAAA,CAAO,UAAA,CAAW,cAAc,CAAA,EAAG;AACrC,UAAA,MAAA,IAAU,MAAA,CAAO,KAAA,CAAM,cAAA,CAAe,MAAM,CAAA;QAC9C,CAAA,MAAA,IAAW,OAAA,CAAQ,UAAA,CAAW,cAAc,CAAA,EAAG;AAC7C,UAAA,MAAA,IAAU,OAAA,CAAQ,KAAA,CAAM,cAAA,CAAe,MAAM,CAAA;QAC/C,CAAA,MAAA,IAAW,MAAA,CAAO,UAAA,CAAW,cAAc,CAAA,EAAG;AAC5C,UAAA,MAAA,IAAU,MAAA,CAAO,KAAA,CAAM,cAAA,CAAe,MAAM,CAAA;AAC9C,QAAA;AACF,MAAA;AACF;AACF,EAAA;AAEA,EAAA,OAAO,MAAA;AACT;AC5YA,eAAsB,iBAAiB,QAAA,EAOpC;AACD,EAAA,IAAI,aAAa,MAAA,EAAW;AAC1B,IAAA,OAAO,EAAE,KAAA,EAAO,MAAA,EAAW,KAAA,EAAO,iBAAA,EAAA;AACpC,EAAA;AAEA,EAAA,IAAI,SAAS,MAAM6C,+BAAAA,CAAc,EAAE,IAAA,EAAM,UAAU,CAAA;AAEnD,EAAA,IAAI,OAAO,OAAA,EAAS;AAClB,IAAA,OAAO,EAAE,KAAA,EAAO,MAAA,CAAO,KAAA,EAAO,OAAO,kBAAA,EAAA;AACvC,EAAA;AAEA,EAAA,MAAA,GAAS,MAAMA,+BAAAA,CAAc,EAAE,MAAM,OAAA,CAAQ,QAAQ,GAAG,CAAA;AAExD,EAAA,IAAI,OAAO,OAAA,EAAS;AAClB,IAAA,OAAO,EAAE,KAAA,EAAO,MAAA,CAAO,KAAA,EAAO,OAAO,gBAAA,EAAA;AACvC,EAAA;AAEA,EAAA,OAAO,EAAE,KAAA,EAAO,MAAA,EAAW,KAAA,EAAO,cAAA,EAAA;AACpC;ACkLO,SAAS,aACd,IAAA,EACgC;AAChC,EAAA,OAAO,IAAA,CAAK,IAAA,CAAK,UAAA,CAAW,OAAO,CAAA;AACrC;AA+GO,SAAS,aACd,IAAA,EACoB;AACpB,EAAA,OAAO,KAAK,IAAA,KAAS,MAAA;AACvB;AAKO,SAAS,aACd,IAAA,EACoB;AACpB,EAAA,OAAO,KAAK,IAAA,KAAS,MAAA;AACvB;AAKO,SAAS,kBACd,IAAA,EACyB;AACzB,EAAA,OAAO,KAAK,IAAA,KAAS,WAAA;AACvB;AAGO,SAAS,aACd,IAAA,EAC2B;AAC3B,EAAA,OAAO,IAAA,CAAK,IAAA,CAAK,UAAA,CAAW,OAAO,CAAA;AACrC;AAEO,SAAS,oBACd,IAAA,EAC2B;AAC3B,EAAA,OAAO,KAAK,IAAA,KAAS,cAAA;AACvB;AAEO,SAAS,0BACd,IAAA,EAC+C;AAC/C,EAAA,OAAO,YAAA,CAAa,IAAI,CAAA,IAAK,mBAAA,CAAoB,IAAI,CAAA;AACvD;AAEO,SAAS,YACd,IAAA,EACa;AACb,EAAA,OAAO,IAAA,CAAK,KAAK,KAAA,CAAM,GAAG,EAAE,KAAA,CAAM,CAAC,CAAA,CAAE,IAAA,CAAK,GAAG,CAAA;AAC/C;AAEO,SAAS,yBACd,IAAA,EACQ;AACR,EAAA,OAAO,oBAAoB,IAAI,CAAA,GAAI,IAAA,CAAK,QAAA,GAAW,YAAY,IAAI,CAAA;AACrE;AC7R2BD,mCAAAA,CAAkB;EAC3C,MAAA,EAAQ,OAAA;EACR,IAAA,EAAM;AACR,CAAC;ACnDM,SAAS,sBAAA,CACd,UACA,OAAA,EAOgB;AAChB,EAAA,MAAM,gBAAgC,EAAA;AAEtC,EAAA,IAAI,OAAA,IAAA,IAAA,GAAA,MAAA,GAAA,OAAA,CAAS,yBAAA,EAA2B;AACtC,IAAA,QAAA,GAAW,QAAA,CAAS,GAAA,CAAI,CAAA,OAAA,MAAY;MAClC,GAAG,OAAA;AACH,MAAA,KAAA,EAAO,QAAQ,KAAA,CAAM,MAAA;QACnB,CAAA,IAAA,KACE,CAAC,yBAAA,CAA0B,IAAI,KAC9B,IAAA,CAAK,KAAA,KAAU,iBAAA,IACd,IAAA,CAAK,KAAA,KAAU;AACrB;AACA,KAAA,CAAA,CAAA;AACJ,EAAA;AAEA,EAAA,KAAA,MAAW,WAAW,QAAA,EAAU;AAC9B,IAAA,QAAQ,QAAQ,IAAA;AACd,MAAA,KAAK,QAAA,EAAU;AACb,QAAA,MAAM,SAAA,GAAY,QAAQ,KAAA,CAAM,MAAA;UAC9B,CAAC,IAAA,KAA6B,KAAK,IAAA,KAAS;AAC9C,SAAA;AAEA,QAAA,MAAM,gBAAA,GAAmB,SAAA,CAAU,MAAA,CAAO,CAAC,KAAK,IAAA,KAAS;AACvD,UAAA,IAAI,IAAA,CAAK,oBAAoB,IAAA,EAAM;AACjC,YAAA,OAAO,EAAE,GAAG,GAAA,EAAK,GAAG,KAAK,gBAAA,EAAA;AAC3B,UAAA;AACA,UAAA,OAAO,GAAA;AACT,QAAA,CAAA,EAAG,EAAE,CAAA;AAEL,QAAA,aAAA,CAAc,IAAA,CAAK;UACjB,IAAA,EAAM,QAAA;UACN,OAAA,EAAS,SAAA,CAAU,IAAI,CAAA,IAAA,KAAQ,KAAK,IAAI,CAAA,CAAE,KAAK,EAAE,CAAA;UACjD,GAAI,MAAA,CAAO,IAAA,CAAK,gBAAgB,CAAA,CAAE,MAAA,GAAS,IACvC,EAAE,eAAA,EAAiB,gBAAA,EAAA,GACnB;AACL,SAAA,CAAA;AACD,QAAA;AACF,MAAA;AAEA,MAAA,KAAK,MAAA,EAAQ;AACX,QAAA,aAAA,CAAc,IAAA,CAAK;UACjB,IAAA,EAAM,MAAA;AACN,UAAA,OAAA,EAAS,OAAA,CAAQ,KAAA,CACd,GAAA,CAAI,CAAC,IAAA,KAA0C;AA9F5D,YAAA,IAAAhD,IAAAA;AAgGc,YAAA,IAAI,YAAA,CAAa,IAAI,CAAA,EAAG;AACtB,cAAA,OAAO;gBACL,IAAA,EAAM,MAAA;AACN,gBAAA,IAAA,EAAM,IAAA,CAAK,IAAA;gBACX,GAAI,IAAA,CAAK,oBAAoB,IAAA,GACzB,EAAE,iBAAiB,IAAA,CAAK,gBAAA,KACxB;AACN,eAAA;AACF,YAAA;AAGA,YAAA,IAAI,YAAA,CAAa,IAAI,CAAA,EAAG;AACtB,cAAA,OAAO;gBACL,IAAA,EAAM,MAAA;AACN,gBAAA,SAAA,EAAW,IAAA,CAAK,SAAA;AAChB,gBAAA,QAAA,EAAU,IAAA,CAAK,QAAA;AACf,gBAAA,IAAA,EAAM,IAAA,CAAK,GAAA;gBACX,GAAI,IAAA,CAAK,oBAAoB,IAAA,GACzB,EAAE,iBAAiB,IAAA,CAAK,gBAAA,KACxB;AACN,eAAA;AACF,YAAA;AAGA,YAAA,IAAI,YAAA,CAAa,IAAI,CAAA,EAAG;AACtB,cAAA,OAAA,CAAOA,IAAAA,GAAA,WAAA,IAAA,GAAA,MAAA,GAAA,QAAS,eAAA,KAAT,IAAA,GAAA,SAAAA,IAAAA,CAAA,IAAA;AAAA,gBAAA,OAAA;AACL,gBAAA;AAAA,eAAA;AAEJ,YAAA;AACF,UAAA,CAAC,CAAA,CACA,MAAA,CAAO,CAAC,IAAA,KAAsC,QAAQ,IAAI;AAC9D,SAAA,CAAA;AAED,QAAA;AACF,MAAA;AAEA,MAAA,KAAK,WAAA,EAAa;AAChB,QAAA,IAAI,OAAA,CAAQ,SAAS,IAAA,EAAM;AAUzB,UAAA,IAASkD,gBAAT,WAAwB;AA/IlC,YAAA,IAAAlD,MAAAC,GAAAA,EAAA,EAAA;AAgJY,YAAA,IAAI,KAAA,CAAM,WAAW,CAAA,EAAG;AACtB,cAAA;AACF,YAAA;AAEA,YAAA,MAAM,UAA4B,EAAA;AAElC,YAAA,KAAA,MAAW,QAAQ,KAAA,EAAO;AACxB,cAAA,IAAI,YAAA,CAAa,IAAI,CAAA,EAAG;AACtB,gBAAA,OAAA,CAAQ,IAAA,CAAK;kBACX,IAAA,EAAM,MAAA;AACN,kBAAA,IAAA,EAAM,IAAA,CAAK,IAAA;kBACX,GAAI,IAAA,CAAK,oBAAoB,IAAA,GACzB,EAAE,iBAAiB,IAAA,CAAK,gBAAA,KACxB;AACL,iBAAA,CAAA;cACH,CAAA,MAAA,IAAW,YAAA,CAAa,IAAI,CAAA,EAAG;AAC7B,gBAAA,OAAA,CAAQ,IAAA,CAAK;kBACX,IAAA,EAAM,MAAA;AACN,kBAAA,SAAA,EAAW,IAAA,CAAK,SAAA;AAChB,kBAAA,QAAA,EAAU,IAAA,CAAK,QAAA;AACf,kBAAA,IAAA,EAAM,IAAA,CAAK;AACZ,iBAAA,CAAA;cACH,CAAA,MAAA,IAAW,iBAAA,CAAkB,IAAI,CAAA,EAAG;AAClC,gBAAA,OAAA,CAAQ,IAAA,CAAK;kBACX,IAAA,EAAM,WAAA;AACN,kBAAA,IAAA,EAAM,IAAA,CAAK,IAAA;AACX,kBAAA,eAAA,EAAiB,IAAA,CAAK;AACvB,iBAAA,CAAA;cACH,CAAA,MAAA,IAAW,mBAAA,CAAoB,IAAI,CAAA,EAAG;AACpC,gBAAA,MAAM,WAAW,IAAA,CAAK,QAAA;AAEtB,gBAAA,IAAI,IAAA,CAAK,UAAU,iBAAA,EAAmB;AACpC,kBAAA,OAAA,CAAQ,IAAA,CAAK;oBACX,IAAA,EAAM,WAAA;AACN,oBAAA,UAAA,EAAY,IAAA,CAAK,UAAA;AACjB,oBAAA,QAAA;AACA,oBAAA,KAAA,EAAO,IAAA,CAAK,KAAA;oBACZ,GAAI,IAAA,CAAK,wBAAwB,IAAA,GAC7B,EAAE,iBAAiB,IAAA,CAAK,oBAAA,KACxB;AACL,mBAAA,CAAA;AACH,gBAAA;cACF,CAAA,MAAA,IAAW,YAAA,CAAa,IAAI,CAAA,EAAG;AAC7B,gBAAA,MAAM,QAAA,GAAW,YAAY,IAAI,CAAA;AAEjC,gBAAA,IAAI,IAAA,CAAK,UAAU,iBAAA,EAAmB;AACpC,kBAAA,OAAA,CAAQ,IAAA,CAAK;oBACX,IAAA,EAAM,WAAA;AACN,oBAAA,UAAA,EAAY,IAAA,CAAK,UAAA;AACjB,oBAAA,QAAA;oBACA,KAAA,EACE,IAAA,CAAK,KAAA,KAAU,cAAA,GAAA,CACVD,IAAAA,GAAA,IAAA,CAAK,UAAL,IAAA,GAAAA,IAAAA,GAAc,IAAA,CAAK,QAAA,GACpB,IAAA,CAAK,KAAA;AACX,oBAAA,gBAAA,EAAkB,IAAA,CAAK,gBAAA;oBACvB,GAAI,IAAA,CAAK,wBAAwB,IAAA,GAC7B,EAAE,iBAAiB,IAAA,CAAK,oBAAA,KACxB;AACL,mBAAA,CAAA;AAED,kBAAA,IACE,IAAA,CAAK,qBAAqB,IAAA,KACzB,IAAA,CAAK,UAAU,kBAAA,IACd,IAAA,CAAK,UAAU,cAAA,CAAA,EACjB;AACA,oBAAA,OAAA,CAAQ,IAAA,CAAK;sBACX,IAAA,EAAM,aAAA;AACN,sBAAA,UAAA,EAAY,IAAA,CAAK,UAAA;AACjB,sBAAA,QAAA;AACA,sBAAA,MAAA,EAAQ,qBAAA,CAAsB;AAC5B,wBAAA,MAAA,EACE,IAAA,CAAK,KAAA,KAAU,cAAA,GACX,IAAA,CAAK,YACL,IAAA,CAAK,MAAA;wBACX,IAAA,EAAA,CAAMC,GAAAA,GAAA,WAAA,IAAA,GAAA,MAAA,GAAA,QAAS,KAAA,KAAT,IAAA,GAAA,MAAA,GAAAA,GAAAA,CAAiB,QAAA,CAAA;wBACvB,SAAA,EACE,IAAA,CAAK,KAAA,KAAU,cAAA,GAAiB,MAAA,GAAS;AAC5C,uBAAA;AACF,qBAAA,CAAA;AACH,kBAAA;AACF,gBAAA;cACF,CAAA,MAAA,IAAW,YAAA,CAAa,IAAI,CAAA,EAAG;AAC7B,gBAAA,MAAM,QAAA,GAAA,CAAW,KAAA,OAAA,IAAA,IAAA,GAAA,SAAA,OAAA,CAAS,eAAA,KAAT,IAAA,GAAA,MAAA,GAAA,EAAA,CAAA,IAAA;AAAA,kBAAA,OAAA;AACf,kBAAA;AAAA,iBAAA;AAGF,gBAAA,IAAI,YAAY,IAAA,EAAM;AACpB,kBAAA,OAAA,CAAQ,KAAK,QAAQ,CAAA;AACvB,gBAAA;cACF,CAAA,MAAO;AACL,gBAAA,MAAM,gBAAA,GAA0B,IAAA;AAChC,gBAAA,MAAM,IAAI,KAAA,CAAM,CAAA,kBAAA,EAAqB,gBAAgB,CAAA,CAAE,CAAA;AACzD,cAAA;AACF,YAAA;AAEA,YAAA,aAAA,CAAc,IAAA,CAAK;cACjB,IAAA,EAAM,WAAA;AACN,cAAA;AACD,aAAA,CAAA;AAGD,YAAA,MAAM,YAAY,KAAA,CAAM,MAAA;cACtB,CAAA,IAAA,KACG,aAAa,IAAI,CAAA,IAAK,KAAK,gBAAA,KAAqB,IAAA,IACjD,KAAK,IAAA,KAAS;AAClB,aAAA;AAMA,YAAA,IAAI,SAAA,CAAU,SAAS,CAAA,EAAG;AACxB,cAAA,aAAA,CAAc,IAAA,CAAK;gBACjB,IAAA,EAAM,MAAA;gBACN,OAAA,EAAS,SAAA,CACN,GAAA,CAAI,CAAC,QAAA,KAAoC;AAnQ5D,kBAAA,IAAAD,IAAAA;AAoQoB,kBAAA,QAAQ,SAAS,KAAA;oBACf,KAAK,cAAA;AACL,oBAAA,KAAK,kBAAA,EAAoB;AACvB,sBAAA,MAAM,QAAA,GAAW,yBAAyB,QAAQ,CAAA;AAElD,sBAAA,OAAO;wBACL,IAAA,EAAM,aAAA;AACN,wBAAA,UAAA,EAAY,QAAA,CAAS,UAAA;AACrB,wBAAA,QAAA;AACA,wBAAA,MAAA,EAAQ,qBAAA,CAAsB;AAC5B,0BAAA,MAAA,EACE,QAAA,CAAS,KAAA,KAAU,cAAA,GACf,QAAA,CAAS,YACT,QAAA,CAAS,MAAA;0BACf,IAAA,EAAA,CAAMA,IAAAA,GAAA,WAAA,IAAA,GAAA,MAAA,GAAA,QAAS,KAAA,KAAT,IAAA,GAAA,MAAA,GAAAA,IAAAA,CAAiB,QAAA,CAAA;0BACvB,SAAA,EACE,QAAA,CAAS,KAAA,KAAU,cAAA,GACf,MAAA,GACA;AACP,yBAAA;AACH,uBAAA;AACF,oBAAA;oBACA,SAAS;AACP,sBAAA,OAAO,IAAA;AACT,oBAAA;AACF;AACF,gBAAA,CAAC,CAAA,CACA,MAAA;AACC,kBAAA,CAAC,WACC,MAAA,IAAU;AACd;AACH,eAAA,CAAA;AACH,YAAA;AAGA,YAAA,KAAA,GAAQ,EAAA;AACV,UAAA,CAAA;AAlKA,UAAA,IAAI,QAOA,EAAA;AA6JJ,UAAA,KAAA,MAAW,IAAA,IAAQ,QAAQ,KAAA,EAAO;AAChC,YAAA,IACE,YAAA,CAAa,IAAI,CAAA,IACjB,iBAAA,CAAkB,IAAI,CAAA,IACtB,YAAA,CAAa,IAAI,CAAA,IACjB,yBAAA,CAA0B,IAAI,CAAA,IAC9B,YAAA,CAAa,IAAI,CAAA,EACjB;AACA,cAAA,KAAA,CAAM,KAAK,IAA8B,CAAA;YAC3C,CAAA,MAAA,IAAW,IAAA,CAAK,SAAS,YAAA,EAAc;AACrCkD,cAAAA,aAAAA,EAAAA;AACF,YAAA;AACF,UAAA;AAEAA,UAAAA,aAAAA,EAAAA;AAEA,UAAA;AACF,QAAA;AAEA,QAAA;AACF,MAAA;MAEA,SAAS;AACP,QAAA,MAAM,mBAA0B,OAAA,CAAQ,IAAA;AACxC,QAAA,MAAM,IAAI,sBAAA,CAAuB;UAC/B,eAAA,EAAiB,OAAA;AACjB,UAAA,OAAA,EAAS,qBAAqB,gBAAgB,CAAA;AAC/C,SAAA,CAAA;AACH,MAAA;AACF;AACF,EAAA;AAEA,EAAA,OAAO,aAAA;AACT;AClTA,eAAsB,KAAA,CAAsB;EAC1C,KAAA,EAAO,QAAA;AACP,EAAA,KAAA;AACA,EAAA,eAAA;EACA,UAAA,EAAY,aAAA;AACZ,EAAA,WAAA;AACA,EAAA,OAAA;EACA,sBAAA,EAAwB;AAC1B,CAAA,EAwCgC;AAC9B,EAAA,MAAM,KAAA,GAAQ,sBAA6B,QAAQ,CAAA;AAEnD,EAAA,MAAM,EAAE,UAAA,EAAY,KAAA,EAAA,GAAU,cAAA,CAAe;IAC3C,UAAA,EAAY,aAAA;AACZ,IAAA;AACD,GAAA,CAAA;AAED,EAAA,MAAM,oBAAA,GAAuBnC,qCAAAA;IAC3B,OAAA,IAAA,IAAA,GAAA,UAAW,EAAA;AACX,IAAA,CAAA,GAAA,EAAMG,QAAO,CAAA;AACf,GAAA;AAEA,EAAA,MAAM,0BAA0B,0BAAA,CAA2B;AACzD,IAAA,KAAA;AACA,IAAA,SAAA;IACA,OAAA,EAAS,oBAAA;AACT,IAAA,QAAA,EAAU,EAAE,UAAA;AACb,GAAA,CAAA;AAED,EAAA,MAAM,MAAA,GAAS,UAAU,SAAS,CAAA;AAElC,EAAA,OAAO,UAAA,CAAW;IAChB,IAAA,EAAM,UAAA;AACN,IAAA,UAAA,EAAY,yBAAA,CAA0B;AACpC,MAAA,SAAA;MACA,UAAA,EAAY;AACV,QAAA,GAAG,qBAAA,CAAsB,EAAE,WAAA,EAAa,UAAA,EAAY,WAAW,CAAA;QAC/D,GAAG,uBAAA;AACH,QAAA,UAAA,EAAY,EAAE,KAAA,EAAO,MAAM,IAAA,CAAK,SAAA,CAAU,KAAK,CAAA;AACjD;AACD,KAAA,CAAA;AACD,IAAA,MAAA;AACA,IAAA,EAAA,EAAI,OAAM,IAAA,KAAQ;AAChB,MAAA,MAAM,EAAE,SAAA,EAAW,KAAA,EAAO,QAAA,EAAU,gBAAA,KAAqB,MAAM,KAAA;AAAM,QAAA;;UAEnE,UAAA,CAAW;YACT,IAAA,EAAM,kBAAA;AACN,YAAA,UAAA,EAAY,yBAAA,CAA0B;AACpC,cAAA,SAAA;cACA,UAAA,EAAY;AACV,gBAAA,GAAG,qBAAA,CAAsB;kBACvB,WAAA,EAAa,kBAAA;AACb,kBAAA;AACD,iBAAA,CAAA;gBACD,GAAG,uBAAA;;gBAEH,WAAA,EAAa,EAAE,OAAO,MAAM,CAAC,KAAK,SAAA,CAAU,KAAK,CAAC,CAAA;AACpD;AACD,aAAA,CAAA;AACD,YAAA,MAAA;AACA,YAAA,EAAA,EAAI,OAAM,WAAA,KAAe;AA5HnC,cAAA,IAAAlB,IAAAA;AA6HY,cAAA,MAAM,aAAA,GAAgB,MAAM,KAAA,CAAM,OAAA,CAAQ;AACxC,gBAAA,MAAA,EAAQ,CAAC,KAAK,CAAA;AACd,gBAAA,WAAA;gBACA,OAAA,EAAS,oBAAA;AACT,gBAAA;AACD,eAAA,CAAA;AAED,cAAA,MAAMmD,UAAAA,GAAY,aAAA,CAAc,UAAA,CAAW,CAAC,CAAA;AAC5C,cAAA,MAAMC,MAAAA,GAAAA,CAAQpD,OAAA,aAAA,CAAc,KAAA,KAAd,OAAAA,IAAAA,GAAuB,EAAE,QAAQ,GAAA,EAAA;AAE/C,cAAA,WAAA,CAAY,aAAA;gBACV,yBAAA,CAA0B;AACxB,kBAAA,SAAA;kBACA,UAAA,EAAY;oBACV,eAAA,EAAiB;sBACf,MAAA,EAAQ,MACN,cAAc,UAAA,CAAW,GAAA;wBAAI,CAAAmD,UAAAA,KAC3B,IAAA,CAAK,SAAA,CAAUA,UAAS;AAC1B;AACJ,qBAAA;AACA,oBAAA,iBAAA,EAAmBC,MAAAA,CAAM;AAC3B;AACD,iBAAA;AACH,eAAA;AAEA,cAAA,OAAO;gBACL,SAAA,EAAAD,UAAAA;gBACA,KAAA,EAAAC,MAAAA;AACA,gBAAA,gBAAA,EAAkB,aAAA,CAAc,gBAAA;AAChC,gBAAA,QAAA,EAAU,aAAA,CAAc;AAC1B,eAAA;AACF,YAAA;AACD,WAAA;;AACH,OAAA;AAEA,MAAA,IAAA,CAAK,aAAA;QACH,yBAAA,CAA0B;AACxB,UAAA,SAAA;UACA,UAAA,EAAY;AACV,YAAA,cAAA,EAAgB,EAAE,MAAA,EAAQ,MAAM,IAAA,CAAK,SAAA,CAAU,SAAS,CAAA,EAAA;AACxD,YAAA,iBAAA,EAAmB,KAAA,CAAM;AAC3B;AACD,SAAA;AACH,OAAA;AAEA,MAAA,OAAO,IAAI,kBAAA,CAAmB;AAC5B,QAAA,KAAA;AACA,QAAA,SAAA;AACA,QAAA,KAAA;AACA,QAAA,gBAAA;AACA,QAAA;AACD,OAAA,CAAA;AACH,IAAA;AACD,GAAA,CAAA;AACH;AAEA,IAAM,qBAAN,MAA8D;AAO5D,EAAA,WAAA,CAAY,OAAA,EAMT;AACD,IAAA,IAAA,CAAK,QAAQ,OAAA,CAAQ,KAAA;AACrB,IAAA,IAAA,CAAK,YAAY,OAAA,CAAQ,SAAA;AACzB,IAAA,IAAA,CAAK,QAAQ,OAAA,CAAQ,KAAA;AACrB,IAAA,IAAA,CAAK,mBAAmB,OAAA,CAAQ,gBAAA;AAChC,IAAA,IAAA,CAAK,WAAW,OAAA,CAAQ,QAAA;AAC1B,EAAA;AACF,CAAA;AC5J2BJ,mCAAAA,CAAkB,EAAE,QAAQ,OAAA,EAAS,IAAA,EAAM,IAAI;ACtCnE,SAAS,eAAA,CAAgB,MAAW,IAAA,EAAoB;AAE7D,EAAA,IAAI,IAAA,KAAS,IAAA;AAAM,IAAA,OAAO,IAAA;AAG1B,EAAA,IAAI,IAAA,IAAQ,QAAQ,IAAA,IAAQ,IAAA;AAAM,IAAA,OAAO,KAAA;AAGzC,EAAA,IAAI,OAAO,IAAA,KAAS,QAAA,IAAY,OAAO,IAAA,KAAS,QAAA;AAC9C,IAAA,OAAO,IAAA,KAAS,IAAA;AAGlB,EAAA,IAAI,IAAA,CAAK,gBAAgB,IAAA,CAAK,WAAA;AAAa,IAAA,OAAO,KAAA;AAGlD,EAAA,IAAI,IAAA,YAAgB,IAAA,IAAQ,IAAA,YAAgB,IAAA,EAAM;AAChD,IAAA,OAAO,IAAA,CAAK,OAAA,EAAA,KAAc,IAAA,CAAK,OAAA,EAAA;AACjC,EAAA;AAGA,EAAA,IAAI,KAAA,CAAM,OAAA,CAAQ,IAAI,CAAA,EAAG;AACvB,IAAA,IAAI,IAAA,CAAK,WAAW,IAAA,CAAK,MAAA;AAAQ,MAAA,OAAO,KAAA;AACxC,IAAA,KAAA,IAAS,CAAA,GAAI,CAAA,EAAG,CAAA,GAAI,IAAA,CAAK,QAAQ,CAAA,EAAA,EAAK;AACpC,MAAA,IAAI,CAAC,eAAA,CAAgB,IAAA,CAAK,CAAC,CAAA,EAAG,IAAA,CAAK,CAAC,CAAC,CAAA;AAAG,QAAA,OAAO,KAAA;AACjD,IAAA;AACA,IAAA,OAAO,IAAA;AACT,EAAA;AAGA,EAAA,MAAM,KAAA,GAAQ,MAAA,CAAO,IAAA,CAAK,IAAI,CAAA;AAC9B,EAAA,MAAM,KAAA,GAAQ,MAAA,CAAO,IAAA,CAAK,IAAI,CAAA;AAC9B,EAAA,IAAI,KAAA,CAAM,WAAW,KAAA,CAAM,MAAA;AAAQ,IAAA,OAAO,KAAA;AAG1C,EAAA,KAAA,MAAW,OAAO,KAAA,EAAO;AACvB,IAAA,IAAI,CAAC,KAAA,CAAM,QAAA,CAAS,GAAG,CAAA;AAAG,MAAA,OAAO,KAAA;AACjC,IAAA,IAAI,CAAC,eAAA,CAAgB,IAAA,CAAK,GAAG,CAAA,EAAG,IAAA,CAAK,GAAG,CAAC,CAAA;AAAG,MAAA,OAAO,KAAA;AACrD,EAAA;AAEA,EAAA,OAAO,IAAA;AACT;ACU2BA,mCAAAA,CAAkB,EAAE,QAAQ,OAAA,EAAS,IAAA,EAAM,IAAI;AC1CnE,IAAM,yBAAA,GAAN,cACG,oBAAA,CAEV;EAGE,WAAA,CAAY;AACV,IAAA,IAAA;AACA,IAAA;AAIC,GAAA,EAAA;AACD,IAAA,KAAA,CAAM,EAAE,IAAA,EAAM,SAAA,EAAW,CAAA;AACzB,IAAA,IAAI,MAAA,GAAS,KAAA;AAGb,IAAA,IAAI,SAAA,EAAW;AACb,MAAA,MAAM,cAAA,GAAiB,SAAA,CAAU,KAAA,CAAM,GAAG,CAAA;AAE1C,MAAA,IAAI,cAAA,CAAe,WAAW,CAAA,EAAG;AAE/B,QAAA,IAAI,cAAc,YAAA,EAAc;AAC9B,UAAA,MAAA,GAAS,eAAe,CAAC,CAAA;AAC3B,QAAA;AACF,MAAA;AACF,IAAA;AAEA,IAAA,IAAI,CAAC,MAAA,EAAQ;AAEX,MAAA,MAAM,IAAI,KAAA;AACR,QAAA;AACF,OAAA;AACF,IAAA;AAEA,IAAA,IAAA,CAAK,MAAA,GAAS,MAAA;AAChB,EAAA;AACF,CAAA;ACjBA,eAAsB,cAAA,CAAe;AACnC,EAAA,KAAA;EACA,IAAA,EAAAT,KAAAA;AACA,EAAA,KAAA;AACA,EAAA,YAAA;AACA,EAAA,YAAA;AACA,EAAA,KAAA;AACA,EAAA,QAAA;AACA,EAAA,eAAA,GAAkB,EAAA;EAClB,UAAA,EAAY,aAAA;AACZ,EAAA,WAAA;AACA,EAAA;AACF,CAAA,EAoE0B;AAnH1B,EAAA,IAAAvC,IAAAA;AAoHE,EAAA,IAAI,KAAA,CAAM,yBAAyB,IAAA,EAAM;AACvC,IAAA,MAAM,IAAI,4BAAA,CAA6B;AACrC,MAAA,OAAA,EAAS,KAAA,CAAM,oBAAA;AACf,MAAA,QAAA,EAAU,KAAA,CAAM,QAAA;AAChB,MAAA,OAAA,EAAS,KAAA,CAAM;AAChB,KAAA,CAAA;AACH,EAAA;AAEA,EAAA,MAAM,oBAAA,GAAuBe,qCAAAA;IAC3B,OAAA,IAAA,IAAA,GAAA,UAAW,EAAA;AACX,IAAA,CAAA,GAAA,EAAMG,QAAO,CAAA;AACf,GAAA;AAEA,EAAA,MAAM,EAAE,KAAA,EAAA,GAAU,cAAA,CAAe;IAC/B,UAAA,EAAY,aAAA;AACZ,IAAA;AACD,GAAA,CAAA;AAED,EAAA,MAAM,SAAS,MAAM,KAAA;AAAM,IAAA,MACzB,MAAM,UAAA,CAAW;MACf,IAAA,EAAAqB,KAAAA;AACA,MAAA,KAAA;AACA,MAAA,YAAA;AACA,MAAA,YAAA;AACA,MAAA,KAAA;AACA,MAAA,QAAA;AACA,MAAA,WAAA;MACA,OAAA,EAAS,oBAAA;AACT,MAAA;AACD,KAAA;AACH,GAAA;AAEA,EAAA,IAAI,CAAC,MAAA,CAAO,KAAA,IAAS,MAAA,CAAO,KAAA,CAAM,WAAW,CAAA,EAAG;AAC9C,IAAA,MAAM,IAAI,uBAAuB,EAAE,SAAA,EAAW,CAAC,MAAA,CAAO,QAAQ,GAAG,CAAA;AACnE,EAAA;AAEA,EAAA,WAAA,CAAY,OAAO,QAAQ,CAAA;AAE3B,EAAA,OAAO,IAAI,mBAAA,CAAoB;AAC7B,IAAA,KAAA,EAAO,IAAI,yBAAA,CAA0B;AACnC,MAAA,IAAA,EAAM,MAAA,CAAO,KAAA;AACb,MAAA,SAAA,EAAA,CACEvC,OAAA,eAAA,CAAgB;AACd,QAAA,IAAA,EAAM,MAAA,CAAO,KAAA;QACb,UAAA,EAAY;AACb,OAAA,CAAA,KAHD,OAAAA,IAAAA,GAGM;AACT,KAAA,CAAA;AACD,IAAA,QAAA,EAAU,MAAA,CAAO,QAAA;IACjB,SAAA,EAAW,CAAC,OAAO,QAAQ,CAAA;AAC3B,IAAA,gBAAA,EAAkB,MAAA,CAAO;AAC1B,GAAA,CAAA;AACH;AAEA,IAAM,sBAAN,MAAkD;AAMhD,EAAA,WAAA,CAAY,OAAA,EAKT;AApLL,IAAA,IAAAA,IAAAA;AAqLI,IAAA,IAAA,CAAK,QAAQ,OAAA,CAAQ,KAAA;AACrB,IAAA,IAAA,CAAK,WAAW,OAAA,CAAQ,QAAA;AACxB,IAAA,IAAA,CAAK,YAAY,OAAA,CAAQ,SAAA;AACzB,IAAA,IAAA,CAAK,oBAAmBA,IAAAA,GAAA,OAAA,CAAQ,gBAAA,KAAR,IAAA,GAAAA,OAA4B,EAAA;AACtD,EAAA;AACF,CAAA;AC1LA,IAAA,iBAAA,EAAA;AAAA,QAAA,CAAA,cAAA,EAAA;AAAA,EAAA,MAAA,EAAA,MAAA,MAAA;AAAA,EAAA,IAAA,EAAA,MAAA;AAAA,CAAA,CAAA;AAiCO,IAAM,OAAO,OAA+B;EACjD,IAAA,EAAM,MAAA;EAEN,cAAA,EAAgB,EAAE,MAAM,MAAA,EAAA;AAExB,EAAA,MAAM,YAAA,CAAa,EAAE,IAAA,EAAAuC,KAAAA,EAAAA,EAA0B;AAC7C,IAAA,OAAO,EAAE,SAASA,KAAAA,EAAAA;AACpB,EAAA,CAAA;AAEA,EAAA,MAAM,WAAA,CAAY,EAAE,IAAA,EAAAA,KAAAA,EAAAA,EAA0B;AAC5C,IAAA,OAAOA,KAAAA;AACT,EAAA;AACF,CAAA,CAAA;AAEO,IAAM,SAAS,CAAS;EAC7B,MAAA,EAAQ;AACV,CAAA,KAE2C;AACzC,EAAA,MAAM,MAAA,GAASc,2BAAS,WAAW,CAAA;AAEnC,EAAA,OAAO;IACL,IAAA,EAAM,QAAA;IAEN,cAAA,EAAgB;MACd,IAAA,EAAM,MAAA;AACN,MAAA,MAAA,EAAQ,MAAA,CAAO;AACjB,KAAA;AAEA,IAAA,MAAM,YAAA,CAAa,EAAE,IAAA,EAAAd,KAAAA,EAAAA,EAA0B;AAC7C,MAAA,MAAM,MAAA,GAAS,MAAM,gBAAA,CAAiBA,KAAI,CAAA;AAE1C,MAAA,QAAQ,OAAO,KAAA;QACb,KAAK,cAAA;QACL,KAAK,iBAAA;AACH,UAAA,OAAO,MAAA;QAET,KAAK,gBAAA;QACL,KAAK,kBAAA;AACH,UAAA,OAAO;;AAEL,YAAA,OAAA,EAAS,MAAA,CAAO;AAClB,WAAA;QAEF,SAAS;AACP,UAAA,MAAM,mBAA0B,MAAA,CAAO,KAAA;AACvC,UAAA,MAAM,IAAI,KAAA,CAAM,CAAA,yBAAA,EAA4B,gBAAgB,CAAA,CAAE,CAAA;AAChE,QAAA;AACF;AACF,IAAA,CAAA;AAEA,IAAA,MAAM,WAAA,CACJ,EAAE,IAAA,EAAAA,KAAAA,IACF,OAAA,EAKA;AACA,MAAA,MAAM,cAAc,MAAMU,+BAAAA,CAAc,EAAE,IAAA,EAAAV,OAAM,CAAA;AAEhD,MAAA,IAAI,CAAC,YAAY,OAAA,EAAS;AACxB,QAAA,MAAM,IAAI,sBAAA,CAAuB;UAC/B,OAAA,EAAS,oDAAA;AACT,UAAA,KAAA,EAAO,WAAA,CAAY,KAAA;UACnB,IAAA,EAAAA,KAAAA;AACA,UAAA,QAAA,EAAU,OAAA,CAAQ,QAAA;AAClB,UAAA,KAAA,EAAO,OAAA,CAAQ,KAAA;AACf,UAAA,YAAA,EAAc,OAAA,CAAQ;AACvB,SAAA,CAAA;AACH,MAAA;AAEA,MAAA,MAAM,gBAAA,GAAmB,MAAMlC,mCAAAA,CAAkB;AAC/C,QAAA,KAAA,EAAO,WAAA,CAAY,KAAA;AACnB,QAAA;AACD,OAAA,CAAA;AAED,MAAA,IAAI,CAAC,iBAAiB,OAAA,EAAS;AAC7B,QAAA,MAAM,IAAI,sBAAA,CAAuB;UAC/B,OAAA,EAAS,qDAAA;AACT,UAAA,KAAA,EAAO,gBAAA,CAAiB,KAAA;UACxB,IAAA,EAAAkC,KAAAA;AACA,UAAA,QAAA,EAAU,OAAA,CAAQ,QAAA;AAClB,UAAA,KAAA,EAAO,OAAA,CAAQ,KAAA;AACf,UAAA,YAAA,EAAc,OAAA,CAAQ;AACvB,SAAA,CAAA;AACH,MAAA;AAEA,MAAA,OAAO,gBAAA,CAAiB,KAAA;AAC1B,IAAA;AACF,GAAA;AACF,CAAA;ACtHO,IAAM,0BAAA,GAAN,cAAyCD,4BAAAA,CAAW;AAGzD,EAAA,WAAA,CAAY,OAAA,EAET;AACD,IAAA,KAAA,CAAM;MACJ,IAAA,EAAM,+BAAA;MACN,OAAA,EAAS;AACV,KAAA,CAAA;AAED,IAAA,IAAA,CAAK,YAAY,OAAA,CAAQ,SAAA;AAC3B,EAAA;AACF,CAAA;ACWA,eAAsB,UAAA,CAAW;AAC/B,EAAA,KAAA;AACA,EAAA,KAAA;AACA,EAAA,eAAA,GAAkB,EAAA;EAClB,UAAA,EAAY,aAAA;AACZ,EAAA,WAAA;AACA,EAAA;AACF,CAAA,EA4CiC;AAC/B,EAAA,IAAI,KAAA,CAAM,yBAAyB,IAAA,EAAM;AACvC,IAAA,MAAM,IAAI,4BAAA,CAA6B;AACrC,MAAA,OAAA,EAAS,KAAA,CAAM,oBAAA;AACf,MAAA,QAAA,EAAU,KAAA,CAAM,QAAA;AAChB,MAAA,OAAA,EAAS,KAAA,CAAM;AAChB,KAAA,CAAA;AACH,EAAA;AAEA,EAAA,MAAM,EAAE,KAAA,EAAA,GAAU,cAAA,CAAe;IAC/B,UAAA,EAAY,aAAA;AACZ,IAAA;AACD,GAAA,CAAA;AAED,EAAA,MAAM,oBAAA,GAAuBvB,qCAAAA;IAC3B,OAAA,IAAA,IAAA,GAAA,UAAW,EAAA;AACX,IAAA,CAAA,GAAA,EAAMG,QAAO,CAAA;AACf,GAAA;AAEA,EAAA,MAAM,SAAA,GACJ,KAAA,YAAiB,GAAA,GAAA,CACZ,MAAM,QAAA,CAAS,EAAE,GAAA,EAAK,KAAA,EAAO,CAAA,EAAG,IAAA,GACjC,8BAAA,CAA+B,KAAK,CAAA;AAE1C,EAAA,MAAM,SAAS,MAAM,KAAA;IAAM,MAAG;AAzGhC,MAAA,IAAAlB,IAAAA;AA0GI,MAAA,OAAA,MAAM,UAAA,CAAW;QACf,KAAA,EAAO,SAAA;AACP,QAAA,WAAA;QACA,OAAA,EAAS,oBAAA;AACT,QAAA,eAAA;AACA,QAAA,SAAA,EAAA,CACEA,OAAA,eAAA,CAAgB;UACd,IAAA,EAAM,SAAA;UACN,UAAA,EAAY;AACb,SAAA,CAAA,KAHD,OAAAA,IAAAA,GAGM;AACT,OAAA,CAAA;AAAA,IAAA;AACH,GAAA;AAEA,EAAA,WAAA,CAAY,OAAO,QAAQ,CAAA;AAE3B,EAAA,IAAI,CAAC,OAAO,IAAA,EAAM;AAChB,IAAA,MAAM,IAAI,2BAA2B,EAAE,SAAA,EAAW,CAAC,MAAA,CAAO,QAAQ,GAAG,CAAA;AACvE,EAAA;AAEA,EAAA,OAAO,IAAI,0BAAA,CAA2B;AACpC,IAAA,IAAA,EAAM,MAAA,CAAO,IAAA;AACb,IAAA,QAAA,EAAU,MAAA,CAAO,QAAA;AACjB,IAAA,QAAA,EAAU,MAAA,CAAO,QAAA;AACjB,IAAA,iBAAA,EAAmB,MAAA,CAAO,iBAAA;AAC1B,IAAA,QAAA,EAAU,MAAA,CAAO,QAAA;IACjB,SAAA,EAAW,CAAC,OAAO,QAAQ,CAAA;AAC3B,IAAA,gBAAA,EAAkB,MAAA,CAAO;AAC1B,GAAA,CAAA;AACH;AAEA,IAAM,6BAAN,MAAgE;AAa9D,EAAA,WAAA,CAAY,OAAA,EAYT;AAjKL,IAAA,IAAAA,IAAAA;AAkKI,IAAA,IAAA,CAAK,OAAO,OAAA,CAAQ,IAAA;AACpB,IAAA,IAAA,CAAK,WAAW,OAAA,CAAQ,QAAA;AACxB,IAAA,IAAA,CAAK,WAAW,OAAA,CAAQ,QAAA;AACxB,IAAA,IAAA,CAAK,oBAAoB,OAAA,CAAQ,iBAAA;AACjC,IAAA,IAAA,CAAK,WAAW,OAAA,CAAQ,QAAA;AACxB,IAAA,IAAA,CAAK,YAAY,OAAA,CAAQ,SAAA;AACzB,IAAA,IAAA,CAAK,oBAAmBA,IAAAA,GAAA,OAAA,CAAQ,gBAAA,KAAR,IAAA,GAAAA,OAA4B,EAAA;AACtD,EAAA;AACF,CAAA;ACtJyBE,+BAAAA;EAAc,MACrCC,2BAAAA;IACEC,IAAAA,CACG,KAAA;AACCA,MAAAA,IAAAA,CAAE,MAAA,CAAO;AACP,QAAA,EAAA,EAAIA,KAAE,MAAA,EAAA;AACN,QAAA,IAAA,EAAMA,KAAE,IAAA,CAAK,CAAC,QAAA,EAAU,MAAA,EAAQ,WAAW,CAAC,CAAA;QAC5C,QAAA,EAAUA,IAAAA,CAAE,OAAA,EAAA,CAAU,QAAA,EAAA;AACtB,QAAA,KAAA,EAAOA,IAAAA,CACJ,KAAA;AACCA,UAAAA,IAAAA,CAAE,KAAA,CAAM;AACNA,YAAAA,IAAAA,CAAE,MAAA,CAAO;cACP,IAAA,EAAMA,IAAAA,CAAE,QAAQ,MAAM,CAAA;AACtB,cAAA,IAAA,EAAMA,KAAE,MAAA,EAAA;AACR,cAAA,KAAA,EAAOA,KAAE,IAAA,CAAK,CAAC,aAAa,MAAM,CAAC,EAAE,QAAA,EAAA;AACrC,cAAA,gBAAA,EAAkB,uBAAuB,QAAA;AAC1C,aAAA,CAAA;AACDA,YAAAA,IAAAA,CAAE,MAAA,CAAO;cACP,IAAA,EAAMA,IAAAA,CAAE,QAAQ,WAAW,CAAA;AAC3B,cAAA,IAAA,EAAMA,KAAE,MAAA,EAAA;AACR,cAAA,KAAA,EAAOA,KAAE,IAAA,CAAK,CAAC,aAAa,MAAM,CAAC,EAAE,QAAA,EAAA;AACrC,cAAA,gBAAA,EAAkB,uBAAuB,QAAA;AAC1C,aAAA,CAAA;AACDA,YAAAA,IAAAA,CAAE,MAAA,CAAO;cACP,IAAA,EAAMA,IAAAA,CAAE,QAAQ,YAAY,CAAA;AAC5B,cAAA,QAAA,EAAUA,KAAE,MAAA,EAAA;AACZ,cAAA,GAAA,EAAKA,KAAE,MAAA,EAAA;cACP,KAAA,EAAOA,IAAAA,CAAE,MAAA,EAAA,CAAS,QAAA,EAAA;AAClB,cAAA,gBAAA,EAAkB,uBAAuB,QAAA;AAC1C,aAAA,CAAA;AACDA,YAAAA,IAAAA,CAAE,MAAA,CAAO;cACP,IAAA,EAAMA,IAAAA,CAAE,QAAQ,iBAAiB,CAAA;AACjC,cAAA,QAAA,EAAUA,KAAE,MAAA,EAAA;AACZ,cAAA,SAAA,EAAWA,KAAE,MAAA,EAAA;AACb,cAAA,KAAA,EAAOA,KAAE,MAAA,EAAA;cACT,QAAA,EAAUA,IAAAA,CAAE,MAAA,EAAA,CAAS,QAAA,EAAA;AACrB,cAAA,gBAAA,EAAkB,uBAAuB,QAAA;AAC1C,aAAA,CAAA;AACDA,YAAAA,IAAAA,CAAE,MAAA,CAAO;cACP,IAAA,EAAMA,IAAAA,CAAE,QAAQ,MAAM,CAAA;AACtB,cAAA,SAAA,EAAWA,KAAE,MAAA,EAAA;cACb,QAAA,EAAUA,IAAAA,CAAE,MAAA,EAAA,CAAS,QAAA,EAAA;AACrB,cAAA,GAAA,EAAKA,KAAE,MAAA,EAAA;AACP,cAAA,gBAAA,EAAkB,uBAAuB,QAAA;AAC1C,aAAA,CAAA;AACDA,YAAAA,IAAAA,CAAE,MAAA,CAAO;cACP,IAAA,EAAMA,IAAAA,CAAE,QAAQ,YAAY;AAC7B,aAAA,CAAA;AACDA,YAAAA,IAAAA,CAAE,MAAA,CAAO;AACP,cAAA,IAAA,EAAMA,IAAAA,CAAE,MAAA,EAAA,CAAS,UAAA,CAAW,OAAO,CAAA;cACnC,EAAA,EAAIA,IAAAA,CAAE,MAAA,EAAA,CAAS,QAAA,EAAA;AACf,cAAA,IAAA,EAAMA,KAAE,OAAA;AACT,aAAA,CAAA;AACDA,YAAAA,IAAAA,CAAE,MAAA,CAAO;cACP,IAAA,EAAMA,IAAAA,CAAE,QAAQ,cAAc,CAAA;AAC9B,cAAA,QAAA,EAAUA,KAAE,MAAA,EAAA;AACZ,cAAA,UAAA,EAAYA,KAAE,MAAA,EAAA;cACd,KAAA,EAAOA,IAAAA,CAAE,QAAQ,iBAAiB,CAAA;cAClC,KAAA,EAAOA,IAAAA,CAAE,OAAA,EAAA,CAAU,QAAA,EAAA;cACnB,gBAAA,EAAkBA,IAAAA,CAAE,OAAA,EAAA,CAAU,QAAA,EAAA;cAC9B,MAAA,EAAQA,IAAAA,CAAE,KAAA,EAAA,CAAQ,QAAA,EAAA;cAClB,SAAA,EAAWA,IAAAA,CAAE,KAAA,EAAA,CAAQ,QAAA;AACtB,aAAA,CAAA;AACDA,YAAAA,IAAAA,CAAE,MAAA,CAAO;cACP,IAAA,EAAMA,IAAAA,CAAE,QAAQ,cAAc,CAAA;AAC9B,cAAA,QAAA,EAAUA,KAAE,MAAA,EAAA;AACZ,cAAA,UAAA,EAAYA,KAAE,MAAA,EAAA;cACd,KAAA,EAAOA,IAAAA,CAAE,QAAQ,iBAAiB,CAAA;AAClC,cAAA,KAAA,EAAOA,KAAE,OAAA,EAAA;cACT,gBAAA,EAAkBA,IAAAA,CAAE,OAAA,EAAA,CAAU,QAAA,EAAA;cAC9B,MAAA,EAAQA,IAAAA,CAAE,KAAA,EAAA,CAAQ,QAAA,EAAA;cAClB,SAAA,EAAWA,IAAAA,CAAE,KAAA,EAAA,CAAQ,QAAA,EAAA;AACrB,cAAA,oBAAA,EAAsB,uBAAuB,QAAA;AAC9C,aAAA,CAAA;AACDA,YAAAA,IAAAA,CAAE,MAAA,CAAO;cACP,IAAA,EAAMA,IAAAA,CAAE,QAAQ,cAAc,CAAA;AAC9B,cAAA,QAAA,EAAUA,KAAE,MAAA,EAAA;AACZ,cAAA,UAAA,EAAYA,KAAE,MAAA,EAAA;cACd,KAAA,EAAOA,IAAAA,CAAE,QAAQ,kBAAkB,CAAA;AACnC,cAAA,KAAA,EAAOA,KAAE,OAAA,EAAA;cACT,gBAAA,EAAkBA,IAAAA,CAAE,OAAA,EAAA,CAAU,QAAA,EAAA;AAC9B,cAAA,MAAA,EAAQA,KAAE,OAAA,EAAA;cACV,SAAA,EAAWA,IAAAA,CAAE,KAAA,EAAA,CAAQ,QAAA,EAAA;AACrB,cAAA,oBAAA,EAAsB,uBAAuB,QAAA,EAAA;cAC7C,WAAA,EAAaA,IAAAA,CAAE,OAAA,EAAA,CAAU,QAAA;AAC1B,aAAA,CAAA;AACDA,YAAAA,IAAAA,CAAE,MAAA,CAAO;cACP,IAAA,EAAMA,IAAAA,CAAE,QAAQ,cAAc,CAAA;AAC9B,cAAA,QAAA,EAAUA,KAAE,MAAA,EAAA;AACZ,cAAA,UAAA,EAAYA,KAAE,MAAA,EAAA;cACd,KAAA,EAAOA,IAAAA,CAAE,QAAQ,cAAc,CAAA;AAC/B,cAAA,KAAA,EAAOA,KAAE,OAAA,EAAA;cACT,gBAAA,EAAkBA,IAAAA,CAAE,OAAA,EAAA,CAAU,QAAA,EAAA;cAC9B,MAAA,EAAQA,IAAAA,CAAE,KAAA,EAAA,CAAQ,QAAA,EAAA;AAClB,cAAA,SAAA,EAAWA,KAAE,MAAA,EAAA;AACb,cAAA,oBAAA,EAAsB,uBAAuB,QAAA;AAC9C,aAAA,CAAA;AACDA,YAAAA,IAAAA,CAAE,MAAA,CAAO;AACP,cAAA,IAAA,EAAMA,IAAAA,CAAE,MAAA,EAAA,CAAS,UAAA,CAAW,OAAO,CAAA;AACnC,cAAA,UAAA,EAAYA,KAAE,MAAA,EAAA;cACd,KAAA,EAAOA,IAAAA,CAAE,QAAQ,iBAAiB,CAAA;cAClC,gBAAA,EAAkBA,IAAAA,CAAE,OAAA,EAAA,CAAU,QAAA,EAAA;cAC9B,KAAA,EAAOA,IAAAA,CAAE,OAAA,EAAA,CAAU,QAAA,EAAA;cACnB,MAAA,EAAQA,IAAAA,CAAE,KAAA,EAAA,CAAQ,QAAA,EAAA;cAClB,SAAA,EAAWA,IAAAA,CAAE,KAAA,EAAA,CAAQ,QAAA,EAAA;cACrB,QAAA,EAAUA,IAAAA,CAAE,KAAA,EAAA,CAAQ,QAAA;AACrB,aAAA,CAAA;AACDA,YAAAA,IAAAA,CAAE,MAAA,CAAO;AACP,cAAA,IAAA,EAAMA,IAAAA,CAAE,MAAA,EAAA,CAAS,UAAA,CAAW,OAAO,CAAA;AACnC,cAAA,UAAA,EAAYA,KAAE,MAAA,EAAA;cACd,KAAA,EAAOA,IAAAA,CAAE,QAAQ,iBAAiB,CAAA;cAClC,gBAAA,EAAkBA,IAAAA,CAAE,OAAA,EAAA,CAAU,QAAA,EAAA;AAC9B,cAAA,KAAA,EAAOA,KAAE,OAAA,EAAA;cACT,MAAA,EAAQA,IAAAA,CAAE,KAAA,EAAA,CAAQ,QAAA,EAAA;cAClB,SAAA,EAAWA,IAAAA,CAAE,KAAA,EAAA,CAAQ,QAAA,EAAA;AACrB,cAAA,oBAAA,EAAsB,uBAAuB,QAAA,EAAA;cAC7C,QAAA,EAAUA,IAAAA,CAAE,KAAA,EAAA,CAAQ,QAAA;AACrB,aAAA,CAAA;AACDA,YAAAA,IAAAA,CAAE,MAAA,CAAO;AACP,cAAA,IAAA,EAAMA,IAAAA,CAAE,MAAA,EAAA,CAAS,UAAA,CAAW,OAAO,CAAA;AACnC,cAAA,UAAA,EAAYA,KAAE,MAAA,EAAA;cACd,KAAA,EAAOA,IAAAA,CAAE,QAAQ,oBAAoB,CAAA;AACrC,cAAA,KAAA,EAAOA,KAAE,OAAA,EAAA;cACT,gBAAA,EAAkBA,IAAAA,CAAE,OAAA,EAAA,CAAU,QAAA,EAAA;cAC9B,MAAA,EAAQA,IAAAA,CAAE,KAAA,EAAA,CAAQ,QAAA,EAAA;cAClB,SAAA,EAAWA,IAAAA,CAAE,KAAA,EAAA,CAAQ,QAAA,EAAA;AACrB,cAAA,oBAAA,EAAsB,uBAAuB,QAAA,EAAA;AAC7C,cAAA,QAAA,EAAUA,KAAE,MAAA,CAAO;AACjB,gBAAA,EAAA,EAAIA,KAAE,MAAA,EAAA;gBACN,QAAA,EAAUA,IAAAA,CAAE,KAAA,EAAA,CAAQ,QAAA,EAAA;gBACpB,MAAA,EAAQA,IAAAA,CAAE,KAAA,EAAA,CAAQ,QAAA;AACnB,eAAA;AACF,aAAA,CAAA;AACDA,YAAAA,IAAAA,CAAE,MAAA,CAAO;AACP,cAAA,IAAA,EAAMA,IAAAA,CAAE,MAAA,EAAA,CAAS,UAAA,CAAW,OAAO,CAAA;AACnC,cAAA,UAAA,EAAYA,KAAE,MAAA,EAAA;cACd,KAAA,EAAOA,IAAAA,CAAE,QAAQ,oBAAoB,CAAA;AACrC,cAAA,KAAA,EAAOA,KAAE,OAAA,EAAA;cACT,gBAAA,EAAkBA,IAAAA,CAAE,OAAA,EAAA,CAAU,QAAA,EAAA;cAC9B,MAAA,EAAQA,IAAAA,CAAE,KAAA,EAAA,CAAQ,QAAA,EAAA;cAClB,SAAA,EAAWA,IAAAA,CAAE,KAAA,EAAA,CAAQ,QAAA,EAAA;AACrB,cAAA,oBAAA,EAAsB,uBAAuB,QAAA,EAAA;AAC7C,cAAA,QAAA,EAAUA,KAAE,MAAA,CAAO;AACjB,gBAAA,EAAA,EAAIA,KAAE,MAAA,EAAA;AACN,gBAAA,QAAA,EAAUA,KAAE,OAAA,EAAA;gBACZ,MAAA,EAAQA,IAAAA,CAAE,MAAA,EAAA,CAAS,QAAA;AACpB,eAAA;AACF,aAAA,CAAA;AACDA,YAAAA,IAAAA,CAAE,MAAA,CAAO;AACP,cAAA,IAAA,EAAMA,IAAAA,CAAE,MAAA,EAAA,CAAS,UAAA,CAAW,OAAO,CAAA;AACnC,cAAA,UAAA,EAAYA,KAAE,MAAA,EAAA;cACd,KAAA,EAAOA,IAAAA,CAAE,QAAQ,kBAAkB,CAAA;cACnC,gBAAA,EAAkBA,IAAAA,CAAE,OAAA,EAAA,CAAU,QAAA,EAAA;AAC9B,cAAA,KAAA,EAAOA,KAAE,OAAA,EAAA;AACT,cAAA,MAAA,EAAQA,KAAE,OAAA,EAAA;cACV,SAAA,EAAWA,IAAAA,CAAE,KAAA,EAAA,CAAQ,QAAA,EAAA;AACrB,cAAA,oBAAA,EAAsB,uBAAuB,QAAA,EAAA;cAC7C,WAAA,EAAaA,IAAAA,CAAE,OAAA,EAAA,CAAU,QAAA,EAAA;AACzB,cAAA,QAAA,EAAUA,KACP,MAAA,CAAO;AACN,gBAAA,EAAA,EAAIA,KAAE,MAAA,EAAA;gBACN,QAAA,EAAUA,IAAAA,CAAE,QAAQ,IAAI,CAAA;gBACxB,MAAA,EAAQA,IAAAA,CAAE,MAAA,EAAA,CAAS,QAAA;AACrB,eAAC,EACA,QAAA;AACJ,aAAA,CAAA;AACDA,YAAAA,IAAAA,CAAE,MAAA,CAAO;AACP,cAAA,IAAA,EAAMA,IAAAA,CAAE,MAAA,EAAA,CAAS,UAAA,CAAW,OAAO,CAAA;AACnC,cAAA,UAAA,EAAYA,KAAE,MAAA,EAAA;cACd,KAAA,EAAOA,IAAAA,CAAE,QAAQ,cAAc,CAAA;cAC/B,gBAAA,EAAkBA,IAAAA,CAAE,OAAA,EAAA,CAAU,QAAA,EAAA;AAC9B,cAAA,KAAA,EAAOA,KAAE,OAAA,EAAA;cACT,MAAA,EAAQA,IAAAA,CAAE,KAAA,EAAA,CAAQ,QAAA,EAAA;AAClB,cAAA,SAAA,EAAWA,KAAE,MAAA,EAAA;AACb,cAAA,oBAAA,EAAsB,uBAAuB,QAAA,EAAA;AAC7C,cAAA,QAAA,EAAUA,KACP,MAAA,CAAO;AACN,gBAAA,EAAA,EAAIA,KAAE,MAAA,EAAA;gBACN,QAAA,EAAUA,IAAAA,CAAE,QAAQ,IAAI,CAAA;gBACxB,MAAA,EAAQA,IAAAA,CAAE,MAAA,EAAA,CAAS,QAAA;AACrB,eAAC,EACA,QAAA;AACJ,aAAA,CAAA;AACDA,YAAAA,IAAAA,CAAE,MAAA,CAAO;AACP,cAAA,IAAA,EAAMA,IAAAA,CAAE,MAAA,EAAA,CAAS,UAAA,CAAW,OAAO,CAAA;AACnC,cAAA,UAAA,EAAYA,KAAE,MAAA,EAAA;cACd,KAAA,EAAOA,IAAAA,CAAE,QAAQ,eAAe,CAAA;cAChC,gBAAA,EAAkBA,IAAAA,CAAE,OAAA,EAAA,CAAU,QAAA,EAAA;AAC9B,cAAA,KAAA,EAAOA,KAAE,OAAA,EAAA;cACT,MAAA,EAAQA,IAAAA,CAAE,KAAA,EAAA,CAAQ,QAAA,EAAA;cAClB,SAAA,EAAWA,IAAAA,CAAE,KAAA,EAAA,CAAQ,QAAA,EAAA;AACrB,cAAA,oBAAA,EAAsB,uBAAuB,QAAA,EAAA;AAC7C,cAAA,QAAA,EAAUA,KAAE,MAAA,CAAO;AACjB,gBAAA,EAAA,EAAIA,KAAE,MAAA,EAAA;gBACN,QAAA,EAAUA,IAAAA,CAAE,QAAQ,KAAK,CAAA;gBACzB,MAAA,EAAQA,IAAAA,CAAE,MAAA,EAAA,CAAS,QAAA;AACpB,eAAA;AACF,aAAA;AACF,WAAA;AACH,SAAA,CACC,SAAS,wCAAwC;AACrD,OAAA;AACH,KAAA,CACC,SAAS,kCAAkC;AAChD;AACF","file":"chunk-CVLIEFWM.cjs","sourcesContent":["\"use strict\";\nvar __defProp = Object.defineProperty;\nvar __getOwnPropDesc = Object.getOwnPropertyDescriptor;\nvar __getOwnPropNames = Object.getOwnPropertyNames;\nvar __hasOwnProp = Object.prototype.hasOwnProperty;\nvar __export = (target, all) => {\n  for (var name in all)\n    __defProp(target, name, { get: all[name], enumerable: true });\n};\nvar __copyProps = (to, from, except, desc) => {\n  if (from && typeof from === \"object\" || typeof from === \"function\") {\n    for (let key of __getOwnPropNames(from))\n      if (!__hasOwnProp.call(to, key) && key !== except)\n        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });\n  }\n  return to;\n};\nvar __toCommonJS = (mod) => __copyProps(__defProp({}, \"__esModule\", { value: true }), mod);\nvar get_context_exports = {};\n__export(get_context_exports, {\n  SYMBOL_FOR_REQ_CONTEXT: () => SYMBOL_FOR_REQ_CONTEXT,\n  getContext: () => getContext\n});\nmodule.exports = __toCommonJS(get_context_exports);\nconst SYMBOL_FOR_REQ_CONTEXT = Symbol.for(\"@vercel/request-context\");\nfunction getContext() {\n  const fromSymbol = globalThis;\n  return fromSymbol[SYMBOL_FOR_REQ_CONTEXT]?.get?.() ?? {};\n}\n// Annotate the CommonJS export names for ESM import in node:\n0 && (module.exports = {\n  SYMBOL_FOR_REQ_CONTEXT,\n  getContext\n});\n","\"use strict\";\nvar __create = Object.create;\nvar __defProp = Object.defineProperty;\nvar __getOwnPropDesc = Object.getOwnPropertyDescriptor;\nvar __getOwnPropNames = Object.getOwnPropertyNames;\nvar __getProtoOf = Object.getPrototypeOf;\nvar __hasOwnProp = Object.prototype.hasOwnProperty;\nvar __export = (target, all) => {\n  for (var name in all)\n    __defProp(target, name, { get: all[name], enumerable: true });\n};\nvar __copyProps = (to, from, except, desc) => {\n  if (from && typeof from === \"object\" || typeof from === \"function\") {\n    for (let key of __getOwnPropNames(from))\n      if (!__hasOwnProp.call(to, key) && key !== except)\n        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });\n  }\n  return to;\n};\nvar __toESM = (mod, isNodeMode, target) => (target = mod != null ? __create(__getProtoOf(mod)) : {}, __copyProps(\n  // If the importer is in node compatibility mode or this is not an ESM\n  // file that has been converted to a CommonJS file using a Babel-\n  // compatible transform (i.e. \"__esModule\" has not been set), then set\n  // \"default\" to the CommonJS \"module.exports\" for node compatibility.\n  isNodeMode || !mod || !mod.__esModule ? __defProp(target, \"default\", { value: mod, enumerable: true }) : target,\n  mod\n));\nvar __toCommonJS = (mod) => __copyProps(__defProp({}, \"__esModule\", { value: true }), mod);\nvar get_vercel_oidc_token_exports = {};\n__export(get_vercel_oidc_token_exports, {\n  getVercelOidcToken: () => getVercelOidcToken,\n  getVercelOidcTokenSync: () => getVercelOidcTokenSync\n});\nmodule.exports = __toCommonJS(get_vercel_oidc_token_exports);\nvar import_get_context = require(\"./get-context\");\nvar import_token_error = require(\"./token-error\");\nasync function getVercelOidcToken() {\n  let token = \"\";\n  let err;\n  try {\n    token = getVercelOidcTokenSync();\n  } catch (error) {\n    err = error;\n  }\n  try {\n    const [{ getTokenPayload, isExpired }, { refreshToken }] = await Promise.all([\n      await import(\"./token-util.js\"),\n      await import(\"./token.js\")\n    ]);\n    if (!token || isExpired(getTokenPayload(token))) {\n      await refreshToken();\n      token = getVercelOidcTokenSync();\n    }\n  } catch (error) {\n    if (err?.message && error instanceof Error) {\n      error.message = `${err.message}\n${error.message}`;\n    }\n    throw new import_token_error.VercelOidcTokenError(`Failed to refresh OIDC token`, error);\n  }\n  return token;\n}\nfunction getVercelOidcTokenSync() {\n  const token = (0, import_get_context.getContext)().headers?.[\"x-vercel-oidc-token\"] ?? process.env.VERCEL_OIDC_TOKEN;\n  if (!token) {\n    throw new Error(\n      `The 'x-vercel-oidc-token' header is missing from the request. Do you have the OIDC option enabled in the Vercel project settings?`\n    );\n  }\n  return token;\n}\n// Annotate the CommonJS export names for ESM import in node:\n0 && (module.exports = {\n  getVercelOidcToken,\n  getVercelOidcTokenSync\n});\n","\"use strict\";\nvar __defProp = Object.defineProperty;\nvar __getOwnPropDesc = Object.getOwnPropertyDescriptor;\nvar __getOwnPropNames = Object.getOwnPropertyNames;\nvar __hasOwnProp = Object.prototype.hasOwnProperty;\nvar __export = (target, all) => {\n  for (var name in all)\n    __defProp(target, name, { get: all[name], enumerable: true });\n};\nvar __copyProps = (to, from, except, desc) => {\n  if (from && typeof from === \"object\" || typeof from === \"function\") {\n    for (let key of __getOwnPropNames(from))\n      if (!__hasOwnProp.call(to, key) && key !== except)\n        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });\n  }\n  return to;\n};\nvar __toCommonJS = (mod) => __copyProps(__defProp({}, \"__esModule\", { value: true }), mod);\nvar src_exports = {};\n__export(src_exports, {\n  getContext: () => import_get_context.getContext,\n  getVercelOidcToken: () => import_get_vercel_oidc_token.getVercelOidcToken,\n  getVercelOidcTokenSync: () => import_get_vercel_oidc_token.getVercelOidcTokenSync\n});\nmodule.exports = __toCommonJS(src_exports);\nvar import_get_vercel_oidc_token = require(\"./get-vercel-oidc-token\");\nvar import_get_context = require(\"./get-context\");\n// Annotate the CommonJS export names for ESM import in node:\n0 && (module.exports = {\n  getContext,\n  getVercelOidcToken,\n  getVercelOidcTokenSync\n});\n","import { getContext } from '@vercel/oidc';\nexport { getVercelOidcToken } from '@vercel/oidc';\n\nexport async function getVercelRequestId(): Promise<string | undefined> {\n  return getContext().headers?.['x-vercel-id'];\n}\n","const marker = 'vercel.ai.gateway.error';\nconst symbol = Symbol.for(marker);\n\nexport abstract class GatewayError extends Error {\n  private readonly [symbol] = true; // used in isInstance\n\n  abstract readonly name: string;\n  abstract readonly type: string;\n  readonly statusCode: number;\n  readonly cause?: unknown;\n\n  constructor({\n    message,\n    statusCode = 500,\n    cause,\n  }: {\n    message: string;\n    statusCode?: number;\n    cause?: unknown;\n  }) {\n    super(message);\n    this.statusCode = statusCode;\n    this.cause = cause;\n  }\n\n  /**\n   * Checks if the given error is a Gateway Error.\n   * @param {unknown} error - The error to check.\n   * @returns {boolean} True if the error is a Gateway Error, false otherwise.\n   */\n  static isInstance(error: unknown): error is GatewayError {\n    return GatewayError.hasMarker(error);\n  }\n\n  static hasMarker(error: unknown): error is GatewayError {\n    return (\n      typeof error === 'object' &&\n      error !== null &&\n      symbol in error &&\n      (error as any)[symbol] === true\n    );\n  }\n}\n","import { GatewayError } from './gateway-error';\n\nconst name = 'GatewayAuthenticationError';\nconst marker = `vercel.ai.gateway.error.${name}`;\nconst symbol = Symbol.for(marker);\n\n/**\n * Authentication failed - invalid API key or OIDC token\n */\nexport class GatewayAuthenticationError extends GatewayError {\n  private readonly [symbol] = true; // used in isInstance\n\n  readonly name = name;\n  readonly type = 'authentication_error';\n\n  constructor({\n    message = 'Authentication failed',\n    statusCode = 401,\n    cause,\n  }: {\n    message?: string;\n    statusCode?: number;\n    cause?: unknown;\n  } = {}) {\n    super({ message, statusCode, cause });\n  }\n\n  static isInstance(error: unknown): error is GatewayAuthenticationError {\n    return GatewayError.hasMarker(error) && symbol in error;\n  }\n\n  /**\n   * Creates a contextual error message when authentication fails\n   */\n  static createContextualError({\n    apiKeyProvided,\n    oidcTokenProvided,\n    message = 'Authentication failed',\n    statusCode = 401,\n    cause,\n  }: {\n    apiKeyProvided: boolean;\n    oidcTokenProvided: boolean;\n    message?: string;\n    statusCode?: number;\n    cause?: unknown;\n  }): GatewayAuthenticationError {\n    let contextualMessage: string;\n\n    if (apiKeyProvided) {\n      contextualMessage = `AI Gateway authentication failed: Invalid API key.\n\nCreate a new API key: https://vercel.com/d?to=%2F%5Bteam%5D%2F%7E%2Fai%2Fapi-keys\n\nProvide via 'apiKey' option or 'AI_GATEWAY_API_KEY' environment variable.`;\n    } else if (oidcTokenProvided) {\n      contextualMessage = `AI Gateway authentication failed: Invalid OIDC token.\n\nRun 'npx vercel link' to link your project, then 'vc env pull' to fetch the token.\n\nAlternatively, use an API key: https://vercel.com/d?to=%2F%5Bteam%5D%2F%7E%2Fai%2Fapi-keys`;\n    } else {\n      contextualMessage = `AI Gateway authentication failed: No authentication provided.\n\nOption 1 - API key:\nCreate an API key: https://vercel.com/d?to=%2F%5Bteam%5D%2F%7E%2Fai%2Fapi-keys\nProvide via 'apiKey' option or 'AI_GATEWAY_API_KEY' environment variable.\n\nOption 2 - OIDC token:\nRun 'npx vercel link' to link your project, then 'vc env pull' to fetch the token.`;\n    }\n\n    return new GatewayAuthenticationError({\n      message: contextualMessage,\n      statusCode,\n      cause,\n    });\n  }\n}\n","import { GatewayError } from './gateway-error';\n\nconst name = 'GatewayInvalidRequestError';\nconst marker = `vercel.ai.gateway.error.${name}`;\nconst symbol = Symbol.for(marker);\n\n/**\n * Invalid request - missing headers, malformed data, etc.\n */\nexport class GatewayInvalidRequestError extends GatewayError {\n  private readonly [symbol] = true; // used in isInstance\n\n  readonly name = name;\n  readonly type = 'invalid_request_error';\n\n  constructor({\n    message = 'Invalid request',\n    statusCode = 400,\n    cause,\n  }: {\n    message?: string;\n    statusCode?: number;\n    cause?: unknown;\n  } = {}) {\n    super({ message, statusCode, cause });\n  }\n\n  static isInstance(error: unknown): error is GatewayInvalidRequestError {\n    return GatewayError.hasMarker(error) && symbol in error;\n  }\n}\n","import { GatewayError } from './gateway-error';\n\nconst name = 'GatewayRateLimitError';\nconst marker = `vercel.ai.gateway.error.${name}`;\nconst symbol = Symbol.for(marker);\n\n/**\n * Rate limit exceeded.\n */\nexport class GatewayRateLimitError extends GatewayError {\n  private readonly [symbol] = true; // used in isInstance\n\n  readonly name = name;\n  readonly type = 'rate_limit_exceeded';\n\n  constructor({\n    message = 'Rate limit exceeded',\n    statusCode = 429,\n    cause,\n  }: {\n    message?: string;\n    statusCode?: number;\n    cause?: unknown;\n  } = {}) {\n    super({ message, statusCode, cause });\n  }\n\n  static isInstance(error: unknown): error is GatewayRateLimitError {\n    return GatewayError.hasMarker(error) && symbol in error;\n  }\n}\n","import { z } from 'zod/v4';\nimport { GatewayError } from './gateway-error';\nimport { lazyValidator, zodSchema } from '@ai-sdk/provider-utils';\n\nconst name = 'GatewayModelNotFoundError';\nconst marker = `vercel.ai.gateway.error.${name}`;\nconst symbol = Symbol.for(marker);\n\nexport const modelNotFoundParamSchema = lazyValidator(() =>\n  zodSchema(\n    z.object({\n      modelId: z.string(),\n    }),\n  ),\n);\n\n/**\n * Model not found or not available\n */\nexport class GatewayModelNotFoundError extends GatewayError {\n  private readonly [symbol] = true; // used in isInstance\n\n  readonly name = name;\n  readonly type = 'model_not_found';\n  readonly modelId?: string;\n\n  constructor({\n    message = 'Model not found',\n    statusCode = 404,\n    modelId,\n    cause,\n  }: {\n    message?: string;\n    statusCode?: number;\n    modelId?: string;\n    cause?: unknown;\n  } = {}) {\n    super({ message, statusCode, cause });\n    this.modelId = modelId;\n  }\n\n  static isInstance(error: unknown): error is GatewayModelNotFoundError {\n    return GatewayError.hasMarker(error) && symbol in error;\n  }\n}\n","import { GatewayError } from './gateway-error';\n\nconst name = 'GatewayInternalServerError';\nconst marker = `vercel.ai.gateway.error.${name}`;\nconst symbol = Symbol.for(marker);\n\n/**\n * Internal server error from the Gateway\n */\nexport class GatewayInternalServerError extends GatewayError {\n  private readonly [symbol] = true; // used in isInstance\n\n  readonly name = name;\n  readonly type = 'internal_server_error';\n\n  constructor({\n    message = 'Internal server error',\n    statusCode = 500,\n    cause,\n  }: {\n    message?: string;\n    statusCode?: number;\n    cause?: unknown;\n  } = {}) {\n    super({ message, statusCode, cause });\n  }\n\n  static isInstance(error: unknown): error is GatewayInternalServerError {\n    return GatewayError.hasMarker(error) && symbol in error;\n  }\n}\n","import { TypeValidationError } from '@ai-sdk/provider';\nimport { GatewayError } from './gateway-error';\n\nconst name = 'GatewayResponseError';\nconst marker = `vercel.ai.gateway.error.${name}`;\nconst symbol = Symbol.for(marker);\n\n/**\n * Gateway response parsing error\n */\nexport class GatewayResponseError extends GatewayError {\n  private readonly [symbol] = true; // used in isInstance\n\n  readonly name = name;\n  readonly type = 'response_error';\n  readonly response?: unknown;\n  readonly validationError?: TypeValidationError;\n\n  constructor({\n    message = 'Invalid response from Gateway',\n    statusCode = 502,\n    response,\n    validationError,\n    cause,\n  }: {\n    message?: string;\n    statusCode?: number;\n    response?: unknown;\n    validationError?: TypeValidationError;\n    cause?: unknown;\n  } = {}) {\n    super({ message, statusCode, cause });\n    this.response = response;\n    this.validationError = validationError;\n  }\n\n  static isInstance(error: unknown): error is GatewayResponseError {\n    return GatewayError.hasMarker(error) && symbol in error;\n  }\n}\n","import { z } from 'zod/v4';\nimport type { GatewayError } from './gateway-error';\nimport { GatewayAuthenticationError } from './gateway-authentication-error';\nimport { GatewayInvalidRequestError } from './gateway-invalid-request-error';\nimport { GatewayRateLimitError } from './gateway-rate-limit-error';\nimport {\n  GatewayModelNotFoundError,\n  modelNotFoundParamSchema,\n} from './gateway-model-not-found-error';\nimport { GatewayInternalServerError } from './gateway-internal-server-error';\nimport { GatewayResponseError } from './gateway-response-error';\nimport {\n  InferValidator,\n  lazyValidator,\n  safeValidateTypes,\n  validateTypes,\n  zodSchema,\n} from '@ai-sdk/provider-utils';\n\nexport async function createGatewayErrorFromResponse({\n  response,\n  statusCode,\n  defaultMessage = 'Gateway request failed',\n  cause,\n  authMethod,\n}: {\n  response: unknown;\n  statusCode: number;\n  defaultMessage?: string;\n  cause?: unknown;\n  authMethod?: 'api-key' | 'oidc';\n}): Promise<GatewayError> {\n  const parseResult = await safeValidateTypes({\n    value: response,\n    schema: gatewayErrorResponseSchema,\n  });\n\n  if (!parseResult.success) {\n    return new GatewayResponseError({\n      message: `Invalid error response format: ${defaultMessage}`,\n      statusCode,\n      response,\n      validationError: parseResult.error,\n      cause,\n    });\n  }\n\n  const validatedResponse: GatewayErrorResponse = parseResult.value;\n  const errorType = validatedResponse.error.type;\n  const message = validatedResponse.error.message;\n\n  switch (errorType) {\n    case 'authentication_error':\n      return GatewayAuthenticationError.createContextualError({\n        apiKeyProvided: authMethod === 'api-key',\n        oidcTokenProvided: authMethod === 'oidc',\n        statusCode,\n        cause,\n      });\n    case 'invalid_request_error':\n      return new GatewayInvalidRequestError({ message, statusCode, cause });\n    case 'rate_limit_exceeded':\n      return new GatewayRateLimitError({ message, statusCode, cause });\n    case 'model_not_found': {\n      const modelResult = await safeValidateTypes({\n        value: validatedResponse.error.param,\n        schema: modelNotFoundParamSchema,\n      });\n\n      return new GatewayModelNotFoundError({\n        message,\n        statusCode,\n        modelId: modelResult.success ? modelResult.value.modelId : undefined,\n        cause,\n      });\n    }\n    case 'internal_server_error':\n      return new GatewayInternalServerError({ message, statusCode, cause });\n    default:\n      return new GatewayInternalServerError({ message, statusCode, cause });\n  }\n}\n\nconst gatewayErrorResponseSchema = lazyValidator(() =>\n  zodSchema(\n    z.object({\n      error: z.object({\n        message: z.string(),\n        type: z.string().nullish(),\n        param: z.unknown().nullish(),\n        code: z.union([z.string(), z.number()]).nullish(),\n      }),\n    }),\n  ),\n);\n\nexport type GatewayErrorResponse = InferValidator<\n  typeof gatewayErrorResponseSchema\n>;\n","import { APICallError } from '@ai-sdk/provider';\nimport { extractApiCallResponse, GatewayError } from '.';\nimport { createGatewayErrorFromResponse } from './create-gateway-error';\n\nexport function asGatewayError(\n  error: unknown,\n  authMethod?: 'api-key' | 'oidc',\n) {\n  if (GatewayError.isInstance(error)) {\n    return error;\n  }\n\n  if (APICallError.isInstance(error)) {\n    return createGatewayErrorFromResponse({\n      response: extractApiCallResponse(error),\n      statusCode: error.statusCode ?? 500,\n      defaultMessage: 'Gateway request failed',\n      cause: error,\n      authMethod,\n    });\n  }\n\n  return createGatewayErrorFromResponse({\n    response: {},\n    statusCode: 500,\n    defaultMessage:\n      error instanceof Error\n        ? `Gateway request failed: ${error.message}`\n        : 'Unknown Gateway error',\n    cause: error,\n    authMethod,\n  });\n}\n","import type { APICallError } from '@ai-sdk/provider';\n\nexport function extractApiCallResponse(error: APICallError): unknown {\n  if (error.data !== undefined) {\n    return error.data;\n  }\n  if (error.responseBody != null) {\n    try {\n      return JSON.parse(error.responseBody);\n    } catch {\n      return error.responseBody;\n    }\n  }\n  return {};\n}\n","import { z } from 'zod/v4';\nimport {\n  lazyValidator,\n  safeValidateTypes,\n  zodSchema,\n} from '@ai-sdk/provider-utils';\n\nexport const GATEWAY_AUTH_METHOD_HEADER = 'ai-gateway-auth-method' as const;\n\nexport async function parseAuthMethod(\n  headers: Record<string, string | undefined>,\n) {\n  const result = await safeValidateTypes({\n    value: headers[GATEWAY_AUTH_METHOD_HEADER],\n    schema: gatewayAuthMethodSchema,\n  });\n\n  return result.success ? result.value : undefined;\n}\n\nconst gatewayAuthMethodSchema = lazyValidator(() =>\n  zodSchema(z.union([z.literal('api-key'), z.literal('oidc')])),\n);\n","import {\n  createJsonErrorResponseHandler,\n  createJsonResponseHandler,\n  getFromApi,\n  lazyValidator,\n  resolve,\n  zodSchema,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\nimport { asGatewayError } from './errors';\nimport type { GatewayConfig } from './gateway-config';\nimport type { GatewayLanguageModelEntry } from './gateway-model-entry';\n\ntype GatewayFetchMetadataConfig = GatewayConfig;\n\nexport interface GatewayFetchMetadataResponse {\n  models: GatewayLanguageModelEntry[];\n}\n\nexport interface GatewayCreditsResponse {\n  /** The remaining gateway credit balance available for API usage */\n  balance: string;\n  /** The total amount of gateway credits that have been consumed */\n  totalUsed: string;\n}\n\nexport class GatewayFetchMetadata {\n  constructor(private readonly config: GatewayFetchMetadataConfig) {}\n\n  async getAvailableModels(): Promise<GatewayFetchMetadataResponse> {\n    try {\n      const { value } = await getFromApi({\n        url: `${this.config.baseURL}/config`,\n        headers: await resolve(this.config.headers()),\n        successfulResponseHandler: createJsonResponseHandler(\n          gatewayAvailableModelsResponseSchema,\n        ),\n        failedResponseHandler: createJsonErrorResponseHandler({\n          errorSchema: z.any(),\n          errorToMessage: data => data,\n        }),\n        fetch: this.config.fetch,\n      });\n\n      return value;\n    } catch (error) {\n      throw await asGatewayError(error);\n    }\n  }\n\n  async getCredits(): Promise<GatewayCreditsResponse> {\n    try {\n      const baseUrl = new URL(this.config.baseURL);\n\n      const { value } = await getFromApi({\n        url: `${baseUrl.origin}/v1/credits`,\n        headers: await resolve(this.config.headers()),\n        successfulResponseHandler: createJsonResponseHandler(\n          gatewayCreditsResponseSchema,\n        ),\n        failedResponseHandler: createJsonErrorResponseHandler({\n          errorSchema: z.any(),\n          errorToMessage: data => data,\n        }),\n        fetch: this.config.fetch,\n      });\n\n      return value;\n    } catch (error) {\n      throw await asGatewayError(error);\n    }\n  }\n}\n\nconst gatewayAvailableModelsResponseSchema = lazyValidator(() =>\n  zodSchema(\n    z.object({\n      models: z.array(\n        z.object({\n          id: z.string(),\n          name: z.string(),\n          description: z.string().nullish(),\n          pricing: z\n            .object({\n              input: z.string(),\n              output: z.string(),\n              input_cache_read: z.string().nullish(),\n              input_cache_write: z.string().nullish(),\n            })\n            .transform(\n              ({ input, output, input_cache_read, input_cache_write }) => ({\n                input,\n                output,\n                ...(input_cache_read\n                  ? { cachedInputTokens: input_cache_read }\n                  : {}),\n                ...(input_cache_write\n                  ? { cacheCreationInputTokens: input_cache_write }\n                  : {}),\n              }),\n            )\n            .nullish(),\n          specification: z.object({\n            specificationVersion: z.literal('v2'),\n            provider: z.string(),\n            modelId: z.string(),\n          }),\n          modelType: z.enum(['language', 'embedding', 'image']).nullish(),\n        }),\n      ),\n    }),\n  ),\n);\n\nconst gatewayCreditsResponseSchema = lazyValidator(() =>\n  zodSchema(\n    z\n      .object({\n        balance: z.string(),\n        total_used: z.string(),\n      })\n      .transform(({ balance, total_used }) => ({\n        balance,\n        totalUsed: total_used,\n      })),\n  ),\n);\n","import type {\n  LanguageModelV2,\n  LanguageModelV2CallOptions,\n  LanguageModelV2CallWarning,\n  LanguageModelV2FilePart,\n  LanguageModelV2StreamPart,\n} from '@ai-sdk/provider';\nimport {\n  combineHeaders,\n  createEventSourceResponseHandler,\n  createJsonErrorResponseHandler,\n  createJsonResponseHandler,\n  postJsonToApi,\n  resolve,\n  type ParseResult,\n  type Resolvable,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\nimport type { GatewayConfig } from './gateway-config';\nimport type { GatewayModelId } from './gateway-language-model-settings';\nimport { asGatewayError } from './errors';\nimport { parseAuthMethod } from './errors/parse-auth-method';\n\ntype GatewayChatConfig = GatewayConfig & {\n  provider: string;\n  o11yHeaders: Resolvable<Record<string, string>>;\n};\n\nexport class GatewayLanguageModel implements LanguageModelV2 {\n  readonly specificationVersion = 'v2';\n  readonly supportedUrls = { '*/*': [/.*/] };\n\n  constructor(\n    readonly modelId: GatewayModelId,\n    private readonly config: GatewayChatConfig,\n  ) {}\n\n  get provider(): string {\n    return this.config.provider;\n  }\n\n  private async getArgs(options: Parameters<LanguageModelV2['doGenerate']>[0]) {\n    const { abortSignal: _abortSignal, ...optionsWithoutSignal } = options;\n\n    return {\n      args: this.maybeEncodeFileParts(optionsWithoutSignal),\n      warnings: [],\n    };\n  }\n\n  async doGenerate(\n    options: Parameters<LanguageModelV2['doGenerate']>[0],\n  ): Promise<Awaited<ReturnType<LanguageModelV2['doGenerate']>>> {\n    const { args, warnings } = await this.getArgs(options);\n    const { abortSignal } = options;\n\n    const resolvedHeaders = await resolve(this.config.headers());\n\n    try {\n      const {\n        responseHeaders,\n        value: responseBody,\n        rawValue: rawResponse,\n      } = await postJsonToApi({\n        url: this.getUrl(),\n        headers: combineHeaders(\n          resolvedHeaders,\n          options.headers,\n          this.getModelConfigHeaders(this.modelId, false),\n          await resolve(this.config.o11yHeaders),\n        ),\n        body: args,\n        successfulResponseHandler: createJsonResponseHandler(z.any()),\n        failedResponseHandler: createJsonErrorResponseHandler({\n          errorSchema: z.any(),\n          errorToMessage: data => data,\n        }),\n        ...(abortSignal && { abortSignal }),\n        fetch: this.config.fetch,\n      });\n\n      return {\n        ...responseBody,\n        request: { body: args },\n        response: { headers: responseHeaders, body: rawResponse },\n        warnings,\n      };\n    } catch (error) {\n      throw await asGatewayError(error, await parseAuthMethod(resolvedHeaders));\n    }\n  }\n\n  async doStream(\n    options: Parameters<LanguageModelV2['doStream']>[0],\n  ): Promise<Awaited<ReturnType<LanguageModelV2['doStream']>>> {\n    const { args, warnings } = await this.getArgs(options);\n    const { abortSignal } = options;\n\n    const resolvedHeaders = await resolve(this.config.headers());\n\n    try {\n      const { value: response, responseHeaders } = await postJsonToApi({\n        url: this.getUrl(),\n        headers: combineHeaders(\n          resolvedHeaders,\n          options.headers,\n          this.getModelConfigHeaders(this.modelId, true),\n          await resolve(this.config.o11yHeaders),\n        ),\n        body: args,\n        successfulResponseHandler: createEventSourceResponseHandler(z.any()),\n        failedResponseHandler: createJsonErrorResponseHandler({\n          errorSchema: z.any(),\n          errorToMessage: data => data,\n        }),\n        ...(abortSignal && { abortSignal }),\n        fetch: this.config.fetch,\n      });\n\n      return {\n        stream: response.pipeThrough(\n          new TransformStream<\n            ParseResult<LanguageModelV2StreamPart>,\n            LanguageModelV2StreamPart\n          >({\n            start(controller) {\n              if (warnings.length > 0) {\n                controller.enqueue({ type: 'stream-start', warnings });\n              }\n            },\n            transform(chunk, controller) {\n              if (chunk.success) {\n                const streamPart = chunk.value;\n\n                // Handle raw chunks: if this is a raw chunk from the gateway API,\n                // only emit it if includeRawChunks is true\n                if (streamPart.type === 'raw' && !options.includeRawChunks) {\n                  return; // Skip raw chunks if not requested\n                }\n\n                if (\n                  streamPart.type === 'response-metadata' &&\n                  streamPart.timestamp &&\n                  typeof streamPart.timestamp === 'string'\n                ) {\n                  streamPart.timestamp = new Date(streamPart.timestamp);\n                }\n\n                controller.enqueue(streamPart);\n              } else {\n                controller.error(\n                  (chunk as { success: false; error: unknown }).error,\n                );\n              }\n            },\n          }),\n        ),\n        request: { body: args },\n        response: { headers: responseHeaders },\n      };\n    } catch (error) {\n      throw await asGatewayError(error, await parseAuthMethod(resolvedHeaders));\n    }\n  }\n\n  private isFilePart(part: unknown) {\n    return (\n      part && typeof part === 'object' && 'type' in part && part.type === 'file'\n    );\n  }\n\n  /**\n   * Encodes file parts in the prompt to base64. Mutates the passed options\n   * instance directly to avoid copying the file data.\n   * @param options - The options to encode.\n   * @returns The options with the file parts encoded.\n   */\n  private maybeEncodeFileParts(options: LanguageModelV2CallOptions) {\n    for (const message of options.prompt) {\n      for (const part of message.content) {\n        if (this.isFilePart(part)) {\n          const filePart = part as LanguageModelV2FilePart;\n          // If the file part is a URL it will get cleanly converted to a string.\n          // If it's a binary file attachment we convert it to a data url.\n          // In either case, server-side we should only ever see URLs as strings.\n          if (filePart.data instanceof Uint8Array) {\n            const buffer = Uint8Array.from(filePart.data);\n            const base64Data = Buffer.from(buffer).toString('base64');\n            filePart.data = new URL(\n              `data:${filePart.mediaType || 'application/octet-stream'};base64,${base64Data}`,\n            );\n          }\n        }\n      }\n    }\n    return options;\n  }\n\n  private getUrl() {\n    return `${this.config.baseURL}/language-model`;\n  }\n\n  private getModelConfigHeaders(modelId: string, streaming: boolean) {\n    return {\n      'ai-language-model-specification-version': '2',\n      'ai-language-model-id': modelId,\n      'ai-language-model-streaming': String(streaming),\n    };\n  }\n}\n","import type {\n  EmbeddingModelV2,\n  SharedV2ProviderMetadata,\n} from '@ai-sdk/provider';\nimport {\n  combineHeaders,\n  createJsonErrorResponseHandler,\n  createJsonResponseHandler,\n  lazyValidator,\n  postJsonToApi,\n  resolve,\n  zodSchema,\n  type Resolvable,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\nimport { asGatewayError } from './errors';\nimport { parseAuthMethod } from './errors/parse-auth-method';\nimport type { GatewayConfig } from './gateway-config';\n\nexport class GatewayEmbeddingModel implements EmbeddingModelV2<string> {\n  readonly specificationVersion = 'v2';\n  readonly maxEmbeddingsPerCall = 2048;\n  readonly supportsParallelCalls = true;\n\n  constructor(\n    readonly modelId: string,\n    private readonly config: GatewayConfig & {\n      provider: string;\n      o11yHeaders: Resolvable<Record<string, string>>;\n    },\n  ) {}\n\n  get provider(): string {\n    return this.config.provider;\n  }\n\n  async doEmbed({\n    values,\n    headers,\n    abortSignal,\n    providerOptions,\n  }: Parameters<EmbeddingModelV2<string>['doEmbed']>[0]): Promise<\n    Awaited<ReturnType<EmbeddingModelV2<string>['doEmbed']>>\n  > {\n    const resolvedHeaders = await resolve(this.config.headers());\n    try {\n      const {\n        responseHeaders,\n        value: responseBody,\n        rawValue,\n      } = await postJsonToApi({\n        url: this.getUrl(),\n        headers: combineHeaders(\n          resolvedHeaders,\n          headers ?? {},\n          this.getModelConfigHeaders(),\n          await resolve(this.config.o11yHeaders),\n        ),\n        body: {\n          input: values.length === 1 ? values[0] : values,\n          ...(providerOptions ? { providerOptions } : {}),\n        },\n        successfulResponseHandler: createJsonResponseHandler(\n          gatewayEmbeddingResponseSchema,\n        ),\n        failedResponseHandler: createJsonErrorResponseHandler({\n          errorSchema: z.any(),\n          errorToMessage: data => data,\n        }),\n        ...(abortSignal && { abortSignal }),\n        fetch: this.config.fetch,\n      });\n\n      return {\n        embeddings: responseBody.embeddings,\n        usage: responseBody.usage ?? undefined,\n        providerMetadata:\n          responseBody.providerMetadata as unknown as SharedV2ProviderMetadata,\n        response: { headers: responseHeaders, body: rawValue },\n      };\n    } catch (error) {\n      throw await asGatewayError(error, await parseAuthMethod(resolvedHeaders));\n    }\n  }\n\n  private getUrl() {\n    return `${this.config.baseURL}/embedding-model`;\n  }\n\n  private getModelConfigHeaders() {\n    return {\n      'ai-embedding-model-specification-version': '2',\n      'ai-model-id': this.modelId,\n    };\n  }\n}\n\nconst gatewayEmbeddingResponseSchema = lazyValidator(() =>\n  zodSchema(\n    z.object({\n      embeddings: z.array(z.array(z.number())),\n      usage: z.object({ tokens: z.number() }).nullish(),\n      providerMetadata: z\n        .record(z.string(), z.record(z.string(), z.unknown()))\n        .optional(),\n    }),\n  ),\n);\n","import type {\n  ImageModelV2,\n  ImageModelV2CallWarning,\n  ImageModelV2ProviderMetadata,\n} from '@ai-sdk/provider';\nimport {\n  combineHeaders,\n  createJsonResponseHandler,\n  createJsonErrorResponseHandler,\n  postJsonToApi,\n  resolve,\n  type Resolvable,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\nimport type { GatewayConfig } from './gateway-config';\nimport { asGatewayError } from './errors';\nimport { parseAuthMethod } from './errors/parse-auth-method';\n\nexport class GatewayImageModel implements ImageModelV2 {\n  readonly specificationVersion = 'v2';\n  // Set a very large number to prevent client-side splitting of requests\n  readonly maxImagesPerCall = Number.MAX_SAFE_INTEGER;\n\n  constructor(\n    readonly modelId: string,\n    private readonly config: GatewayConfig & {\n      provider: string;\n      o11yHeaders: Resolvable<Record<string, string>>;\n    },\n  ) {}\n\n  get provider(): string {\n    return this.config.provider;\n  }\n\n  async doGenerate({\n    prompt,\n    n,\n    size,\n    aspectRatio,\n    seed,\n    providerOptions,\n    headers,\n    abortSignal,\n  }: Parameters<ImageModelV2['doGenerate']>[0]): Promise<\n    Awaited<ReturnType<ImageModelV2['doGenerate']>>\n  > {\n    const resolvedHeaders = await resolve(this.config.headers());\n    try {\n      const {\n        responseHeaders,\n        value: responseBody,\n        rawValue,\n      } = await postJsonToApi({\n        url: this.getUrl(),\n        headers: combineHeaders(\n          resolvedHeaders,\n          headers ?? {},\n          this.getModelConfigHeaders(),\n          await resolve(this.config.o11yHeaders),\n        ),\n        body: {\n          prompt,\n          n,\n          ...(size && { size }),\n          ...(aspectRatio && { aspectRatio }),\n          ...(seed && { seed }),\n          ...(providerOptions && { providerOptions }),\n        },\n        successfulResponseHandler: createJsonResponseHandler(\n          gatewayImageResponseSchema,\n        ),\n        failedResponseHandler: createJsonErrorResponseHandler({\n          errorSchema: z.any(),\n          errorToMessage: data => data,\n        }),\n        ...(abortSignal && { abortSignal }),\n        fetch: this.config.fetch,\n      });\n\n      return {\n        images: responseBody.images, // Always base64 strings from server\n        warnings: responseBody.warnings ?? [],\n        providerMetadata:\n          responseBody.providerMetadata as ImageModelV2ProviderMetadata,\n        response: {\n          timestamp: new Date(),\n          modelId: this.modelId,\n          headers: responseHeaders,\n        },\n      };\n    } catch (error) {\n      throw asGatewayError(error, await parseAuthMethod(resolvedHeaders));\n    }\n  }\n\n  private getUrl() {\n    return `${this.config.baseURL}/image-model`;\n  }\n\n  private getModelConfigHeaders() {\n    return {\n      'ai-image-model-specification-version': '2',\n      'ai-model-id': this.modelId,\n    };\n  }\n}\n\nconst providerMetadataEntrySchema = z\n  .object({\n    images: z.array(z.unknown()).optional(),\n  })\n  .catchall(z.unknown());\n\nconst gatewayImageResponseSchema = z.object({\n  images: z.array(z.string()), // Always base64 strings over the wire\n  warnings: z\n    .array(\n      z.object({\n        type: z.literal('other'),\n        message: z.string(),\n      }),\n    )\n    .optional(),\n  providerMetadata: z\n    .record(z.string(), providerMetadataEntrySchema)\n    .optional(),\n});\n","// Version string of this package injected at build time.\ndeclare const __PACKAGE_VERSION__: string | undefined;\nexport const VERSION: string =\n  typeof __PACKAGE_VERSION__ !== 'undefined'\n    ? __PACKAGE_VERSION__\n    : '0.0.0-test';\n","import {\n  loadOptionalSetting,\n  withoutTrailingSlash,\n  type FetchFunction,\n} from '@ai-sdk/provider-utils';\nimport { asGatewayError, GatewayAuthenticationError } from './errors';\nimport {\n  GATEWAY_AUTH_METHOD_HEADER,\n  parseAuthMethod,\n} from './errors/parse-auth-method';\nimport {\n  GatewayFetchMetadata,\n  type GatewayFetchMetadataResponse,\n  type GatewayCreditsResponse,\n} from './gateway-fetch-metadata';\nimport { GatewayLanguageModel } from './gateway-language-model';\nimport { GatewayEmbeddingModel } from './gateway-embedding-model';\nimport { GatewayImageModel } from './gateway-image-model';\nimport type { GatewayEmbeddingModelId } from './gateway-embedding-model-settings';\nimport type { GatewayImageModelId } from './gateway-image-model-settings';\nimport { getVercelOidcToken, getVercelRequestId } from './vercel-environment';\nimport type { GatewayModelId } from './gateway-language-model-settings';\nimport type {\n  LanguageModelV2,\n  EmbeddingModelV2,\n  ImageModelV2,\n  ProviderV2,\n} from '@ai-sdk/provider';\nimport { withUserAgentSuffix } from '@ai-sdk/provider-utils';\nimport { VERSION } from './version';\n\nexport interface GatewayProvider extends ProviderV2 {\n  (modelId: GatewayModelId): LanguageModelV2;\n\n  /**\nCreates a model for text generation.\n*/\n  languageModel(modelId: GatewayModelId): LanguageModelV2;\n\n  /**\nReturns available providers and models for use with the remote provider.\n */\n  getAvailableModels(): Promise<GatewayFetchMetadataResponse>;\n\n  /**\nReturns credit information for the authenticated user.\n */\n  getCredits(): Promise<GatewayCreditsResponse>;\n\n  /**\nCreates a model for generating text embeddings.\n*/\n  textEmbeddingModel(\n    modelId: GatewayEmbeddingModelId,\n  ): EmbeddingModelV2<string>;\n\n  /**\nCreates a model for generating images.\n*/\n  imageModel(modelId: GatewayImageModelId): ImageModelV2;\n}\n\nexport interface GatewayProviderSettings {\n  /**\nThe base URL prefix for API calls. Defaults to `https://ai-gateway.vercel.sh/v1/ai`.\n   */\n  baseURL?: string;\n\n  /**\nAPI key that is being sent using the `Authorization` header.\n   */\n  apiKey?: string;\n\n  /**\nCustom headers to include in the requests.\n     */\n  headers?: Record<string, string>;\n\n  /**\nCustom fetch implementation. You can use it as a middleware to intercept requests,\nor to provide a custom fetch implementation for e.g. testing.\n    */\n  fetch?: FetchFunction;\n\n  /**\nHow frequently to refresh the metadata cache in milliseconds.\n   */\n  metadataCacheRefreshMillis?: number;\n\n  /**\n   * @internal For testing purposes only\n   */\n  _internal?: {\n    currentDate?: () => Date;\n  };\n}\n\nconst AI_GATEWAY_PROTOCOL_VERSION = '0.0.1';\n\n/**\nCreate a remote provider instance.\n */\nexport function createGatewayProvider(\n  options: GatewayProviderSettings = {},\n): GatewayProvider {\n  let pendingMetadata: Promise<GatewayFetchMetadataResponse> | null = null;\n  let metadataCache: GatewayFetchMetadataResponse | null = null;\n  const cacheRefreshMillis =\n    options.metadataCacheRefreshMillis ?? 1000 * 60 * 5;\n  let lastFetchTime = 0;\n\n  const baseURL =\n    withoutTrailingSlash(options.baseURL) ??\n    'https://ai-gateway.vercel.sh/v1/ai';\n\n  const getHeaders = async () => {\n    const auth = await getGatewayAuthToken(options);\n    if (auth) {\n      return withUserAgentSuffix(\n        {\n          Authorization: `Bearer ${auth.token}`,\n          'ai-gateway-protocol-version': AI_GATEWAY_PROTOCOL_VERSION,\n          [GATEWAY_AUTH_METHOD_HEADER]: auth.authMethod,\n          ...options.headers,\n        },\n        `ai-sdk/gateway/${VERSION}`,\n      );\n    }\n\n    throw GatewayAuthenticationError.createContextualError({\n      apiKeyProvided: false,\n      oidcTokenProvided: false,\n      statusCode: 401,\n    });\n  };\n\n  const createO11yHeaders = () => {\n    const deploymentId = loadOptionalSetting({\n      settingValue: undefined,\n      environmentVariableName: 'VERCEL_DEPLOYMENT_ID',\n    });\n    const environment = loadOptionalSetting({\n      settingValue: undefined,\n      environmentVariableName: 'VERCEL_ENV',\n    });\n    const region = loadOptionalSetting({\n      settingValue: undefined,\n      environmentVariableName: 'VERCEL_REGION',\n    });\n\n    return async () => {\n      const requestId = await getVercelRequestId();\n      return {\n        ...(deploymentId && { 'ai-o11y-deployment-id': deploymentId }),\n        ...(environment && { 'ai-o11y-environment': environment }),\n        ...(region && { 'ai-o11y-region': region }),\n        ...(requestId && { 'ai-o11y-request-id': requestId }),\n      };\n    };\n  };\n\n  const createLanguageModel = (modelId: GatewayModelId) => {\n    return new GatewayLanguageModel(modelId, {\n      provider: 'gateway',\n      baseURL,\n      headers: getHeaders,\n      fetch: options.fetch,\n      o11yHeaders: createO11yHeaders(),\n    });\n  };\n\n  const getAvailableModels = async () => {\n    const now = options._internal?.currentDate?.().getTime() ?? Date.now();\n    if (!pendingMetadata || now - lastFetchTime > cacheRefreshMillis) {\n      lastFetchTime = now;\n\n      pendingMetadata = new GatewayFetchMetadata({\n        baseURL,\n        headers: getHeaders,\n        fetch: options.fetch,\n      })\n        .getAvailableModels()\n        .then(metadata => {\n          metadataCache = metadata;\n          return metadata;\n        })\n        .catch(async (error: unknown) => {\n          throw await asGatewayError(\n            error,\n            await parseAuthMethod(await getHeaders()),\n          );\n        });\n    }\n\n    return metadataCache ? Promise.resolve(metadataCache) : pendingMetadata;\n  };\n\n  const getCredits = async () => {\n    return new GatewayFetchMetadata({\n      baseURL,\n      headers: getHeaders,\n      fetch: options.fetch,\n    })\n      .getCredits()\n      .catch(async (error: unknown) => {\n        throw await asGatewayError(\n          error,\n          await parseAuthMethod(await getHeaders()),\n        );\n      });\n  };\n\n  const provider = function (modelId: GatewayModelId) {\n    if (new.target) {\n      throw new Error(\n        'The Gateway Provider model function cannot be called with the new keyword.',\n      );\n    }\n\n    return createLanguageModel(modelId);\n  };\n\n  provider.getAvailableModels = getAvailableModels;\n  provider.getCredits = getCredits;\n  provider.imageModel = (modelId: GatewayImageModelId) => {\n    return new GatewayImageModel(modelId, {\n      provider: 'gateway',\n      baseURL,\n      headers: getHeaders,\n      fetch: options.fetch,\n      o11yHeaders: createO11yHeaders(),\n    });\n  };\n  provider.languageModel = createLanguageModel;\n  provider.textEmbeddingModel = (modelId: GatewayEmbeddingModelId) => {\n    return new GatewayEmbeddingModel(modelId, {\n      provider: 'gateway',\n      baseURL,\n      headers: getHeaders,\n      fetch: options.fetch,\n      o11yHeaders: createO11yHeaders(),\n    });\n  };\n\n  return provider;\n}\n\nexport const gateway = createGatewayProvider();\n\nexport async function getGatewayAuthToken(\n  options: GatewayProviderSettings,\n): Promise<{\n  token: string;\n  authMethod: 'api-key' | 'oidc';\n} | null> {\n  const apiKey = loadOptionalSetting({\n    settingValue: options.apiKey,\n    environmentVariableName: 'AI_GATEWAY_API_KEY',\n  });\n\n  if (apiKey) {\n    return {\n      token: apiKey,\n      authMethod: 'api-key',\n    };\n  }\n\n  try {\n    const oidcToken = await getVercelOidcToken();\n    return {\n      token: oidcToken,\n      authMethod: 'oidc',\n    };\n  } catch {\n    return null;\n  }\n}\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n/** only globals that common to node and browsers are allowed */\n// eslint-disable-next-line node/no-unsupported-features/es-builtins\nexport const _globalThis = typeof globalThis === 'object' ? globalThis : global;\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n// this is autogenerated file, see scripts/version-update.js\nexport const VERSION = '1.9.0';\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { VERSION } from '../version';\n\nconst re = /^(\\d+)\\.(\\d+)\\.(\\d+)(-(.+))?$/;\n\n/**\n * Create a function to test an API version to see if it is compatible with the provided ownVersion.\n *\n * The returned function has the following semantics:\n * - Exact match is always compatible\n * - Major versions must match exactly\n *    - 1.x package cannot use global 2.x package\n *    - 2.x package cannot use global 1.x package\n * - The minor version of the API module requesting access to the global API must be less than or equal to the minor version of this API\n *    - 1.3 package may use 1.4 global because the later global contains all functions 1.3 expects\n *    - 1.4 package may NOT use 1.3 global because it may try to call functions which don't exist on 1.3\n * - If the major version is 0, the minor version is treated as the major and the patch is treated as the minor\n * - Patch and build tag differences are not considered at this time\n *\n * @param ownVersion version which should be checked against\n */\nexport function _makeCompatibilityCheck(\n  ownVersion: string\n): (globalVersion: string) => boolean {\n  const acceptedVersions = new Set<string>([ownVersion]);\n  const rejectedVersions = new Set<string>();\n\n  const myVersionMatch = ownVersion.match(re);\n  if (!myVersionMatch) {\n    // we cannot guarantee compatibility so we always return noop\n    return () => false;\n  }\n\n  const ownVersionParsed = {\n    major: +myVersionMatch[1],\n    minor: +myVersionMatch[2],\n    patch: +myVersionMatch[3],\n    prerelease: myVersionMatch[4],\n  };\n\n  // if ownVersion has a prerelease tag, versions must match exactly\n  if (ownVersionParsed.prerelease != null) {\n    return function isExactmatch(globalVersion: string): boolean {\n      return globalVersion === ownVersion;\n    };\n  }\n\n  function _reject(v: string) {\n    rejectedVersions.add(v);\n    return false;\n  }\n\n  function _accept(v: string) {\n    acceptedVersions.add(v);\n    return true;\n  }\n\n  return function isCompatible(globalVersion: string): boolean {\n    if (acceptedVersions.has(globalVersion)) {\n      return true;\n    }\n\n    if (rejectedVersions.has(globalVersion)) {\n      return false;\n    }\n\n    const globalVersionMatch = globalVersion.match(re);\n    if (!globalVersionMatch) {\n      // cannot parse other version\n      // we cannot guarantee compatibility so we always noop\n      return _reject(globalVersion);\n    }\n\n    const globalVersionParsed = {\n      major: +globalVersionMatch[1],\n      minor: +globalVersionMatch[2],\n      patch: +globalVersionMatch[3],\n      prerelease: globalVersionMatch[4],\n    };\n\n    // if globalVersion has a prerelease tag, versions must match exactly\n    if (globalVersionParsed.prerelease != null) {\n      return _reject(globalVersion);\n    }\n\n    // major versions must match\n    if (ownVersionParsed.major !== globalVersionParsed.major) {\n      return _reject(globalVersion);\n    }\n\n    if (ownVersionParsed.major === 0) {\n      if (\n        ownVersionParsed.minor === globalVersionParsed.minor &&\n        ownVersionParsed.patch <= globalVersionParsed.patch\n      ) {\n        return _accept(globalVersion);\n      }\n\n      return _reject(globalVersion);\n    }\n\n    if (ownVersionParsed.minor <= globalVersionParsed.minor) {\n      return _accept(globalVersion);\n    }\n\n    return _reject(globalVersion);\n  };\n}\n\n/**\n * Test an API version to see if it is compatible with this API.\n *\n * - Exact match is always compatible\n * - Major versions must match exactly\n *    - 1.x package cannot use global 2.x package\n *    - 2.x package cannot use global 1.x package\n * - The minor version of the API module requesting access to the global API must be less than or equal to the minor version of this API\n *    - 1.3 package may use 1.4 global because the later global contains all functions 1.3 expects\n *    - 1.4 package may NOT use 1.3 global because it may try to call functions which don't exist on 1.3\n * - If the major version is 0, the minor version is treated as the major and the patch is treated as the minor\n * - Patch and build tag differences are not considered at this time\n *\n * @param version version of the API requesting an instance of the global API\n */\nexport const isCompatible = _makeCompatibilityCheck(VERSION);\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { MeterProvider } from '../metrics/MeterProvider';\nimport { ContextManager } from '../context/types';\nimport { DiagLogger } from '../diag/types';\nimport { _globalThis } from '../platform';\nimport { TextMapPropagator } from '../propagation/TextMapPropagator';\nimport type { TracerProvider } from '../trace/tracer_provider';\nimport { VERSION } from '../version';\nimport { isCompatible } from './semver';\n\nconst major = VERSION.split('.')[0];\nconst GLOBAL_OPENTELEMETRY_API_KEY = Symbol.for(\n  `opentelemetry.js.api.${major}`\n);\n\nconst _global = _globalThis as OTelGlobal;\n\nexport function registerGlobal<Type extends keyof OTelGlobalAPI>(\n  type: Type,\n  instance: OTelGlobalAPI[Type],\n  diag: DiagLogger,\n  allowOverride = false\n): boolean {\n  const api = (_global[GLOBAL_OPENTELEMETRY_API_KEY] = _global[\n    GLOBAL_OPENTELEMETRY_API_KEY\n  ] ?? {\n    version: VERSION,\n  });\n\n  if (!allowOverride && api[type]) {\n    // already registered an API of this type\n    const err = new Error(\n      `@opentelemetry/api: Attempted duplicate registration of API: ${type}`\n    );\n    diag.error(err.stack || err.message);\n    return false;\n  }\n\n  if (api.version !== VERSION) {\n    // All registered APIs must be of the same version exactly\n    const err = new Error(\n      `@opentelemetry/api: Registration of version v${api.version} for ${type} does not match previously registered API v${VERSION}`\n    );\n    diag.error(err.stack || err.message);\n    return false;\n  }\n\n  api[type] = instance;\n  diag.debug(\n    `@opentelemetry/api: Registered a global for ${type} v${VERSION}.`\n  );\n\n  return true;\n}\n\nexport function getGlobal<Type extends keyof OTelGlobalAPI>(\n  type: Type\n): OTelGlobalAPI[Type] | undefined {\n  const globalVersion = _global[GLOBAL_OPENTELEMETRY_API_KEY]?.version;\n  if (!globalVersion || !isCompatible(globalVersion)) {\n    return;\n  }\n  return _global[GLOBAL_OPENTELEMETRY_API_KEY]?.[type];\n}\n\nexport function unregisterGlobal(type: keyof OTelGlobalAPI, diag: DiagLogger) {\n  diag.debug(\n    `@opentelemetry/api: Unregistering a global for ${type} v${VERSION}.`\n  );\n  const api = _global[GLOBAL_OPENTELEMETRY_API_KEY];\n\n  if (api) {\n    delete api[type];\n  }\n}\n\ntype OTelGlobal = {\n  [GLOBAL_OPENTELEMETRY_API_KEY]?: OTelGlobalAPI;\n};\n\ntype OTelGlobalAPI = {\n  version: string;\n\n  diag?: DiagLogger;\n  trace?: TracerProvider;\n  context?: ContextManager;\n  metrics?: MeterProvider;\n  propagation?: TextMapPropagator;\n};\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { getGlobal } from '../internal/global-utils';\nimport { ComponentLoggerOptions, DiagLogger, DiagLogFunction } from './types';\n\n/**\n * Component Logger which is meant to be used as part of any component which\n * will add automatically additional namespace in front of the log message.\n * It will then forward all message to global diag logger\n * @example\n * const cLogger = diag.createComponentLogger({ namespace: '@opentelemetry/instrumentation-http' });\n * cLogger.debug('test');\n * // @opentelemetry/instrumentation-http test\n */\nexport class DiagComponentLogger implements DiagLogger {\n  private _namespace: string;\n\n  constructor(props: ComponentLoggerOptions) {\n    this._namespace = props.namespace || 'DiagComponentLogger';\n  }\n\n  public debug(...args: any[]): void {\n    return logProxy('debug', this._namespace, args);\n  }\n\n  public error(...args: any[]): void {\n    return logProxy('error', this._namespace, args);\n  }\n\n  public info(...args: any[]): void {\n    return logProxy('info', this._namespace, args);\n  }\n\n  public warn(...args: any[]): void {\n    return logProxy('warn', this._namespace, args);\n  }\n\n  public verbose(...args: any[]): void {\n    return logProxy('verbose', this._namespace, args);\n  }\n}\n\nfunction logProxy(\n  funcName: keyof DiagLogger,\n  namespace: string,\n  args: any\n): void {\n  const logger = getGlobal('diag');\n  // shortcut if logger not set\n  if (!logger) {\n    return;\n  }\n\n  args.unshift(namespace);\n  return logger[funcName](...(args as Parameters<DiagLogFunction>));\n}\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nexport type DiagLogFunction = (message: string, ...args: unknown[]) => void;\n\n/**\n * Defines an internal diagnostic logger interface which is used to log internal diagnostic\n * messages, you can set the default diagnostic logger via the {@link DiagAPI} setLogger function.\n * API provided implementations include :-\n * - a No-Op {@link createNoopDiagLogger}\n * - a {@link DiagLogLevel} filtering wrapper {@link createLogLevelDiagLogger}\n * - a general Console {@link DiagConsoleLogger} version.\n */\nexport interface DiagLogger {\n  /** Log an error scenario that was not expected and caused the requested operation to fail. */\n  error: DiagLogFunction;\n\n  /**\n   * Log a warning scenario to inform the developer of an issues that should be investigated.\n   * The requested operation may or may not have succeeded or completed.\n   */\n  warn: DiagLogFunction;\n\n  /**\n   * Log a general informational message, this should not affect functionality.\n   * This is also the default logging level so this should NOT be used for logging\n   * debugging level information.\n   */\n  info: DiagLogFunction;\n\n  /**\n   * Log a general debug message that can be useful for identifying a failure.\n   * Information logged at this level may include diagnostic details that would\n   * help identify a failure scenario.\n   * For example: Logging the order of execution of async operations.\n   */\n  debug: DiagLogFunction;\n\n  /**\n   * Log a detailed (verbose) trace level logging that can be used to identify failures\n   * where debug level logging would be insufficient, this level of tracing can include\n   * input and output parameters and as such may include PII information passing through\n   * the API. As such it is recommended that this level of tracing should not be enabled\n   * in a production environment.\n   */\n  verbose: DiagLogFunction;\n}\n\n/**\n * Defines the available internal logging levels for the diagnostic logger, the numeric values\n * of the levels are defined to match the original values from the initial LogLevel to avoid\n * compatibility/migration issues for any implementation that assume the numeric ordering.\n */\nexport enum DiagLogLevel {\n  /** Diagnostic Logging level setting to disable all logging (except and forced logs) */\n  NONE = 0,\n\n  /** Identifies an error scenario */\n  ERROR = 30,\n\n  /** Identifies a warning scenario */\n  WARN = 50,\n\n  /** General informational log message */\n  INFO = 60,\n\n  /** General debug log message */\n  DEBUG = 70,\n\n  /**\n   * Detailed trace level logging should only be used for development, should only be set\n   * in a development environment.\n   */\n  VERBOSE = 80,\n\n  /** Used to set the logging level to include all logging */\n  ALL = 9999,\n}\n\n/**\n * Defines options for ComponentLogger\n */\nexport interface ComponentLoggerOptions {\n  namespace: string;\n}\n\nexport interface DiagLoggerOptions {\n  /**\n   * The {@link DiagLogLevel} used to filter logs sent to the logger.\n   *\n   * @defaultValue DiagLogLevel.INFO\n   */\n  logLevel?: DiagLogLevel;\n\n  /**\n   * Setting this value to `true` will suppress the warning message normally emitted when registering a logger when another logger is already registered.\n   */\n  suppressOverrideMessage?: boolean;\n}\n\nexport interface DiagLoggerApi {\n  /**\n   * Set the global DiagLogger and DiagLogLevel.\n   * If a global diag logger is already set, this will override it.\n   *\n   * @param logger - The {@link DiagLogger} instance to set as the default logger.\n   * @param options - A {@link DiagLoggerOptions} object. If not provided, default values will be set.\n   * @returns `true` if the logger was successfully registered, else `false`\n   */\n  setLogger(logger: DiagLogger, options?: DiagLoggerOptions): boolean;\n\n  /**\n   *\n   * @param logger - The {@link DiagLogger} instance to set as the default logger.\n   * @param logLevel - The {@link DiagLogLevel} used to filter logs sent to the logger. If not provided it will default to {@link DiagLogLevel.INFO}.\n   * @returns `true` if the logger was successfully registered, else `false`\n   */\n  setLogger(logger: DiagLogger, logLevel?: DiagLogLevel): boolean;\n}\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { DiagLogFunction, DiagLogger, DiagLogLevel } from '../types';\n\nexport function createLogLevelDiagLogger(\n  maxLevel: DiagLogLevel,\n  logger: DiagLogger\n): DiagLogger {\n  if (maxLevel < DiagLogLevel.NONE) {\n    maxLevel = DiagLogLevel.NONE;\n  } else if (maxLevel > DiagLogLevel.ALL) {\n    maxLevel = DiagLogLevel.ALL;\n  }\n\n  // In case the logger is null or undefined\n  logger = logger || {};\n\n  function _filterFunc(\n    funcName: keyof DiagLogger,\n    theLevel: DiagLogLevel\n  ): DiagLogFunction {\n    const theFunc = logger[funcName];\n\n    if (typeof theFunc === 'function' && maxLevel >= theLevel) {\n      return theFunc.bind(logger);\n    }\n    return function () {};\n  }\n\n  return {\n    error: _filterFunc('error', DiagLogLevel.ERROR),\n    warn: _filterFunc('warn', DiagLogLevel.WARN),\n    info: _filterFunc('info', DiagLogLevel.INFO),\n    debug: _filterFunc('debug', DiagLogLevel.DEBUG),\n    verbose: _filterFunc('verbose', DiagLogLevel.VERBOSE),\n  };\n}\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { DiagComponentLogger } from '../diag/ComponentLogger';\nimport { createLogLevelDiagLogger } from '../diag/internal/logLevelLogger';\nimport {\n  ComponentLoggerOptions,\n  DiagLogFunction,\n  DiagLogger,\n  DiagLoggerApi,\n  DiagLogLevel,\n} from '../diag/types';\nimport {\n  getGlobal,\n  registerGlobal,\n  unregisterGlobal,\n} from '../internal/global-utils';\n\nconst API_NAME = 'diag';\n\n/**\n * Singleton object which represents the entry point to the OpenTelemetry internal\n * diagnostic API\n */\nexport class DiagAPI implements DiagLogger, DiagLoggerApi {\n  private static _instance?: DiagAPI;\n\n  /** Get the singleton instance of the DiagAPI API */\n  public static instance(): DiagAPI {\n    if (!this._instance) {\n      this._instance = new DiagAPI();\n    }\n\n    return this._instance;\n  }\n\n  /**\n   * Private internal constructor\n   * @private\n   */\n  private constructor() {\n    function _logProxy(funcName: keyof DiagLogger): DiagLogFunction {\n      return function (...args) {\n        const logger = getGlobal('diag');\n        // shortcut if logger not set\n        if (!logger) return;\n        return logger[funcName](...args);\n      };\n    }\n\n    // Using self local variable for minification purposes as 'this' cannot be minified\n    const self = this;\n\n    // DiagAPI specific functions\n\n    const setLogger: DiagLoggerApi['setLogger'] = (\n      logger,\n      optionsOrLogLevel = { logLevel: DiagLogLevel.INFO }\n    ) => {\n      if (logger === self) {\n        // There isn't much we can do here.\n        // Logging to the console might break the user application.\n        // Try to log to self. If a logger was previously registered it will receive the log.\n        const err = new Error(\n          'Cannot use diag as the logger for itself. Please use a DiagLogger implementation like ConsoleDiagLogger or a custom implementation'\n        );\n        self.error(err.stack ?? err.message);\n        return false;\n      }\n\n      if (typeof optionsOrLogLevel === 'number') {\n        optionsOrLogLevel = {\n          logLevel: optionsOrLogLevel,\n        };\n      }\n\n      const oldLogger = getGlobal('diag');\n      const newLogger = createLogLevelDiagLogger(\n        optionsOrLogLevel.logLevel ?? DiagLogLevel.INFO,\n        logger\n      );\n      // There already is an logger registered. We'll let it know before overwriting it.\n      if (oldLogger && !optionsOrLogLevel.suppressOverrideMessage) {\n        const stack = new Error().stack ?? '<failed to generate stacktrace>';\n        oldLogger.warn(`Current logger will be overwritten from ${stack}`);\n        newLogger.warn(\n          `Current logger will overwrite one already registered from ${stack}`\n        );\n      }\n\n      return registerGlobal('diag', newLogger, self, true);\n    };\n\n    self.setLogger = setLogger;\n\n    self.disable = () => {\n      unregisterGlobal(API_NAME, self);\n    };\n\n    self.createComponentLogger = (options: ComponentLoggerOptions) => {\n      return new DiagComponentLogger(options);\n    };\n\n    self.verbose = _logProxy('verbose');\n    self.debug = _logProxy('debug');\n    self.info = _logProxy('info');\n    self.warn = _logProxy('warn');\n    self.error = _logProxy('error');\n  }\n\n  public setLogger!: DiagLoggerApi['setLogger'];\n  /**\n   *\n   */\n  public createComponentLogger!: (\n    options: ComponentLoggerOptions\n  ) => DiagLogger;\n\n  // DiagLogger implementation\n  public verbose!: DiagLogFunction;\n  public debug!: DiagLogFunction;\n  public info!: DiagLogFunction;\n  public warn!: DiagLogFunction;\n  public error!: DiagLogFunction;\n\n  /**\n   * Unregister the global logger and return to Noop\n   */\n  public disable!: () => void;\n}\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Context } from './types';\n\n/** Get a key to uniquely identify a context value */\nexport function createContextKey(description: string) {\n  // The specification states that for the same input, multiple calls should\n  // return different keys. Due to the nature of the JS dependency management\n  // system, this creates problems where multiple versions of some package\n  // could hold different keys for the same property.\n  //\n  // Therefore, we use Symbol.for which returns the same key for the same input.\n  return Symbol.for(description);\n}\n\nclass BaseContext implements Context {\n  private _currentContext!: Map<symbol, unknown>;\n\n  /**\n   * Construct a new context which inherits values from an optional parent context.\n   *\n   * @param parentContext a context from which to inherit values\n   */\n  constructor(parentContext?: Map<symbol, unknown>) {\n    // for minification\n    const self = this;\n\n    self._currentContext = parentContext ? new Map(parentContext) : new Map();\n\n    self.getValue = (key: symbol) => self._currentContext.get(key);\n\n    self.setValue = (key: symbol, value: unknown): Context => {\n      const context = new BaseContext(self._currentContext);\n      context._currentContext.set(key, value);\n      return context;\n    };\n\n    self.deleteValue = (key: symbol): Context => {\n      const context = new BaseContext(self._currentContext);\n      context._currentContext.delete(key);\n      return context;\n    };\n  }\n\n  /**\n   * Get a value from the context.\n   *\n   * @param key key which identifies a context value\n   */\n  public getValue!: (key: symbol) => unknown;\n\n  /**\n   * Create a new context which inherits from this context and has\n   * the given key set to the given value.\n   *\n   * @param key context key for which to set the value\n   * @param value value to set for the given key\n   */\n  public setValue!: (key: symbol, value: unknown) => Context;\n\n  /**\n   * Return a new context which inherits from this context but does\n   * not contain a value for the given key.\n   *\n   * @param key context key for which to clear a value\n   */\n  public deleteValue!: (key: symbol) => Context;\n}\n\n/** The root context is used as the default parent context when there is no active context */\nexport const ROOT_CONTEXT: Context = new BaseContext();\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { ROOT_CONTEXT } from './context';\nimport * as types from './types';\n\nexport class NoopContextManager implements types.ContextManager {\n  active(): types.Context {\n    return ROOT_CONTEXT;\n  }\n\n  with<A extends unknown[], F extends (...args: A) => ReturnType<F>>(\n    _context: types.Context,\n    fn: F,\n    thisArg?: ThisParameterType<F>,\n    ...args: A\n  ): ReturnType<F> {\n    return fn.call(thisArg, ...args);\n  }\n\n  bind<T>(_context: types.Context, target: T): T {\n    return target;\n  }\n\n  enable(): this {\n    return this;\n  }\n\n  disable(): this {\n    return this;\n  }\n}\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { NoopContextManager } from '../context/NoopContextManager';\nimport { Context, ContextManager } from '../context/types';\nimport {\n  getGlobal,\n  registerGlobal,\n  unregisterGlobal,\n} from '../internal/global-utils';\nimport { DiagAPI } from './diag';\n\nconst API_NAME = 'context';\nconst NOOP_CONTEXT_MANAGER = new NoopContextManager();\n\n/**\n * Singleton object which represents the entry point to the OpenTelemetry Context API\n */\nexport class ContextAPI {\n  private static _instance?: ContextAPI;\n\n  /** Empty private constructor prevents end users from constructing a new instance of the API */\n  private constructor() {}\n\n  /** Get the singleton instance of the Context API */\n  public static getInstance(): ContextAPI {\n    if (!this._instance) {\n      this._instance = new ContextAPI();\n    }\n\n    return this._instance;\n  }\n\n  /**\n   * Set the current context manager.\n   *\n   * @returns true if the context manager was successfully registered, else false\n   */\n  public setGlobalContextManager(contextManager: ContextManager): boolean {\n    return registerGlobal(API_NAME, contextManager, DiagAPI.instance());\n  }\n\n  /**\n   * Get the currently active context\n   */\n  public active(): Context {\n    return this._getContextManager().active();\n  }\n\n  /**\n   * Execute a function with an active context\n   *\n   * @param context context to be active during function execution\n   * @param fn function to execute in a context\n   * @param thisArg optional receiver to be used for calling fn\n   * @param args optional arguments forwarded to fn\n   */\n  public with<A extends unknown[], F extends (...args: A) => ReturnType<F>>(\n    context: Context,\n    fn: F,\n    thisArg?: ThisParameterType<F>,\n    ...args: A\n  ): ReturnType<F> {\n    return this._getContextManager().with(context, fn, thisArg, ...args);\n  }\n\n  /**\n   * Bind a context to a target function or event emitter\n   *\n   * @param context context to bind to the event emitter or function. Defaults to the currently active context\n   * @param target function or event emitter to bind\n   */\n  public bind<T>(context: Context, target: T): T {\n    return this._getContextManager().bind(context, target);\n  }\n\n  private _getContextManager(): ContextManager {\n    return getGlobal(API_NAME) || NOOP_CONTEXT_MANAGER;\n  }\n\n  /** Disable and remove the global context manager */\n  public disable() {\n    this._getContextManager().disable();\n    unregisterGlobal(API_NAME, DiagAPI.instance());\n  }\n}\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nexport enum TraceFlags {\n  /** Represents no flag set. */\n  NONE = 0x0,\n  /** Bit to represent whether trace is sampled in trace flags. */\n  SAMPLED = 0x1 << 0,\n}\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { SpanContext } from './span_context';\nimport { TraceFlags } from './trace_flags';\n\nexport const INVALID_SPANID = '0000000000000000';\nexport const INVALID_TRACEID = '00000000000000000000000000000000';\nexport const INVALID_SPAN_CONTEXT: SpanContext = {\n  traceId: INVALID_TRACEID,\n  spanId: INVALID_SPANID,\n  traceFlags: TraceFlags.NONE,\n};\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Exception } from '../common/Exception';\nimport { TimeInput } from '../common/Time';\nimport { SpanAttributes } from './attributes';\nimport { INVALID_SPAN_CONTEXT } from './invalid-span-constants';\nimport { Span } from './span';\nimport { SpanContext } from './span_context';\nimport { SpanStatus } from './status';\nimport { Link } from './link';\n\n/**\n * The NonRecordingSpan is the default {@link Span} that is used when no Span\n * implementation is available. All operations are no-op including context\n * propagation.\n */\nexport class NonRecordingSpan implements Span {\n  constructor(\n    private readonly _spanContext: SpanContext = INVALID_SPAN_CONTEXT\n  ) {}\n\n  // Returns a SpanContext.\n  spanContext(): SpanContext {\n    return this._spanContext;\n  }\n\n  // By default does nothing\n  setAttribute(_key: string, _value: unknown): this {\n    return this;\n  }\n\n  // By default does nothing\n  setAttributes(_attributes: SpanAttributes): this {\n    return this;\n  }\n\n  // By default does nothing\n  addEvent(_name: string, _attributes?: SpanAttributes): this {\n    return this;\n  }\n\n  addLink(_link: Link): this {\n    return this;\n  }\n\n  addLinks(_links: Link[]): this {\n    return this;\n  }\n\n  // By default does nothing\n  setStatus(_status: SpanStatus): this {\n    return this;\n  }\n\n  // By default does nothing\n  updateName(_name: string): this {\n    return this;\n  }\n\n  // By default does nothing\n  end(_endTime?: TimeInput): void {}\n\n  // isRecording always returns false for NonRecordingSpan.\n  isRecording(): boolean {\n    return false;\n  }\n\n  // By default does nothing\n  recordException(_exception: Exception, _time?: TimeInput): void {}\n}\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { createContextKey } from '../context/context';\nimport { Context } from '../context/types';\nimport { Span } from './span';\nimport { SpanContext } from './span_context';\nimport { NonRecordingSpan } from './NonRecordingSpan';\nimport { ContextAPI } from '../api/context';\n\n/**\n * span key\n */\nconst SPAN_KEY = createContextKey('OpenTelemetry Context Key SPAN');\n\n/**\n * Return the span if one exists\n *\n * @param context context to get span from\n */\nexport function getSpan(context: Context): Span | undefined {\n  return (context.getValue(SPAN_KEY) as Span) || undefined;\n}\n\n/**\n * Gets the span from the current context, if one exists.\n */\nexport function getActiveSpan(): Span | undefined {\n  return getSpan(ContextAPI.getInstance().active());\n}\n\n/**\n * Set the span on a context\n *\n * @param context context to use as parent\n * @param span span to set active\n */\nexport function setSpan(context: Context, span: Span): Context {\n  return context.setValue(SPAN_KEY, span);\n}\n\n/**\n * Remove current span stored in the context\n *\n * @param context context to delete span from\n */\nexport function deleteSpan(context: Context): Context {\n  return context.deleteValue(SPAN_KEY);\n}\n\n/**\n * Wrap span context in a NoopSpan and set as span in a new\n * context\n *\n * @param context context to set active span on\n * @param spanContext span context to be wrapped\n */\nexport function setSpanContext(\n  context: Context,\n  spanContext: SpanContext\n): Context {\n  return setSpan(context, new NonRecordingSpan(spanContext));\n}\n\n/**\n * Get the span context of the span if it exists.\n *\n * @param context context to get values from\n */\nexport function getSpanContext(context: Context): SpanContext | undefined {\n  return getSpan(context)?.spanContext();\n}\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nimport { INVALID_SPANID, INVALID_TRACEID } from './invalid-span-constants';\nimport { NonRecordingSpan } from './NonRecordingSpan';\nimport { Span } from './span';\nimport { SpanContext } from './span_context';\n\nconst VALID_TRACEID_REGEX = /^([0-9a-f]{32})$/i;\nconst VALID_SPANID_REGEX = /^[0-9a-f]{16}$/i;\n\nexport function isValidTraceId(traceId: string): boolean {\n  return VALID_TRACEID_REGEX.test(traceId) && traceId !== INVALID_TRACEID;\n}\n\nexport function isValidSpanId(spanId: string): boolean {\n  return VALID_SPANID_REGEX.test(spanId) && spanId !== INVALID_SPANID;\n}\n\n/**\n * Returns true if this {@link SpanContext} is valid.\n * @return true if this {@link SpanContext} is valid.\n */\nexport function isSpanContextValid(spanContext: SpanContext): boolean {\n  return (\n    isValidTraceId(spanContext.traceId) && isValidSpanId(spanContext.spanId)\n  );\n}\n\n/**\n * Wrap the given {@link SpanContext} in a new non-recording {@link Span}\n *\n * @param spanContext span context to be wrapped\n * @returns a new non-recording {@link Span} with the provided context\n */\nexport function wrapSpanContext(spanContext: SpanContext): Span {\n  return new NonRecordingSpan(spanContext);\n}\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { ContextAPI } from '../api/context';\nimport { Context } from '../context/types';\nimport { getSpanContext, setSpan } from '../trace/context-utils';\nimport { NonRecordingSpan } from './NonRecordingSpan';\nimport { Span } from './span';\nimport { isSpanContextValid } from './spancontext-utils';\nimport { SpanOptions } from './SpanOptions';\nimport { SpanContext } from './span_context';\nimport { Tracer } from './tracer';\n\nconst contextApi = ContextAPI.getInstance();\n\n/**\n * No-op implementations of {@link Tracer}.\n */\nexport class NoopTracer implements Tracer {\n  // startSpan starts a noop span.\n  startSpan(\n    name: string,\n    options?: SpanOptions,\n    context = contextApi.active()\n  ): Span {\n    const root = Boolean(options?.root);\n    if (root) {\n      return new NonRecordingSpan();\n    }\n\n    const parentFromContext = context && getSpanContext(context);\n\n    if (\n      isSpanContext(parentFromContext) &&\n      isSpanContextValid(parentFromContext)\n    ) {\n      return new NonRecordingSpan(parentFromContext);\n    } else {\n      return new NonRecordingSpan();\n    }\n  }\n\n  startActiveSpan<F extends (span: Span) => ReturnType<F>>(\n    name: string,\n    fn: F\n  ): ReturnType<F>;\n  startActiveSpan<F extends (span: Span) => ReturnType<F>>(\n    name: string,\n    opts: SpanOptions | undefined,\n    fn: F\n  ): ReturnType<F>;\n  startActiveSpan<F extends (span: Span) => ReturnType<F>>(\n    name: string,\n    opts: SpanOptions | undefined,\n    ctx: Context | undefined,\n    fn: F\n  ): ReturnType<F>;\n  startActiveSpan<F extends (span: Span) => ReturnType<F>>(\n    name: string,\n    arg2?: F | SpanOptions,\n    arg3?: F | Context,\n    arg4?: F\n  ): ReturnType<F> | undefined {\n    let opts: SpanOptions | undefined;\n    let ctx: Context | undefined;\n    let fn: F;\n\n    if (arguments.length < 2) {\n      return;\n    } else if (arguments.length === 2) {\n      fn = arg2 as F;\n    } else if (arguments.length === 3) {\n      opts = arg2 as SpanOptions | undefined;\n      fn = arg3 as F;\n    } else {\n      opts = arg2 as SpanOptions | undefined;\n      ctx = arg3 as Context | undefined;\n      fn = arg4 as F;\n    }\n\n    const parentContext = ctx ?? contextApi.active();\n    const span = this.startSpan(name, opts, parentContext);\n    const contextWithSpanSet = setSpan(parentContext, span);\n\n    return contextApi.with(contextWithSpanSet, fn, undefined, span);\n  }\n}\n\nfunction isSpanContext(spanContext: any): spanContext is SpanContext {\n  return (\n    typeof spanContext === 'object' &&\n    typeof spanContext['spanId'] === 'string' &&\n    typeof spanContext['traceId'] === 'string' &&\n    typeof spanContext['traceFlags'] === 'number'\n  );\n}\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Context } from '../context/types';\nimport { NoopTracer } from './NoopTracer';\nimport { Span } from './span';\nimport { SpanOptions } from './SpanOptions';\nimport { Tracer } from './tracer';\nimport { TracerOptions } from './tracer_options';\n\nconst NOOP_TRACER = new NoopTracer();\n\n/**\n * Proxy tracer provided by the proxy tracer provider\n */\nexport class ProxyTracer implements Tracer {\n  // When a real implementation is provided, this will be it\n  private _delegate?: Tracer;\n\n  constructor(\n    private _provider: TracerDelegator,\n    public readonly name: string,\n    public readonly version?: string,\n    public readonly options?: TracerOptions\n  ) {}\n\n  startSpan(name: string, options?: SpanOptions, context?: Context): Span {\n    return this._getTracer().startSpan(name, options, context);\n  }\n\n  startActiveSpan<F extends (span: Span) => unknown>(\n    _name: string,\n    _options: F | SpanOptions,\n    _context?: F | Context,\n    _fn?: F\n  ): ReturnType<F> {\n    const tracer = this._getTracer();\n    return Reflect.apply(tracer.startActiveSpan, tracer, arguments);\n  }\n\n  /**\n   * Try to get a tracer from the proxy tracer provider.\n   * If the proxy tracer provider has no delegate, return a noop tracer.\n   */\n  private _getTracer() {\n    if (this._delegate) {\n      return this._delegate;\n    }\n\n    const tracer = this._provider.getDelegateTracer(\n      this.name,\n      this.version,\n      this.options\n    );\n\n    if (!tracer) {\n      return NOOP_TRACER;\n    }\n\n    this._delegate = tracer;\n    return this._delegate;\n  }\n}\n\nexport interface TracerDelegator {\n  getDelegateTracer(\n    name: string,\n    version?: string,\n    options?: TracerOptions\n  ): Tracer | undefined;\n}\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { NoopTracer } from './NoopTracer';\nimport { Tracer } from './tracer';\nimport { TracerOptions } from './tracer_options';\nimport { TracerProvider } from './tracer_provider';\n\n/**\n * An implementation of the {@link TracerProvider} which returns an impotent\n * Tracer for all calls to `getTracer`.\n *\n * All operations are no-op.\n */\nexport class NoopTracerProvider implements TracerProvider {\n  getTracer(\n    _name?: string,\n    _version?: string,\n    _options?: TracerOptions\n  ): Tracer {\n    return new NoopTracer();\n  }\n}\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Tracer } from './tracer';\nimport { TracerProvider } from './tracer_provider';\nimport { ProxyTracer } from './ProxyTracer';\nimport { NoopTracerProvider } from './NoopTracerProvider';\nimport { TracerOptions } from './tracer_options';\n\nconst NOOP_TRACER_PROVIDER = new NoopTracerProvider();\n\n/**\n * Tracer provider which provides {@link ProxyTracer}s.\n *\n * Before a delegate is set, tracers provided are NoOp.\n *   When a delegate is set, traces are provided from the delegate.\n *   When a delegate is set after tracers have already been provided,\n *   all tracers already provided will use the provided delegate implementation.\n */\nexport class ProxyTracerProvider implements TracerProvider {\n  private _delegate?: TracerProvider;\n\n  /**\n   * Get a {@link ProxyTracer}\n   */\n  getTracer(name: string, version?: string, options?: TracerOptions): Tracer {\n    return (\n      this.getDelegateTracer(name, version, options) ??\n      new ProxyTracer(this, name, version, options)\n    );\n  }\n\n  getDelegate(): TracerProvider {\n    return this._delegate ?? NOOP_TRACER_PROVIDER;\n  }\n\n  /**\n   * Set the delegate tracer provider\n   */\n  setDelegate(delegate: TracerProvider) {\n    this._delegate = delegate;\n  }\n\n  getDelegateTracer(\n    name: string,\n    version?: string,\n    options?: TracerOptions\n  ): Tracer | undefined {\n    return this._delegate?.getTracer(name, version, options);\n  }\n}\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nexport interface SpanStatus {\n  /** The status code of this message. */\n  code: SpanStatusCode;\n  /** A developer-facing error message. */\n  message?: string;\n}\n\n/**\n * An enumeration of status codes.\n */\nexport enum SpanStatusCode {\n  /**\n   * The default status.\n   */\n  UNSET = 0,\n  /**\n   * The operation has been validated by an Application developer or\n   * Operator to have completed successfully.\n   */\n  OK = 1,\n  /**\n   * The operation contains an error.\n   */\n  ERROR = 2,\n}\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  getGlobal,\n  registerGlobal,\n  unregisterGlobal,\n} from '../internal/global-utils';\nimport { ProxyTracerProvider } from '../trace/ProxyTracerProvider';\nimport {\n  isSpanContextValid,\n  wrapSpanContext,\n} from '../trace/spancontext-utils';\nimport { Tracer } from '../trace/tracer';\nimport { TracerProvider } from '../trace/tracer_provider';\nimport {\n  deleteSpan,\n  getActiveSpan,\n  getSpan,\n  getSpanContext,\n  setSpan,\n  setSpanContext,\n} from '../trace/context-utils';\nimport { DiagAPI } from './diag';\n\nconst API_NAME = 'trace';\n\n/**\n * Singleton object which represents the entry point to the OpenTelemetry Tracing API\n */\nexport class TraceAPI {\n  private static _instance?: TraceAPI;\n\n  private _proxyTracerProvider = new ProxyTracerProvider();\n\n  /** Empty private constructor prevents end users from constructing a new instance of the API */\n  private constructor() {}\n\n  /** Get the singleton instance of the Trace API */\n  public static getInstance(): TraceAPI {\n    if (!this._instance) {\n      this._instance = new TraceAPI();\n    }\n\n    return this._instance;\n  }\n\n  /**\n   * Set the current global tracer.\n   *\n   * @returns true if the tracer provider was successfully registered, else false\n   */\n  public setGlobalTracerProvider(provider: TracerProvider): boolean {\n    const success = registerGlobal(\n      API_NAME,\n      this._proxyTracerProvider,\n      DiagAPI.instance()\n    );\n    if (success) {\n      this._proxyTracerProvider.setDelegate(provider);\n    }\n    return success;\n  }\n\n  /**\n   * Returns the global tracer provider.\n   */\n  public getTracerProvider(): TracerProvider {\n    return getGlobal(API_NAME) || this._proxyTracerProvider;\n  }\n\n  /**\n   * Returns a tracer from the global tracer provider.\n   */\n  public getTracer(name: string, version?: string): Tracer {\n    return this.getTracerProvider().getTracer(name, version);\n  }\n\n  /** Remove the global tracer provider */\n  public disable() {\n    unregisterGlobal(API_NAME, DiagAPI.instance());\n    this._proxyTracerProvider = new ProxyTracerProvider();\n  }\n\n  public wrapSpanContext = wrapSpanContext;\n\n  public isSpanContextValid = isSpanContextValid;\n\n  public deleteSpan = deleteSpan;\n\n  public getSpan = getSpan;\n\n  public getActiveSpan = getActiveSpan;\n\n  public getSpanContext = getSpanContext;\n\n  public setSpan = setSpan;\n\n  public setSpanContext = setSpanContext;\n}\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n// Split module-level variable definition into separate files to allow\n// tree-shaking on each api instance.\nimport { TraceAPI } from './api/trace';\n/** Entrypoint for trace API */\nexport const trace = TraceAPI.getInstance();\n","import {\n  ImageModelV2CallWarning,\n  LanguageModelV2CallWarning,\n  SpeechModelV2CallWarning,\n  TranscriptionModelV2CallWarning,\n} from '@ai-sdk/provider';\n\nexport type Warning =\n  | LanguageModelV2CallWarning\n  | ImageModelV2CallWarning\n  | SpeechModelV2CallWarning\n  | TranscriptionModelV2CallWarning;\n\nexport type LogWarningsFunction = (warnings: Warning[]) => void;\n\n/**\n * Formats a warning object into a human-readable string with clear AI SDK branding\n */\nfunction formatWarning(warning: Warning): string {\n  const prefix = 'AI SDK Warning:';\n\n  switch (warning.type) {\n    case 'unsupported-setting': {\n      let message = `${prefix} The \"${warning.setting}\" setting is not supported by this model`;\n      if (warning.details) {\n        message += ` - ${warning.details}`;\n      }\n      return message;\n    }\n\n    case 'unsupported-tool': {\n      const toolName =\n        'name' in warning.tool ? warning.tool.name : 'unknown tool';\n      let message = `${prefix} The tool \"${toolName}\" is not supported by this model`;\n      if (warning.details) {\n        message += ` - ${warning.details}`;\n      }\n      return message;\n    }\n\n    case 'other': {\n      return `${prefix} ${warning.message}`;\n    }\n\n    default: {\n      // Fallback for any unknown warning types\n      return `${prefix} ${JSON.stringify(warning, null, 2)}`;\n    }\n  }\n}\n\nexport const FIRST_WARNING_INFO_MESSAGE =\n  'AI SDK Warning System: To turn off warning logging, set the AI_SDK_LOG_WARNINGS global to false.';\n\nlet hasLoggedBefore = false;\n\nexport const logWarnings: LogWarningsFunction = warnings => {\n  // if the warnings array is empty, do nothing\n  if (warnings.length === 0) {\n    return;\n  }\n\n  const logger = globalThis.AI_SDK_LOG_WARNINGS;\n\n  // if the logger is set to false, do nothing\n  if (logger === false) {\n    return;\n  }\n\n  // use the provided logger if it is a function\n  if (typeof logger === 'function') {\n    logger(warnings);\n    return;\n  }\n\n  // display information note on first call\n  if (!hasLoggedBefore) {\n    hasLoggedBefore = true;\n    console.info(FIRST_WARNING_INFO_MESSAGE);\n  }\n\n  // default behavior: log warnings to the console\n  for (const warning of warnings) {\n    console.warn(formatWarning(warning));\n  }\n};\n\n// Reset function for testing purposes\nexport const resetLogWarningsState = () => {\n  hasLoggedBefore = false;\n};\n","import { AISDKError } from '@ai-sdk/provider';\n\nconst name = 'AI_InvalidArgumentError';\nconst marker = `vercel.ai.error.${name}`;\nconst symbol = Symbol.for(marker);\n\nexport class InvalidArgumentError extends AISDKError {\n  private readonly [symbol] = true; // used in isInstance\n\n  readonly parameter: string;\n  readonly value: unknown;\n\n  constructor({\n    parameter,\n    value,\n    message,\n  }: {\n    parameter: string;\n    value: unknown;\n    message: string;\n  }) {\n    super({\n      name,\n      message: `Invalid argument for parameter ${parameter}: ${message}`,\n    });\n\n    this.parameter = parameter;\n    this.value = value;\n  }\n\n  static isInstance(error: unknown): error is InvalidArgumentError {\n    return AISDKError.hasMarker(error, marker);\n  }\n}\n","import { AISDKError } from '@ai-sdk/provider';\nimport { FinishReason } from '../types/language-model';\nimport { LanguageModelResponseMetadata } from '../types/language-model-response-metadata';\nimport { LanguageModelUsage } from '../types/usage';\n\nconst name = 'AI_NoObjectGeneratedError';\nconst marker = `vercel.ai.error.${name}`;\nconst symbol = Symbol.for(marker);\n\n/**\nThrown when no object could be generated. This can have several causes:\n\n- The model failed to generate a response.\n- The model generated a response that could not be parsed.\n- The model generated a response that could not be validated against the schema.\n\nThe error contains the following properties:\n\n- `text`: The text that was generated by the model. This can be the raw text or the tool call text, depending on the model.\n */\nexport class NoObjectGeneratedError extends AISDKError {\n  private readonly [symbol] = true; // used in isInstance\n\n  /**\n  The text that was generated by the model. This can be the raw text or the tool call text, depending on the model.\n   */\n  readonly text: string | undefined;\n\n  /**\n  The response metadata.\n   */\n  readonly response: LanguageModelResponseMetadata | undefined;\n\n  /**\n  The usage of the model.\n   */\n  readonly usage: LanguageModelUsage | undefined;\n\n  /**\n  Reason why the model finished generating a response.\n   */\n  readonly finishReason: FinishReason | undefined;\n\n  constructor({\n    message = 'No object generated.',\n    cause,\n    text,\n    response,\n    usage,\n    finishReason,\n  }: {\n    message?: string;\n    cause?: Error;\n    text?: string;\n    response: LanguageModelResponseMetadata;\n    usage: LanguageModelUsage;\n    finishReason: FinishReason;\n  }) {\n    super({ name, message, cause });\n\n    this.text = text;\n    this.response = response;\n    this.usage = usage;\n    this.finishReason = finishReason;\n  }\n\n  static isInstance(error: unknown): error is NoObjectGeneratedError {\n    return AISDKError.hasMarker(error, marker);\n  }\n}\n","import { AISDKError } from '@ai-sdk/provider';\nimport { SpeechModelResponseMetadata } from '../types/speech-model-response-metadata';\n\n/**\nError that is thrown when no speech audio was generated.\n */\nexport class NoSpeechGeneratedError extends AISDKError {\n  readonly responses: Array<SpeechModelResponseMetadata>;\n\n  constructor(options: { responses: Array<SpeechModelResponseMetadata> }) {\n    super({\n      name: 'AI_NoSpeechGeneratedError',\n      message: 'No speech audio generated.',\n    });\n\n    this.responses = options.responses;\n  }\n}\n","import { AISDKError } from '@ai-sdk/provider';\n\n/**\nError that is thrown when a model with an unsupported version is used.\n */\nexport class UnsupportedModelVersionError extends AISDKError {\n  readonly version: string;\n  readonly provider: string;\n  readonly modelId: string;\n\n  constructor(options: { version: string; provider: string; modelId: string }) {\n    super({\n      name: 'AI_UnsupportedModelVersionError',\n      message:\n        `Unsupported model version ${options.version} for provider \"${options.provider}\" and model \"${options.modelId}\". ` +\n        `AI SDK 5 only supports models that implement specification version \"v2\".`,\n    });\n\n    this.version = options.version;\n    this.provider = options.provider;\n    this.modelId = options.modelId;\n  }\n}\n","import { AISDKError } from '@ai-sdk/provider';\n\nconst name = 'AI_InvalidDataContentError';\nconst marker = `vercel.ai.error.${name}`;\nconst symbol = Symbol.for(marker);\n\nexport class InvalidDataContentError extends AISDKError {\n  private readonly [symbol] = true; // used in isInstance\n\n  readonly content: unknown;\n\n  constructor({\n    content,\n    cause,\n    message = `Invalid data content. Expected a base64 string, Uint8Array, ArrayBuffer, or Buffer, but got ${typeof content}.`,\n  }: {\n    content: unknown;\n    cause?: unknown;\n    message?: string;\n  }) {\n    super({ name, message, cause });\n\n    this.content = content;\n  }\n\n  static isInstance(error: unknown): error is InvalidDataContentError {\n    return AISDKError.hasMarker(error, marker);\n  }\n}\n","import { AISDKError } from '@ai-sdk/provider';\nimport { UIMessage } from '../ui/ui-messages';\n\nconst name = 'AI_MessageConversionError';\nconst marker = `vercel.ai.error.${name}`;\nconst symbol = Symbol.for(marker);\n\nexport class MessageConversionError extends AISDKError {\n  private readonly [symbol] = true; // used in isInstance\n\n  readonly originalMessage: Omit<UIMessage, 'id'>;\n\n  constructor({\n    originalMessage,\n    message,\n  }: {\n    originalMessage: Omit<UIMessage, 'id'>;\n    message: string;\n  }) {\n    super({ name, message });\n\n    this.originalMessage = originalMessage;\n  }\n\n  static isInstance(error: unknown): error is MessageConversionError {\n    return AISDKError.hasMarker(error, marker);\n  }\n}\n","import { AISDKError } from '@ai-sdk/provider';\n\nconst name = 'AI_DownloadError';\nconst marker = `vercel.ai.error.${name}`;\nconst symbol = Symbol.for(marker);\n\nexport class DownloadError extends AISDKError {\n  private readonly [symbol] = true; // used in isInstance\n\n  readonly url: string;\n  readonly statusCode?: number;\n  readonly statusText?: string;\n\n  constructor({\n    url,\n    statusCode,\n    statusText,\n    cause,\n    message = cause == null\n      ? `Failed to download ${url}: ${statusCode} ${statusText}`\n      : `Failed to download ${url}: ${cause}`,\n  }: {\n    url: string;\n    statusCode?: number;\n    statusText?: string;\n    message?: string;\n    cause?: unknown;\n  }) {\n    super({ name, message, cause });\n\n    this.url = url;\n    this.statusCode = statusCode;\n    this.statusText = statusText;\n  }\n\n  static isInstance(error: unknown): error is DownloadError {\n    return AISDKError.hasMarker(error, marker);\n  }\n}\n","import { AISDKError } from '@ai-sdk/provider';\n\nconst name = 'AI_RetryError';\nconst marker = `vercel.ai.error.${name}`;\nconst symbol = Symbol.for(marker);\n\nexport type RetryErrorReason =\n  | 'maxRetriesExceeded'\n  | 'errorNotRetryable'\n  | 'abort';\n\nexport class RetryError extends AISDKError {\n  private readonly [symbol] = true; // used in isInstance\n\n  // note: property order determines debugging output\n  readonly reason: RetryErrorReason;\n  readonly lastError: unknown;\n  readonly errors: Array<unknown>;\n\n  constructor({\n    message,\n    reason,\n    errors,\n  }: {\n    message: string;\n    reason: RetryErrorReason;\n    errors: Array<unknown>;\n  }) {\n    super({ name, message });\n\n    this.reason = reason;\n    this.errors = errors;\n\n    // separate our last error to make debugging via log easier:\n    this.lastError = errors[errors.length - 1];\n  }\n\n  static isInstance(error: unknown): error is RetryError {\n    return AISDKError.hasMarker(error, marker);\n  }\n}\n","import { gateway } from '@ai-sdk/gateway';\nimport {\n  EmbeddingModelV2,\n  ImageModelV2,\n  LanguageModelV2,\n  ProviderV2,\n} from '@ai-sdk/provider';\nimport { UnsupportedModelVersionError } from '../error';\nimport { EmbeddingModel } from '../types/embedding-model';\nimport { LanguageModel } from '../types/language-model';\nimport { ImageModel } from '../types/image-model';\n\nexport function resolveLanguageModel(model: LanguageModel): LanguageModelV2 {\n  if (typeof model !== 'string') {\n    if (model.specificationVersion !== 'v2') {\n      throw new UnsupportedModelVersionError({\n        version: model.specificationVersion,\n        provider: model.provider,\n        modelId: model.modelId,\n      });\n    }\n\n    return model;\n  }\n\n  return getGlobalProvider().languageModel(model);\n}\n\nexport function resolveEmbeddingModel<VALUE = string>(\n  model: EmbeddingModel<VALUE>,\n): EmbeddingModelV2<VALUE> {\n  if (typeof model !== 'string') {\n    if (model.specificationVersion !== 'v2') {\n      throw new UnsupportedModelVersionError({\n        version: model.specificationVersion,\n        provider: model.provider,\n        modelId: model.modelId,\n      });\n    }\n\n    return model;\n  }\n\n  // TODO AI SDK 6: figure out how to cleanly support different generic types\n  return getGlobalProvider().textEmbeddingModel(\n    model,\n  ) as EmbeddingModelV2<VALUE>;\n}\n\nexport function resolveImageModel(model: ImageModel): ImageModelV2 {\n  if (typeof model !== 'string') {\n    if (model.specificationVersion !== 'v2') {\n      throw new UnsupportedModelVersionError({\n        version: model.specificationVersion,\n        provider: model.provider,\n        modelId: model.modelId,\n      });\n    }\n\n    return model;\n  }\n\n  return getGlobalProvider().imageModel(model);\n}\n\nfunction getGlobalProvider(): ProviderV2 {\n  return globalThis.AI_SDK_DEFAULT_PROVIDER ?? gateway;\n}\n","import { convertBase64ToUint8Array } from '@ai-sdk/provider-utils';\n\nexport const imageMediaTypeSignatures = [\n  {\n    mediaType: 'image/gif' as const,\n    bytesPrefix: [0x47, 0x49, 0x46], // GIF\n  },\n  {\n    mediaType: 'image/png' as const,\n    bytesPrefix: [0x89, 0x50, 0x4e, 0x47], // PNG\n  },\n  {\n    mediaType: 'image/jpeg' as const,\n    bytesPrefix: [0xff, 0xd8], // JPEG\n  },\n  {\n    mediaType: 'image/webp' as const,\n    bytesPrefix: [\n      0x52,\n      0x49,\n      0x46,\n      0x46, // \"RIFF\"\n      null,\n      null,\n      null,\n      null, // file size (variable)\n      0x57,\n      0x45,\n      0x42,\n      0x50, // \"WEBP\"\n    ],\n  },\n  {\n    mediaType: 'image/bmp' as const,\n    bytesPrefix: [0x42, 0x4d],\n  },\n  {\n    mediaType: 'image/tiff' as const,\n    bytesPrefix: [0x49, 0x49, 0x2a, 0x00],\n  },\n  {\n    mediaType: 'image/tiff' as const,\n    bytesPrefix: [0x4d, 0x4d, 0x00, 0x2a],\n  },\n  {\n    mediaType: 'image/avif' as const,\n    bytesPrefix: [\n      0x00, 0x00, 0x00, 0x20, 0x66, 0x74, 0x79, 0x70, 0x61, 0x76, 0x69, 0x66,\n    ],\n  },\n  {\n    mediaType: 'image/heic' as const,\n    bytesPrefix: [\n      0x00, 0x00, 0x00, 0x20, 0x66, 0x74, 0x79, 0x70, 0x68, 0x65, 0x69, 0x63,\n    ],\n  },\n] as const;\n\nexport const audioMediaTypeSignatures = [\n  {\n    mediaType: 'audio/mpeg' as const,\n    bytesPrefix: [0xff, 0xfb],\n  },\n  {\n    mediaType: 'audio/mpeg' as const,\n    bytesPrefix: [0xff, 0xfa],\n  },\n  {\n    mediaType: 'audio/mpeg' as const,\n    bytesPrefix: [0xff, 0xf3],\n  },\n  {\n    mediaType: 'audio/mpeg' as const,\n    bytesPrefix: [0xff, 0xf2],\n  },\n  {\n    mediaType: 'audio/mpeg' as const,\n    bytesPrefix: [0xff, 0xe3],\n  },\n  {\n    mediaType: 'audio/mpeg' as const,\n    bytesPrefix: [0xff, 0xe2],\n  },\n  {\n    mediaType: 'audio/wav' as const,\n    bytesPrefix: [\n      0x52, // R\n      0x49, // I\n      0x46, // F\n      0x46, // F\n      null,\n      null,\n      null,\n      null,\n      0x57, // W\n      0x41, // A\n      0x56, // V\n      0x45, // E\n    ],\n  },\n  {\n    mediaType: 'audio/ogg' as const,\n    bytesPrefix: [0x4f, 0x67, 0x67, 0x53],\n  },\n  {\n    mediaType: 'audio/flac' as const,\n    bytesPrefix: [0x66, 0x4c, 0x61, 0x43],\n  },\n  {\n    mediaType: 'audio/aac' as const,\n    bytesPrefix: [0x40, 0x15, 0x00, 0x00],\n  },\n  {\n    mediaType: 'audio/mp4' as const,\n    bytesPrefix: [0x66, 0x74, 0x79, 0x70],\n  },\n  {\n    mediaType: 'audio/webm',\n    bytesPrefix: [0x1a, 0x45, 0xdf, 0xa3],\n  },\n] as const;\n\nconst stripID3 = (data: Uint8Array | string) => {\n  const bytes =\n    typeof data === 'string' ? convertBase64ToUint8Array(data) : data;\n  const id3Size =\n    ((bytes[6] & 0x7f) << 21) |\n    ((bytes[7] & 0x7f) << 14) |\n    ((bytes[8] & 0x7f) << 7) |\n    (bytes[9] & 0x7f);\n\n  // The raw MP3 starts here\n  return bytes.slice(id3Size + 10);\n};\n\nfunction stripID3TagsIfPresent(data: Uint8Array | string): Uint8Array | string {\n  const hasId3 =\n    (typeof data === 'string' && data.startsWith('SUQz')) ||\n    (typeof data !== 'string' &&\n      data.length > 10 &&\n      data[0] === 0x49 && // 'I'\n      data[1] === 0x44 && // 'D'\n      data[2] === 0x33); // '3'\n\n  return hasId3 ? stripID3(data) : data;\n}\n\n/**\n * Detect the media IANA media type of a file using a list of signatures.\n *\n * @param data - The file data.\n * @param signatures - The signatures to use for detection.\n * @returns The media type of the file.\n */\nexport function detectMediaType({\n  data,\n  signatures,\n}: {\n  data: Uint8Array | string;\n  signatures: typeof audioMediaTypeSignatures | typeof imageMediaTypeSignatures;\n}): (typeof signatures)[number]['mediaType'] | undefined {\n  const processedData = stripID3TagsIfPresent(data);\n\n  // Convert the first ~18 bytes (24 base64 chars) for consistent detection logic:\n  const bytes =\n    typeof processedData === 'string'\n      ? convertBase64ToUint8Array(\n          processedData.substring(0, Math.min(processedData.length, 24)),\n        )\n      : processedData;\n\n  for (const signature of signatures) {\n    if (\n      bytes.length >= signature.bytesPrefix.length &&\n      signature.bytesPrefix.every(\n        (byte, index) => byte === null || bytes[index] === byte,\n      )\n    ) {\n      return signature.mediaType;\n    }\n  }\n\n  return undefined;\n}\n","declare const __PACKAGE_VERSION__: string | undefined;\nexport const VERSION: string =\n  typeof __PACKAGE_VERSION__ !== 'undefined'\n    ? __PACKAGE_VERSION__\n    : '0.0.0-test';\n","import { DownloadError } from './download-error';\nimport {\n  withUserAgentSuffix,\n  getRuntimeEnvironmentUserAgent,\n} from '@ai-sdk/provider-utils';\nimport { VERSION } from '../../version';\n\n/**\n * Download a file from a URL.\n *\n * @param url - The URL to download from.\n * @returns The downloaded data and media type.\n *\n * @throws DownloadError if the download fails.\n */\nexport const download = async ({ url }: { url: URL }) => {\n  const urlText = url.toString();\n  try {\n    const response = await fetch(urlText, {\n      headers: withUserAgentSuffix(\n        {},\n        `ai-sdk/${VERSION}`,\n        getRuntimeEnvironmentUserAgent(),\n      ),\n    });\n\n    if (!response.ok) {\n      throw new DownloadError({\n        url: urlText,\n        statusCode: response.status,\n        statusText: response.statusText,\n      });\n    }\n\n    return {\n      data: new Uint8Array(await response.arrayBuffer()),\n      mediaType: response.headers.get('content-type') ?? undefined,\n    };\n  } catch (error) {\n    if (DownloadError.isInstance(error)) {\n      throw error;\n    }\n\n    throw new DownloadError({ url: urlText, cause: error });\n  }\n};\n","import { AISDKError, LanguageModelV2DataContent } from '@ai-sdk/provider';\nimport {\n  convertBase64ToUint8Array,\n  convertUint8ArrayToBase64,\n  DataContent,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\nimport { InvalidDataContentError } from './invalid-data-content-error';\nimport { splitDataUrl } from './split-data-url';\n\n/**\n@internal\n */\nexport const dataContentSchema: z.ZodType<DataContent> = z.union([\n  z.string(),\n  z.instanceof(Uint8Array),\n  z.instanceof(ArrayBuffer),\n  z.custom<Buffer>(\n    // Buffer might not be available in some environments such as CloudFlare:\n    (value: unknown): value is Buffer =>\n      globalThis.Buffer?.isBuffer(value) ?? false,\n    { message: 'Must be a Buffer' },\n  ),\n]);\n\nexport function convertToLanguageModelV2DataContent(\n  content: DataContent | URL,\n): {\n  data: LanguageModelV2DataContent;\n  mediaType: string | undefined;\n} {\n  // Buffer & Uint8Array:\n  if (content instanceof Uint8Array) {\n    return { data: content, mediaType: undefined };\n  }\n\n  // ArrayBuffer needs conversion to Uint8Array (lightweight):\n  if (content instanceof ArrayBuffer) {\n    return { data: new Uint8Array(content), mediaType: undefined };\n  }\n\n  // Attempt to create a URL from the data. If it fails, we can assume the data\n  // is not a URL and likely some other sort of data.\n  if (typeof content === 'string') {\n    try {\n      content = new URL(content);\n    } catch (error) {\n      // ignored\n    }\n  }\n\n  // Extract data from data URL:\n  if (content instanceof URL && content.protocol === 'data:') {\n    const { mediaType: dataUrlMediaType, base64Content } = splitDataUrl(\n      content.toString(),\n    );\n\n    if (dataUrlMediaType == null || base64Content == null) {\n      throw new AISDKError({\n        name: 'InvalidDataContentError',\n        message: `Invalid data URL format in content ${content.toString()}`,\n      });\n    }\n\n    return { data: base64Content, mediaType: dataUrlMediaType };\n  }\n\n  return { data: content, mediaType: undefined };\n}\n\n/**\nConverts data content to a base64-encoded string.\n\n@param content - Data content to convert.\n@returns Base64-encoded string.\n*/\nexport function convertDataContentToBase64String(content: DataContent): string {\n  if (typeof content === 'string') {\n    return content;\n  }\n\n  if (content instanceof ArrayBuffer) {\n    return convertUint8ArrayToBase64(new Uint8Array(content));\n  }\n\n  return convertUint8ArrayToBase64(content);\n}\n\n/**\nConverts data content to a Uint8Array.\n\n@param content - Data content to convert.\n@returns Uint8Array.\n */\nexport function convertDataContentToUint8Array(\n  content: DataContent,\n): Uint8Array {\n  if (content instanceof Uint8Array) {\n    return content;\n  }\n\n  if (typeof content === 'string') {\n    try {\n      return convertBase64ToUint8Array(content);\n    } catch (error) {\n      throw new InvalidDataContentError({\n        message:\n          'Invalid data content. Content string is not a base64-encoded media.',\n        content,\n        cause: error,\n      });\n    }\n  }\n\n  if (content instanceof ArrayBuffer) {\n    return new Uint8Array(content);\n  }\n\n  throw new InvalidDataContentError({ content });\n}\n\n/**\n * Converts a Uint8Array to a string of text.\n *\n * @param uint8Array - The Uint8Array to convert.\n * @returns The converted string.\n */\nexport function convertUint8ArrayToText(uint8Array: Uint8Array): string {\n  try {\n    return new TextDecoder().decode(uint8Array);\n  } catch (error) {\n    throw new Error('Error decoding Uint8Array to text');\n  }\n}\n","import { JSONValue as OriginalJSONValue } from '@ai-sdk/provider';\nimport { z } from 'zod/v4';\n\nexport const jsonValueSchema: z.ZodType<JSONValue> = z.lazy(() =>\n  z.union([\n    z.null(),\n    z.string(),\n    z.number(),\n    z.boolean(),\n    z.record(z.string(), jsonValueSchema),\n    z.array(jsonValueSchema),\n  ]),\n);\n\nexport type JSONValue = OriginalJSONValue;\n","import { SharedV2ProviderMetadata } from '@ai-sdk/provider';\nimport { z } from 'zod/v4';\nimport { jsonValueSchema } from './json-value';\n\n/**\nAdditional provider-specific metadata that is returned from the provider.\n\nThis is needed to enable provider-specific functionality that can be\nfully encapsulated in the provider.\n */\nexport type ProviderMetadata = SharedV2ProviderMetadata;\n\nexport const providerMetadataSchema: z.ZodType<ProviderMetadata> = z.record(\n  z.string(),\n  z.record(z.string(), jsonValueSchema),\n);\n","import { LanguageModelV2ToolResultOutput } from '@ai-sdk/provider';\nimport {\n  FilePart,\n  ImagePart,\n  ProviderOptions,\n  ReasoningPart,\n  TextPart,\n  ToolResultPart,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\nimport { jsonValueSchema } from '../types/json-value';\nimport { providerMetadataSchema } from '../types/provider-metadata';\nimport { dataContentSchema } from './data-content';\n\n/**\n@internal\n */\nexport const textPartSchema: z.ZodType<TextPart> = z.object({\n  type: z.literal('text'),\n  text: z.string(),\n  providerOptions: providerMetadataSchema.optional(),\n});\n\n/**\n@internal\n */\nexport const imagePartSchema: z.ZodType<ImagePart> = z.object({\n  type: z.literal('image'),\n  image: z.union([dataContentSchema, z.instanceof(URL)]),\n  mediaType: z.string().optional(),\n  providerOptions: providerMetadataSchema.optional(),\n});\n\n/**\n@internal\n */\nexport const filePartSchema: z.ZodType<FilePart> = z.object({\n  type: z.literal('file'),\n  data: z.union([dataContentSchema, z.instanceof(URL)]),\n  filename: z.string().optional(),\n  mediaType: z.string(),\n  providerOptions: providerMetadataSchema.optional(),\n});\n\n/**\n@internal\n */\nexport const reasoningPartSchema: z.ZodType<ReasoningPart> = z.object({\n  type: z.literal('reasoning'),\n  text: z.string(),\n  providerOptions: providerMetadataSchema.optional(),\n});\n\n/**\nTool call content part of a prompt. It contains a tool call (usually generated by the AI model).\n */\nexport interface ToolCallPart {\n  type: 'tool-call';\n\n  /**\nID of the tool call. This ID is used to match the tool call with the tool result.\n */\n  toolCallId: string;\n\n  /**\nName of the tool that is being called.\n */\n  toolName: string;\n\n  /**\nArguments of the tool call. This is a JSON-serializable object that matches the tool's input schema.\n   */\n  input: unknown;\n\n  /**\nAdditional provider-specific metadata. They are passed through\nto the provider from the AI SDK and enable provider-specific\nfunctionality that can be fully encapsulated in the provider.\n */\n  providerOptions?: ProviderOptions;\n}\n\n/**\n@internal\n */\nexport const toolCallPartSchema: z.ZodType<ToolCallPart> = z.object({\n  type: z.literal('tool-call'),\n  toolCallId: z.string(),\n  toolName: z.string(),\n  input: z.unknown(),\n  providerOptions: providerMetadataSchema.optional(),\n  providerExecuted: z.boolean().optional(),\n}) as z.ZodType<ToolCallPart>; // necessary bc input is optional on Zod type\n\n/**\n@internal\n */\nexport const outputSchema: z.ZodType<LanguageModelV2ToolResultOutput> =\n  z.discriminatedUnion('type', [\n    z.object({\n      type: z.literal('text'),\n      value: z.string(),\n    }),\n    z.object({\n      type: z.literal('json'),\n      value: jsonValueSchema,\n    }),\n    z.object({\n      type: z.literal('error-text'),\n      value: z.string(),\n    }),\n    z.object({\n      type: z.literal('error-json'),\n      value: jsonValueSchema,\n    }),\n    z.object({\n      type: z.literal('content'),\n      value: z.array(\n        z.union([\n          z.object({\n            type: z.literal('text'),\n            text: z.string(),\n          }),\n          z.object({\n            type: z.literal('media'),\n            data: z.string(),\n            mediaType: z.string(),\n          }),\n        ]),\n      ),\n    }),\n  ]);\n\n/**\n@internal\n */\nexport const toolResultPartSchema: z.ZodType<ToolResultPart> = z.object({\n  type: z.literal('tool-result'),\n  toolCallId: z.string(),\n  toolName: z.string(),\n  output: outputSchema,\n  providerOptions: providerMetadataSchema.optional(),\n}) as z.ZodType<ToolResultPart>; // necessary bc result is optional on Zod type\n","import {\n  AssistantModelMessage,\n  ModelMessage,\n  SystemModelMessage,\n  ToolModelMessage,\n  UserModelMessage,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\nimport { providerMetadataSchema } from '../types/provider-metadata';\nimport {\n  filePartSchema,\n  imagePartSchema,\n  reasoningPartSchema,\n  textPartSchema,\n  toolCallPartSchema,\n  toolResultPartSchema,\n} from './content-part';\n\n/**\n@deprecated Use `SystemModelMessage` instead.\n */\n// TODO remove in AI SDK 6\nexport type CoreSystemMessage = SystemModelMessage;\n\nexport const systemModelMessageSchema: z.ZodType<SystemModelMessage> = z.object(\n  {\n    role: z.literal('system'),\n    content: z.string(),\n    providerOptions: providerMetadataSchema.optional(),\n  },\n);\n\n/**\n@deprecated Use `systemModelMessageSchema` instead.\n */\n// TODO remove in AI SDK 6\nexport const coreSystemMessageSchema = systemModelMessageSchema;\n\n/**\n@deprecated Use `UserModelMessage` instead.\n */\n// TODO remove in AI SDK 6\nexport type CoreUserMessage = UserModelMessage;\n\nexport const userModelMessageSchema: z.ZodType<UserModelMessage> = z.object({\n  role: z.literal('user'),\n  content: z.union([\n    z.string(),\n    z.array(z.union([textPartSchema, imagePartSchema, filePartSchema])),\n  ]),\n  providerOptions: providerMetadataSchema.optional(),\n});\n\n/**\n@deprecated Use `userModelMessageSchema` instead.\n */\n// TODO remove in AI SDK 6\nexport const coreUserMessageSchema = userModelMessageSchema;\n\n/**\n@deprecated Use `AssistantModelMessage` instead.\n */\n// TODO remove in AI SDK 6\nexport type CoreAssistantMessage = AssistantModelMessage;\n\nexport const assistantModelMessageSchema: z.ZodType<AssistantModelMessage> =\n  z.object({\n    role: z.literal('assistant'),\n    content: z.union([\n      z.string(),\n      z.array(\n        z.union([\n          textPartSchema,\n          filePartSchema,\n          reasoningPartSchema,\n          toolCallPartSchema,\n          toolResultPartSchema,\n        ]),\n      ),\n    ]),\n    providerOptions: providerMetadataSchema.optional(),\n  });\n\n/**\n@deprecated Use `assistantModelMessageSchema` instead.\n */\n// TODO remove in AI SDK 6\nexport const coreAssistantMessageSchema = assistantModelMessageSchema;\n\n/**\n@deprecated Use `ToolModelMessage` instead.\n */\n// TODO remove in AI SDK 6\nexport type CoreToolMessage = ToolModelMessage;\n\nexport const toolModelMessageSchema: z.ZodType<ToolModelMessage> = z.object({\n  role: z.literal('tool'),\n  content: z.array(toolResultPartSchema),\n  providerOptions: providerMetadataSchema.optional(),\n});\n\n/**\n@deprecated Use `toolModelMessageSchema` instead.\n */\n// TODO remove in AI SDK 6\nexport const coreToolMessageSchema = toolModelMessageSchema;\n\n/**\n@deprecated Use `ModelMessage` instead.\n   */\n// TODO remove in AI SDK 6\nexport type CoreMessage = ModelMessage;\n\nexport const modelMessageSchema: z.ZodType<ModelMessage> = z.union([\n  systemModelMessageSchema,\n  userModelMessageSchema,\n  assistantModelMessageSchema,\n  toolModelMessageSchema,\n]);\n\n/**\n@deprecated Use `modelMessageSchema` instead.\n */\n// TODO remove in AI SDK 6\nexport const coreMessageSchema: z.ZodType<CoreMessage> = modelMessageSchema;\n","import { TelemetrySettings } from './telemetry-settings';\n\nexport function assembleOperationName({\n  operationId,\n  telemetry,\n}: {\n  operationId: string;\n  telemetry?: TelemetrySettings;\n}) {\n  return {\n    // standardized operation and resource name:\n    'operation.name': `${operationId}${\n      telemetry?.functionId != null ? ` ${telemetry.functionId}` : ''\n    }`,\n    'resource.name': telemetry?.functionId,\n\n    // detailed, AI SDK specific data:\n    'ai.operationId': operationId,\n    'ai.telemetry.functionId': telemetry?.functionId,\n  };\n}\n","import { Attributes } from '@opentelemetry/api';\nimport { CallSettings } from '../prompt/call-settings';\nimport { TelemetrySettings } from './telemetry-settings';\n\nexport function getBaseTelemetryAttributes({\n  model,\n  settings,\n  telemetry,\n  headers,\n}: {\n  model: { modelId: string; provider: string };\n  settings: Omit<CallSettings, 'abortSignal' | 'headers' | 'temperature'>;\n  telemetry: TelemetrySettings | undefined;\n  headers: Record<string, string | undefined> | undefined;\n}): Attributes {\n  return {\n    'ai.model.provider': model.provider,\n    'ai.model.id': model.modelId,\n\n    // settings:\n    ...Object.entries(settings).reduce((attributes, [key, value]) => {\n      attributes[`ai.settings.${key}`] = value;\n      return attributes;\n    }, {} as Attributes),\n\n    // add metadata as attributes:\n    ...Object.entries(telemetry?.metadata ?? {}).reduce(\n      (attributes, [key, value]) => {\n        attributes[`ai.telemetry.metadata.${key}`] = value;\n        return attributes;\n      },\n      {} as Attributes,\n    ),\n\n    // request headers\n    ...Object.entries(headers ?? {}).reduce((attributes, [key, value]) => {\n      if (value !== undefined) {\n        attributes[`ai.request.headers.${key}`] = value;\n      }\n      return attributes;\n    }, {} as Attributes),\n  };\n}\n","import { Span, SpanContext, Tracer } from '@opentelemetry/api';\n\n/**\n * Tracer implementation that does nothing (null object).\n */\nexport const noopTracer: Tracer = {\n  startSpan(): Span {\n    return noopSpan;\n  },\n\n  startActiveSpan<F extends (span: Span) => unknown>(\n    name: unknown,\n    arg1: unknown,\n    arg2?: unknown,\n    arg3?: F,\n  ): ReturnType<any> {\n    if (typeof arg1 === 'function') {\n      return arg1(noopSpan);\n    }\n    if (typeof arg2 === 'function') {\n      return arg2(noopSpan);\n    }\n    if (typeof arg3 === 'function') {\n      return arg3(noopSpan);\n    }\n  },\n};\n\nconst noopSpan: Span = {\n  spanContext() {\n    return noopSpanContext;\n  },\n  setAttribute() {\n    return this;\n  },\n  setAttributes() {\n    return this;\n  },\n  addEvent() {\n    return this;\n  },\n  addLink() {\n    return this;\n  },\n  addLinks() {\n    return this;\n  },\n  setStatus() {\n    return this;\n  },\n  updateName() {\n    return this;\n  },\n  end() {\n    return this;\n  },\n  isRecording() {\n    return false;\n  },\n  recordException() {\n    return this;\n  },\n};\n\nconst noopSpanContext: SpanContext = {\n  traceId: '',\n  spanId: '',\n  traceFlags: 0,\n};\n","import { Tracer, trace } from '@opentelemetry/api';\nimport { noopTracer } from './noop-tracer';\n\nexport function getTracer({\n  isEnabled = false,\n  tracer,\n}: {\n  isEnabled?: boolean;\n  tracer?: Tracer;\n} = {}): Tracer {\n  if (!isEnabled) {\n    return noopTracer;\n  }\n\n  if (tracer) {\n    return tracer;\n  }\n\n  return trace.getTracer('ai');\n}\n","import { Attributes, Span, Tracer, SpanStatusCode } from '@opentelemetry/api';\n\nexport function recordSpan<T>({\n  name,\n  tracer,\n  attributes,\n  fn,\n  endWhenDone = true,\n}: {\n  name: string;\n  tracer: Tracer;\n  attributes: Attributes;\n  fn: (span: Span) => Promise<T>;\n  endWhenDone?: boolean;\n}) {\n  return tracer.startActiveSpan(name, { attributes }, async span => {\n    try {\n      const result = await fn(span);\n\n      if (endWhenDone) {\n        span.end();\n      }\n\n      return result;\n    } catch (error) {\n      try {\n        recordErrorOnSpan(span, error);\n      } finally {\n        // always stop the span when there is an error:\n        span.end();\n      }\n\n      throw error;\n    }\n  });\n}\n\n/**\n * Record an error on a span. If the error is an instance of Error, an exception event will be recorded on the span, otherwise\n * the span will be set to an error status.\n *\n * @param span - The span to record the error on.\n * @param error - The error to record on the span.\n */\nexport function recordErrorOnSpan(span: Span, error: unknown) {\n  if (error instanceof Error) {\n    span.recordException({\n      name: error.name,\n      message: error.message,\n      stack: error.stack,\n    });\n    span.setStatus({\n      code: SpanStatusCode.ERROR,\n      message: error.message,\n    });\n  } else {\n    span.setStatus({ code: SpanStatusCode.ERROR });\n  }\n}\n","import type { Attributes, AttributeValue } from '@opentelemetry/api';\nimport type { TelemetrySettings } from './telemetry-settings';\n\nexport function selectTelemetryAttributes({\n  telemetry,\n  attributes,\n}: {\n  telemetry?: TelemetrySettings;\n  attributes: {\n    [attributeKey: string]:\n      | AttributeValue\n      | { input: () => AttributeValue | undefined }\n      | { output: () => AttributeValue | undefined }\n      | undefined;\n  };\n}): Attributes {\n  // when telemetry is disabled, return an empty object to avoid serialization overhead:\n  if (telemetry?.isEnabled !== true) {\n    return {};\n  }\n\n  return Object.entries(attributes).reduce((attributes, [key, value]) => {\n    if (value == null) {\n      return attributes;\n    }\n\n    // input value, check if it should be recorded:\n    if (\n      typeof value === 'object' &&\n      'input' in value &&\n      typeof value.input === 'function'\n    ) {\n      // default to true:\n      if (telemetry?.recordInputs === false) {\n        return attributes;\n      }\n\n      const result = value.input();\n\n      return result == null ? attributes : { ...attributes, [key]: result };\n    }\n\n    // output value, check if it should be recorded:\n    if (\n      typeof value === 'object' &&\n      'output' in value &&\n      typeof value.output === 'function'\n    ) {\n      // default to true:\n      if (telemetry?.recordOutputs === false) {\n        return attributes;\n      }\n\n      const result = value.output();\n\n      return result == null ? attributes : { ...attributes, [key]: result };\n    }\n\n    // value is an attribute value already:\n    return { ...attributes, [key]: value };\n  }, {});\n}\n","import { APICallError } from '@ai-sdk/provider';\nimport { delay, getErrorMessage, isAbortError } from '@ai-sdk/provider-utils';\nimport { RetryError } from './retry-error';\n\nexport type RetryFunction = <OUTPUT>(\n  fn: () => PromiseLike<OUTPUT>,\n) => PromiseLike<OUTPUT>;\n\nfunction getRetryDelayInMs({\n  error,\n  exponentialBackoffDelay,\n}: {\n  error: APICallError;\n  exponentialBackoffDelay: number;\n}): number {\n  const headers = error.responseHeaders;\n\n  if (!headers) return exponentialBackoffDelay;\n\n  let ms: number | undefined;\n\n  // retry-ms is more precise than retry-after and used by e.g. OpenAI\n  const retryAfterMs = headers['retry-after-ms'];\n  if (retryAfterMs) {\n    const timeoutMs = parseFloat(retryAfterMs);\n    if (!Number.isNaN(timeoutMs)) {\n      ms = timeoutMs;\n    }\n  }\n\n  // About the Retry-After header: https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Retry-After\n  const retryAfter = headers['retry-after'];\n  if (retryAfter && ms === undefined) {\n    const timeoutSeconds = parseFloat(retryAfter);\n    if (!Number.isNaN(timeoutSeconds)) {\n      ms = timeoutSeconds * 1000;\n    } else {\n      ms = Date.parse(retryAfter) - Date.now();\n    }\n  }\n\n  // check that the delay is reasonable:\n  if (\n    ms != null &&\n    !Number.isNaN(ms) &&\n    0 <= ms &&\n    (ms < 60 * 1000 || ms < exponentialBackoffDelay)\n  ) {\n    return ms;\n  }\n\n  return exponentialBackoffDelay;\n}\n\n/**\nThe `retryWithExponentialBackoffRespectingRetryHeaders` strategy retries a failed API call with an exponential backoff,\nwhile respecting rate limit headers (retry-after-ms and retry-after) if they are provided and reasonable (0-60 seconds).\nYou can configure the maximum number of retries, the initial delay, and the backoff factor.\n */\nexport const retryWithExponentialBackoffRespectingRetryHeaders =\n  ({\n    maxRetries = 2,\n    initialDelayInMs = 2000,\n    backoffFactor = 2,\n    abortSignal,\n  }: {\n    maxRetries?: number;\n    initialDelayInMs?: number;\n    backoffFactor?: number;\n    abortSignal?: AbortSignal;\n  } = {}): RetryFunction =>\n  async <OUTPUT>(f: () => PromiseLike<OUTPUT>) =>\n    _retryWithExponentialBackoff(f, {\n      maxRetries,\n      delayInMs: initialDelayInMs,\n      backoffFactor,\n      abortSignal,\n    });\n\nasync function _retryWithExponentialBackoff<OUTPUT>(\n  f: () => PromiseLike<OUTPUT>,\n  {\n    maxRetries,\n    delayInMs,\n    backoffFactor,\n    abortSignal,\n  }: {\n    maxRetries: number;\n    delayInMs: number;\n    backoffFactor: number;\n    abortSignal: AbortSignal | undefined;\n  },\n  errors: unknown[] = [],\n): Promise<OUTPUT> {\n  try {\n    return await f();\n  } catch (error) {\n    if (isAbortError(error)) {\n      throw error; // don't retry when the request was aborted\n    }\n\n    if (maxRetries === 0) {\n      throw error; // don't wrap the error when retries are disabled\n    }\n\n    const errorMessage = getErrorMessage(error);\n    const newErrors = [...errors, error];\n    const tryNumber = newErrors.length;\n\n    if (tryNumber > maxRetries) {\n      throw new RetryError({\n        message: `Failed after ${tryNumber} attempts. Last error: ${errorMessage}`,\n        reason: 'maxRetriesExceeded',\n        errors: newErrors,\n      });\n    }\n\n    if (\n      error instanceof Error &&\n      APICallError.isInstance(error) &&\n      error.isRetryable === true &&\n      tryNumber <= maxRetries\n    ) {\n      await delay(\n        getRetryDelayInMs({\n          error,\n          exponentialBackoffDelay: delayInMs,\n        }),\n        { abortSignal },\n      );\n\n      return _retryWithExponentialBackoff(\n        f,\n        {\n          maxRetries,\n          delayInMs: backoffFactor * delayInMs,\n          backoffFactor,\n          abortSignal,\n        },\n        newErrors,\n      );\n    }\n\n    if (tryNumber === 1) {\n      throw error; // don't wrap the error when a non-retryable error occurs on the first try\n    }\n\n    throw new RetryError({\n      message: `Failed after ${tryNumber} attempts with non-retryable error: '${errorMessage}'`,\n      reason: 'errorNotRetryable',\n      errors: newErrors,\n    });\n  }\n}\n","import { InvalidArgumentError } from '../error/invalid-argument-error';\nimport {\n  RetryFunction,\n  retryWithExponentialBackoffRespectingRetryHeaders,\n} from '../util/retry-with-exponential-backoff';\n\n/**\n * Validate and prepare retries.\n */\nexport function prepareRetries({\n  maxRetries,\n  abortSignal,\n}: {\n  maxRetries: number | undefined;\n  abortSignal: AbortSignal | undefined;\n}): {\n  maxRetries: number;\n  retry: RetryFunction;\n} {\n  if (maxRetries != null) {\n    if (!Number.isInteger(maxRetries)) {\n      throw new InvalidArgumentError({\n        parameter: 'maxRetries',\n        value: maxRetries,\n        message: 'maxRetries must be an integer',\n      });\n    }\n\n    if (maxRetries < 0) {\n      throw new InvalidArgumentError({\n        parameter: 'maxRetries',\n        value: maxRetries,\n        message: 'maxRetries must be >= 0',\n      });\n    }\n  }\n\n  const maxRetriesResult = maxRetries ?? 2;\n\n  return {\n    maxRetries: maxRetriesResult,\n    retry: retryWithExponentialBackoffRespectingRetryHeaders({\n      maxRetries: maxRetriesResult,\n      abortSignal,\n    }),\n  };\n}\n","import {\n  convertBase64ToUint8Array,\n  convertUint8ArrayToBase64,\n} from '@ai-sdk/provider-utils';\n\n/**\n * A generated file.\n */\nexport interface GeneratedFile {\n  /**\nFile as a base64 encoded string.\n     */\n  readonly base64: string;\n\n  /**\nFile as a Uint8Array.\n     */\n  readonly uint8Array: Uint8Array;\n\n  /**\nThe IANA media type of the file.\n\n@see https://www.iana.org/assignments/media-types/media-types.xhtml\n   */\n  readonly mediaType: string;\n}\n\nexport class DefaultGeneratedFile implements GeneratedFile {\n  private base64Data: string | undefined;\n  private uint8ArrayData: Uint8Array | undefined;\n\n  readonly mediaType: string;\n\n  constructor({\n    data,\n    mediaType,\n  }: {\n    data: string | Uint8Array;\n    mediaType: string;\n  }) {\n    const isUint8Array = data instanceof Uint8Array;\n    this.base64Data = isUint8Array ? undefined : data;\n    this.uint8ArrayData = isUint8Array ? data : undefined;\n    this.mediaType = mediaType;\n  }\n\n  // lazy conversion with caching to avoid unnecessary conversion overhead:\n  get base64() {\n    if (this.base64Data == null) {\n      this.base64Data = convertUint8ArrayToBase64(this.uint8ArrayData!);\n    }\n    return this.base64Data;\n  }\n\n  // lazy conversion with caching to avoid unnecessary conversion overhead:\n  get uint8Array() {\n    if (this.uint8ArrayData == null) {\n      this.uint8ArrayData = convertBase64ToUint8Array(this.base64Data!);\n    }\n    return this.uint8ArrayData;\n  }\n}\n\nexport class DefaultGeneratedFileWithType extends DefaultGeneratedFile {\n  readonly type = 'file';\n\n  constructor(options: { data: string | Uint8Array; mediaType: string }) {\n    super(options);\n  }\n}\n","import { StepResult } from './step-result';\nimport { ToolSet } from './tool-set';\n\nexport type StopCondition<TOOLS extends ToolSet> = (options: {\n  steps: Array<StepResult<TOOLS>>;\n}) => PromiseLike<boolean> | boolean;\n\nexport function stepCountIs(stepCount: number): StopCondition<any> {\n  return ({ steps }) => steps.length === stepCount;\n}\n\nexport function hasToolCall(toolName: string): StopCondition<any> {\n  return ({ steps }) =>\n    steps[steps.length - 1]?.toolCalls?.some(\n      toolCall => toolCall.toolName === toolName,\n    ) ?? false;\n}\n\nexport async function isStopConditionMet<TOOLS extends ToolSet>({\n  stopConditions,\n  steps,\n}: {\n  stopConditions: Array<StopCondition<TOOLS>>;\n  steps: Array<StepResult<TOOLS>>;\n}): Promise<boolean> {\n  return (\n    await Promise.all(stopConditions.map(condition => condition({ steps })))\n  ).some(result => result);\n}\n","import {\n  getErrorMessage,\n  JSONValue,\n  LanguageModelV2ToolResultOutput,\n} from '@ai-sdk/provider';\nimport { Tool } from '@ai-sdk/provider-utils';\n\nexport function createToolModelOutput({\n  output,\n  tool,\n  errorMode,\n}: {\n  output: unknown;\n  tool: Tool | undefined;\n  errorMode: 'none' | 'text' | 'json';\n}): LanguageModelV2ToolResultOutput {\n  if (errorMode === 'text') {\n    return { type: 'error-text', value: getErrorMessage(output) };\n  } else if (errorMode === 'json') {\n    return { type: 'error-json', value: toJSONValue(output) };\n  }\n\n  if (tool?.toModelOutput) {\n    return tool.toModelOutput(output);\n  }\n\n  return typeof output === 'string'\n    ? { type: 'text', value: output }\n    : { type: 'json', value: toJSONValue(output) };\n}\n\nfunction toJSONValue(value: unknown): JSONValue {\n  return value === undefined ? null : (value as JSONValue);\n}\n","import {\n  LanguageModelV2,\n  LanguageModelV2Content,\n  LanguageModelV2ToolCall,\n} from '@ai-sdk/provider';\nimport {\n  createIdGenerator,\n  executeTool,\n  getErrorMessage,\n  IdGenerator,\n  ProviderOptions,\n  withUserAgentSuffix,\n} from '@ai-sdk/provider-utils';\nimport { Tracer } from '@opentelemetry/api';\nimport { NoOutputSpecifiedError } from '../error/no-output-specified-error';\nimport { logWarnings } from '../logger/log-warnings';\nimport { resolveLanguageModel } from '../model/resolve-model';\nimport { ModelMessage } from '../prompt';\nimport { CallSettings } from '../prompt/call-settings';\nimport { convertToLanguageModelPrompt } from '../prompt/convert-to-language-model-prompt';\nimport { prepareCallSettings } from '../prompt/prepare-call-settings';\nimport { prepareToolsAndToolChoice } from '../prompt/prepare-tools-and-tool-choice';\nimport { Prompt } from '../prompt/prompt';\nimport { standardizePrompt } from '../prompt/standardize-prompt';\nimport { wrapGatewayError } from '../prompt/wrap-gateway-error';\nimport { assembleOperationName } from '../telemetry/assemble-operation-name';\nimport { getBaseTelemetryAttributes } from '../telemetry/get-base-telemetry-attributes';\nimport { getTracer } from '../telemetry/get-tracer';\nimport { recordErrorOnSpan, recordSpan } from '../telemetry/record-span';\nimport { selectTelemetryAttributes } from '../telemetry/select-telemetry-attributes';\nimport { stringifyForTelemetry } from '../telemetry/stringify-for-telemetry';\nimport { TelemetrySettings } from '../telemetry/telemetry-settings';\nimport { LanguageModel, ToolChoice } from '../types';\nimport { addLanguageModelUsage, LanguageModelUsage } from '../types/usage';\nimport { asArray } from '../util/as-array';\nimport { DownloadFunction } from '../util/download/download-function';\nimport { prepareRetries } from '../util/prepare-retries';\nimport { ContentPart } from './content-part';\nimport { extractTextContent } from './extract-text-content';\nimport { GenerateTextResult } from './generate-text-result';\nimport { DefaultGeneratedFile } from './generated-file';\nimport { Output } from './output';\nimport { parseToolCall } from './parse-tool-call';\nimport { PrepareStepFunction } from './prepare-step';\nimport { ResponseMessage } from './response-message';\nimport { DefaultStepResult, StepResult } from './step-result';\nimport {\n  isStopConditionMet,\n  stepCountIs,\n  StopCondition,\n} from './stop-condition';\nimport { toResponseMessages } from './to-response-messages';\nimport { TypedToolCall } from './tool-call';\nimport { ToolCallRepairFunction } from './tool-call-repair-function';\nimport { TypedToolError } from './tool-error';\nimport { ToolOutput } from './tool-output';\nimport { TypedToolResult } from './tool-result';\nimport { ToolSet } from './tool-set';\nimport { VERSION } from '../version';\n\nconst originalGenerateId = createIdGenerator({\n  prefix: 'aitxt',\n  size: 24,\n});\n\n/**\nCallback that is set using the `onStepFinish` option.\n\n@param stepResult - The result of the step.\n */\nexport type GenerateTextOnStepFinishCallback<TOOLS extends ToolSet> = (\n  stepResult: StepResult<TOOLS>,\n) => Promise<void> | void;\n\n/**\nGenerate a text and call tools for a given prompt using a language model.\n\nThis function does not stream the output. If you want to stream the output, use `streamText` instead.\n\n@param model - The language model to use.\n\n@param tools - Tools that are accessible to and can be called by the model. The model needs to support calling tools.\n@param toolChoice - The tool choice strategy. Default: 'auto'.\n\n@param system - A system message that will be part of the prompt.\n@param prompt - A simple text prompt. You can either use `prompt` or `messages` but not both.\n@param messages - A list of messages. You can either use `prompt` or `messages` but not both.\n\n@param maxOutputTokens - Maximum number of tokens to generate.\n@param temperature - Temperature setting.\nThe value is passed through to the provider. The range depends on the provider and model.\nIt is recommended to set either `temperature` or `topP`, but not both.\n@param topP - Nucleus sampling.\nThe value is passed through to the provider. The range depends on the provider and model.\nIt is recommended to set either `temperature` or `topP`, but not both.\n@param topK - Only sample from the top K options for each subsequent token.\nUsed to remove \"long tail\" low probability responses.\nRecommended for advanced use cases only. You usually only need to use temperature.\n@param presencePenalty - Presence penalty setting.\nIt affects the likelihood of the model to repeat information that is already in the prompt.\nThe value is passed through to the provider. The range depends on the provider and model.\n@param frequencyPenalty - Frequency penalty setting.\nIt affects the likelihood of the model to repeatedly use the same words or phrases.\nThe value is passed through to the provider. The range depends on the provider and model.\n@param stopSequences - Stop sequences.\nIf set, the model will stop generating text when one of the stop sequences is generated.\n@param seed - The seed (integer) to use for random sampling.\nIf set and supported by the model, calls will generate deterministic results.\n\n@param maxRetries - Maximum number of retries. Set to 0 to disable retries. Default: 2.\n@param abortSignal - An optional abort signal that can be used to cancel the call.\n@param headers - Additional HTTP headers to be sent with the request. Only applicable for HTTP-based providers.\n\n@param experimental_generateMessageId - Generate a unique ID for each message.\n\n@param onStepFinish - Callback that is called when each step (LLM call) is finished, including intermediate steps.\n\n@returns\nA result object that contains the generated text, the results of the tool calls, and additional information.\n */\nexport async function generateText<\n  TOOLS extends ToolSet,\n  OUTPUT = never,\n  OUTPUT_PARTIAL = never,\n>({\n  model: modelArg,\n  tools,\n  toolChoice,\n  system,\n  prompt,\n  messages,\n  maxRetries: maxRetriesArg,\n  abortSignal,\n  headers,\n  stopWhen = stepCountIs(1),\n  experimental_output: output,\n  experimental_telemetry: telemetry,\n  providerOptions,\n  experimental_activeTools,\n  activeTools = experimental_activeTools,\n  experimental_prepareStep,\n  prepareStep = experimental_prepareStep,\n  experimental_repairToolCall: repairToolCall,\n  experimental_download: download,\n  experimental_context,\n  _internal: {\n    generateId = originalGenerateId,\n    currentDate = () => new Date(),\n  } = {},\n  onStepFinish,\n  ...settings\n}: CallSettings &\n  Prompt & {\n    /**\nThe language model to use.\n     */\n    model: LanguageModel;\n\n    /**\nThe tools that the model can call. The model needs to support calling tools.\n*/\n    tools?: TOOLS;\n\n    /**\nThe tool choice strategy. Default: 'auto'.\n     */\n    toolChoice?: ToolChoice<NoInfer<TOOLS>>;\n\n    /**\nCondition for stopping the generation when there are tool results in the last step.\nWhen the condition is an array, any of the conditions can be met to stop the generation.\n\n@default stepCountIs(1)\n     */\n    stopWhen?:\n      | StopCondition<NoInfer<TOOLS>>\n      | Array<StopCondition<NoInfer<TOOLS>>>;\n\n    /**\nOptional telemetry configuration (experimental).\n     */\n    experimental_telemetry?: TelemetrySettings;\n\n    /**\nAdditional provider-specific options. They are passed through\nto the provider from the AI SDK and enable provider-specific\nfunctionality that can be fully encapsulated in the provider.\n */\n    providerOptions?: ProviderOptions;\n\n    /**\n     * @deprecated Use `activeTools` instead.\n     */\n    experimental_activeTools?: Array<keyof NoInfer<TOOLS>>;\n\n    /**\nLimits the tools that are available for the model to call without\nchanging the tool call and result types in the result.\n     */\n    activeTools?: Array<keyof NoInfer<TOOLS>>;\n\n    /**\nOptional specification for parsing structured outputs from the LLM response.\n     */\n    experimental_output?: Output<OUTPUT, OUTPUT_PARTIAL>;\n\n    /**\nCustom download function to use for URLs.\n\nBy default, files are downloaded if the model does not support the URL for the given media type.\n     */\n    experimental_download?: DownloadFunction | undefined;\n\n    /**\n     * @deprecated Use `prepareStep` instead.\n     */\n    experimental_prepareStep?: PrepareStepFunction<NoInfer<TOOLS>>;\n\n    /**\nOptional function that you can use to provide different settings for a step.\n    */\n    prepareStep?: PrepareStepFunction<NoInfer<TOOLS>>;\n\n    /**\nA function that attempts to repair a tool call that failed to parse.\n     */\n    experimental_repairToolCall?: ToolCallRepairFunction<NoInfer<TOOLS>>;\n\n    /**\n    Callback that is called when each step (LLM call) is finished, including intermediate steps.\n    */\n    onStepFinish?: GenerateTextOnStepFinishCallback<NoInfer<TOOLS>>;\n\n    /**\n     * Context that is passed into tool execution.\n     *\n     * Experimental (can break in patch releases).\n     *\n     * @default undefined\n     */\n    experimental_context?: unknown;\n\n    /**\n     * Internal. For test use only. May change without notice.\n     */\n    _internal?: {\n      generateId?: IdGenerator;\n      currentDate?: () => Date;\n    };\n  }): Promise<GenerateTextResult<TOOLS, OUTPUT>> {\n  const model = resolveLanguageModel(modelArg);\n  const stopConditions = asArray(stopWhen);\n  const { maxRetries, retry } = prepareRetries({\n    maxRetries: maxRetriesArg,\n    abortSignal,\n  });\n\n  const callSettings = prepareCallSettings(settings);\n\n  const headersWithUserAgent = withUserAgentSuffix(\n    headers ?? {},\n    `ai/${VERSION}`,\n  );\n\n  const baseTelemetryAttributes = getBaseTelemetryAttributes({\n    model,\n    telemetry,\n    headers: headersWithUserAgent,\n    settings: { ...callSettings, maxRetries },\n  });\n\n  const initialPrompt = await standardizePrompt({\n    system,\n    prompt,\n    messages,\n  } as Prompt);\n\n  const tracer = getTracer(telemetry);\n\n  try {\n    return await recordSpan({\n      name: 'ai.generateText',\n      attributes: selectTelemetryAttributes({\n        telemetry,\n        attributes: {\n          ...assembleOperationName({\n            operationId: 'ai.generateText',\n            telemetry,\n          }),\n          ...baseTelemetryAttributes,\n          // model:\n          'ai.model.provider': model.provider,\n          'ai.model.id': model.modelId,\n          // specific settings that only make sense on the outer level:\n          'ai.prompt': {\n            input: () => JSON.stringify({ system, prompt, messages }),\n          },\n        },\n      }),\n      tracer,\n      fn: async span => {\n        const callSettings = prepareCallSettings(settings);\n\n        let currentModelResponse: Awaited<\n          ReturnType<LanguageModelV2['doGenerate']>\n        > & { response: { id: string; timestamp: Date; modelId: string } };\n        let clientToolCalls: Array<TypedToolCall<TOOLS>> = [];\n        let clientToolOutputs: Array<ToolOutput<TOOLS>> = [];\n        const responseMessages: Array<ResponseMessage> = [];\n        const steps: GenerateTextResult<TOOLS, OUTPUT>['steps'] = [];\n\n        do {\n          const stepInputMessages = [\n            ...initialPrompt.messages,\n            ...responseMessages,\n          ];\n\n          const prepareStepResult = await prepareStep?.({\n            model,\n            steps,\n            stepNumber: steps.length,\n            messages: stepInputMessages,\n          });\n\n          const stepModel = resolveLanguageModel(\n            prepareStepResult?.model ?? model,\n          );\n\n          const promptMessages = await convertToLanguageModelPrompt({\n            prompt: {\n              system: prepareStepResult?.system ?? initialPrompt.system,\n              messages: prepareStepResult?.messages ?? stepInputMessages,\n            },\n            supportedUrls: await stepModel.supportedUrls,\n            download,\n          });\n\n          const { toolChoice: stepToolChoice, tools: stepTools } =\n            prepareToolsAndToolChoice({\n              tools,\n              toolChoice: prepareStepResult?.toolChoice ?? toolChoice,\n              activeTools: prepareStepResult?.activeTools ?? activeTools,\n            });\n\n          currentModelResponse = await retry(() =>\n            recordSpan({\n              name: 'ai.generateText.doGenerate',\n              attributes: selectTelemetryAttributes({\n                telemetry,\n                attributes: {\n                  ...assembleOperationName({\n                    operationId: 'ai.generateText.doGenerate',\n                    telemetry,\n                  }),\n                  ...baseTelemetryAttributes,\n                  // model:\n                  'ai.model.provider': stepModel.provider,\n                  'ai.model.id': stepModel.modelId,\n                  // prompt:\n                  'ai.prompt.messages': {\n                    input: () => stringifyForTelemetry(promptMessages),\n                  },\n                  'ai.prompt.tools': {\n                    // convert the language model level tools:\n                    input: () => stepTools?.map(tool => JSON.stringify(tool)),\n                  },\n                  'ai.prompt.toolChoice': {\n                    input: () =>\n                      stepToolChoice != null\n                        ? JSON.stringify(stepToolChoice)\n                        : undefined,\n                  },\n\n                  // standardized gen-ai llm span attributes:\n                  'gen_ai.system': stepModel.provider,\n                  'gen_ai.request.model': stepModel.modelId,\n                  'gen_ai.request.frequency_penalty': settings.frequencyPenalty,\n                  'gen_ai.request.max_tokens': settings.maxOutputTokens,\n                  'gen_ai.request.presence_penalty': settings.presencePenalty,\n                  'gen_ai.request.stop_sequences': settings.stopSequences,\n                  'gen_ai.request.temperature':\n                    settings.temperature ?? undefined,\n                  'gen_ai.request.top_k': settings.topK,\n                  'gen_ai.request.top_p': settings.topP,\n                },\n              }),\n              tracer,\n              fn: async span => {\n                const result = await stepModel.doGenerate({\n                  ...callSettings,\n                  tools: stepTools,\n                  toolChoice: stepToolChoice,\n                  responseFormat: output?.responseFormat,\n                  prompt: promptMessages,\n                  providerOptions,\n                  abortSignal,\n                  headers: headersWithUserAgent,\n                });\n\n                // Fill in default values:\n                const responseData = {\n                  id: result.response?.id ?? generateId(),\n                  timestamp: result.response?.timestamp ?? currentDate(),\n                  modelId: result.response?.modelId ?? stepModel.modelId,\n                  headers: result.response?.headers,\n                  body: result.response?.body,\n                };\n\n                // Add response information to the span:\n                span.setAttributes(\n                  selectTelemetryAttributes({\n                    telemetry,\n                    attributes: {\n                      'ai.response.finishReason': result.finishReason,\n                      'ai.response.text': {\n                        output: () => extractTextContent(result.content),\n                      },\n                      'ai.response.toolCalls': {\n                        output: () => {\n                          const toolCalls = asToolCalls(result.content);\n                          return toolCalls == null\n                            ? undefined\n                            : JSON.stringify(toolCalls);\n                        },\n                      },\n                      'ai.response.id': responseData.id,\n                      'ai.response.model': responseData.modelId,\n                      'ai.response.timestamp':\n                        responseData.timestamp.toISOString(),\n                      'ai.response.providerMetadata': JSON.stringify(\n                        result.providerMetadata,\n                      ),\n\n                      // TODO rename telemetry attributes to inputTokens and outputTokens\n                      'ai.usage.promptTokens': result.usage.inputTokens,\n                      'ai.usage.completionTokens': result.usage.outputTokens,\n\n                      // standardized gen-ai llm span attributes:\n                      'gen_ai.response.finish_reasons': [result.finishReason],\n                      'gen_ai.response.id': responseData.id,\n                      'gen_ai.response.model': responseData.modelId,\n                      'gen_ai.usage.input_tokens': result.usage.inputTokens,\n                      'gen_ai.usage.output_tokens': result.usage.outputTokens,\n                    },\n                  }),\n                );\n\n                return { ...result, response: responseData };\n              },\n            }),\n          );\n\n          // parse tool calls:\n          const stepToolCalls: TypedToolCall<TOOLS>[] = await Promise.all(\n            currentModelResponse.content\n              .filter(\n                (part): part is LanguageModelV2ToolCall =>\n                  part.type === 'tool-call',\n              )\n              .map(toolCall =>\n                parseToolCall({\n                  toolCall,\n                  tools,\n                  repairToolCall,\n                  system,\n                  messages: stepInputMessages,\n                }),\n              ),\n          );\n\n          // notify the tools that the tool calls are available:\n          for (const toolCall of stepToolCalls) {\n            if (toolCall.invalid) {\n              continue; // ignore invalid tool calls\n            }\n\n            const tool = tools![toolCall.toolName];\n            if (tool?.onInputAvailable != null) {\n              await tool.onInputAvailable({\n                input: toolCall.input,\n                toolCallId: toolCall.toolCallId,\n                messages: stepInputMessages,\n                abortSignal,\n                experimental_context,\n              });\n            }\n          }\n\n          // insert error tool outputs for invalid tool calls:\n          // TODO AI SDK 6: invalid inputs should not require output parts\n          const invalidToolCalls = stepToolCalls.filter(\n            toolCall => toolCall.invalid && toolCall.dynamic,\n          );\n\n          clientToolOutputs = [];\n\n          for (const toolCall of invalidToolCalls) {\n            clientToolOutputs.push({\n              type: 'tool-error',\n              toolCallId: toolCall.toolCallId,\n              toolName: toolCall.toolName,\n              input: toolCall.input,\n              error: getErrorMessage(toolCall.error!),\n              dynamic: true,\n            });\n          }\n\n          // execute client tool calls:\n          clientToolCalls = stepToolCalls.filter(\n            toolCall => !toolCall.providerExecuted,\n          );\n\n          if (tools != null) {\n            clientToolOutputs.push(\n              ...(await executeTools({\n                toolCalls: clientToolCalls.filter(\n                  toolCall => !toolCall.invalid,\n                ),\n                tools,\n                tracer,\n                telemetry,\n                messages: stepInputMessages,\n                abortSignal,\n                experimental_context,\n              })),\n            );\n          }\n\n          // content:\n          const stepContent = asContent({\n            content: currentModelResponse.content,\n            toolCalls: stepToolCalls,\n            toolOutputs: clientToolOutputs,\n          });\n\n          // append to messages for potential next step:\n          responseMessages.push(\n            ...toResponseMessages({\n              content: stepContent,\n              tools,\n            }),\n          );\n\n          // Add step information (after response messages are updated):\n          const currentStepResult: StepResult<TOOLS> = new DefaultStepResult({\n            content: stepContent,\n            finishReason: currentModelResponse.finishReason,\n            usage: currentModelResponse.usage,\n            warnings: currentModelResponse.warnings,\n            providerMetadata: currentModelResponse.providerMetadata,\n            request: currentModelResponse.request ?? {},\n            response: {\n              ...currentModelResponse.response,\n              // deep clone msgs to avoid mutating past messages in multi-step:\n              messages: structuredClone(responseMessages),\n            },\n          });\n\n          logWarnings(currentModelResponse.warnings ?? []);\n\n          steps.push(currentStepResult);\n          await onStepFinish?.(currentStepResult);\n        } while (\n          // there are tool calls:\n          clientToolCalls.length > 0 &&\n          // all current tool calls have outputs (incl. execution errors):\n          clientToolOutputs.length === clientToolCalls.length &&\n          // continue until a stop condition is met:\n          !(await isStopConditionMet({ stopConditions, steps }))\n        );\n\n        // Add response information to the span:\n        span.setAttributes(\n          selectTelemetryAttributes({\n            telemetry,\n            attributes: {\n              'ai.response.finishReason': currentModelResponse.finishReason,\n              'ai.response.text': {\n                output: () => extractTextContent(currentModelResponse.content),\n              },\n              'ai.response.toolCalls': {\n                output: () => {\n                  const toolCalls = asToolCalls(currentModelResponse.content);\n                  return toolCalls == null\n                    ? undefined\n                    : JSON.stringify(toolCalls);\n                },\n              },\n              'ai.response.providerMetadata': JSON.stringify(\n                currentModelResponse.providerMetadata,\n              ),\n\n              // TODO rename telemetry attributes to inputTokens and outputTokens\n              'ai.usage.promptTokens': currentModelResponse.usage.inputTokens,\n              'ai.usage.completionTokens':\n                currentModelResponse.usage.outputTokens,\n            },\n          }),\n        );\n\n        const lastStep = steps[steps.length - 1];\n\n        // parse output only if the last step was finished with \"stop\":\n        let resolvedOutput;\n        if (lastStep.finishReason === 'stop') {\n          resolvedOutput = await output?.parseOutput(\n            { text: lastStep.text },\n            {\n              response: lastStep.response,\n              usage: lastStep.usage,\n              finishReason: lastStep.finishReason,\n            },\n          );\n        }\n\n        return new DefaultGenerateTextResult({\n          steps,\n          resolvedOutput,\n        });\n      },\n    });\n  } catch (error) {\n    throw wrapGatewayError(error);\n  }\n}\n\nasync function executeTools<TOOLS extends ToolSet>({\n  toolCalls,\n  tools,\n  tracer,\n  telemetry,\n  messages,\n  abortSignal,\n  experimental_context,\n}: {\n  toolCalls: Array<TypedToolCall<TOOLS>>;\n  tools: TOOLS;\n  tracer: Tracer;\n  telemetry: TelemetrySettings | undefined;\n  messages: ModelMessage[];\n  abortSignal: AbortSignal | undefined;\n  experimental_context: unknown;\n}): Promise<Array<ToolOutput<TOOLS>>> {\n  const toolOutputs = await Promise.all(\n    toolCalls.map(async ({ toolCallId, toolName, input }) => {\n      const tool = tools[toolName];\n\n      if (tool?.execute == null) {\n        return undefined;\n      }\n\n      return recordSpan({\n        name: 'ai.toolCall',\n        attributes: selectTelemetryAttributes({\n          telemetry,\n          attributes: {\n            ...assembleOperationName({\n              operationId: 'ai.toolCall',\n              telemetry,\n            }),\n            'ai.toolCall.name': toolName,\n            'ai.toolCall.id': toolCallId,\n            'ai.toolCall.args': {\n              output: () => JSON.stringify(input),\n            },\n          },\n        }),\n        tracer,\n        fn: async span => {\n          try {\n            const stream = executeTool({\n              execute: tool.execute!.bind(tool),\n              input,\n              options: {\n                toolCallId,\n                messages,\n                abortSignal,\n                experimental_context,\n              },\n            });\n\n            let output: unknown;\n            for await (const part of stream) {\n              if (part.type === 'final') {\n                output = part.output;\n              }\n            }\n            try {\n              span.setAttributes(\n                selectTelemetryAttributes({\n                  telemetry,\n                  attributes: {\n                    'ai.toolCall.result': {\n                      output: () => JSON.stringify(output),\n                    },\n                  },\n                }),\n              );\n            } catch (ignored) {\n              // JSON stringify might fail if the result is not serializable,\n              // in which case we just ignore it. In the future we might want to\n              // add an optional serialize method to the tool interface and warn\n              // if the result is not serializable.\n            }\n\n            return {\n              type: 'tool-result',\n              toolCallId,\n              toolName,\n              input,\n              output,\n              dynamic: tool.type === 'dynamic',\n            } as TypedToolResult<TOOLS>;\n          } catch (error) {\n            recordErrorOnSpan(span, error);\n            return {\n              type: 'tool-error',\n              toolCallId,\n              toolName,\n              input,\n              error,\n              dynamic: tool.type === 'dynamic',\n            } as TypedToolError<TOOLS>;\n          }\n        },\n      });\n    }),\n  );\n\n  return toolOutputs.filter(\n    (output): output is NonNullable<typeof output> => output != null,\n  );\n}\n\nclass DefaultGenerateTextResult<TOOLS extends ToolSet, OUTPUT>\n  implements GenerateTextResult<TOOLS, OUTPUT>\n{\n  readonly steps: GenerateTextResult<TOOLS, OUTPUT>['steps'];\n\n  private readonly resolvedOutput: OUTPUT;\n\n  constructor(options: {\n    steps: GenerateTextResult<TOOLS, OUTPUT>['steps'];\n    resolvedOutput: OUTPUT;\n  }) {\n    this.steps = options.steps;\n    this.resolvedOutput = options.resolvedOutput;\n  }\n\n  private get finalStep() {\n    return this.steps[this.steps.length - 1];\n  }\n\n  get content() {\n    return this.finalStep.content;\n  }\n\n  get text() {\n    return this.finalStep.text;\n  }\n\n  get files() {\n    return this.finalStep.files;\n  }\n\n  get reasoningText() {\n    return this.finalStep.reasoningText;\n  }\n\n  get reasoning() {\n    return this.finalStep.reasoning;\n  }\n\n  get toolCalls() {\n    return this.finalStep.toolCalls;\n  }\n\n  get staticToolCalls() {\n    return this.finalStep.staticToolCalls;\n  }\n\n  get dynamicToolCalls() {\n    return this.finalStep.dynamicToolCalls;\n  }\n\n  get toolResults() {\n    return this.finalStep.toolResults;\n  }\n\n  get staticToolResults() {\n    return this.finalStep.staticToolResults;\n  }\n\n  get dynamicToolResults() {\n    return this.finalStep.dynamicToolResults;\n  }\n\n  get sources() {\n    return this.finalStep.sources;\n  }\n\n  get finishReason() {\n    return this.finalStep.finishReason;\n  }\n\n  get warnings() {\n    return this.finalStep.warnings;\n  }\n\n  get providerMetadata() {\n    return this.finalStep.providerMetadata;\n  }\n\n  get response() {\n    return this.finalStep.response;\n  }\n\n  get request() {\n    return this.finalStep.request;\n  }\n\n  get usage() {\n    return this.finalStep.usage;\n  }\n\n  get totalUsage() {\n    return this.steps.reduce(\n      (totalUsage, step) => {\n        return addLanguageModelUsage(totalUsage, step.usage);\n      },\n      {\n        inputTokens: undefined,\n        outputTokens: undefined,\n        totalTokens: undefined,\n        reasoningTokens: undefined,\n        cachedInputTokens: undefined,\n      } as LanguageModelUsage,\n    );\n  }\n\n  get experimental_output() {\n    if (this.resolvedOutput == null) {\n      throw new NoOutputSpecifiedError();\n    }\n\n    return this.resolvedOutput;\n  }\n}\n\nfunction asToolCalls(content: Array<LanguageModelV2Content>) {\n  const parts = content.filter(\n    (part): part is LanguageModelV2ToolCall => part.type === 'tool-call',\n  );\n\n  if (parts.length === 0) {\n    return undefined;\n  }\n\n  return parts.map(toolCall => ({\n    toolCallId: toolCall.toolCallId,\n    toolName: toolCall.toolName,\n    input: toolCall.input,\n  }));\n}\n\nfunction asContent<TOOLS extends ToolSet>({\n  content,\n  toolCalls,\n  toolOutputs,\n}: {\n  content: Array<LanguageModelV2Content>;\n  toolCalls: Array<TypedToolCall<TOOLS>>;\n  toolOutputs: Array<ToolOutput<TOOLS>>;\n}): Array<ContentPart<TOOLS>> {\n  return [\n    ...content.map(part => {\n      switch (part.type) {\n        case 'text':\n        case 'reasoning':\n        case 'source':\n          return part;\n\n        case 'file': {\n          return {\n            type: 'file' as const,\n            file: new DefaultGeneratedFile(part),\n          };\n        }\n\n        case 'tool-call': {\n          return toolCalls.find(\n            toolCall => toolCall.toolCallId === part.toolCallId,\n          )!;\n        }\n\n        case 'tool-result': {\n          const toolCall = toolCalls.find(\n            toolCall => toolCall.toolCallId === part.toolCallId,\n          )!;\n\n          if (toolCall == null) {\n            throw new Error(`Tool call ${part.toolCallId} not found.`);\n          }\n\n          if (part.isError) {\n            return {\n              type: 'tool-error' as const,\n              toolCallId: part.toolCallId,\n              toolName: part.toolName as keyof TOOLS & string,\n              input: toolCall.input,\n              error: part.result,\n              providerExecuted: true,\n              dynamic: toolCall.dynamic,\n            } as TypedToolError<TOOLS>;\n          }\n\n          return {\n            type: 'tool-result' as const,\n            toolCallId: part.toolCallId,\n            toolName: part.toolName as keyof TOOLS & string,\n            input: toolCall.input,\n            output: part.result,\n            providerExecuted: true,\n            dynamic: toolCall.dynamic,\n          } as TypedToolResult<TOOLS>;\n        }\n      }\n    }),\n    ...toolOutputs,\n  ];\n}\n","import { z } from 'zod/v4';\nimport {\n  ProviderMetadata,\n  providerMetadataSchema,\n} from '../types/provider-metadata';\nimport { FinishReason } from '../types/language-model';\nimport {\n  InferUIMessageData,\n  InferUIMessageMetadata,\n  UIDataTypes,\n  UIMessage,\n} from '../ui/ui-messages';\nimport { ValueOf } from '../util/value-of';\nimport { lazyValidator, zodSchema } from '@ai-sdk/provider-utils';\n\nexport const uiMessageChunkSchema = lazyValidator(() =>\n  zodSchema(\n    z.union([\n      z.strictObject({\n        type: z.literal('text-start'),\n        id: z.string(),\n        providerMetadata: providerMetadataSchema.optional(),\n      }),\n      z.strictObject({\n        type: z.literal('text-delta'),\n        id: z.string(),\n        delta: z.string(),\n        providerMetadata: providerMetadataSchema.optional(),\n      }),\n      z.strictObject({\n        type: z.literal('text-end'),\n        id: z.string(),\n        providerMetadata: providerMetadataSchema.optional(),\n      }),\n      z.strictObject({\n        type: z.literal('error'),\n        errorText: z.string(),\n      }),\n      z.strictObject({\n        type: z.literal('tool-input-start'),\n        toolCallId: z.string(),\n        toolName: z.string(),\n        providerExecuted: z.boolean().optional(),\n        dynamic: z.boolean().optional(),\n      }),\n      z.strictObject({\n        type: z.literal('tool-input-delta'),\n        toolCallId: z.string(),\n        inputTextDelta: z.string(),\n      }),\n      z.strictObject({\n        type: z.literal('tool-input-available'),\n        toolCallId: z.string(),\n        toolName: z.string(),\n        input: z.unknown(),\n        providerExecuted: z.boolean().optional(),\n        providerMetadata: providerMetadataSchema.optional(),\n        dynamic: z.boolean().optional(),\n      }),\n      z.strictObject({\n        type: z.literal('tool-input-error'),\n        toolCallId: z.string(),\n        toolName: z.string(),\n        input: z.unknown(),\n        providerExecuted: z.boolean().optional(),\n        providerMetadata: providerMetadataSchema.optional(),\n        dynamic: z.boolean().optional(),\n        errorText: z.string(),\n      }),\n      z.strictObject({\n        type: z.literal('tool-output-available'),\n        toolCallId: z.string(),\n        output: z.unknown(),\n        providerExecuted: z.boolean().optional(),\n        dynamic: z.boolean().optional(),\n        preliminary: z.boolean().optional(),\n      }),\n      z.strictObject({\n        type: z.literal('tool-output-error'),\n        toolCallId: z.string(),\n        errorText: z.string(),\n        providerExecuted: z.boolean().optional(),\n        dynamic: z.boolean().optional(),\n      }),\n      z.strictObject({\n        type: z.literal('reasoning-start'),\n        id: z.string(),\n        providerMetadata: providerMetadataSchema.optional(),\n      }),\n      z.strictObject({\n        type: z.literal('reasoning-delta'),\n        id: z.string(),\n        delta: z.string(),\n        providerMetadata: providerMetadataSchema.optional(),\n      }),\n      z.strictObject({\n        type: z.literal('reasoning-end'),\n        id: z.string(),\n        providerMetadata: providerMetadataSchema.optional(),\n      }),\n      z.strictObject({\n        type: z.literal('source-url'),\n        sourceId: z.string(),\n        url: z.string(),\n        title: z.string().optional(),\n        providerMetadata: providerMetadataSchema.optional(),\n      }),\n      z.strictObject({\n        type: z.literal('source-document'),\n        sourceId: z.string(),\n        mediaType: z.string(),\n        title: z.string(),\n        filename: z.string().optional(),\n        providerMetadata: providerMetadataSchema.optional(),\n      }),\n      z.strictObject({\n        type: z.literal('file'),\n        url: z.string(),\n        mediaType: z.string(),\n        providerMetadata: providerMetadataSchema.optional(),\n      }),\n      z.strictObject({\n        type: z.custom<`data-${string}`>(\n          (value): value is `data-${string}` =>\n            typeof value === 'string' && value.startsWith('data-'),\n          { message: 'Type must start with \"data-\"' },\n        ),\n        id: z.string().optional(),\n        data: z.unknown(),\n        transient: z.boolean().optional(),\n      }),\n      z.strictObject({\n        type: z.literal('start-step'),\n      }),\n      z.strictObject({\n        type: z.literal('finish-step'),\n      }),\n      z.strictObject({\n        type: z.literal('start'),\n        messageId: z.string().optional(),\n        messageMetadata: z.unknown().optional(),\n      }),\n      z.strictObject({\n        type: z.literal('finish'),\n        finishReason: z\n          .enum([\n            'stop',\n            'length',\n            'content-filter',\n            'tool-calls',\n            'error',\n            'other',\n            'unknown',\n          ] as const satisfies readonly FinishReason[])\n          .optional(),\n        messageMetadata: z.unknown().optional(),\n      }),\n      z.strictObject({\n        type: z.literal('abort'),\n      }),\n      z.strictObject({\n        type: z.literal('message-metadata'),\n        messageMetadata: z.unknown(),\n      }),\n    ]),\n  ),\n);\n\nexport type DataUIMessageChunk<DATA_TYPES extends UIDataTypes> = ValueOf<{\n  [NAME in keyof DATA_TYPES & string]: {\n    type: `data-${NAME}`;\n    id?: string;\n    data: DATA_TYPES[NAME];\n    transient?: boolean;\n  };\n}>;\n\nexport type UIMessageChunk<\n  METADATA = unknown,\n  DATA_TYPES extends UIDataTypes = UIDataTypes,\n> =\n  | {\n      type: 'text-start';\n      id: string;\n      providerMetadata?: ProviderMetadata;\n    }\n  | {\n      type: 'text-delta';\n      delta: string;\n      id: string;\n      providerMetadata?: ProviderMetadata;\n    }\n  | {\n      type: 'text-end';\n      id: string;\n      providerMetadata?: ProviderMetadata;\n    }\n  | {\n      type: 'reasoning-start';\n      id: string;\n      providerMetadata?: ProviderMetadata;\n    }\n  | {\n      type: 'reasoning-delta';\n      id: string;\n      delta: string;\n      providerMetadata?: ProviderMetadata;\n    }\n  | {\n      type: 'reasoning-end';\n      id: string;\n      providerMetadata?: ProviderMetadata;\n    }\n  | {\n      type: 'error';\n      errorText: string;\n    }\n  | {\n      type: 'tool-input-available';\n      toolCallId: string;\n      toolName: string;\n      input: unknown;\n      providerExecuted?: boolean;\n      providerMetadata?: ProviderMetadata;\n      dynamic?: boolean;\n    }\n  | {\n      type: 'tool-input-error';\n      toolCallId: string;\n      toolName: string;\n      input: unknown;\n      providerExecuted?: boolean;\n      providerMetadata?: ProviderMetadata;\n      dynamic?: boolean;\n      errorText: string;\n    }\n  | {\n      type: 'tool-output-available';\n      toolCallId: string;\n      output: unknown;\n      providerExecuted?: boolean;\n      dynamic?: boolean;\n      preliminary?: boolean;\n    }\n  | {\n      type: 'tool-output-error';\n      toolCallId: string;\n      errorText: string;\n      providerExecuted?: boolean;\n      dynamic?: boolean;\n    }\n  | {\n      type: 'tool-input-start';\n      toolCallId: string;\n      toolName: string;\n      providerExecuted?: boolean;\n      dynamic?: boolean;\n    }\n  | {\n      type: 'tool-input-delta';\n      toolCallId: string;\n      inputTextDelta: string;\n    }\n  | {\n      type: 'source-url';\n      sourceId: string;\n      url: string;\n      title?: string;\n      providerMetadata?: ProviderMetadata;\n    }\n  | {\n      type: 'source-document';\n      sourceId: string;\n      mediaType: string;\n      title: string;\n      filename?: string;\n      providerMetadata?: ProviderMetadata;\n    }\n  | {\n      type: 'file';\n      url: string;\n      mediaType: string;\n      providerMetadata?: ProviderMetadata;\n    }\n  | DataUIMessageChunk<DATA_TYPES>\n  | {\n      type: 'start-step';\n    }\n  | {\n      type: 'finish-step';\n    }\n  | {\n      type: 'start';\n      messageId?: string;\n      messageMetadata?: METADATA;\n    }\n  | {\n      type: 'finish';\n      finishReason?: FinishReason;\n      messageMetadata?: METADATA;\n    }\n  | {\n      type: 'abort';\n    }\n  | {\n      type: 'message-metadata';\n      messageMetadata: METADATA;\n    };\n\nexport function isDataUIMessageChunk(\n  chunk: UIMessageChunk,\n): chunk is DataUIMessageChunk<UIDataTypes> {\n  return chunk.type.startsWith('data-');\n}\n\nexport type InferUIMessageChunk<T extends UIMessage> = UIMessageChunk<\n  InferUIMessageMetadata<T>,\n  InferUIMessageData<T>\n>;\n","type State =\n  | 'ROOT'\n  | 'FINISH'\n  | 'INSIDE_STRING'\n  | 'INSIDE_STRING_ESCAPE'\n  | 'INSIDE_LITERAL'\n  | 'INSIDE_NUMBER'\n  | 'INSIDE_OBJECT_START'\n  | 'INSIDE_OBJECT_KEY'\n  | 'INSIDE_OBJECT_AFTER_KEY'\n  | 'INSIDE_OBJECT_BEFORE_VALUE'\n  | 'INSIDE_OBJECT_AFTER_VALUE'\n  | 'INSIDE_OBJECT_AFTER_COMMA'\n  | 'INSIDE_ARRAY_START'\n  | 'INSIDE_ARRAY_AFTER_VALUE'\n  | 'INSIDE_ARRAY_AFTER_COMMA';\n\n// Implemented as a scanner with additional fixing\n// that performs a single linear time scan pass over the partial JSON.\n//\n// The states should ideally match relevant states from the JSON spec:\n// https://www.json.org/json-en.html\n//\n// Please note that invalid JSON is not considered/covered, because it\n// is assumed that the resulting JSON will be processed by a standard\n// JSON parser that will detect any invalid JSON.\nexport function fixJson(input: string): string {\n  const stack: State[] = ['ROOT'];\n  let lastValidIndex = -1;\n  let literalStart: number | null = null;\n\n  function processValueStart(char: string, i: number, swapState: State) {\n    {\n      switch (char) {\n        case '\"': {\n          lastValidIndex = i;\n          stack.pop();\n          stack.push(swapState);\n          stack.push('INSIDE_STRING');\n          break;\n        }\n\n        case 'f':\n        case 't':\n        case 'n': {\n          lastValidIndex = i;\n          literalStart = i;\n          stack.pop();\n          stack.push(swapState);\n          stack.push('INSIDE_LITERAL');\n          break;\n        }\n\n        case '-': {\n          stack.pop();\n          stack.push(swapState);\n          stack.push('INSIDE_NUMBER');\n          break;\n        }\n        case '0':\n        case '1':\n        case '2':\n        case '3':\n        case '4':\n        case '5':\n        case '6':\n        case '7':\n        case '8':\n        case '9': {\n          lastValidIndex = i;\n          stack.pop();\n          stack.push(swapState);\n          stack.push('INSIDE_NUMBER');\n          break;\n        }\n\n        case '{': {\n          lastValidIndex = i;\n          stack.pop();\n          stack.push(swapState);\n          stack.push('INSIDE_OBJECT_START');\n          break;\n        }\n\n        case '[': {\n          lastValidIndex = i;\n          stack.pop();\n          stack.push(swapState);\n          stack.push('INSIDE_ARRAY_START');\n          break;\n        }\n      }\n    }\n  }\n\n  function processAfterObjectValue(char: string, i: number) {\n    switch (char) {\n      case ',': {\n        stack.pop();\n        stack.push('INSIDE_OBJECT_AFTER_COMMA');\n        break;\n      }\n      case '}': {\n        lastValidIndex = i;\n        stack.pop();\n        break;\n      }\n    }\n  }\n\n  function processAfterArrayValue(char: string, i: number) {\n    switch (char) {\n      case ',': {\n        stack.pop();\n        stack.push('INSIDE_ARRAY_AFTER_COMMA');\n        break;\n      }\n      case ']': {\n        lastValidIndex = i;\n        stack.pop();\n        break;\n      }\n    }\n  }\n\n  for (let i = 0; i < input.length; i++) {\n    const char = input[i];\n    const currentState = stack[stack.length - 1];\n\n    switch (currentState) {\n      case 'ROOT':\n        processValueStart(char, i, 'FINISH');\n        break;\n\n      case 'INSIDE_OBJECT_START': {\n        switch (char) {\n          case '\"': {\n            stack.pop();\n            stack.push('INSIDE_OBJECT_KEY');\n            break;\n          }\n          case '}': {\n            lastValidIndex = i;\n            stack.pop();\n            break;\n          }\n        }\n        break;\n      }\n\n      case 'INSIDE_OBJECT_AFTER_COMMA': {\n        switch (char) {\n          case '\"': {\n            stack.pop();\n            stack.push('INSIDE_OBJECT_KEY');\n            break;\n          }\n        }\n        break;\n      }\n\n      case 'INSIDE_OBJECT_KEY': {\n        switch (char) {\n          case '\"': {\n            stack.pop();\n            stack.push('INSIDE_OBJECT_AFTER_KEY');\n            break;\n          }\n        }\n        break;\n      }\n\n      case 'INSIDE_OBJECT_AFTER_KEY': {\n        switch (char) {\n          case ':': {\n            stack.pop();\n            stack.push('INSIDE_OBJECT_BEFORE_VALUE');\n\n            break;\n          }\n        }\n        break;\n      }\n\n      case 'INSIDE_OBJECT_BEFORE_VALUE': {\n        processValueStart(char, i, 'INSIDE_OBJECT_AFTER_VALUE');\n        break;\n      }\n\n      case 'INSIDE_OBJECT_AFTER_VALUE': {\n        processAfterObjectValue(char, i);\n        break;\n      }\n\n      case 'INSIDE_STRING': {\n        switch (char) {\n          case '\"': {\n            stack.pop();\n            lastValidIndex = i;\n            break;\n          }\n\n          case '\\\\': {\n            stack.push('INSIDE_STRING_ESCAPE');\n            break;\n          }\n\n          default: {\n            lastValidIndex = i;\n          }\n        }\n\n        break;\n      }\n\n      case 'INSIDE_ARRAY_START': {\n        switch (char) {\n          case ']': {\n            lastValidIndex = i;\n            stack.pop();\n            break;\n          }\n\n          default: {\n            lastValidIndex = i;\n            processValueStart(char, i, 'INSIDE_ARRAY_AFTER_VALUE');\n            break;\n          }\n        }\n        break;\n      }\n\n      case 'INSIDE_ARRAY_AFTER_VALUE': {\n        switch (char) {\n          case ',': {\n            stack.pop();\n            stack.push('INSIDE_ARRAY_AFTER_COMMA');\n            break;\n          }\n\n          case ']': {\n            lastValidIndex = i;\n            stack.pop();\n            break;\n          }\n\n          default: {\n            lastValidIndex = i;\n            break;\n          }\n        }\n\n        break;\n      }\n\n      case 'INSIDE_ARRAY_AFTER_COMMA': {\n        processValueStart(char, i, 'INSIDE_ARRAY_AFTER_VALUE');\n        break;\n      }\n\n      case 'INSIDE_STRING_ESCAPE': {\n        stack.pop();\n        lastValidIndex = i;\n\n        break;\n      }\n\n      case 'INSIDE_NUMBER': {\n        switch (char) {\n          case '0':\n          case '1':\n          case '2':\n          case '3':\n          case '4':\n          case '5':\n          case '6':\n          case '7':\n          case '8':\n          case '9': {\n            lastValidIndex = i;\n            break;\n          }\n\n          case 'e':\n          case 'E':\n          case '-':\n          case '.': {\n            break;\n          }\n\n          case ',': {\n            stack.pop();\n\n            if (stack[stack.length - 1] === 'INSIDE_ARRAY_AFTER_VALUE') {\n              processAfterArrayValue(char, i);\n            }\n\n            if (stack[stack.length - 1] === 'INSIDE_OBJECT_AFTER_VALUE') {\n              processAfterObjectValue(char, i);\n            }\n\n            break;\n          }\n\n          case '}': {\n            stack.pop();\n\n            if (stack[stack.length - 1] === 'INSIDE_OBJECT_AFTER_VALUE') {\n              processAfterObjectValue(char, i);\n            }\n\n            break;\n          }\n\n          case ']': {\n            stack.pop();\n\n            if (stack[stack.length - 1] === 'INSIDE_ARRAY_AFTER_VALUE') {\n              processAfterArrayValue(char, i);\n            }\n\n            break;\n          }\n\n          default: {\n            stack.pop();\n            break;\n          }\n        }\n\n        break;\n      }\n\n      case 'INSIDE_LITERAL': {\n        const partialLiteral = input.substring(literalStart!, i + 1);\n\n        if (\n          !'false'.startsWith(partialLiteral) &&\n          !'true'.startsWith(partialLiteral) &&\n          !'null'.startsWith(partialLiteral)\n        ) {\n          stack.pop();\n\n          if (stack[stack.length - 1] === 'INSIDE_OBJECT_AFTER_VALUE') {\n            processAfterObjectValue(char, i);\n          } else if (stack[stack.length - 1] === 'INSIDE_ARRAY_AFTER_VALUE') {\n            processAfterArrayValue(char, i);\n          }\n        } else {\n          lastValidIndex = i;\n        }\n\n        break;\n      }\n    }\n  }\n\n  let result = input.slice(0, lastValidIndex + 1);\n\n  for (let i = stack.length - 1; i >= 0; i--) {\n    const state = stack[i];\n\n    switch (state) {\n      case 'INSIDE_STRING': {\n        result += '\"';\n        break;\n      }\n\n      case 'INSIDE_OBJECT_KEY':\n      case 'INSIDE_OBJECT_AFTER_KEY':\n      case 'INSIDE_OBJECT_AFTER_COMMA':\n      case 'INSIDE_OBJECT_START':\n      case 'INSIDE_OBJECT_BEFORE_VALUE':\n      case 'INSIDE_OBJECT_AFTER_VALUE': {\n        result += '}';\n        break;\n      }\n\n      case 'INSIDE_ARRAY_START':\n      case 'INSIDE_ARRAY_AFTER_COMMA':\n      case 'INSIDE_ARRAY_AFTER_VALUE': {\n        result += ']';\n        break;\n      }\n\n      case 'INSIDE_LITERAL': {\n        const partialLiteral = input.substring(literalStart!, input.length);\n\n        if ('true'.startsWith(partialLiteral)) {\n          result += 'true'.slice(partialLiteral.length);\n        } else if ('false'.startsWith(partialLiteral)) {\n          result += 'false'.slice(partialLiteral.length);\n        } else if ('null'.startsWith(partialLiteral)) {\n          result += 'null'.slice(partialLiteral.length);\n        }\n      }\n    }\n  }\n\n  return result;\n}\n","import { JSONValue } from '@ai-sdk/provider';\nimport { safeParseJSON } from '@ai-sdk/provider-utils';\nimport { fixJson } from './fix-json';\n\nexport async function parsePartialJson(jsonText: string | undefined): Promise<{\n  value: JSONValue | undefined;\n  state:\n    | 'undefined-input'\n    | 'successful-parse'\n    | 'repaired-parse'\n    | 'failed-parse';\n}> {\n  if (jsonText === undefined) {\n    return { value: undefined, state: 'undefined-input' };\n  }\n\n  let result = await safeParseJSON({ text: jsonText });\n\n  if (result.success) {\n    return { value: result.value, state: 'successful-parse' };\n  }\n\n  result = await safeParseJSON({ text: fixJson(jsonText) });\n\n  if (result.success) {\n    return { value: result.value, state: 'repaired-parse' };\n  }\n\n  return { value: undefined, state: 'failed-parse' };\n}\n","import {\n  InferToolInput,\n  InferToolOutput,\n  Tool,\n  ToolCall,\n} from '@ai-sdk/provider-utils';\nimport { ToolSet } from '../generate-text';\nimport { ProviderMetadata } from '../types/provider-metadata';\nimport { DeepPartial } from '../util/deep-partial';\nimport { ValueOf } from '../util/value-of';\n\n/**\nThe data types that can be used in the UI message for the UI message data parts.\n */\nexport type UIDataTypes = Record<string, unknown>;\n\nexport type UITool = {\n  input: unknown;\n  output: unknown | undefined;\n};\n\n/**\n * Infer the input and output types of a tool so it can be used as a UI tool.\n */\nexport type InferUITool<TOOL extends Tool> = {\n  input: InferToolInput<TOOL>;\n  output: InferToolOutput<TOOL>;\n};\n\n/**\n * Infer the input and output types of a tool set so it can be used as a UI tool set.\n */\nexport type InferUITools<TOOLS extends ToolSet> = {\n  [NAME in keyof TOOLS & string]: InferUITool<TOOLS[NAME]>;\n};\n\nexport type UITools = Record<string, UITool>;\n\n/**\nAI SDK UI Messages. They are used in the client and to communicate between the frontend and the API routes.\n */\nexport interface UIMessage<\n  METADATA = unknown,\n  DATA_PARTS extends UIDataTypes = UIDataTypes,\n  TOOLS extends UITools = UITools,\n> {\n  /**\nA unique identifier for the message.\n   */\n  id: string;\n\n  /**\nThe role of the message.\n   */\n  role: 'system' | 'user' | 'assistant';\n\n  /**\nThe metadata of the message.\n   */\n  metadata?: METADATA;\n\n  /**\nThe parts of the message. Use this for rendering the message in the UI.\n\nSystem messages should be avoided (set the system prompt on the server instead).\nThey can have text parts.\n\nUser messages can have text parts and file parts.\n\nAssistant messages can have text, reasoning, tool invocation, and file parts.\n   */\n  parts: Array<UIMessagePart<DATA_PARTS, TOOLS>>;\n}\n\nexport type UIMessagePart<\n  DATA_TYPES extends UIDataTypes,\n  TOOLS extends UITools,\n> =\n  | TextUIPart\n  | ReasoningUIPart\n  | ToolUIPart<TOOLS>\n  | DynamicToolUIPart\n  | SourceUrlUIPart\n  | SourceDocumentUIPart\n  | FileUIPart\n  | DataUIPart<DATA_TYPES>\n  | StepStartUIPart;\n\n/**\n * A text part of a message.\n */\nexport type TextUIPart = {\n  type: 'text';\n\n  /**\n   * The text content.\n   */\n  text: string;\n\n  /**\n   * The state of the text part.\n   */\n  state?: 'streaming' | 'done';\n\n  /**\n   * The provider metadata.\n   */\n  providerMetadata?: ProviderMetadata;\n};\n\n/**\n * A reasoning part of a message.\n */\nexport type ReasoningUIPart = {\n  type: 'reasoning';\n\n  /**\n   * The reasoning text.\n   */\n  text: string;\n\n  /**\n   * The state of the reasoning part.\n   */\n  state?: 'streaming' | 'done';\n\n  /**\n   * The provider metadata.\n   */\n  providerMetadata?: ProviderMetadata;\n};\n\n/**\n * A source part of a message.\n */\nexport type SourceUrlUIPart = {\n  type: 'source-url';\n  sourceId: string;\n  url: string;\n  title?: string;\n  providerMetadata?: ProviderMetadata;\n};\n\n/**\n * A document source part of a message.\n */\nexport type SourceDocumentUIPart = {\n  type: 'source-document';\n  sourceId: string;\n  mediaType: string;\n  title: string;\n  filename?: string;\n  providerMetadata?: ProviderMetadata;\n};\n\n/**\n * A file part of a message.\n */\nexport type FileUIPart = {\n  type: 'file';\n\n  /**\n   * IANA media type of the file.\n   *\n   * @see https://www.iana.org/assignments/media-types/media-types.xhtml\n   */\n  mediaType: string;\n\n  /**\n   * Optional filename of the file.\n   */\n  filename?: string;\n\n  /**\n   * The URL of the file.\n   * It can either be a URL to a hosted file or a [Data URL](https://developer.mozilla.org/en-US/docs/Web/HTTP/Basics_of_HTTP/Data_URLs).\n   */\n  url: string;\n\n  /**\n   * The provider metadata.\n   */\n  providerMetadata?: ProviderMetadata;\n};\n\n/**\n * A step boundary part of a message.\n */\nexport type StepStartUIPart = {\n  type: 'step-start';\n};\n\nexport type DataUIPart<DATA_TYPES extends UIDataTypes> = ValueOf<{\n  [NAME in keyof DATA_TYPES & string]: {\n    type: `data-${NAME}`;\n    id?: string;\n    data: DATA_TYPES[NAME];\n  };\n}>;\n\ntype asUITool<TOOL extends UITool | Tool> = TOOL extends Tool\n  ? InferUITool<TOOL>\n  : TOOL;\n\n/**\n * Check if a message part is a data part.\n */\nexport function isDataUIPart<DATA_TYPES extends UIDataTypes>(\n  part: UIMessagePart<DATA_TYPES, UITools>,\n): part is DataUIPart<DATA_TYPES> {\n  return part.type.startsWith('data-');\n}\n\n/**\n * A UI tool invocation contains all the information needed to render a tool invocation in the UI.\n * It can be derived from a tool without knowing the tool name, and can be used to define\n * UI components for the tool.\n */\nexport type UIToolInvocation<TOOL extends UITool | Tool> = {\n  /**\n   * ID of the tool call.\n   */\n  toolCallId: string;\n\n  /**\n   * Whether the tool call was executed by the provider.\n   */\n  providerExecuted?: boolean;\n} & (\n  | {\n      state: 'input-streaming';\n      input: DeepPartial<asUITool<TOOL>['input']> | undefined;\n      providerExecuted?: boolean;\n      output?: never;\n      errorText?: never;\n    }\n  | {\n      state: 'input-available';\n      input: asUITool<TOOL>['input'];\n      providerExecuted?: boolean;\n      output?: never;\n      errorText?: never;\n      callProviderMetadata?: ProviderMetadata;\n    }\n  | {\n      state: 'output-available';\n      input: asUITool<TOOL>['input'];\n      output: asUITool<TOOL>['output'];\n      errorText?: never;\n      providerExecuted?: boolean;\n      callProviderMetadata?: ProviderMetadata;\n      preliminary?: boolean;\n    }\n  | {\n      state: 'output-error'; // TODO AI SDK 6: change to 'error' state\n      input: asUITool<TOOL>['input'] | undefined;\n      rawInput?: unknown; // TODO AI SDK 6: remove this field, input should be unknown\n      output?: never;\n      errorText: string;\n      providerExecuted?: boolean;\n      callProviderMetadata?: ProviderMetadata;\n    }\n);\n\nexport type ToolUIPart<TOOLS extends UITools = UITools> = ValueOf<{\n  [NAME in keyof TOOLS & string]: {\n    type: `tool-${NAME}`;\n  } & UIToolInvocation<TOOLS[NAME]>;\n}>;\n\nexport type DynamicToolUIPart = {\n  type: 'dynamic-tool';\n\n  /**\n   * Name of the tool that is being called.\n   */\n  toolName: string;\n\n  /**\n   * ID of the tool call.\n   */\n  toolCallId: string;\n  title?: string;\n\n  /**\n   * Whether the tool call was executed by the provider.\n   */\n  providerExecuted?: boolean;\n} & (\n  | {\n      state: 'input-streaming';\n      input: unknown | undefined;\n      output?: never;\n      errorText?: never;\n    }\n  | {\n      state: 'input-available';\n      input: unknown;\n      output?: never;\n      errorText?: never;\n      callProviderMetadata?: ProviderMetadata;\n    }\n  | {\n      state: 'output-available';\n      input: unknown;\n      output: unknown;\n      errorText?: never;\n      callProviderMetadata?: ProviderMetadata;\n      preliminary?: boolean;\n    }\n  | {\n      state: 'output-error'; // TODO AI SDK 6: change to 'error' state\n      input: unknown;\n      output?: never;\n      errorText: string;\n      callProviderMetadata?: ProviderMetadata;\n    }\n);\n\n/**\n * Type guard to check if a message part is a text part.\n */\nexport function isTextUIPart(\n  part: UIMessagePart<UIDataTypes, UITools>,\n): part is TextUIPart {\n  return part.type === 'text';\n}\n\n/**\n * Type guard to check if a message part is a file part.\n */\nexport function isFileUIPart(\n  part: UIMessagePart<UIDataTypes, UITools>,\n): part is FileUIPart {\n  return part.type === 'file';\n}\n\n/**\n * Type guard to check if a message part is a reasoning part.\n */\nexport function isReasoningUIPart(\n  part: UIMessagePart<UIDataTypes, UITools>,\n): part is ReasoningUIPart {\n  return part.type === 'reasoning';\n}\n\n// TODO AI SDK 6: rename to isStaticToolUIPart\nexport function isToolUIPart<TOOLS extends UITools>(\n  part: UIMessagePart<UIDataTypes, TOOLS>,\n): part is ToolUIPart<TOOLS> {\n  return part.type.startsWith('tool-');\n}\n\nexport function isDynamicToolUIPart(\n  part: UIMessagePart<UIDataTypes, UITools>,\n): part is DynamicToolUIPart {\n  return part.type === 'dynamic-tool';\n}\n\nexport function isToolOrDynamicToolUIPart<TOOLS extends UITools>(\n  part: UIMessagePart<UIDataTypes, TOOLS>,\n): part is ToolUIPart<TOOLS> | DynamicToolUIPart {\n  return isToolUIPart(part) || isDynamicToolUIPart(part);\n}\n\nexport function getToolName<TOOLS extends UITools>(\n  part: ToolUIPart<TOOLS>,\n): keyof TOOLS {\n  return part.type.split('-').slice(1).join('-') as keyof TOOLS;\n}\n\nexport function getToolOrDynamicToolName(\n  part: ToolUIPart<UITools> | DynamicToolUIPart,\n): string {\n  return isDynamicToolUIPart(part) ? part.toolName : getToolName(part);\n}\n\nexport type InferUIMessageMetadata<T extends UIMessage> =\n  T extends UIMessage<infer METADATA> ? METADATA : unknown;\n\nexport type InferUIMessageData<T extends UIMessage> =\n  T extends UIMessage<unknown, infer DATA_TYPES> ? DATA_TYPES : UIDataTypes;\n\nexport type InferUIMessageTools<T extends UIMessage> =\n  T extends UIMessage<unknown, UIDataTypes, infer TOOLS> ? TOOLS : UITools;\n\nexport type InferUIMessageToolOutputs<UI_MESSAGE extends UIMessage> =\n  InferUIMessageTools<UI_MESSAGE>[keyof InferUIMessageTools<UI_MESSAGE>]['output'];\n\nexport type InferUIMessageToolCall<UI_MESSAGE extends UIMessage> =\n  | ValueOf<{\n      [NAME in keyof InferUIMessageTools<UI_MESSAGE>]: ToolCall<\n        NAME & string,\n        InferUIMessageTools<UI_MESSAGE>[NAME] extends { input: infer INPUT }\n          ? INPUT\n          : never\n      > & { dynamic?: false };\n    }>\n  | (ToolCall<string, unknown> & { dynamic: true });\n\nexport type InferUIMessagePart<UI_MESSAGE extends UIMessage> = UIMessagePart<\n  InferUIMessageData<UI_MESSAGE>,\n  InferUIMessageTools<UI_MESSAGE>\n>;\n","import {\n  getErrorMessage,\n  LanguageModelV2,\n  LanguageModelV2CallWarning,\n} from '@ai-sdk/provider';\nimport {\n  createIdGenerator,\n  IdGenerator,\n  isAbortError,\n  ProviderOptions,\n} from '@ai-sdk/provider-utils';\nimport { Span } from '@opentelemetry/api';\nimport { ServerResponse } from 'node:http';\nimport { NoOutputGeneratedError } from '../error';\nimport { NoOutputSpecifiedError } from '../error/no-output-specified-error';\nimport { logWarnings } from '../logger/log-warnings';\nimport { resolveLanguageModel } from '../model/resolve-model';\nimport { CallSettings } from '../prompt/call-settings';\nimport { convertToLanguageModelPrompt } from '../prompt/convert-to-language-model-prompt';\nimport { prepareCallSettings } from '../prompt/prepare-call-settings';\nimport { prepareToolsAndToolChoice } from '../prompt/prepare-tools-and-tool-choice';\nimport { Prompt } from '../prompt/prompt';\nimport { standardizePrompt } from '../prompt/standardize-prompt';\nimport { wrapGatewayError } from '../prompt/wrap-gateway-error';\nimport { assembleOperationName } from '../telemetry/assemble-operation-name';\nimport { getBaseTelemetryAttributes } from '../telemetry/get-base-telemetry-attributes';\nimport { getTracer } from '../telemetry/get-tracer';\nimport { recordSpan } from '../telemetry/record-span';\nimport { selectTelemetryAttributes } from '../telemetry/select-telemetry-attributes';\nimport { stringifyForTelemetry } from '../telemetry/stringify-for-telemetry';\nimport { TelemetrySettings } from '../telemetry/telemetry-settings';\nimport { createTextStreamResponse } from '../text-stream/create-text-stream-response';\nimport { pipeTextStreamToResponse } from '../text-stream/pipe-text-stream-to-response';\nimport { LanguageModelRequestMetadata } from '../types';\nimport {\n  CallWarning,\n  FinishReason,\n  LanguageModel,\n  ToolChoice,\n} from '../types/language-model';\nimport { ProviderMetadata } from '../types/provider-metadata';\nimport { addLanguageModelUsage, LanguageModelUsage } from '../types/usage';\nimport { UIMessage } from '../ui';\nimport { createUIMessageStreamResponse } from '../ui-message-stream/create-ui-message-stream-response';\nimport { getResponseUIMessageId } from '../ui-message-stream/get-response-ui-message-id';\nimport { handleUIMessageStreamFinish } from '../ui-message-stream/handle-ui-message-stream-finish';\nimport { pipeUIMessageStreamToResponse } from '../ui-message-stream/pipe-ui-message-stream-to-response';\nimport {\n  InferUIMessageChunk,\n  UIMessageChunk,\n} from '../ui-message-stream/ui-message-chunks';\nimport { UIMessageStreamResponseInit } from '../ui-message-stream/ui-message-stream-response-init';\nimport { InferUIMessageData, InferUIMessageMetadata } from '../ui/ui-messages';\nimport { asArray } from '../util/as-array';\nimport {\n  AsyncIterableStream,\n  createAsyncIterableStream,\n} from '../util/async-iterable-stream';\nimport { consumeStream } from '../util/consume-stream';\nimport { createStitchableStream } from '../util/create-stitchable-stream';\nimport { DelayedPromise } from '../util/delayed-promise';\nimport { DownloadFunction } from '../util/download/download-function';\nimport { now as originalNow } from '../util/now';\nimport { prepareRetries } from '../util/prepare-retries';\nimport { ContentPart } from './content-part';\nimport { Output } from './output';\nimport { PrepareStepFunction } from './prepare-step';\nimport { ResponseMessage } from './response-message';\nimport {\n  runToolsTransformation,\n  SingleRequestTextStreamPart,\n} from './run-tools-transformation';\nimport { DefaultStepResult, StepResult } from './step-result';\nimport {\n  isStopConditionMet,\n  stepCountIs,\n  StopCondition,\n} from './stop-condition';\nimport {\n  ConsumeStreamOptions,\n  StreamTextResult,\n  TextStreamPart,\n  UIMessageStreamOptions,\n} from './stream-text-result';\nimport { toResponseMessages } from './to-response-messages';\nimport { TypedToolCall } from './tool-call';\nimport { ToolCallRepairFunction } from './tool-call-repair-function';\nimport { ToolOutput } from './tool-output';\nimport { ToolSet } from './tool-set';\n\nconst originalGenerateId = createIdGenerator({\n  prefix: 'aitxt',\n  size: 24,\n});\n\n/**\nA transformation that is applied to the stream.\n\n@param stopStream - A function that stops the source stream.\n@param tools - The tools that are accessible to and can be called by the model. The model needs to support calling tools.\n */\nexport type StreamTextTransform<TOOLS extends ToolSet> = (options: {\n  tools: TOOLS; // for type inference\n  stopStream: () => void;\n}) => TransformStream<TextStreamPart<TOOLS>, TextStreamPart<TOOLS>>;\n\n/**\nCallback that is set using the `onError` option.\n\n@param event - The event that is passed to the callback.\n */\nexport type StreamTextOnErrorCallback = (event: {\n  error: unknown;\n}) => PromiseLike<void> | void;\n\n/**\nCallback that is set using the `onStepFinish` option.\n\n@param stepResult - The result of the step.\n */\nexport type StreamTextOnStepFinishCallback<TOOLS extends ToolSet> = (\n  stepResult: StepResult<TOOLS>,\n) => PromiseLike<void> | void;\n\n/**\nCallback that is set using the `onChunk` option.\n\n@param event - The event that is passed to the callback.\n */\nexport type StreamTextOnChunkCallback<TOOLS extends ToolSet> = (event: {\n  chunk: Extract<\n    TextStreamPart<TOOLS>,\n    {\n      type:\n        | 'text-delta'\n        | 'reasoning-delta'\n        | 'source'\n        | 'tool-call'\n        | 'tool-input-start'\n        | 'tool-input-delta'\n        | 'tool-result'\n        | 'raw';\n    }\n  >;\n}) => PromiseLike<void> | void;\n\n/**\nCallback that is set using the `onFinish` option.\n\n@param event - The event that is passed to the callback.\n */\nexport type StreamTextOnFinishCallback<TOOLS extends ToolSet> = (\n  event: StepResult<TOOLS> & {\n    /**\nDetails for all steps.\n   */\n    readonly steps: StepResult<TOOLS>[];\n\n    /**\nTotal usage for all steps. This is the sum of the usage of all steps.\n     */\n    readonly totalUsage: LanguageModelUsage;\n  },\n) => PromiseLike<void> | void;\n\n/**\nCallback that is set using the `onAbort` option.\n\n@param event - The event that is passed to the callback.\n */\nexport type StreamTextOnAbortCallback<TOOLS extends ToolSet> = (event: {\n  /**\nDetails for all previously finished steps.\n   */\n  readonly steps: StepResult<TOOLS>[];\n}) => PromiseLike<void> | void;\n\n/**\nGenerate a text and call tools for a given prompt using a language model.\n\nThis function streams the output. If you do not want to stream the output, use `generateText` instead.\n\n@param model - The language model to use.\n@param tools - Tools that are accessible to and can be called by the model. The model needs to support calling tools.\n\n@param system - A system message that will be part of the prompt.\n@param prompt - A simple text prompt. You can either use `prompt` or `messages` but not both.\n@param messages - A list of messages. You can either use `prompt` or `messages` but not both.\n\n@param maxOutputTokens - Maximum number of tokens to generate.\n@param temperature - Temperature setting.\nThe value is passed through to the provider. The range depends on the provider and model.\nIt is recommended to set either `temperature` or `topP`, but not both.\n@param topP - Nucleus sampling.\nThe value is passed through to the provider. The range depends on the provider and model.\nIt is recommended to set either `temperature` or `topP`, but not both.\n@param topK - Only sample from the top K options for each subsequent token.\nUsed to remove \"long tail\" low probability responses.\nRecommended for advanced use cases only. You usually only need to use temperature.\n@param presencePenalty - Presence penalty setting.\nIt affects the likelihood of the model to repeat information that is already in the prompt.\nThe value is passed through to the provider. The range depends on the provider and model.\n@param frequencyPenalty - Frequency penalty setting.\nIt affects the likelihood of the model to repeatedly use the same words or phrases.\nThe value is passed through to the provider. The range depends on the provider and model.\n@param stopSequences - Stop sequences.\nIf set, the model will stop generating text when one of the stop sequences is generated.\n@param seed - The seed (integer) to use for random sampling.\nIf set and supported by the model, calls will generate deterministic results.\n\n@param maxRetries - Maximum number of retries. Set to 0 to disable retries. Default: 2.\n@param abortSignal - An optional abort signal that can be used to cancel the call.\n@param headers - Additional HTTP headers to be sent with the request. Only applicable for HTTP-based providers.\n\n@param maxSteps - Maximum number of sequential LLM calls (steps), e.g. when you use tool calls.\n\n@param onChunk - Callback that is called for each chunk of the stream. The stream processing will pause until the callback promise is resolved.\n@param onError - Callback that is called when an error occurs during streaming. You can use it to log errors.\n@param onStepFinish - Callback that is called when each step (LLM call) is finished, including intermediate steps.\n@param onFinish - Callback that is called when the LLM response and all request tool executions\n(for tools that have an `execute` function) are finished.\n\n@return\nA result object for accessing different stream types and additional information.\n */\nexport function streamText<\n  TOOLS extends ToolSet,\n  OUTPUT = never,\n  PARTIAL_OUTPUT = never,\n>({\n  model,\n  tools,\n  toolChoice,\n  system,\n  prompt,\n  messages,\n  maxRetries,\n  abortSignal,\n  headers,\n  stopWhen = stepCountIs(1),\n  experimental_output: output,\n  experimental_telemetry: telemetry,\n  prepareStep,\n  providerOptions,\n  experimental_activeTools,\n  activeTools = experimental_activeTools,\n  experimental_repairToolCall: repairToolCall,\n  experimental_transform: transform,\n  experimental_download: download,\n  includeRawChunks = false,\n  onChunk,\n  onError = ({ error }) => {\n    console.error(error);\n  },\n  onFinish,\n  onAbort,\n  onStepFinish,\n  experimental_context,\n  _internal: {\n    now = originalNow,\n    generateId = originalGenerateId,\n    currentDate = () => new Date(),\n  } = {},\n  ...settings\n}: CallSettings &\n  Prompt & {\n    /**\nThe language model to use.\n     */\n    model: LanguageModel;\n\n    /**\nThe tools that the model can call. The model needs to support calling tools.\n    */\n    tools?: TOOLS;\n\n    /**\nThe tool choice strategy. Default: 'auto'.\n     */\n    toolChoice?: ToolChoice<TOOLS>;\n\n    /**\nCondition for stopping the generation when there are tool results in the last step.\nWhen the condition is an array, any of the conditions can be met to stop the generation.\n\n@default stepCountIs(1)\n     */\n    stopWhen?:\n      | StopCondition<NoInfer<TOOLS>>\n      | Array<StopCondition<NoInfer<TOOLS>>>;\n\n    /**\nOptional telemetry configuration (experimental).\n     */\n    experimental_telemetry?: TelemetrySettings;\n\n    /**\nAdditional provider-specific options. They are passed through\nto the provider from the AI SDK and enable provider-specific\nfunctionality that can be fully encapsulated in the provider.\n */\n    providerOptions?: ProviderOptions;\n\n    /**\n     * @deprecated Use `activeTools` instead.\n     */\n    experimental_activeTools?: Array<keyof NoInfer<TOOLS>>;\n\n    /**\n   Limits the tools that are available for the model to call without\n   changing the tool call and result types in the result.\n        */\n    activeTools?: Array<keyof NoInfer<TOOLS>>;\n\n    /**\nOptional specification for parsing structured outputs from the LLM response.\n     */\n    experimental_output?: Output<OUTPUT, PARTIAL_OUTPUT>;\n\n    /**\nOptional function that you can use to provide different settings for a step.\n\n@param options - The options for the step.\n@param options.steps - The steps that have been executed so far.\n@param options.stepNumber - The number of the step that is being executed.\n@param options.model - The model that is being used.\n\n@returns An object that contains the settings for the step.\nIf you return undefined (or for undefined settings), the settings from the outer level will be used.\n    */\n    prepareStep?: PrepareStepFunction<NoInfer<TOOLS>>;\n\n    /**\nA function that attempts to repair a tool call that failed to parse.\n     */\n    experimental_repairToolCall?: ToolCallRepairFunction<TOOLS>;\n\n    /**\nOptional stream transformations.\nThey are applied in the order they are provided.\nThe stream transformations must maintain the stream structure for streamText to work correctly.\n     */\n    experimental_transform?:\n      | StreamTextTransform<TOOLS>\n      | Array<StreamTextTransform<TOOLS>>;\n\n    /**\nCustom download function to use for URLs.\n\nBy default, files are downloaded if the model does not support the URL for the given media type.\n     */\n    experimental_download?: DownloadFunction | undefined;\n\n    /**\nWhether to include raw chunks from the provider in the stream.\nWhen enabled, you will receive raw chunks with type 'raw' that contain the unprocessed data from the provider.\nThis allows access to cutting-edge provider features not yet wrapped by the AI SDK.\nDefaults to false.\n     */\n    includeRawChunks?: boolean;\n\n    /**\nCallback that is called for each chunk of the stream.\nThe stream processing will pause until the callback promise is resolved.\n     */\n    onChunk?: StreamTextOnChunkCallback<TOOLS>;\n\n    /**\nCallback that is invoked when an error occurs during streaming.\nYou can use it to log errors.\nThe stream processing will pause until the callback promise is resolved.\n     */\n    onError?: StreamTextOnErrorCallback;\n\n    /**\nCallback that is called when the LLM response and all request tool executions\n(for tools that have an `execute` function) are finished.\n\nThe usage is the combined usage of all steps.\n     */\n    onFinish?: StreamTextOnFinishCallback<TOOLS>;\n\n    onAbort?: StreamTextOnAbortCallback<TOOLS>;\n\n    /**\nCallback that is called when each step (LLM call) is finished, including intermediate steps.\n    */\n    onStepFinish?: StreamTextOnStepFinishCallback<TOOLS>;\n\n    /**\n     * Context that is passed into tool execution.\n     *\n     * Experimental (can break in patch releases).\n     *\n     * @default undefined\n     */\n    experimental_context?: unknown;\n\n    /**\nInternal. For test use only. May change without notice.\n     */\n    _internal?: {\n      now?: () => number;\n      generateId?: IdGenerator;\n      currentDate?: () => Date;\n    };\n  }): StreamTextResult<TOOLS, PARTIAL_OUTPUT> {\n  return new DefaultStreamTextResult<TOOLS, OUTPUT, PARTIAL_OUTPUT>({\n    model: resolveLanguageModel(model),\n    telemetry,\n    headers,\n    settings,\n    maxRetries,\n    abortSignal,\n    system,\n    prompt,\n    messages,\n    tools,\n    toolChoice,\n    transforms: asArray(transform),\n    activeTools,\n    repairToolCall,\n    stopConditions: asArray(stopWhen),\n    output,\n    providerOptions,\n    prepareStep,\n    includeRawChunks,\n    onChunk,\n    onError,\n    onFinish,\n    onAbort,\n    onStepFinish,\n    now,\n    currentDate,\n    generateId,\n    experimental_context,\n    download,\n  });\n}\n\ntype EnrichedStreamPart<TOOLS extends ToolSet, PARTIAL_OUTPUT> = {\n  part: TextStreamPart<TOOLS>;\n  partialOutput: PARTIAL_OUTPUT | undefined;\n};\n\nfunction createOutputTransformStream<\n  TOOLS extends ToolSet,\n  OUTPUT,\n  PARTIAL_OUTPUT,\n>(\n  output: Output<OUTPUT, PARTIAL_OUTPUT> | undefined,\n): TransformStream<\n  TextStreamPart<TOOLS>,\n  EnrichedStreamPart<TOOLS, PARTIAL_OUTPUT>\n> {\n  if (!output) {\n    return new TransformStream<\n      TextStreamPart<TOOLS>,\n      EnrichedStreamPart<TOOLS, PARTIAL_OUTPUT>\n    >({\n      transform(chunk, controller) {\n        controller.enqueue({ part: chunk, partialOutput: undefined });\n      },\n    });\n  }\n\n  let firstTextChunkId: string | undefined = undefined;\n  let text = '';\n  let textChunk = '';\n  let lastPublishedJson = '';\n\n  function publishTextChunk({\n    controller,\n    partialOutput = undefined,\n  }: {\n    controller: TransformStreamDefaultController<\n      EnrichedStreamPart<TOOLS, PARTIAL_OUTPUT>\n    >;\n    partialOutput?: PARTIAL_OUTPUT;\n  }) {\n    controller.enqueue({\n      part: {\n        type: 'text-delta',\n        id: firstTextChunkId!,\n        text: textChunk,\n      },\n      partialOutput,\n    });\n    textChunk = '';\n  }\n\n  return new TransformStream<\n    TextStreamPart<TOOLS>,\n    EnrichedStreamPart<TOOLS, PARTIAL_OUTPUT>\n  >({\n    async transform(chunk, controller) {\n      // ensure that we publish the last text chunk before the step finish:\n      if (chunk.type === 'finish-step' && textChunk.length > 0) {\n        publishTextChunk({ controller });\n      }\n\n      if (\n        chunk.type !== 'text-delta' &&\n        chunk.type !== 'text-start' &&\n        chunk.type !== 'text-end'\n      ) {\n        controller.enqueue({ part: chunk, partialOutput: undefined });\n        return;\n      }\n\n      // we have to pick a text chunk which contains the json text\n      // since we are streaming, we have to pick the first text chunk\n      if (firstTextChunkId == null) {\n        firstTextChunkId = chunk.id;\n      } else if (chunk.id !== firstTextChunkId) {\n        controller.enqueue({ part: chunk, partialOutput: undefined });\n        return;\n      }\n\n      if (chunk.type === 'text-start') {\n        controller.enqueue({ part: chunk, partialOutput: undefined });\n        return;\n      }\n\n      if (chunk.type === 'text-end') {\n        if (textChunk.length > 0) {\n          publishTextChunk({ controller });\n        }\n        controller.enqueue({ part: chunk, partialOutput: undefined });\n        return;\n      }\n\n      text += chunk.text;\n      textChunk += chunk.text;\n\n      // only publish if partial json can be parsed:\n      const result = await output.parsePartial({ text });\n      if (result != null) {\n        // only send new json if it has changed:\n        const currentJson = JSON.stringify(result.partial);\n        if (currentJson !== lastPublishedJson) {\n          publishTextChunk({ controller, partialOutput: result.partial });\n          lastPublishedJson = currentJson;\n        }\n      }\n    },\n  });\n}\n\nclass DefaultStreamTextResult<TOOLS extends ToolSet, OUTPUT, PARTIAL_OUTPUT>\n  implements StreamTextResult<TOOLS, PARTIAL_OUTPUT>\n{\n  private readonly _totalUsage = new DelayedPromise<\n    Awaited<StreamTextResult<TOOLS, PARTIAL_OUTPUT>['usage']>\n  >();\n  private readonly _finishReason = new DelayedPromise<\n    Awaited<StreamTextResult<TOOLS, PARTIAL_OUTPUT>['finishReason']>\n  >();\n  private readonly _steps = new DelayedPromise<\n    Awaited<StreamTextResult<TOOLS, PARTIAL_OUTPUT>['steps']>\n  >();\n\n  private readonly addStream: (\n    stream: ReadableStream<TextStreamPart<TOOLS>>,\n  ) => void;\n\n  private readonly closeStream: () => void;\n\n  private baseStream: ReadableStream<EnrichedStreamPart<TOOLS, PARTIAL_OUTPUT>>;\n\n  private output: Output<OUTPUT, PARTIAL_OUTPUT> | undefined;\n\n  private includeRawChunks: boolean;\n\n  private tools: TOOLS | undefined;\n\n  constructor({\n    model,\n    telemetry,\n    headers,\n    settings,\n    maxRetries: maxRetriesArg,\n    abortSignal,\n    system,\n    prompt,\n    messages,\n    tools,\n    toolChoice,\n    transforms,\n    activeTools,\n    repairToolCall,\n    stopConditions,\n    output,\n    providerOptions,\n    prepareStep,\n    includeRawChunks,\n    now,\n    currentDate,\n    generateId,\n    onChunk,\n    onError,\n    onFinish,\n    onAbort,\n    onStepFinish,\n    experimental_context,\n    download,\n  }: {\n    model: LanguageModelV2;\n    telemetry: TelemetrySettings | undefined;\n    headers: Record<string, string | undefined> | undefined;\n    settings: Omit<CallSettings, 'abortSignal' | 'headers'>;\n    maxRetries: number | undefined;\n    abortSignal: AbortSignal | undefined;\n    system: Prompt['system'];\n    prompt: Prompt['prompt'];\n    messages: Prompt['messages'];\n    tools: TOOLS | undefined;\n    toolChoice: ToolChoice<TOOLS> | undefined;\n    transforms: Array<StreamTextTransform<TOOLS>>;\n    activeTools: Array<keyof TOOLS> | undefined;\n    repairToolCall: ToolCallRepairFunction<TOOLS> | undefined;\n    stopConditions: Array<StopCondition<NoInfer<TOOLS>>>;\n    output: Output<OUTPUT, PARTIAL_OUTPUT> | undefined;\n    providerOptions: ProviderOptions | undefined;\n    prepareStep: PrepareStepFunction<NoInfer<TOOLS>> | undefined;\n    includeRawChunks: boolean;\n    now: () => number;\n    currentDate: () => Date;\n    generateId: () => string;\n    experimental_context: unknown;\n    download: DownloadFunction | undefined;\n\n    // callbacks:\n    onChunk: undefined | StreamTextOnChunkCallback<TOOLS>;\n    onError: StreamTextOnErrorCallback;\n    onFinish: undefined | StreamTextOnFinishCallback<TOOLS>;\n    onAbort: undefined | StreamTextOnAbortCallback<TOOLS>;\n    onStepFinish: undefined | StreamTextOnStepFinishCallback<TOOLS>;\n  }) {\n    this.output = output;\n    this.includeRawChunks = includeRawChunks;\n    this.tools = tools;\n\n    // promise to ensure that the step has been fully processed by the event processor\n    // before a new step is started. This is required because the continuation condition\n    // needs the updated steps to determine if another step is needed.\n    let stepFinish!: DelayedPromise<void>;\n\n    let recordedContent: Array<ContentPart<TOOLS>> = [];\n    const recordedResponseMessages: Array<ResponseMessage> = [];\n    let recordedFinishReason: FinishReason | undefined = undefined;\n    let recordedTotalUsage: LanguageModelUsage | undefined = undefined;\n    let recordedRequest: LanguageModelRequestMetadata = {};\n    let recordedWarnings: Array<CallWarning> = [];\n    const recordedSteps: StepResult<TOOLS>[] = [];\n\n    let rootSpan!: Span;\n\n    let activeTextContent: Record<\n      string,\n      {\n        type: 'text';\n        text: string;\n        providerMetadata: ProviderMetadata | undefined;\n      }\n    > = {};\n\n    let activeReasoningContent: Record<\n      string,\n      {\n        type: 'reasoning';\n        text: string;\n        providerMetadata: ProviderMetadata | undefined;\n      }\n    > = {};\n\n    const eventProcessor = new TransformStream<\n      EnrichedStreamPart<TOOLS, PARTIAL_OUTPUT>,\n      EnrichedStreamPart<TOOLS, PARTIAL_OUTPUT>\n    >({\n      async transform(chunk, controller) {\n        controller.enqueue(chunk); // forward the chunk to the next stream\n\n        const { part } = chunk;\n\n        if (\n          part.type === 'text-delta' ||\n          part.type === 'reasoning-delta' ||\n          part.type === 'source' ||\n          part.type === 'tool-call' ||\n          part.type === 'tool-result' ||\n          part.type === 'tool-input-start' ||\n          part.type === 'tool-input-delta' ||\n          part.type === 'raw'\n        ) {\n          await onChunk?.({ chunk: part });\n        }\n\n        if (part.type === 'error') {\n          await onError({ error: wrapGatewayError(part.error) });\n        }\n\n        if (part.type === 'text-start') {\n          activeTextContent[part.id] = {\n            type: 'text',\n            text: '',\n            providerMetadata: part.providerMetadata,\n          };\n\n          recordedContent.push(activeTextContent[part.id]);\n        }\n\n        if (part.type === 'text-delta') {\n          const activeText = activeTextContent[part.id];\n\n          if (activeText == null) {\n            controller.enqueue({\n              part: {\n                type: 'error',\n                error: `text part ${part.id} not found`,\n              },\n              partialOutput: undefined,\n            });\n            return;\n          }\n\n          activeText.text += part.text;\n          activeText.providerMetadata =\n            part.providerMetadata ?? activeText.providerMetadata;\n        }\n\n        if (part.type === 'text-end') {\n          const activeText = activeTextContent[part.id];\n\n          if (activeText == null) {\n            controller.enqueue({\n              part: {\n                type: 'error',\n                error: `text part ${part.id} not found`,\n              },\n              partialOutput: undefined,\n            });\n            return;\n          }\n\n          activeText.providerMetadata =\n            part.providerMetadata ?? activeText.providerMetadata;\n\n          delete activeTextContent[part.id];\n        }\n\n        if (part.type === 'reasoning-start') {\n          activeReasoningContent[part.id] = {\n            type: 'reasoning',\n            text: '',\n            providerMetadata: part.providerMetadata,\n          };\n\n          recordedContent.push(activeReasoningContent[part.id]);\n        }\n\n        if (part.type === 'reasoning-delta') {\n          const activeReasoning = activeReasoningContent[part.id];\n\n          if (activeReasoning == null) {\n            controller.enqueue({\n              part: {\n                type: 'error',\n                error: `reasoning part ${part.id} not found`,\n              },\n              partialOutput: undefined,\n            });\n            return;\n          }\n\n          activeReasoning.text += part.text;\n          activeReasoning.providerMetadata =\n            part.providerMetadata ?? activeReasoning.providerMetadata;\n        }\n\n        if (part.type === 'reasoning-end') {\n          const activeReasoning = activeReasoningContent[part.id];\n\n          if (activeReasoning == null) {\n            controller.enqueue({\n              part: {\n                type: 'error',\n                error: `reasoning part ${part.id} not found`,\n              },\n              partialOutput: undefined,\n            });\n            return;\n          }\n\n          activeReasoning.providerMetadata =\n            part.providerMetadata ?? activeReasoning.providerMetadata;\n\n          delete activeReasoningContent[part.id];\n        }\n\n        if (part.type === 'file') {\n          recordedContent.push({ type: 'file', file: part.file });\n        }\n\n        if (part.type === 'source') {\n          recordedContent.push(part);\n        }\n\n        if (part.type === 'tool-call') {\n          recordedContent.push(part);\n        }\n\n        if (part.type === 'tool-result' && !part.preliminary) {\n          recordedContent.push(part);\n        }\n\n        if (part.type === 'tool-error') {\n          recordedContent.push(part);\n        }\n\n        if (part.type === 'start-step') {\n          recordedRequest = part.request;\n          recordedWarnings = part.warnings;\n        }\n\n        if (part.type === 'finish-step') {\n          const stepMessages = toResponseMessages({\n            content: recordedContent,\n            tools,\n          });\n\n          // Add step information (after response messages are updated):\n          const currentStepResult: StepResult<TOOLS> = new DefaultStepResult({\n            content: recordedContent,\n            finishReason: part.finishReason,\n            usage: part.usage,\n            warnings: recordedWarnings,\n            request: recordedRequest,\n            response: {\n              ...part.response,\n              messages: [...recordedResponseMessages, ...stepMessages],\n            },\n            providerMetadata: part.providerMetadata,\n          });\n\n          await onStepFinish?.(currentStepResult);\n\n          logWarnings(recordedWarnings);\n\n          recordedSteps.push(currentStepResult);\n\n          recordedContent = [];\n          activeReasoningContent = {};\n          activeTextContent = {};\n\n          recordedResponseMessages.push(...stepMessages);\n\n          // resolve the promise to signal that the step has been fully processed\n          // by the event processor:\n          stepFinish.resolve();\n        }\n\n        if (part.type === 'finish') {\n          recordedTotalUsage = part.totalUsage;\n          recordedFinishReason = part.finishReason;\n        }\n      },\n\n      async flush(controller) {\n        try {\n          if (recordedSteps.length === 0) {\n            const error = new NoOutputGeneratedError({\n              message: 'No output generated. Check the stream for errors.',\n            });\n\n            self._finishReason.reject(error);\n            self._totalUsage.reject(error);\n            self._steps.reject(error);\n\n            return; // no steps recorded (e.g. in error scenario)\n          }\n\n          // derived:\n          const finishReason = recordedFinishReason ?? 'unknown';\n          const totalUsage = recordedTotalUsage ?? {\n            inputTokens: undefined,\n            outputTokens: undefined,\n            totalTokens: undefined,\n          };\n\n          // from finish:\n          self._finishReason.resolve(finishReason);\n          self._totalUsage.resolve(totalUsage);\n\n          // aggregate results:\n          self._steps.resolve(recordedSteps);\n\n          // call onFinish callback:\n          const finalStep = recordedSteps[recordedSteps.length - 1];\n          await onFinish?.({\n            finishReason,\n            totalUsage,\n            usage: finalStep.usage,\n            content: finalStep.content,\n            text: finalStep.text,\n            reasoningText: finalStep.reasoningText,\n            reasoning: finalStep.reasoning,\n            files: finalStep.files,\n            sources: finalStep.sources,\n            toolCalls: finalStep.toolCalls,\n            staticToolCalls: finalStep.staticToolCalls,\n            dynamicToolCalls: finalStep.dynamicToolCalls,\n            toolResults: finalStep.toolResults,\n            staticToolResults: finalStep.staticToolResults,\n            dynamicToolResults: finalStep.dynamicToolResults,\n            request: finalStep.request,\n            response: finalStep.response,\n            warnings: finalStep.warnings,\n            providerMetadata: finalStep.providerMetadata,\n            steps: recordedSteps,\n          });\n\n          // Add response information to the root span:\n          rootSpan.setAttributes(\n            selectTelemetryAttributes({\n              telemetry,\n              attributes: {\n                'ai.response.finishReason': finishReason,\n                'ai.response.text': { output: () => finalStep.text },\n                'ai.response.toolCalls': {\n                  output: () =>\n                    finalStep.toolCalls?.length\n                      ? JSON.stringify(finalStep.toolCalls)\n                      : undefined,\n                },\n                'ai.response.providerMetadata': JSON.stringify(\n                  finalStep.providerMetadata,\n                ),\n\n                'ai.usage.inputTokens': totalUsage.inputTokens,\n                'ai.usage.outputTokens': totalUsage.outputTokens,\n                'ai.usage.totalTokens': totalUsage.totalTokens,\n                'ai.usage.reasoningTokens': totalUsage.reasoningTokens,\n                'ai.usage.cachedInputTokens': totalUsage.cachedInputTokens,\n              },\n            }),\n          );\n        } catch (error) {\n          controller.error(error);\n        } finally {\n          rootSpan.end();\n        }\n      },\n    });\n\n    // initialize the stitchable stream and the transformed stream:\n    const stitchableStream = createStitchableStream<TextStreamPart<TOOLS>>();\n    this.addStream = stitchableStream.addStream;\n    this.closeStream = stitchableStream.close;\n\n    // resilient stream that handles abort signals and errors:\n    const reader = stitchableStream.stream.getReader();\n    let stream = new ReadableStream<TextStreamPart<TOOLS>>({\n      async start(controller) {\n        // send start event:\n        controller.enqueue({ type: 'start' });\n      },\n\n      async pull(controller) {\n        // abort handling:\n        function abort() {\n          onAbort?.({ steps: recordedSteps });\n          controller.enqueue({ type: 'abort' });\n          controller.close();\n        }\n\n        try {\n          const { done, value } = await reader.read();\n\n          if (done) {\n            controller.close();\n            return;\n          }\n\n          if (abortSignal?.aborted) {\n            abort();\n            return;\n          }\n\n          controller.enqueue(value);\n        } catch (error) {\n          if (isAbortError(error) && abortSignal?.aborted) {\n            abort();\n          } else {\n            controller.error(error);\n          }\n        }\n      },\n\n      cancel(reason) {\n        return stitchableStream.stream.cancel(reason);\n      },\n    });\n\n    // transform the stream before output parsing\n    // to enable replacement of stream segments:\n    for (const transform of transforms) {\n      stream = stream.pipeThrough(\n        transform({\n          tools: tools as TOOLS,\n          stopStream() {\n            stitchableStream.terminate();\n          },\n        }),\n      );\n    }\n\n    this.baseStream = stream\n      .pipeThrough(createOutputTransformStream(output))\n      .pipeThrough(eventProcessor);\n\n    const { maxRetries, retry } = prepareRetries({\n      maxRetries: maxRetriesArg,\n      abortSignal,\n    });\n\n    const tracer = getTracer(telemetry);\n\n    const callSettings = prepareCallSettings(settings);\n\n    const baseTelemetryAttributes = getBaseTelemetryAttributes({\n      model,\n      telemetry,\n      headers,\n      settings: { ...callSettings, maxRetries },\n    });\n\n    const self = this;\n\n    recordSpan({\n      name: 'ai.streamText',\n      attributes: selectTelemetryAttributes({\n        telemetry,\n        attributes: {\n          ...assembleOperationName({ operationId: 'ai.streamText', telemetry }),\n          ...baseTelemetryAttributes,\n          // specific settings that only make sense on the outer level:\n          'ai.prompt': {\n            input: () => JSON.stringify({ system, prompt, messages }),\n          },\n        },\n      }),\n      tracer,\n      endWhenDone: false,\n      fn: async rootSpanArg => {\n        rootSpan = rootSpanArg;\n\n        async function streamStep({\n          currentStep,\n          responseMessages,\n          usage,\n        }: {\n          currentStep: number;\n          responseMessages: Array<ResponseMessage>;\n          usage: LanguageModelUsage;\n        }) {\n          const includeRawChunks = self.includeRawChunks;\n\n          stepFinish = new DelayedPromise<void>();\n\n          const initialPrompt = await standardizePrompt({\n            system,\n            prompt,\n            messages,\n          } as Prompt);\n\n          const stepInputMessages = [\n            ...initialPrompt.messages,\n            ...responseMessages,\n          ];\n\n          const prepareStepResult = await prepareStep?.({\n            model,\n            steps: recordedSteps,\n            stepNumber: recordedSteps.length,\n            messages: stepInputMessages,\n          });\n\n          const stepModel = resolveLanguageModel(\n            prepareStepResult?.model ?? model,\n          );\n\n          const promptMessages = await convertToLanguageModelPrompt({\n            prompt: {\n              system: prepareStepResult?.system ?? initialPrompt.system,\n              messages: prepareStepResult?.messages ?? stepInputMessages,\n            },\n            supportedUrls: await stepModel.supportedUrls,\n            download,\n          });\n\n          const { toolChoice: stepToolChoice, tools: stepTools } =\n            prepareToolsAndToolChoice({\n              tools,\n              toolChoice: prepareStepResult?.toolChoice ?? toolChoice,\n              activeTools: prepareStepResult?.activeTools ?? activeTools,\n            });\n\n          const {\n            result: { stream, response, request },\n            doStreamSpan,\n            startTimestampMs,\n          } = await retry(() =>\n            recordSpan({\n              name: 'ai.streamText.doStream',\n              attributes: selectTelemetryAttributes({\n                telemetry,\n                attributes: {\n                  ...assembleOperationName({\n                    operationId: 'ai.streamText.doStream',\n                    telemetry,\n                  }),\n                  ...baseTelemetryAttributes,\n                  // model:\n                  'ai.model.provider': stepModel.provider,\n                  'ai.model.id': stepModel.modelId,\n                  // prompt:\n                  'ai.prompt.messages': {\n                    input: () => stringifyForTelemetry(promptMessages),\n                  },\n                  'ai.prompt.tools': {\n                    // convert the language model level tools:\n                    input: () => stepTools?.map(tool => JSON.stringify(tool)),\n                  },\n                  'ai.prompt.toolChoice': {\n                    input: () =>\n                      stepToolChoice != null\n                        ? JSON.stringify(stepToolChoice)\n                        : undefined,\n                  },\n\n                  // standardized gen-ai llm span attributes:\n                  'gen_ai.system': stepModel.provider,\n                  'gen_ai.request.model': stepModel.modelId,\n                  'gen_ai.request.frequency_penalty':\n                    callSettings.frequencyPenalty,\n                  'gen_ai.request.max_tokens': callSettings.maxOutputTokens,\n                  'gen_ai.request.presence_penalty':\n                    callSettings.presencePenalty,\n                  'gen_ai.request.stop_sequences': callSettings.stopSequences,\n                  'gen_ai.request.temperature': callSettings.temperature,\n                  'gen_ai.request.top_k': callSettings.topK,\n                  'gen_ai.request.top_p': callSettings.topP,\n                },\n              }),\n              tracer,\n              endWhenDone: false,\n              fn: async doStreamSpan => {\n                return {\n                  startTimestampMs: now(), // get before the call\n                  doStreamSpan,\n                  result: await stepModel.doStream({\n                    ...callSettings,\n                    tools: stepTools,\n                    toolChoice: stepToolChoice,\n                    responseFormat: output?.responseFormat,\n                    prompt: promptMessages,\n                    providerOptions,\n                    abortSignal,\n                    headers,\n                    includeRawChunks,\n                  }),\n                };\n              },\n            }),\n          );\n\n          const streamWithToolResults = runToolsTransformation({\n            tools,\n            generatorStream: stream,\n            tracer,\n            telemetry,\n            system,\n            messages: stepInputMessages,\n            repairToolCall,\n            abortSignal,\n            experimental_context,\n          });\n\n          const stepRequest = request ?? {};\n          const stepToolCalls: TypedToolCall<TOOLS>[] = [];\n          const stepToolOutputs: ToolOutput<TOOLS>[] = [];\n          let warnings: LanguageModelV2CallWarning[] | undefined;\n\n          const activeToolCallToolNames: Record<string, string> = {};\n\n          let stepFinishReason: FinishReason = 'unknown';\n          let stepUsage: LanguageModelUsage = {\n            inputTokens: undefined,\n            outputTokens: undefined,\n            totalTokens: undefined,\n          };\n          let stepProviderMetadata: ProviderMetadata | undefined;\n          let stepFirstChunk = true;\n          let stepResponse: { id: string; timestamp: Date; modelId: string } = {\n            id: generateId(),\n            timestamp: currentDate(),\n            modelId: model.modelId,\n          };\n\n          // raw text as it comes from the provider. recorded for telemetry.\n          let activeText = '';\n\n          self.addStream(\n            streamWithToolResults.pipeThrough(\n              new TransformStream<\n                SingleRequestTextStreamPart<TOOLS>,\n                TextStreamPart<TOOLS>\n              >({\n                async transform(chunk, controller): Promise<void> {\n                  if (chunk.type === 'stream-start') {\n                    warnings = chunk.warnings;\n                    return; // stream start chunks are sent immediately and do not count as first chunk\n                  }\n\n                  if (stepFirstChunk) {\n                    // Telemetry for first chunk:\n                    const msToFirstChunk = now() - startTimestampMs;\n\n                    stepFirstChunk = false;\n\n                    doStreamSpan.addEvent('ai.stream.firstChunk', {\n                      'ai.response.msToFirstChunk': msToFirstChunk,\n                    });\n\n                    doStreamSpan.setAttributes({\n                      'ai.response.msToFirstChunk': msToFirstChunk,\n                    });\n\n                    // Step start:\n                    controller.enqueue({\n                      type: 'start-step',\n                      request: stepRequest,\n                      warnings: warnings ?? [],\n                    });\n                  }\n\n                  const chunkType = chunk.type;\n                  switch (chunkType) {\n                    case 'text-start':\n                    case 'text-end': {\n                      controller.enqueue(chunk);\n                      break;\n                    }\n\n                    case 'text-delta': {\n                      if (chunk.delta.length > 0) {\n                        controller.enqueue({\n                          type: 'text-delta',\n                          id: chunk.id,\n                          text: chunk.delta,\n                          providerMetadata: chunk.providerMetadata,\n                        });\n                        activeText += chunk.delta;\n                      }\n                      break;\n                    }\n\n                    case 'reasoning-start':\n                    case 'reasoning-end': {\n                      controller.enqueue(chunk);\n                      break;\n                    }\n\n                    case 'reasoning-delta': {\n                      controller.enqueue({\n                        type: 'reasoning-delta',\n                        id: chunk.id,\n                        text: chunk.delta,\n                        providerMetadata: chunk.providerMetadata,\n                      });\n                      break;\n                    }\n\n                    case 'tool-call': {\n                      controller.enqueue(chunk);\n                      // store tool calls for onFinish callback and toolCalls promise:\n                      stepToolCalls.push(chunk);\n                      break;\n                    }\n\n                    case 'tool-result': {\n                      controller.enqueue(chunk);\n\n                      if (!chunk.preliminary) {\n                        stepToolOutputs.push(chunk);\n                      }\n\n                      break;\n                    }\n\n                    case 'tool-error': {\n                      controller.enqueue(chunk);\n                      stepToolOutputs.push(chunk);\n                      break;\n                    }\n\n                    case 'response-metadata': {\n                      stepResponse = {\n                        id: chunk.id ?? stepResponse.id,\n                        timestamp: chunk.timestamp ?? stepResponse.timestamp,\n                        modelId: chunk.modelId ?? stepResponse.modelId,\n                      };\n                      break;\n                    }\n\n                    case 'finish': {\n                      // Note: tool executions might not be finished yet when the finish event is emitted.\n                      // store usage and finish reason for promises and onFinish callback:\n                      stepUsage = chunk.usage;\n                      stepFinishReason = chunk.finishReason;\n                      stepProviderMetadata = chunk.providerMetadata;\n\n                      // Telemetry for finish event timing\n                      // (since tool executions can take longer and distort calculations)\n                      const msToFinish = now() - startTimestampMs;\n                      doStreamSpan.addEvent('ai.stream.finish');\n                      doStreamSpan.setAttributes({\n                        'ai.response.msToFinish': msToFinish,\n                        'ai.response.avgOutputTokensPerSecond':\n                          (1000 * (stepUsage.outputTokens ?? 0)) / msToFinish,\n                      });\n\n                      break;\n                    }\n\n                    case 'file': {\n                      controller.enqueue(chunk);\n                      break;\n                    }\n\n                    case 'source': {\n                      controller.enqueue(chunk);\n                      break;\n                    }\n\n                    case 'tool-input-start': {\n                      activeToolCallToolNames[chunk.id] = chunk.toolName;\n\n                      const tool = tools?.[chunk.toolName];\n                      if (tool?.onInputStart != null) {\n                        await tool.onInputStart({\n                          toolCallId: chunk.id,\n                          messages: stepInputMessages,\n                          abortSignal,\n                          experimental_context,\n                        });\n                      }\n\n                      controller.enqueue({\n                        ...chunk,\n                        dynamic: tool?.type === 'dynamic',\n                      });\n                      break;\n                    }\n\n                    case 'tool-input-end': {\n                      delete activeToolCallToolNames[chunk.id];\n                      controller.enqueue(chunk);\n                      break;\n                    }\n\n                    case 'tool-input-delta': {\n                      const toolName = activeToolCallToolNames[chunk.id];\n                      const tool = tools?.[toolName];\n\n                      if (tool?.onInputDelta != null) {\n                        await tool.onInputDelta({\n                          inputTextDelta: chunk.delta,\n                          toolCallId: chunk.id,\n                          messages: stepInputMessages,\n                          abortSignal,\n                          experimental_context,\n                        });\n                      }\n\n                      controller.enqueue(chunk);\n                      break;\n                    }\n\n                    case 'error': {\n                      controller.enqueue(chunk);\n                      stepFinishReason = 'error';\n                      break;\n                    }\n\n                    case 'raw': {\n                      if (includeRawChunks) {\n                        controller.enqueue(chunk);\n                      }\n                      break;\n                    }\n\n                    default: {\n                      const exhaustiveCheck: never = chunkType;\n                      throw new Error(`Unknown chunk type: ${exhaustiveCheck}`);\n                    }\n                  }\n                },\n\n                // invoke onFinish callback and resolve toolResults promise when the stream is about to close:\n                async flush(controller) {\n                  const stepToolCallsJson =\n                    stepToolCalls.length > 0\n                      ? JSON.stringify(stepToolCalls)\n                      : undefined;\n\n                  // record telemetry information first to ensure best effort timing\n                  try {\n                    doStreamSpan.setAttributes(\n                      selectTelemetryAttributes({\n                        telemetry,\n                        attributes: {\n                          'ai.response.finishReason': stepFinishReason,\n                          'ai.response.text': {\n                            output: () => activeText,\n                          },\n                          'ai.response.toolCalls': {\n                            output: () => stepToolCallsJson,\n                          },\n                          'ai.response.id': stepResponse.id,\n                          'ai.response.model': stepResponse.modelId,\n                          'ai.response.timestamp':\n                            stepResponse.timestamp.toISOString(),\n                          'ai.response.providerMetadata':\n                            JSON.stringify(stepProviderMetadata),\n\n                          'ai.usage.inputTokens': stepUsage.inputTokens,\n                          'ai.usage.outputTokens': stepUsage.outputTokens,\n                          'ai.usage.totalTokens': stepUsage.totalTokens,\n                          'ai.usage.reasoningTokens': stepUsage.reasoningTokens,\n                          'ai.usage.cachedInputTokens':\n                            stepUsage.cachedInputTokens,\n\n                          // standardized gen-ai llm span attributes:\n                          'gen_ai.response.finish_reasons': [stepFinishReason],\n                          'gen_ai.response.id': stepResponse.id,\n                          'gen_ai.response.model': stepResponse.modelId,\n                          'gen_ai.usage.input_tokens': stepUsage.inputTokens,\n                          'gen_ai.usage.output_tokens': stepUsage.outputTokens,\n                        },\n                      }),\n                    );\n                  } catch (error) {\n                    // ignore error setting telemetry attributes\n                  } finally {\n                    // finish doStreamSpan before other operations for correct timing:\n                    doStreamSpan.end();\n                  }\n\n                  controller.enqueue({\n                    type: 'finish-step',\n                    finishReason: stepFinishReason,\n                    usage: stepUsage,\n                    providerMetadata: stepProviderMetadata,\n                    response: {\n                      ...stepResponse,\n                      headers: response?.headers,\n                    },\n                  });\n\n                  const combinedUsage = addLanguageModelUsage(usage, stepUsage);\n\n                  // wait for the step to be fully processed by the event processor\n                  // to ensure that the recorded steps are complete:\n                  await stepFinish.promise;\n\n                  const clientToolCalls = stepToolCalls.filter(\n                    toolCall => toolCall.providerExecuted !== true,\n                  );\n                  const clientToolOutputs = stepToolOutputs.filter(\n                    toolOutput => toolOutput.providerExecuted !== true,\n                  );\n\n                  if (\n                    clientToolCalls.length > 0 &&\n                    // all current tool calls have outputs (incl. execution errors):\n                    clientToolOutputs.length === clientToolCalls.length &&\n                    // continue until a stop condition is met:\n                    !(await isStopConditionMet({\n                      stopConditions,\n                      steps: recordedSteps,\n                    }))\n                  ) {\n                    // append to messages for the next step:\n                    responseMessages.push(\n                      ...toResponseMessages({\n                        content:\n                          // use transformed content to create the messages for the next step:\n                          recordedSteps[recordedSteps.length - 1].content,\n                        tools,\n                      }),\n                    );\n\n                    try {\n                      await streamStep({\n                        currentStep: currentStep + 1,\n                        responseMessages,\n                        usage: combinedUsage,\n                      });\n                    } catch (error) {\n                      controller.enqueue({\n                        type: 'error',\n                        error,\n                      });\n\n                      self.closeStream();\n                    }\n                  } else {\n                    controller.enqueue({\n                      type: 'finish',\n                      finishReason: stepFinishReason,\n                      totalUsage: combinedUsage,\n                    });\n\n                    self.closeStream(); // close the stitchable stream\n                  }\n                },\n              }),\n            ),\n          );\n        }\n\n        // add the initial stream to the stitchable stream\n        await streamStep({\n          currentStep: 0,\n          responseMessages: [],\n          usage: {\n            inputTokens: undefined,\n            outputTokens: undefined,\n            totalTokens: undefined,\n          },\n        });\n      },\n    }).catch(error => {\n      // add an error stream part and close the streams:\n      self.addStream(\n        new ReadableStream({\n          start(controller) {\n            controller.enqueue({ type: 'error', error });\n            controller.close();\n          },\n        }),\n      );\n      self.closeStream();\n    });\n  }\n\n  get steps() {\n    // when any of the promises are accessed, the stream is consumed\n    // so it resolves without needing to consume the stream separately\n    this.consumeStream();\n\n    return this._steps.promise;\n  }\n\n  private get finalStep() {\n    return this.steps.then(steps => steps[steps.length - 1]);\n  }\n\n  get content() {\n    return this.finalStep.then(step => step.content);\n  }\n\n  get warnings() {\n    return this.finalStep.then(step => step.warnings);\n  }\n\n  get providerMetadata() {\n    return this.finalStep.then(step => step.providerMetadata);\n  }\n\n  get text() {\n    return this.finalStep.then(step => step.text);\n  }\n\n  get reasoningText() {\n    return this.finalStep.then(step => step.reasoningText);\n  }\n\n  get reasoning() {\n    return this.finalStep.then(step => step.reasoning);\n  }\n\n  get sources() {\n    return this.finalStep.then(step => step.sources);\n  }\n\n  get files() {\n    return this.finalStep.then(step => step.files);\n  }\n\n  get toolCalls() {\n    return this.finalStep.then(step => step.toolCalls);\n  }\n\n  get staticToolCalls() {\n    return this.finalStep.then(step => step.staticToolCalls);\n  }\n\n  get dynamicToolCalls() {\n    return this.finalStep.then(step => step.dynamicToolCalls);\n  }\n\n  get toolResults() {\n    return this.finalStep.then(step => step.toolResults);\n  }\n\n  get staticToolResults() {\n    return this.finalStep.then(step => step.staticToolResults);\n  }\n\n  get dynamicToolResults() {\n    return this.finalStep.then(step => step.dynamicToolResults);\n  }\n\n  get usage() {\n    return this.finalStep.then(step => step.usage);\n  }\n\n  get request() {\n    return this.finalStep.then(step => step.request);\n  }\n\n  get response() {\n    return this.finalStep.then(step => step.response);\n  }\n\n  get totalUsage() {\n    // when any of the promises are accessed, the stream is consumed\n    // so it resolves without needing to consume the stream separately\n    this.consumeStream();\n\n    return this._totalUsage.promise;\n  }\n\n  get finishReason() {\n    // when any of the promises are accessed, the stream is consumed\n    // so it resolves without needing to consume the stream separately\n    this.consumeStream();\n\n    return this._finishReason.promise;\n  }\n\n  /**\nSplit out a new stream from the original stream.\nThe original stream is replaced to allow for further splitting,\nsince we do not know how many times the stream will be split.\n\nNote: this leads to buffering the stream content on the server.\nHowever, the LLM results are expected to be small enough to not cause issues.\n   */\n  private teeStream() {\n    const [stream1, stream2] = this.baseStream.tee();\n    this.baseStream = stream2;\n    return stream1;\n  }\n\n  get textStream(): AsyncIterableStream<string> {\n    return createAsyncIterableStream(\n      this.teeStream().pipeThrough(\n        new TransformStream<EnrichedStreamPart<TOOLS, PARTIAL_OUTPUT>, string>({\n          transform({ part }, controller) {\n            if (part.type === 'text-delta') {\n              controller.enqueue(part.text);\n            }\n          },\n        }),\n      ),\n    );\n  }\n\n  get fullStream(): AsyncIterableStream<TextStreamPart<TOOLS>> {\n    return createAsyncIterableStream(\n      this.teeStream().pipeThrough(\n        new TransformStream<\n          EnrichedStreamPart<TOOLS, PARTIAL_OUTPUT>,\n          TextStreamPart<TOOLS>\n        >({\n          transform({ part }, controller) {\n            controller.enqueue(part);\n          },\n        }),\n      ),\n    );\n  }\n\n  async consumeStream(options?: ConsumeStreamOptions): Promise<void> {\n    try {\n      await consumeStream({\n        stream: this.fullStream,\n        onError: options?.onError,\n      });\n    } catch (error) {\n      options?.onError?.(error);\n    }\n  }\n\n  get experimental_partialOutputStream(): AsyncIterableStream<PARTIAL_OUTPUT> {\n    if (this.output == null) {\n      throw new NoOutputSpecifiedError();\n    }\n\n    return createAsyncIterableStream(\n      this.teeStream().pipeThrough(\n        new TransformStream<\n          EnrichedStreamPart<TOOLS, PARTIAL_OUTPUT>,\n          PARTIAL_OUTPUT\n        >({\n          transform({ partialOutput }, controller) {\n            if (partialOutput != null) {\n              controller.enqueue(partialOutput);\n            }\n          },\n        }),\n      ),\n    );\n  }\n\n  toUIMessageStream<UI_MESSAGE extends UIMessage>({\n    originalMessages,\n    generateMessageId,\n    onFinish,\n    messageMetadata,\n    sendReasoning = true,\n    sendSources = false,\n    sendStart = true,\n    sendFinish = true,\n    onError = getErrorMessage,\n  }: UIMessageStreamOptions<UI_MESSAGE> = {}): AsyncIterableStream<\n    InferUIMessageChunk<UI_MESSAGE>\n  > {\n    const responseMessageId =\n      generateMessageId != null\n        ? getResponseUIMessageId({\n            originalMessages,\n            responseMessageId: generateMessageId,\n          })\n        : undefined;\n\n    const toolNamesByCallId: Record<string, string> = {};\n\n    const isDynamic = (toolCallId: string) => {\n      const toolName = toolNamesByCallId[toolCallId];\n      const dynamic = this.tools?.[toolName]?.type === 'dynamic';\n      return dynamic ? true : undefined; // only send when dynamic to reduce data transfer\n    };\n\n    const baseStream = this.fullStream.pipeThrough(\n      new TransformStream<\n        TextStreamPart<TOOLS>,\n        UIMessageChunk<\n          InferUIMessageMetadata<UI_MESSAGE>,\n          InferUIMessageData<UI_MESSAGE>\n        >\n      >({\n        transform: async (part, controller) => {\n          const messageMetadataValue = messageMetadata?.({ part });\n\n          const partType = part.type;\n          switch (partType) {\n            case 'text-start': {\n              controller.enqueue({\n                type: 'text-start',\n                id: part.id,\n                ...(part.providerMetadata != null\n                  ? { providerMetadata: part.providerMetadata }\n                  : {}),\n              });\n              break;\n            }\n\n            case 'text-delta': {\n              controller.enqueue({\n                type: 'text-delta',\n                id: part.id,\n                delta: part.text,\n                ...(part.providerMetadata != null\n                  ? { providerMetadata: part.providerMetadata }\n                  : {}),\n              });\n              break;\n            }\n\n            case 'text-end': {\n              controller.enqueue({\n                type: 'text-end',\n                id: part.id,\n                ...(part.providerMetadata != null\n                  ? { providerMetadata: part.providerMetadata }\n                  : {}),\n              });\n              break;\n            }\n\n            case 'reasoning-start': {\n              controller.enqueue({\n                type: 'reasoning-start',\n                id: part.id,\n                ...(part.providerMetadata != null\n                  ? { providerMetadata: part.providerMetadata }\n                  : {}),\n              });\n              break;\n            }\n\n            case 'reasoning-delta': {\n              if (sendReasoning) {\n                controller.enqueue({\n                  type: 'reasoning-delta',\n                  id: part.id,\n                  delta: part.text,\n                  ...(part.providerMetadata != null\n                    ? { providerMetadata: part.providerMetadata }\n                    : {}),\n                });\n              }\n              break;\n            }\n\n            case 'reasoning-end': {\n              controller.enqueue({\n                type: 'reasoning-end',\n                id: part.id,\n                ...(part.providerMetadata != null\n                  ? { providerMetadata: part.providerMetadata }\n                  : {}),\n              });\n              break;\n            }\n\n            case 'file': {\n              controller.enqueue({\n                type: 'file',\n                mediaType: part.file.mediaType,\n                url: `data:${part.file.mediaType};base64,${part.file.base64}`,\n              });\n              break;\n            }\n\n            case 'source': {\n              if (sendSources && part.sourceType === 'url') {\n                controller.enqueue({\n                  type: 'source-url',\n                  sourceId: part.id,\n                  url: part.url,\n                  title: part.title,\n                  ...(part.providerMetadata != null\n                    ? { providerMetadata: part.providerMetadata }\n                    : {}),\n                });\n              }\n\n              if (sendSources && part.sourceType === 'document') {\n                controller.enqueue({\n                  type: 'source-document',\n                  sourceId: part.id,\n                  mediaType: part.mediaType,\n                  title: part.title,\n                  filename: part.filename,\n                  ...(part.providerMetadata != null\n                    ? { providerMetadata: part.providerMetadata }\n                    : {}),\n                });\n              }\n              break;\n            }\n\n            case 'tool-input-start': {\n              toolNamesByCallId[part.id] = part.toolName;\n              const dynamic = isDynamic(part.id);\n\n              controller.enqueue({\n                type: 'tool-input-start',\n                toolCallId: part.id,\n                toolName: part.toolName,\n                ...(part.providerExecuted != null\n                  ? { providerExecuted: part.providerExecuted }\n                  : {}),\n                ...(dynamic != null ? { dynamic } : {}),\n              });\n              break;\n            }\n\n            case 'tool-input-delta': {\n              controller.enqueue({\n                type: 'tool-input-delta',\n                toolCallId: part.id,\n                inputTextDelta: part.delta,\n              });\n              break;\n            }\n\n            case 'tool-call': {\n              toolNamesByCallId[part.toolCallId] = part.toolName;\n              const dynamic = isDynamic(part.toolCallId);\n\n              if (part.invalid) {\n                controller.enqueue({\n                  type: 'tool-input-error',\n                  toolCallId: part.toolCallId,\n                  toolName: part.toolName,\n                  input: part.input,\n                  ...(part.providerExecuted != null\n                    ? { providerExecuted: part.providerExecuted }\n                    : {}),\n                  ...(part.providerMetadata != null\n                    ? { providerMetadata: part.providerMetadata }\n                    : {}),\n                  ...(dynamic != null ? { dynamic } : {}),\n                  errorText: onError(part.error),\n                });\n              } else {\n                controller.enqueue({\n                  type: 'tool-input-available',\n                  toolCallId: part.toolCallId,\n                  toolName: part.toolName,\n                  input: part.input,\n                  ...(part.providerExecuted != null\n                    ? { providerExecuted: part.providerExecuted }\n                    : {}),\n                  ...(part.providerMetadata != null\n                    ? { providerMetadata: part.providerMetadata }\n                    : {}),\n                  ...(dynamic != null ? { dynamic } : {}),\n                });\n              }\n\n              break;\n            }\n\n            case 'tool-result': {\n              const dynamic = isDynamic(part.toolCallId);\n\n              controller.enqueue({\n                type: 'tool-output-available',\n                toolCallId: part.toolCallId,\n                output: part.output,\n                ...(part.providerExecuted != null\n                  ? { providerExecuted: part.providerExecuted }\n                  : {}),\n                ...(part.preliminary != null\n                  ? { preliminary: part.preliminary }\n                  : {}),\n                ...(dynamic != null ? { dynamic } : {}),\n              });\n              break;\n            }\n\n            case 'tool-error': {\n              const dynamic = isDynamic(part.toolCallId);\n\n              controller.enqueue({\n                type: 'tool-output-error',\n                toolCallId: part.toolCallId,\n                errorText: onError(part.error),\n                ...(part.providerExecuted != null\n                  ? { providerExecuted: part.providerExecuted }\n                  : {}),\n                ...(dynamic != null ? { dynamic } : {}),\n              });\n              break;\n            }\n\n            case 'error': {\n              controller.enqueue({\n                type: 'error',\n                errorText: onError(part.error),\n              });\n              break;\n            }\n\n            case 'start-step': {\n              controller.enqueue({ type: 'start-step' });\n              break;\n            }\n\n            case 'finish-step': {\n              controller.enqueue({ type: 'finish-step' });\n              break;\n            }\n\n            case 'start': {\n              if (sendStart) {\n                controller.enqueue({\n                  type: 'start',\n                  ...(messageMetadataValue != null\n                    ? { messageMetadata: messageMetadataValue }\n                    : {}),\n                  ...(responseMessageId != null\n                    ? { messageId: responseMessageId }\n                    : {}),\n                });\n              }\n              break;\n            }\n\n            case 'finish': {\n              if (sendFinish) {\n                controller.enqueue({\n                  type: 'finish',\n                  finishReason: part.finishReason,\n                  ...(messageMetadataValue != null\n                    ? { messageMetadata: messageMetadataValue }\n                    : {}),\n                });\n              }\n              break;\n            }\n\n            case 'abort': {\n              controller.enqueue(part);\n              break;\n            }\n\n            case 'tool-input-end': {\n              break;\n            }\n\n            case 'raw': {\n              // Raw chunks are not included in UI message streams\n              // as they contain provider-specific data for developer use\n              break;\n            }\n\n            default: {\n              const exhaustiveCheck: never = partType;\n              throw new Error(`Unknown chunk type: ${exhaustiveCheck}`);\n            }\n          }\n\n          // start and finish events already have metadata\n          // so we only need to send metadata for other parts\n          if (\n            messageMetadataValue != null &&\n            partType !== 'start' &&\n            partType !== 'finish'\n          ) {\n            controller.enqueue({\n              type: 'message-metadata',\n              messageMetadata: messageMetadataValue,\n            });\n          }\n        },\n      }),\n    );\n\n    return createAsyncIterableStream(\n      handleUIMessageStreamFinish<UI_MESSAGE>({\n        stream: baseStream,\n        messageId: responseMessageId ?? generateMessageId?.(),\n        originalMessages,\n        onFinish,\n        onError,\n      }),\n    );\n  }\n\n  pipeUIMessageStreamToResponse<UI_MESSAGE extends UIMessage>(\n    response: ServerResponse,\n    {\n      originalMessages,\n      generateMessageId,\n      onFinish,\n      messageMetadata,\n      sendReasoning,\n      sendSources,\n      sendFinish,\n      sendStart,\n      onError,\n      ...init\n    }: UIMessageStreamResponseInit & UIMessageStreamOptions<UI_MESSAGE> = {},\n  ) {\n    pipeUIMessageStreamToResponse({\n      response,\n      stream: this.toUIMessageStream({\n        originalMessages,\n        generateMessageId,\n        onFinish,\n        messageMetadata,\n        sendReasoning,\n        sendSources,\n        sendFinish,\n        sendStart,\n        onError,\n      }),\n      ...init,\n    });\n  }\n\n  pipeTextStreamToResponse(response: ServerResponse, init?: ResponseInit) {\n    pipeTextStreamToResponse({\n      response,\n      textStream: this.textStream,\n      ...init,\n    });\n  }\n\n  toUIMessageStreamResponse<UI_MESSAGE extends UIMessage>({\n    originalMessages,\n    generateMessageId,\n    onFinish,\n    messageMetadata,\n    sendReasoning,\n    sendSources,\n    sendFinish,\n    sendStart,\n    onError,\n    ...init\n  }: UIMessageStreamResponseInit &\n    UIMessageStreamOptions<UI_MESSAGE> = {}): Response {\n    return createUIMessageStreamResponse({\n      stream: this.toUIMessageStream({\n        originalMessages,\n        generateMessageId,\n        onFinish,\n        messageMetadata,\n        sendReasoning,\n        sendSources,\n        sendFinish,\n        sendStart,\n        onError,\n      }),\n      ...init,\n    });\n  }\n\n  toTextStreamResponse(init?: ResponseInit): Response {\n    return createTextStreamResponse({\n      textStream: this.textStream,\n      ...init,\n    });\n  }\n}\n","import {\n  AssistantContent,\n  FilePart,\n  ModelMessage,\n  TextPart,\n  ToolResultPart,\n} from '@ai-sdk/provider-utils';\nimport { ToolSet } from '../generate-text/tool-set';\nimport { createToolModelOutput } from '../prompt/create-tool-model-output';\nimport { MessageConversionError } from '../prompt/message-conversion-error';\nimport {\n  DataUIPart,\n  DynamicToolUIPart,\n  FileUIPart,\n  getToolName,\n  getToolOrDynamicToolName,\n  InferUIMessageData,\n  InferUIMessageTools,\n  isDataUIPart,\n  isDynamicToolUIPart,\n  isFileUIPart,\n  isReasoningUIPart,\n  isTextUIPart,\n  isToolOrDynamicToolUIPart,\n  isToolUIPart,\n  ReasoningUIPart,\n  TextUIPart,\n  ToolUIPart,\n  UIMessage,\n} from './ui-messages';\n\n/**\nConverts an array of UI messages from useChat into an array of ModelMessages that can be used\nwith the AI functions (e.g. `streamText`, `generateText`).\n\n@param messages - The UI messages to convert.\n@param options.tools - The tools to use.\n@param options.ignoreIncompleteToolCalls - Whether to ignore incomplete tool calls. Default is `false`.\n@param options.convertDataPart - Optional function to convert data parts to text or file model message parts. Returns `undefined` if the part should be ignored.\n\n@returns An array of ModelMessages.\n */\nexport function convertToModelMessages<UI_MESSAGE extends UIMessage>(\n  messages: Array<Omit<UI_MESSAGE, 'id'>>,\n  options?: {\n    tools?: ToolSet;\n    ignoreIncompleteToolCalls?: boolean;\n    convertDataPart?: (\n      part: DataUIPart<InferUIMessageData<UI_MESSAGE>>,\n    ) => TextPart | FilePart | undefined;\n  },\n): ModelMessage[] {\n  const modelMessages: ModelMessage[] = [];\n\n  if (options?.ignoreIncompleteToolCalls) {\n    messages = messages.map(message => ({\n      ...message,\n      parts: message.parts.filter(\n        part =>\n          !isToolOrDynamicToolUIPart(part) ||\n          (part.state !== 'input-streaming' &&\n            part.state !== 'input-available'),\n      ),\n    }));\n  }\n\n  for (const message of messages) {\n    switch (message.role) {\n      case 'system': {\n        const textParts = message.parts.filter(\n          (part): part is TextUIPart => part.type === 'text',\n        );\n\n        const providerMetadata = textParts.reduce((acc, part) => {\n          if (part.providerMetadata != null) {\n            return { ...acc, ...part.providerMetadata };\n          }\n          return acc;\n        }, {});\n\n        modelMessages.push({\n          role: 'system',\n          content: textParts.map(part => part.text).join(''),\n          ...(Object.keys(providerMetadata).length > 0\n            ? { providerOptions: providerMetadata }\n            : {}),\n        });\n        break;\n      }\n\n      case 'user': {\n        modelMessages.push({\n          role: 'user',\n          content: message.parts\n            .map((part): TextPart | FilePart | undefined => {\n              // Process text parts\n              if (isTextUIPart(part)) {\n                return {\n                  type: 'text' as const,\n                  text: part.text,\n                  ...(part.providerMetadata != null\n                    ? { providerOptions: part.providerMetadata }\n                    : {}),\n                };\n              }\n\n              // Process file parts\n              if (isFileUIPart(part)) {\n                return {\n                  type: 'file' as const,\n                  mediaType: part.mediaType,\n                  filename: part.filename,\n                  data: part.url,\n                  ...(part.providerMetadata != null\n                    ? { providerOptions: part.providerMetadata }\n                    : {}),\n                };\n              }\n\n              // Process data parts with converter if provided\n              if (isDataUIPart(part)) {\n                return options?.convertDataPart?.(\n                  part as DataUIPart<InferUIMessageData<UI_MESSAGE>>,\n                );\n              }\n            })\n            .filter((part): part is TextPart | FilePart => part != null),\n        });\n\n        break;\n      }\n\n      case 'assistant': {\n        if (message.parts != null) {\n          let block: Array<\n            | TextUIPart\n            | ToolUIPart<InferUIMessageTools<UI_MESSAGE>>\n            | ReasoningUIPart\n            | FileUIPart\n            | DynamicToolUIPart\n            | DataUIPart<InferUIMessageData<UI_MESSAGE>>\n          > = [];\n\n          function processBlock() {\n            if (block.length === 0) {\n              return;\n            }\n\n            const content: AssistantContent = [];\n\n            for (const part of block) {\n              if (isTextUIPart(part)) {\n                content.push({\n                  type: 'text' as const,\n                  text: part.text,\n                  ...(part.providerMetadata != null\n                    ? { providerOptions: part.providerMetadata }\n                    : {}),\n                });\n              } else if (isFileUIPart(part)) {\n                content.push({\n                  type: 'file' as const,\n                  mediaType: part.mediaType,\n                  filename: part.filename,\n                  data: part.url,\n                });\n              } else if (isReasoningUIPart(part)) {\n                content.push({\n                  type: 'reasoning' as const,\n                  text: part.text,\n                  providerOptions: part.providerMetadata,\n                });\n              } else if (isDynamicToolUIPart(part)) {\n                const toolName = part.toolName;\n\n                if (part.state !== 'input-streaming') {\n                  content.push({\n                    type: 'tool-call' as const,\n                    toolCallId: part.toolCallId,\n                    toolName,\n                    input: part.input,\n                    ...(part.callProviderMetadata != null\n                      ? { providerOptions: part.callProviderMetadata }\n                      : {}),\n                  });\n                }\n              } else if (isToolUIPart(part)) {\n                const toolName = getToolName(part);\n\n                if (part.state !== 'input-streaming') {\n                  content.push({\n                    type: 'tool-call' as const,\n                    toolCallId: part.toolCallId,\n                    toolName: toolName as string,\n                    input:\n                      part.state === 'output-error'\n                        ? (part.input ?? part.rawInput)\n                        : part.input,\n                    providerExecuted: part.providerExecuted,\n                    ...(part.callProviderMetadata != null\n                      ? { providerOptions: part.callProviderMetadata }\n                      : {}),\n                  });\n\n                  if (\n                    part.providerExecuted === true &&\n                    (part.state === 'output-available' ||\n                      part.state === 'output-error')\n                  ) {\n                    content.push({\n                      type: 'tool-result',\n                      toolCallId: part.toolCallId,\n                      toolName: toolName as string,\n                      output: createToolModelOutput({\n                        output:\n                          part.state === 'output-error'\n                            ? part.errorText\n                            : part.output,\n                        tool: options?.tools?.[toolName],\n                        errorMode:\n                          part.state === 'output-error' ? 'json' : 'none',\n                      }),\n                    });\n                  }\n                }\n              } else if (isDataUIPart(part)) {\n                const dataPart = options?.convertDataPart?.(\n                  part as DataUIPart<InferUIMessageData<UI_MESSAGE>>,\n                );\n\n                if (dataPart != null) {\n                  content.push(dataPart);\n                }\n              } else {\n                const _exhaustiveCheck: never = part;\n                throw new Error(`Unsupported part: ${_exhaustiveCheck}`);\n              }\n            }\n\n            modelMessages.push({\n              role: 'assistant',\n              content,\n            });\n\n            // check if there are tool invocations with results in the block\n            const toolParts = block.filter(\n              part =>\n                (isToolUIPart(part) && part.providerExecuted !== true) ||\n                part.type === 'dynamic-tool',\n            ) as (\n              | ToolUIPart<InferUIMessageTools<UI_MESSAGE>>\n              | DynamicToolUIPart\n            )[];\n\n            // tool message with tool results\n            if (toolParts.length > 0) {\n              modelMessages.push({\n                role: 'tool',\n                content: toolParts\n                  .map((toolPart): ToolResultPart | null => {\n                    switch (toolPart.state) {\n                      case 'output-error':\n                      case 'output-available': {\n                        const toolName = getToolOrDynamicToolName(toolPart);\n\n                        return {\n                          type: 'tool-result',\n                          toolCallId: toolPart.toolCallId,\n                          toolName,\n                          output: createToolModelOutput({\n                            output:\n                              toolPart.state === 'output-error'\n                                ? toolPart.errorText\n                                : toolPart.output,\n                            tool: options?.tools?.[toolName],\n                            errorMode:\n                              toolPart.state === 'output-error'\n                                ? 'text'\n                                : 'none',\n                          }),\n                        };\n                      }\n                      default: {\n                        return null;\n                      }\n                    }\n                  })\n                  .filter(\n                    (output): output is NonNullable<typeof output> =>\n                      output != null,\n                  ),\n              });\n            }\n\n            // updates for next block\n            block = [];\n          }\n\n          for (const part of message.parts) {\n            if (\n              isTextUIPart(part) ||\n              isReasoningUIPart(part) ||\n              isFileUIPart(part) ||\n              isToolOrDynamicToolUIPart(part) ||\n              isDataUIPart(part)\n            ) {\n              block.push(part as (typeof block)[number]);\n            } else if (part.type === 'step-start') {\n              processBlock();\n            }\n          }\n\n          processBlock();\n\n          break;\n        }\n\n        break;\n      }\n\n      default: {\n        const _exhaustiveCheck: never = message.role;\n        throw new MessageConversionError({\n          originalMessage: message,\n          message: `Unsupported role: ${_exhaustiveCheck}`,\n        });\n      }\n    }\n  }\n\n  return modelMessages;\n}\n\n/**\n@deprecated Use `convertToModelMessages` instead.\n */\n// TODO remove in AI SDK 6\nexport const convertToCoreMessages = convertToModelMessages;\n","import { ProviderOptions, withUserAgentSuffix } from '@ai-sdk/provider-utils';\nimport { resolveEmbeddingModel } from '../model/resolve-model';\nimport { assembleOperationName } from '../telemetry/assemble-operation-name';\nimport { getBaseTelemetryAttributes } from '../telemetry/get-base-telemetry-attributes';\nimport { getTracer } from '../telemetry/get-tracer';\nimport { recordSpan } from '../telemetry/record-span';\nimport { selectTelemetryAttributes } from '../telemetry/select-telemetry-attributes';\nimport { TelemetrySettings } from '../telemetry/telemetry-settings';\nimport { EmbeddingModel } from '../types';\nimport { prepareRetries } from '../util/prepare-retries';\nimport { EmbedResult } from './embed-result';\nimport { VERSION } from '../version';\n\n/**\nEmbed a value using an embedding model. The type of the value is defined by the embedding model.\n\n@param model - The embedding model to use.\n@param value - The value that should be embedded.\n\n@param maxRetries - Maximum number of retries. Set to 0 to disable retries. Default: 2.\n@param abortSignal - An optional abort signal that can be used to cancel the call.\n@param headers - Additional HTTP headers to be sent with the request. Only applicable for HTTP-based providers.\n\n@returns A result object that contains the embedding, the value, and additional information.\n */\nexport async function embed<VALUE = string>({\n  model: modelArg,\n  value,\n  providerOptions,\n  maxRetries: maxRetriesArg,\n  abortSignal,\n  headers,\n  experimental_telemetry: telemetry,\n}: {\n  /**\nThe embedding model to use.\n     */\n  model: EmbeddingModel<VALUE>;\n\n  /**\nThe value that should be embedded.\n   */\n  value: VALUE;\n\n  /**\nMaximum number of retries per embedding model call. Set to 0 to disable retries.\n\n@default 2\n   */\n  maxRetries?: number;\n\n  /**\nAbort signal.\n */\n  abortSignal?: AbortSignal;\n\n  /**\nAdditional headers to include in the request.\nOnly applicable for HTTP-based providers.\n */\n  headers?: Record<string, string>;\n\n  /**\n  Additional provider-specific options. They are passed through\n  to the provider from the AI SDK and enable provider-specific\n  functionality that can be fully encapsulated in the provider.\n  */\n  providerOptions?: ProviderOptions;\n\n  /**\n   * Optional telemetry configuration (experimental).\n   */\n  experimental_telemetry?: TelemetrySettings;\n}): Promise<EmbedResult<VALUE>> {\n  const model = resolveEmbeddingModel<VALUE>(modelArg);\n\n  const { maxRetries, retry } = prepareRetries({\n    maxRetries: maxRetriesArg,\n    abortSignal,\n  });\n\n  const headersWithUserAgent = withUserAgentSuffix(\n    headers ?? {},\n    `ai/${VERSION}`,\n  );\n\n  const baseTelemetryAttributes = getBaseTelemetryAttributes({\n    model: model,\n    telemetry,\n    headers: headersWithUserAgent,\n    settings: { maxRetries },\n  });\n\n  const tracer = getTracer(telemetry);\n\n  return recordSpan({\n    name: 'ai.embed',\n    attributes: selectTelemetryAttributes({\n      telemetry,\n      attributes: {\n        ...assembleOperationName({ operationId: 'ai.embed', telemetry }),\n        ...baseTelemetryAttributes,\n        'ai.value': { input: () => JSON.stringify(value) },\n      },\n    }),\n    tracer,\n    fn: async span => {\n      const { embedding, usage, response, providerMetadata } = await retry(() =>\n        // nested spans to align with the embedMany telemetry data:\n        recordSpan({\n          name: 'ai.embed.doEmbed',\n          attributes: selectTelemetryAttributes({\n            telemetry,\n            attributes: {\n              ...assembleOperationName({\n                operationId: 'ai.embed.doEmbed',\n                telemetry,\n              }),\n              ...baseTelemetryAttributes,\n              // specific settings that only make sense on the outer level:\n              'ai.values': { input: () => [JSON.stringify(value)] },\n            },\n          }),\n          tracer,\n          fn: async doEmbedSpan => {\n            const modelResponse = await model.doEmbed({\n              values: [value],\n              abortSignal,\n              headers: headersWithUserAgent,\n              providerOptions,\n            });\n\n            const embedding = modelResponse.embeddings[0];\n            const usage = modelResponse.usage ?? { tokens: NaN };\n\n            doEmbedSpan.setAttributes(\n              selectTelemetryAttributes({\n                telemetry,\n                attributes: {\n                  'ai.embeddings': {\n                    output: () =>\n                      modelResponse.embeddings.map(embedding =>\n                        JSON.stringify(embedding),\n                      ),\n                  },\n                  'ai.usage.tokens': usage.tokens,\n                },\n              }),\n            );\n\n            return {\n              embedding,\n              usage,\n              providerMetadata: modelResponse.providerMetadata,\n              response: modelResponse.response,\n            };\n          },\n        }),\n      );\n\n      span.setAttributes(\n        selectTelemetryAttributes({\n          telemetry,\n          attributes: {\n            'ai.embedding': { output: () => JSON.stringify(embedding) },\n            'ai.usage.tokens': usage.tokens,\n          },\n        }),\n      );\n\n      return new DefaultEmbedResult({\n        value,\n        embedding,\n        usage,\n        providerMetadata,\n        response,\n      });\n    },\n  });\n}\n\nclass DefaultEmbedResult<VALUE> implements EmbedResult<VALUE> {\n  readonly value: EmbedResult<VALUE>['value'];\n  readonly embedding: EmbedResult<VALUE>['embedding'];\n  readonly usage: EmbedResult<VALUE>['usage'];\n  readonly providerMetadata: EmbedResult<VALUE>['providerMetadata'];\n  readonly response: EmbedResult<VALUE>['response'];\n\n  constructor(options: {\n    value: EmbedResult<VALUE>['value'];\n    embedding: EmbedResult<VALUE>['embedding'];\n    usage: EmbedResult<VALUE>['usage'];\n    providerMetadata?: EmbedResult<VALUE>['providerMetadata'];\n    response?: EmbedResult<VALUE>['response'];\n  }) {\n    this.value = options.value;\n    this.embedding = options.embedding;\n    this.usage = options.usage;\n    this.providerMetadata = options.providerMetadata;\n    this.response = options.response;\n  }\n}\n","import { JSONValue } from '@ai-sdk/provider';\nimport {\n  createIdGenerator,\n  FlexibleSchema,\n  InferSchema,\n  ProviderOptions,\n  withUserAgentSuffix,\n} from '@ai-sdk/provider-utils';\nimport { NoObjectGeneratedError } from '../error/no-object-generated-error';\nimport { extractReasoningContent } from '../generate-text/extract-reasoning-content';\nimport { extractTextContent } from '../generate-text/extract-text-content';\nimport { logWarnings } from '../logger/log-warnings';\nimport { resolveLanguageModel } from '../model/resolve-model';\nimport { CallSettings } from '../prompt/call-settings';\nimport { convertToLanguageModelPrompt } from '../prompt/convert-to-language-model-prompt';\nimport { prepareCallSettings } from '../prompt/prepare-call-settings';\nimport { Prompt } from '../prompt/prompt';\nimport { standardizePrompt } from '../prompt/standardize-prompt';\nimport { wrapGatewayError } from '../prompt/wrap-gateway-error';\nimport { assembleOperationName } from '../telemetry/assemble-operation-name';\nimport { getBaseTelemetryAttributes } from '../telemetry/get-base-telemetry-attributes';\nimport { getTracer } from '../telemetry/get-tracer';\nimport { recordSpan } from '../telemetry/record-span';\nimport { selectTelemetryAttributes } from '../telemetry/select-telemetry-attributes';\nimport { stringifyForTelemetry } from '../telemetry/stringify-for-telemetry';\nimport { TelemetrySettings } from '../telemetry/telemetry-settings';\nimport {\n  CallWarning,\n  FinishReason,\n  LanguageModel,\n} from '../types/language-model';\nimport { LanguageModelRequestMetadata } from '../types/language-model-request-metadata';\nimport { LanguageModelResponseMetadata } from '../types/language-model-response-metadata';\nimport { ProviderMetadata } from '../types/provider-metadata';\nimport { LanguageModelUsage } from '../types/usage';\nimport { DownloadFunction } from '../util/download/download-function';\nimport { prepareHeaders } from '../util/prepare-headers';\nimport { prepareRetries } from '../util/prepare-retries';\nimport { VERSION } from '../version';\nimport { GenerateObjectResult } from './generate-object-result';\nimport { getOutputStrategy } from './output-strategy';\nimport { parseAndValidateObjectResultWithRepair } from './parse-and-validate-object-result';\nimport { RepairTextFunction } from './repair-text';\nimport { validateObjectGenerationInput } from './validate-object-generation-input';\n\nconst originalGenerateId = createIdGenerator({ prefix: 'aiobj', size: 24 });\n\n/**\nGenerate a structured, typed object for a given prompt and schema using a language model.\n\nThis function does not stream the output. If you want to stream the output, use `streamObject` instead.\n\n@param model - The language model to use.\n@param tools - Tools that are accessible to and can be called by the model. The model needs to support calling tools.\n\n@param system - A system message that will be part of the prompt.\n@param prompt - A simple text prompt. You can either use `prompt` or `messages` but not both.\n@param messages - A list of messages. You can either use `prompt` or `messages` but not both.\n\n@param maxOutputTokens - Maximum number of tokens to generate.\n@param temperature - Temperature setting.\nThe value is passed through to the provider. The range depends on the provider and model.\nIt is recommended to set either `temperature` or `topP`, but not both.\n@param topP - Nucleus sampling.\nThe value is passed through to the provider. The range depends on the provider and model.\nIt is recommended to set either `temperature` or `topP`, but not both.\n@param topK - Only sample from the top K options for each subsequent token.\nUsed to remove \"long tail\" low probability responses.\nRecommended for advanced use cases only. You usually only need to use temperature.\n@param presencePenalty - Presence penalty setting.\nIt affects the likelihood of the model to repeat information that is already in the prompt.\nThe value is passed through to the provider. The range depends on the provider and model.\n@param frequencyPenalty - Frequency penalty setting.\nIt affects the likelihood of the model to repeatedly use the same words or phrases.\nThe value is passed through to the provider. The range depends on the provider and model.\n@param stopSequences - Stop sequences.\nIf set, the model will stop generating text when one of the stop sequences is generated.\n@param seed - The seed (integer) to use for random sampling.\nIf set and supported by the model, calls will generate deterministic results.\n\n@param maxRetries - Maximum number of retries. Set to 0 to disable retries. Default: 2.\n@param abortSignal - An optional abort signal that can be used to cancel the call.\n@param headers - Additional HTTP headers to be sent with the request. Only applicable for HTTP-based providers.\n\n@param schema - The schema of the object that the model should generate.\n@param schemaName - Optional name of the output that should be generated.\nUsed by some providers for additional LLM guidance, e.g.\nvia tool or schema name.\n@param schemaDescription - Optional description of the output that should be generated.\nUsed by some providers for additional LLM guidance, e.g.\nvia tool or schema description.\n\n@param output - The type of the output.\n\n- 'object': The output is an object.\n- 'array': The output is an array.\n- 'enum': The output is an enum.\n- 'no-schema': The output is not a schema.\n\n@param experimental_repairText - A function that attempts to repair the raw output of the model\nto enable JSON parsing.\n\n@param experimental_telemetry - Optional telemetry configuration (experimental).\n\n@param providerOptions - Additional provider-specific options. They are passed through\nto the provider from the AI SDK and enable provider-specific\nfunctionality that can be fully encapsulated in the provider.\n\n@returns\nA result object that contains the generated object, the finish reason, the token usage, and additional information.\n */\nexport async function generateObject<\n  SCHEMA extends FlexibleSchema<unknown> = FlexibleSchema<JSONValue>,\n  OUTPUT extends\n    | 'object'\n    | 'array'\n    | 'enum'\n    | 'no-schema' = InferSchema<SCHEMA> extends string ? 'enum' : 'object',\n  RESULT = OUTPUT extends 'array'\n    ? Array<InferSchema<SCHEMA>>\n    : InferSchema<SCHEMA>,\n>(\n  options: Omit<CallSettings, 'stopSequences'> &\n    Prompt &\n    (OUTPUT extends 'enum'\n      ? {\n          /**\nThe enum values that the model should use.\n        */\n          enum: Array<RESULT>;\n          mode?: 'json';\n          output: 'enum';\n        }\n      : OUTPUT extends 'no-schema'\n        ? {}\n        : {\n            /**\nThe schema of the object that the model should generate.\n        */\n            schema: SCHEMA;\n\n            /**\nOptional name of the output that should be generated.\nUsed by some providers for additional LLM guidance, e.g.\nvia tool or schema name.\n        */\n            schemaName?: string;\n\n            /**\nOptional description of the output that should be generated.\nUsed by some providers for additional LLM guidance, e.g.\nvia tool or schema description.\n        */\n            schemaDescription?: string;\n\n            /**\nThe mode to use for object generation.\n\nThe schema is converted into a JSON schema and used in one of the following ways\n\n- 'auto': The provider will choose the best mode for the model.\n- 'tool': A tool with the JSON schema as parameters is provided and the provider is instructed to use it.\n- 'json': The JSON schema and an instruction are injected into the prompt. If the provider supports JSON mode, it is enabled. If the provider supports JSON grammars, the grammar is used.\n\nPlease note that most providers do not support all modes.\n\nDefault and recommended: 'auto' (best mode for the model).\n        */\n            mode?: 'auto' | 'json' | 'tool';\n          }) & {\n      output?: OUTPUT;\n\n      /**\n  The language model to use.\n       */\n      model: LanguageModel;\n      /**\n  A function that attempts to repair the raw output of the model\n  to enable JSON parsing.\n       */\n      experimental_repairText?: RepairTextFunction;\n\n      /**\n  Optional telemetry configuration (experimental).\n         */\n\n      experimental_telemetry?: TelemetrySettings;\n\n      /**\n  Custom download function to use for URLs.\n\n  By default, files are downloaded if the model does not support the URL for the given media type.\n       */\n      experimental_download?: DownloadFunction | undefined;\n\n      /**\n  Additional provider-specific options. They are passed through\n  to the provider from the AI SDK and enable provider-specific\n  functionality that can be fully encapsulated in the provider.\n   */\n      providerOptions?: ProviderOptions;\n\n      /**\n       * Internal. For test use only. May change without notice.\n       */\n      _internal?: {\n        generateId?: () => string;\n        currentDate?: () => Date;\n      };\n    },\n): Promise<GenerateObjectResult<RESULT>> {\n  const {\n    model: modelArg,\n    output = 'object',\n    system,\n    prompt,\n    messages,\n    maxRetries: maxRetriesArg,\n    abortSignal,\n    headers,\n    experimental_repairText: repairText,\n    experimental_telemetry: telemetry,\n    experimental_download: download,\n    providerOptions,\n    _internal: {\n      generateId = originalGenerateId,\n      currentDate = () => new Date(),\n    } = {},\n    ...settings\n  } = options;\n\n  const model = resolveLanguageModel(modelArg);\n\n  const enumValues = 'enum' in options ? options.enum : undefined;\n  const {\n    schema: inputSchema,\n    schemaDescription,\n    schemaName,\n  } = 'schema' in options ? options : {};\n\n  validateObjectGenerationInput({\n    output,\n    schema: inputSchema,\n    schemaName,\n    schemaDescription,\n    enumValues,\n  });\n\n  const { maxRetries, retry } = prepareRetries({\n    maxRetries: maxRetriesArg,\n    abortSignal,\n  });\n\n  const outputStrategy = getOutputStrategy({\n    output,\n    schema: inputSchema,\n    enumValues,\n  });\n\n  const callSettings = prepareCallSettings(settings);\n\n  const headersWithUserAgent = withUserAgentSuffix(\n    headers ?? {},\n    `ai/${VERSION}`,\n  );\n\n  const baseTelemetryAttributes = getBaseTelemetryAttributes({\n    model,\n    telemetry,\n    headers: headersWithUserAgent,\n    settings: { ...callSettings, maxRetries },\n  });\n\n  const tracer = getTracer(telemetry);\n\n  try {\n    return await recordSpan({\n      name: 'ai.generateObject',\n      attributes: selectTelemetryAttributes({\n        telemetry,\n        attributes: {\n          ...assembleOperationName({\n            operationId: 'ai.generateObject',\n            telemetry,\n          }),\n          ...baseTelemetryAttributes,\n          // specific settings that only make sense on the outer level:\n          'ai.prompt': {\n            input: () => JSON.stringify({ system, prompt, messages }),\n          },\n          'ai.schema':\n            outputStrategy.jsonSchema != null\n              ? { input: () => JSON.stringify(outputStrategy.jsonSchema) }\n              : undefined,\n          'ai.schema.name': schemaName,\n          'ai.schema.description': schemaDescription,\n          'ai.settings.output': outputStrategy.type,\n        },\n      }),\n      tracer,\n      fn: async span => {\n        let result: string;\n        let finishReason: FinishReason;\n        let usage: LanguageModelUsage;\n        let warnings: CallWarning[] | undefined;\n        let response: LanguageModelResponseMetadata;\n        let request: LanguageModelRequestMetadata;\n        let resultProviderMetadata: ProviderMetadata | undefined;\n        let reasoning: string | undefined;\n\n        const standardizedPrompt = await standardizePrompt({\n          system,\n          prompt,\n          messages,\n        } as Prompt);\n\n        const promptMessages = await convertToLanguageModelPrompt({\n          prompt: standardizedPrompt,\n          supportedUrls: await model.supportedUrls,\n          download,\n        });\n\n        const generateResult = await retry(() =>\n          recordSpan({\n            name: 'ai.generateObject.doGenerate',\n            attributes: selectTelemetryAttributes({\n              telemetry,\n              attributes: {\n                ...assembleOperationName({\n                  operationId: 'ai.generateObject.doGenerate',\n                  telemetry,\n                }),\n                ...baseTelemetryAttributes,\n                'ai.prompt.messages': {\n                  input: () => stringifyForTelemetry(promptMessages),\n                },\n\n                // standardized gen-ai llm span attributes:\n                'gen_ai.system': model.provider,\n                'gen_ai.request.model': model.modelId,\n                'gen_ai.request.frequency_penalty':\n                  callSettings.frequencyPenalty,\n                'gen_ai.request.max_tokens': callSettings.maxOutputTokens,\n                'gen_ai.request.presence_penalty': callSettings.presencePenalty,\n                'gen_ai.request.temperature': callSettings.temperature,\n                'gen_ai.request.top_k': callSettings.topK,\n                'gen_ai.request.top_p': callSettings.topP,\n              },\n            }),\n            tracer,\n            fn: async span => {\n              const result = await model.doGenerate({\n                responseFormat: {\n                  type: 'json',\n                  schema: outputStrategy.jsonSchema,\n                  name: schemaName,\n                  description: schemaDescription,\n                },\n                ...prepareCallSettings(settings),\n                prompt: promptMessages,\n                providerOptions,\n                abortSignal,\n                headers: headersWithUserAgent,\n              });\n\n              const responseData = {\n                id: result.response?.id ?? generateId(),\n                timestamp: result.response?.timestamp ?? currentDate(),\n                modelId: result.response?.modelId ?? model.modelId,\n                headers: result.response?.headers,\n                body: result.response?.body,\n              };\n\n              const text = extractTextContent(result.content);\n              const reasoning = extractReasoningContent(result.content);\n\n              if (text === undefined) {\n                throw new NoObjectGeneratedError({\n                  message:\n                    'No object generated: the model did not return a response.',\n                  response: responseData,\n                  usage: result.usage,\n                  finishReason: result.finishReason,\n                });\n              }\n\n              // Add response information to the span:\n              span.setAttributes(\n                selectTelemetryAttributes({\n                  telemetry,\n                  attributes: {\n                    'ai.response.finishReason': result.finishReason,\n                    'ai.response.object': { output: () => text },\n                    'ai.response.id': responseData.id,\n                    'ai.response.model': responseData.modelId,\n                    'ai.response.timestamp':\n                      responseData.timestamp.toISOString(),\n                    'ai.response.providerMetadata': JSON.stringify(\n                      result.providerMetadata,\n                    ),\n\n                    // TODO rename telemetry attributes to inputTokens and outputTokens\n                    'ai.usage.promptTokens': result.usage.inputTokens,\n                    'ai.usage.completionTokens': result.usage.outputTokens,\n\n                    // standardized gen-ai llm span attributes:\n                    'gen_ai.response.finish_reasons': [result.finishReason],\n                    'gen_ai.response.id': responseData.id,\n                    'gen_ai.response.model': responseData.modelId,\n                    'gen_ai.usage.input_tokens': result.usage.inputTokens,\n                    'gen_ai.usage.output_tokens': result.usage.outputTokens,\n                  },\n                }),\n              );\n\n              return {\n                ...result,\n                objectText: text,\n                reasoning,\n                responseData,\n              };\n            },\n          }),\n        );\n\n        result = generateResult.objectText;\n        finishReason = generateResult.finishReason;\n        usage = generateResult.usage;\n        warnings = generateResult.warnings;\n        resultProviderMetadata = generateResult.providerMetadata;\n        request = generateResult.request ?? {};\n        response = generateResult.responseData;\n        reasoning = generateResult.reasoning;\n\n        logWarnings(warnings);\n\n        const object = await parseAndValidateObjectResultWithRepair(\n          result,\n          outputStrategy,\n          repairText,\n          {\n            response,\n            usage,\n            finishReason,\n          },\n        );\n\n        // Add response information to the span:\n        span.setAttributes(\n          selectTelemetryAttributes({\n            telemetry,\n            attributes: {\n              'ai.response.finishReason': finishReason,\n              'ai.response.object': {\n                output: () => JSON.stringify(object),\n              },\n              'ai.response.providerMetadata': JSON.stringify(\n                resultProviderMetadata,\n              ),\n\n              // TODO rename telemetry attributes to inputTokens and outputTokens\n              'ai.usage.promptTokens': usage.inputTokens,\n              'ai.usage.completionTokens': usage.outputTokens,\n            },\n          }),\n        );\n\n        return new DefaultGenerateObjectResult({\n          object,\n          reasoning,\n          finishReason,\n          usage,\n          warnings,\n          request,\n          response,\n          providerMetadata: resultProviderMetadata,\n        });\n      },\n    });\n  } catch (error) {\n    throw wrapGatewayError(error);\n  }\n}\n\nclass DefaultGenerateObjectResult<T> implements GenerateObjectResult<T> {\n  readonly object: GenerateObjectResult<T>['object'];\n  readonly finishReason: GenerateObjectResult<T>['finishReason'];\n  readonly usage: GenerateObjectResult<T>['usage'];\n  readonly warnings: GenerateObjectResult<T>['warnings'];\n  readonly providerMetadata: GenerateObjectResult<T>['providerMetadata'];\n  readonly response: GenerateObjectResult<T>['response'];\n  readonly request: GenerateObjectResult<T>['request'];\n  readonly reasoning: GenerateObjectResult<T>['reasoning'];\n\n  constructor(options: {\n    object: GenerateObjectResult<T>['object'];\n    finishReason: GenerateObjectResult<T>['finishReason'];\n    usage: GenerateObjectResult<T>['usage'];\n    warnings: GenerateObjectResult<T>['warnings'];\n    providerMetadata: GenerateObjectResult<T>['providerMetadata'];\n    response: GenerateObjectResult<T>['response'];\n    request: GenerateObjectResult<T>['request'];\n    reasoning: GenerateObjectResult<T>['reasoning'];\n  }) {\n    this.object = options.object;\n    this.finishReason = options.finishReason;\n    this.usage = options.usage;\n    this.warnings = options.warnings;\n    this.providerMetadata = options.providerMetadata;\n    this.response = options.response;\n    this.request = options.request;\n    this.reasoning = options.reasoning;\n  }\n\n  toJsonResponse(init?: ResponseInit): Response {\n    return new Response(JSON.stringify(this.object), {\n      status: init?.status ?? 200,\n      headers: prepareHeaders(init?.headers, {\n        'content-type': 'application/json; charset=utf-8',\n      }),\n    });\n  }\n}\n","/**\n * Performs a deep-equal comparison of two parsed JSON objects.\n *\n * @param {any} obj1 - The first object to compare.\n * @param {any} obj2 - The second object to compare.\n * @returns {boolean} - Returns true if the two objects are deeply equal, false otherwise.\n */\nexport function isDeepEqualData(obj1: any, obj2: any): boolean {\n  // Check for strict equality first\n  if (obj1 === obj2) return true;\n\n  // Check if either is null or undefined\n  if (obj1 == null || obj2 == null) return false;\n\n  // Check if both are objects\n  if (typeof obj1 !== 'object' && typeof obj2 !== 'object')\n    return obj1 === obj2;\n\n  // If they are not strictly equal, they both need to be Objects\n  if (obj1.constructor !== obj2.constructor) return false;\n\n  // Special handling for Date objects\n  if (obj1 instanceof Date && obj2 instanceof Date) {\n    return obj1.getTime() === obj2.getTime();\n  }\n\n  // Handle arrays: compare length and then perform a recursive deep comparison on each item\n  if (Array.isArray(obj1)) {\n    if (obj1.length !== obj2.length) return false;\n    for (let i = 0; i < obj1.length; i++) {\n      if (!isDeepEqualData(obj1[i], obj2[i])) return false;\n    }\n    return true; // All array elements matched\n  }\n\n  // Compare the set of keys in each object\n  const keys1 = Object.keys(obj1);\n  const keys2 = Object.keys(obj2);\n  if (keys1.length !== keys2.length) return false;\n\n  // Check each key-value pair recursively\n  for (const key of keys1) {\n    if (!keys2.includes(key)) return false;\n    if (!isDeepEqualData(obj1[key], obj2[key])) return false;\n  }\n\n  return true; // All keys and values matched\n}\n","import {\n  JSONValue,\n  LanguageModelV2CallWarning,\n  LanguageModelV2FinishReason,\n  LanguageModelV2StreamPart,\n  LanguageModelV2Usage,\n  SharedV2ProviderMetadata,\n} from '@ai-sdk/provider';\nimport {\n  createIdGenerator,\n  FlexibleSchema,\n  ProviderOptions,\n  type InferSchema,\n} from '@ai-sdk/provider-utils';\nimport { ServerResponse } from 'http';\nimport { logWarnings } from '../logger/log-warnings';\nimport { resolveLanguageModel } from '../model/resolve-model';\nimport { CallSettings } from '../prompt/call-settings';\nimport { convertToLanguageModelPrompt } from '../prompt/convert-to-language-model-prompt';\nimport { prepareCallSettings } from '../prompt/prepare-call-settings';\nimport { Prompt } from '../prompt/prompt';\nimport { standardizePrompt } from '../prompt/standardize-prompt';\nimport { wrapGatewayError } from '../prompt/wrap-gateway-error';\nimport { assembleOperationName } from '../telemetry/assemble-operation-name';\nimport { getBaseTelemetryAttributes } from '../telemetry/get-base-telemetry-attributes';\nimport { getTracer } from '../telemetry/get-tracer';\nimport { recordSpan } from '../telemetry/record-span';\nimport { selectTelemetryAttributes } from '../telemetry/select-telemetry-attributes';\nimport { stringifyForTelemetry } from '../telemetry/stringify-for-telemetry';\nimport { TelemetrySettings } from '../telemetry/telemetry-settings';\nimport { createTextStreamResponse } from '../text-stream/create-text-stream-response';\nimport { pipeTextStreamToResponse } from '../text-stream/pipe-text-stream-to-response';\nimport {\n  CallWarning,\n  FinishReason,\n  LanguageModel,\n} from '../types/language-model';\nimport { LanguageModelRequestMetadata } from '../types/language-model-request-metadata';\nimport { LanguageModelResponseMetadata } from '../types/language-model-response-metadata';\nimport { ProviderMetadata } from '../types/provider-metadata';\nimport { LanguageModelUsage } from '../types/usage';\nimport { DeepPartial, isDeepEqualData, parsePartialJson } from '../util';\nimport {\n  AsyncIterableStream,\n  createAsyncIterableStream,\n} from '../util/async-iterable-stream';\nimport { createStitchableStream } from '../util/create-stitchable-stream';\nimport { DelayedPromise } from '../util/delayed-promise';\nimport { DownloadFunction } from '../util/download/download-function';\nimport { now as originalNow } from '../util/now';\nimport { prepareRetries } from '../util/prepare-retries';\nimport { getOutputStrategy, OutputStrategy } from './output-strategy';\nimport { parseAndValidateObjectResultWithRepair } from './parse-and-validate-object-result';\nimport { RepairTextFunction } from './repair-text';\nimport { ObjectStreamPart, StreamObjectResult } from './stream-object-result';\nimport { validateObjectGenerationInput } from './validate-object-generation-input';\n\nconst originalGenerateId = createIdGenerator({ prefix: 'aiobj', size: 24 });\n\n/**\nCallback that is set using the `onError` option.\n\n@param event - The event that is passed to the callback.\n */\nexport type StreamObjectOnErrorCallback = (event: {\n  error: unknown;\n}) => Promise<void> | void;\n\n/**\nCallback that is set using the `onFinish` option.\n\n@param event - The event that is passed to the callback.\n */\nexport type StreamObjectOnFinishCallback<RESULT> = (event: {\n  /**\nThe token usage of the generated response.\n*/\n  usage: LanguageModelUsage;\n\n  /**\nThe generated object. Can be undefined if the final object does not match the schema.\n*/\n  object: RESULT | undefined;\n\n  /**\nOptional error object. This is e.g. a TypeValidationError when the final object does not match the schema.\n*/\n  error: unknown | undefined;\n\n  /**\nResponse metadata.\n */\n  response: LanguageModelResponseMetadata;\n\n  /**\nWarnings from the model provider (e.g. unsupported settings).\n*/\n  warnings?: CallWarning[];\n\n  /**\nAdditional provider-specific metadata. They are passed through\nto the provider from the AI SDK and enable provider-specific\nfunctionality that can be fully encapsulated in the provider.\n*/\n  providerMetadata: ProviderMetadata | undefined;\n}) => Promise<void> | void;\n\n/**\nGenerate a structured, typed object for a given prompt and schema using a language model.\n\nThis function streams the output. If you do not want to stream the output, use `generateObject` instead.\n\n@param model - The language model to use.\n@param tools - Tools that are accessible to and can be called by the model. The model needs to support calling tools.\n\n@param system - A system message that will be part of the prompt.\n@param prompt - A simple text prompt. You can either use `prompt` or `messages` but not both.\n@param messages - A list of messages. You can either use `prompt` or `messages` but not both.\n\n@param maxOutputTokens - Maximum number of tokens to generate.\n@param temperature - Temperature setting.\nThe value is passed through to the provider. The range depends on the provider and model.\nIt is recommended to set either `temperature` or `topP`, but not both.\n@param topP - Nucleus sampling.\nThe value is passed through to the provider. The range depends on the provider and model.\nIt is recommended to set either `temperature` or `topP`, but not both.\n@param topK - Only sample from the top K options for each subsequent token.\nUsed to remove \"long tail\" low probability responses.\nRecommended for advanced use cases only. You usually only need to use temperature.\n@param presencePenalty - Presence penalty setting.\nIt affects the likelihood of the model to repeat information that is already in the prompt.\nThe value is passed through to the provider. The range depends on the provider and model.\n@param frequencyPenalty - Frequency penalty setting.\nIt affects the likelihood of the model to repeatedly use the same words or phrases.\nThe value is passed through to the provider. The range depends on the provider and model.\n@param stopSequences - Stop sequences.\nIf set, the model will stop generating text when one of the stop sequences is generated.\n@param seed - The seed (integer) to use for random sampling.\nIf set and supported by the model, calls will generate deterministic results.\n\n@param maxRetries - Maximum number of retries. Set to 0 to disable retries. Default: 2.\n@param abortSignal - An optional abort signal that can be used to cancel the call.\n@param headers - Additional HTTP headers to be sent with the request. Only applicable for HTTP-based providers.\n\n@param schema - The schema of the object that the model should generate.\n@param schemaName - Optional name of the output that should be generated.\nUsed by some providers for additional LLM guidance, e.g.\nvia tool or schema name.\n@param schemaDescription - Optional description of the output that should be generated.\nUsed by some providers for additional LLM guidance, e.g.\nvia tool or schema description.\n\n@param output - The type of the output.\n\n- 'object': The output is an object.\n- 'array': The output is an array.\n- 'enum': The output is an enum.\n- 'no-schema': The output is not a schema.\n\n@param experimental_telemetry - Optional telemetry configuration (experimental).\n\n@param providerOptions - Additional provider-specific options. They are passed through\nto the provider from the AI SDK and enable provider-specific\nfunctionality that can be fully encapsulated in the provider.\n\n@returns\nA result object for accessing the partial object stream and additional information.\n */\nexport function streamObject<\n  SCHEMA extends FlexibleSchema<unknown> = FlexibleSchema<JSONValue>,\n  OUTPUT extends\n    | 'object'\n    | 'array'\n    | 'enum'\n    | 'no-schema' = InferSchema<SCHEMA> extends string ? 'enum' : 'object',\n  RESULT = OUTPUT extends 'array'\n    ? Array<InferSchema<SCHEMA>>\n    : InferSchema<SCHEMA>,\n>(\n  options: Omit<CallSettings, 'stopSequences'> &\n    Prompt &\n    (OUTPUT extends 'enum'\n      ? {\n          /**\nThe enum values that the model should use.\n        */\n          enum: Array<RESULT>;\n          mode?: 'json';\n          output: 'enum';\n        }\n      : OUTPUT extends 'no-schema'\n        ? {}\n        : {\n            /**\nThe schema of the object that the model should generate.\n      */\n            schema: SCHEMA;\n\n            /**\nOptional name of the output that should be generated.\nUsed by some providers for additional LLM guidance, e.g.\nvia tool or schema name.\n      */\n            schemaName?: string;\n\n            /**\nOptional description of the output that should be generated.\nUsed by some providers for additional LLM guidance, e.g.\nvia tool or schema description.\n      */\n            schemaDescription?: string;\n\n            /**\nThe mode to use for object generation.\n\nThe schema is converted into a JSON schema and used in one of the following ways\n\n- 'auto': The provider will choose the best mode for the model.\n- 'tool': A tool with the JSON schema as parameters is provided and the provider is instructed to use it.\n- 'json': The JSON schema and an instruction are injected into the prompt. If the provider supports JSON mode, it is enabled. If the provider supports JSON grammars, the grammar is used.\n\nPlease note that most providers do not support all modes.\n\nDefault and recommended: 'auto' (best mode for the model).\n      */\n            mode?: 'auto' | 'json' | 'tool';\n          }) & {\n      output?: OUTPUT;\n\n      /**\nThe language model to use.\n     */\n      model: LanguageModel;\n\n      /**\nA function that attempts to repair the raw output of the model\nto enable JSON parsing.\n       */\n      experimental_repairText?: RepairTextFunction;\n\n      /**\nOptional telemetry configuration (experimental).\n       */\n\n      experimental_telemetry?: TelemetrySettings;\n\n      /**\n  Custom download function to use for URLs.\n\n  By default, files are downloaded if the model does not support the URL for the given media type.\n       */\n      experimental_download?: DownloadFunction | undefined;\n\n      /**\nAdditional provider-specific options. They are passed through\nto the provider from the AI SDK and enable provider-specific\nfunctionality that can be fully encapsulated in the provider.\n */\n      providerOptions?: ProviderOptions;\n\n      /**\nCallback that is invoked when an error occurs during streaming.\nYou can use it to log errors.\nThe stream processing will pause until the callback promise is resolved.\n     */\n      onError?: StreamObjectOnErrorCallback;\n\n      /**\nCallback that is called when the LLM response and the final object validation are finished.\n*/\n      onFinish?: StreamObjectOnFinishCallback<RESULT>;\n\n      /**\n       * Internal. For test use only. May change without notice.\n       */\n      _internal?: {\n        generateId?: () => string;\n        currentDate?: () => Date;\n        now?: () => number;\n      };\n    },\n): StreamObjectResult<\n  OUTPUT extends 'enum'\n    ? string\n    : OUTPUT extends 'array'\n      ? RESULT\n      : DeepPartial<RESULT>,\n  OUTPUT extends 'array' ? RESULT : RESULT,\n  OUTPUT extends 'array'\n    ? RESULT extends Array<infer U>\n      ? AsyncIterableStream<U>\n      : never\n    : never\n> {\n  const {\n    model,\n    output = 'object',\n    system,\n    prompt,\n    messages,\n    maxRetries,\n    abortSignal,\n    headers,\n    experimental_repairText: repairText,\n    experimental_telemetry: telemetry,\n    experimental_download: download,\n    providerOptions,\n    onError = ({ error }: { error: unknown }) => {\n      console.error(error);\n    },\n    onFinish,\n    _internal: {\n      generateId = originalGenerateId,\n      currentDate = () => new Date(),\n      now = originalNow,\n    } = {},\n    ...settings\n  } = options;\n\n  const enumValues =\n    'enum' in options && options.enum ? options.enum : undefined;\n\n  const {\n    schema: inputSchema,\n    schemaDescription,\n    schemaName,\n  } = 'schema' in options ? options : {};\n\n  validateObjectGenerationInput({\n    output,\n    schema: inputSchema,\n    schemaName,\n    schemaDescription,\n    enumValues,\n  });\n\n  const outputStrategy = getOutputStrategy({\n    output,\n    schema: inputSchema,\n    enumValues,\n  });\n\n  return new DefaultStreamObjectResult({\n    model,\n    telemetry,\n    headers,\n    settings,\n    maxRetries,\n    abortSignal,\n    outputStrategy,\n    system,\n    prompt,\n    messages,\n    schemaName,\n    schemaDescription,\n    providerOptions,\n    repairText,\n    onError,\n    onFinish,\n    download,\n    generateId,\n    currentDate,\n    now,\n  });\n}\n\nclass DefaultStreamObjectResult<PARTIAL, RESULT, ELEMENT_STREAM>\n  implements StreamObjectResult<PARTIAL, RESULT, ELEMENT_STREAM>\n{\n  private readonly _object = new DelayedPromise<RESULT>();\n  private readonly _usage = new DelayedPromise<LanguageModelUsage>();\n  private readonly _providerMetadata = new DelayedPromise<\n    ProviderMetadata | undefined\n  >();\n  private readonly _warnings = new DelayedPromise<CallWarning[] | undefined>();\n  private readonly _request =\n    new DelayedPromise<LanguageModelRequestMetadata>();\n  private readonly _response =\n    new DelayedPromise<LanguageModelResponseMetadata>();\n  private readonly _finishReason = new DelayedPromise<FinishReason>();\n\n  private readonly baseStream: ReadableStream<ObjectStreamPart<PARTIAL>>;\n\n  private readonly outputStrategy: OutputStrategy<\n    PARTIAL,\n    RESULT,\n    ELEMENT_STREAM\n  >;\n\n  constructor({\n    model: modelArg,\n    headers,\n    telemetry,\n    settings,\n    maxRetries: maxRetriesArg,\n    abortSignal,\n    outputStrategy,\n    system,\n    prompt,\n    messages,\n    schemaName,\n    schemaDescription,\n    providerOptions,\n    repairText,\n    onError,\n    onFinish,\n    download,\n    generateId,\n    currentDate,\n    now,\n  }: {\n    model: LanguageModel;\n    telemetry: TelemetrySettings | undefined;\n    headers: Record<string, string | undefined> | undefined;\n    settings: Omit<CallSettings, 'abortSignal' | 'headers'>;\n    maxRetries: number | undefined;\n    abortSignal: AbortSignal | undefined;\n    outputStrategy: OutputStrategy<PARTIAL, RESULT, ELEMENT_STREAM>;\n    system: Prompt['system'];\n    prompt: Prompt['prompt'];\n    messages: Prompt['messages'];\n    schemaName: string | undefined;\n    schemaDescription: string | undefined;\n    providerOptions: ProviderOptions | undefined;\n    repairText: RepairTextFunction | undefined;\n    onError: StreamObjectOnErrorCallback;\n    onFinish: StreamObjectOnFinishCallback<RESULT> | undefined;\n    download: DownloadFunction | undefined;\n    generateId: () => string;\n    currentDate: () => Date;\n    now: () => number;\n  }) {\n    const model = resolveLanguageModel(modelArg);\n\n    const { maxRetries, retry } = prepareRetries({\n      maxRetries: maxRetriesArg,\n      abortSignal,\n    });\n\n    const callSettings = prepareCallSettings(settings);\n\n    const baseTelemetryAttributes = getBaseTelemetryAttributes({\n      model,\n      telemetry,\n      headers,\n      settings: { ...callSettings, maxRetries },\n    });\n\n    const tracer = getTracer(telemetry);\n    const self = this;\n\n    const stitchableStream =\n      createStitchableStream<ObjectStreamPart<PARTIAL>>();\n\n    const eventProcessor = new TransformStream<\n      ObjectStreamPart<PARTIAL>,\n      ObjectStreamPart<PARTIAL>\n    >({\n      transform(chunk, controller) {\n        controller.enqueue(chunk);\n\n        if (chunk.type === 'error') {\n          onError({ error: wrapGatewayError(chunk.error) });\n        }\n      },\n    });\n\n    this.baseStream = stitchableStream.stream.pipeThrough(eventProcessor);\n\n    recordSpan({\n      name: 'ai.streamObject',\n      attributes: selectTelemetryAttributes({\n        telemetry,\n        attributes: {\n          ...assembleOperationName({\n            operationId: 'ai.streamObject',\n            telemetry,\n          }),\n          ...baseTelemetryAttributes,\n          // specific settings that only make sense on the outer level:\n          'ai.prompt': {\n            input: () => JSON.stringify({ system, prompt, messages }),\n          },\n          'ai.schema':\n            outputStrategy.jsonSchema != null\n              ? { input: () => JSON.stringify(outputStrategy.jsonSchema) }\n              : undefined,\n          'ai.schema.name': schemaName,\n          'ai.schema.description': schemaDescription,\n          'ai.settings.output': outputStrategy.type,\n        },\n      }),\n      tracer,\n      endWhenDone: false,\n      fn: async rootSpan => {\n        const standardizedPrompt = await standardizePrompt({\n          system,\n          prompt,\n          messages,\n        } as Prompt);\n\n        const callOptions = {\n          responseFormat: {\n            type: 'json' as const,\n            schema: outputStrategy.jsonSchema,\n            name: schemaName,\n            description: schemaDescription,\n          },\n          ...prepareCallSettings(settings),\n          prompt: await convertToLanguageModelPrompt({\n            prompt: standardizedPrompt,\n            supportedUrls: await model.supportedUrls,\n            download,\n          }),\n          providerOptions,\n          abortSignal,\n          headers,\n          includeRawChunks: false,\n        };\n\n        const transformer: Transformer<\n          LanguageModelV2StreamPart,\n          ObjectStreamInputPart\n        > = {\n          transform: (chunk, controller) => {\n            switch (chunk.type) {\n              case 'text-delta':\n                controller.enqueue(chunk.delta);\n                break;\n              case 'response-metadata':\n              case 'finish':\n              case 'error':\n              case 'stream-start':\n                controller.enqueue(chunk);\n                break;\n            }\n          },\n        };\n\n        const {\n          result: { stream, response, request },\n          doStreamSpan,\n          startTimestampMs,\n        } = await retry(() =>\n          recordSpan({\n            name: 'ai.streamObject.doStream',\n            attributes: selectTelemetryAttributes({\n              telemetry,\n              attributes: {\n                ...assembleOperationName({\n                  operationId: 'ai.streamObject.doStream',\n                  telemetry,\n                }),\n                ...baseTelemetryAttributes,\n                'ai.prompt.messages': {\n                  input: () => stringifyForTelemetry(callOptions.prompt),\n                },\n\n                // standardized gen-ai llm span attributes:\n                'gen_ai.system': model.provider,\n                'gen_ai.request.model': model.modelId,\n                'gen_ai.request.frequency_penalty':\n                  callSettings.frequencyPenalty,\n                'gen_ai.request.max_tokens': callSettings.maxOutputTokens,\n                'gen_ai.request.presence_penalty': callSettings.presencePenalty,\n                'gen_ai.request.temperature': callSettings.temperature,\n                'gen_ai.request.top_k': callSettings.topK,\n                'gen_ai.request.top_p': callSettings.topP,\n              },\n            }),\n            tracer,\n            endWhenDone: false,\n            fn: async doStreamSpan => ({\n              startTimestampMs: now(),\n              doStreamSpan,\n              result: await model.doStream(callOptions),\n            }),\n          }),\n        );\n\n        self._request.resolve(request ?? {});\n\n        // store information for onFinish callback:\n        let warnings: LanguageModelV2CallWarning[] | undefined;\n        let usage: LanguageModelUsage = {\n          inputTokens: undefined,\n          outputTokens: undefined,\n          totalTokens: undefined,\n        };\n        let finishReason: LanguageModelV2FinishReason | undefined;\n        let providerMetadata: ProviderMetadata | undefined;\n        let object: RESULT | undefined;\n        let error: unknown | undefined;\n\n        // pipe chunks through a transformation stream that extracts metadata:\n        let accumulatedText = '';\n        let textDelta = '';\n        let fullResponse: {\n          id: string;\n          timestamp: Date;\n          modelId: string;\n        } = {\n          id: generateId(),\n          timestamp: currentDate(),\n          modelId: model.modelId,\n        };\n\n        // Keep track of raw parse result before type validation, since e.g. Zod might\n        // change the object by mapping properties.\n        let latestObjectJson: JSONValue | undefined = undefined;\n        let latestObject: PARTIAL | undefined = undefined;\n        let isFirstChunk = true;\n        let isFirstDelta = true;\n\n        const transformedStream = stream\n          .pipeThrough(new TransformStream(transformer))\n          .pipeThrough(\n            new TransformStream<\n              string | ObjectStreamInputPart,\n              ObjectStreamPart<PARTIAL>\n            >({\n              async transform(chunk, controller): Promise<void> {\n                if (\n                  typeof chunk === 'object' &&\n                  chunk.type === 'stream-start'\n                ) {\n                  warnings = chunk.warnings;\n                  return; // stream start chunks are sent immediately and do not count as first chunk\n                }\n\n                // Telemetry event for first chunk:\n                if (isFirstChunk) {\n                  const msToFirstChunk = now() - startTimestampMs;\n\n                  isFirstChunk = false;\n\n                  doStreamSpan.addEvent('ai.stream.firstChunk', {\n                    'ai.stream.msToFirstChunk': msToFirstChunk,\n                  });\n\n                  doStreamSpan.setAttributes({\n                    'ai.stream.msToFirstChunk': msToFirstChunk,\n                  });\n                }\n\n                // process partial text chunks\n                if (typeof chunk === 'string') {\n                  accumulatedText += chunk;\n                  textDelta += chunk;\n\n                  const { value: currentObjectJson, state: parseState } =\n                    await parsePartialJson(accumulatedText);\n\n                  if (\n                    currentObjectJson !== undefined &&\n                    !isDeepEqualData(latestObjectJson, currentObjectJson)\n                  ) {\n                    const validationResult =\n                      await outputStrategy.validatePartialResult({\n                        value: currentObjectJson,\n                        textDelta,\n                        latestObject,\n                        isFirstDelta,\n                        isFinalDelta: parseState === 'successful-parse',\n                      });\n\n                    if (\n                      validationResult.success &&\n                      !isDeepEqualData(\n                        latestObject,\n                        validationResult.value.partial,\n                      )\n                    ) {\n                      // inside inner check to correctly parse the final element in array mode:\n                      latestObjectJson = currentObjectJson;\n                      latestObject = validationResult.value.partial;\n\n                      controller.enqueue({\n                        type: 'object',\n                        object: latestObject,\n                      });\n\n                      controller.enqueue({\n                        type: 'text-delta',\n                        textDelta: validationResult.value.textDelta,\n                      });\n\n                      textDelta = '';\n                      isFirstDelta = false;\n                    }\n                  }\n\n                  return;\n                }\n\n                switch (chunk.type) {\n                  case 'response-metadata': {\n                    fullResponse = {\n                      id: chunk.id ?? fullResponse.id,\n                      timestamp: chunk.timestamp ?? fullResponse.timestamp,\n                      modelId: chunk.modelId ?? fullResponse.modelId,\n                    };\n                    break;\n                  }\n\n                  case 'finish': {\n                    // send final text delta:\n                    if (textDelta !== '') {\n                      controller.enqueue({ type: 'text-delta', textDelta });\n                    }\n\n                    // store finish reason for telemetry:\n                    finishReason = chunk.finishReason;\n\n                    // store usage and metadata for promises and onFinish callback:\n                    usage = chunk.usage;\n                    providerMetadata = chunk.providerMetadata;\n\n                    controller.enqueue({\n                      ...chunk,\n                      usage,\n                      response: fullResponse,\n                    });\n\n                    // log warnings:\n                    logWarnings(warnings ?? []);\n\n                    // resolve promises that can be resolved now:\n                    self._usage.resolve(usage);\n                    self._providerMetadata.resolve(providerMetadata);\n                    self._warnings.resolve(warnings);\n                    self._response.resolve({\n                      ...fullResponse,\n                      headers: response?.headers,\n                    });\n                    self._finishReason.resolve(finishReason ?? 'unknown');\n\n                    try {\n                      object = await parseAndValidateObjectResultWithRepair(\n                        accumulatedText,\n                        outputStrategy,\n                        repairText,\n                        {\n                          response: fullResponse,\n                          usage,\n                          finishReason,\n                        },\n                      );\n                      self._object.resolve(object);\n                    } catch (e) {\n                      error = e;\n                      self._object.reject(e);\n                    }\n                    break;\n                  }\n\n                  default: {\n                    controller.enqueue(chunk);\n                    break;\n                  }\n                }\n              },\n\n              // invoke onFinish callback and resolve toolResults promise when the stream is about to close:\n              async flush(controller) {\n                try {\n                  const finalUsage = usage ?? {\n                    promptTokens: NaN,\n                    completionTokens: NaN,\n                    totalTokens: NaN,\n                  };\n\n                  doStreamSpan.setAttributes(\n                    selectTelemetryAttributes({\n                      telemetry,\n                      attributes: {\n                        'ai.response.finishReason': finishReason,\n                        'ai.response.object': {\n                          output: () => JSON.stringify(object),\n                        },\n                        'ai.response.id': fullResponse.id,\n                        'ai.response.model': fullResponse.modelId,\n                        'ai.response.timestamp':\n                          fullResponse.timestamp.toISOString(),\n                        'ai.response.providerMetadata':\n                          JSON.stringify(providerMetadata),\n\n                        'ai.usage.inputTokens': finalUsage.inputTokens,\n                        'ai.usage.outputTokens': finalUsage.outputTokens,\n                        'ai.usage.totalTokens': finalUsage.totalTokens,\n                        'ai.usage.reasoningTokens': finalUsage.reasoningTokens,\n                        'ai.usage.cachedInputTokens':\n                          finalUsage.cachedInputTokens,\n\n                        // standardized gen-ai llm span attributes:\n                        'gen_ai.response.finish_reasons': [finishReason],\n                        'gen_ai.response.id': fullResponse.id,\n                        'gen_ai.response.model': fullResponse.modelId,\n                        'gen_ai.usage.input_tokens': finalUsage.inputTokens,\n                        'gen_ai.usage.output_tokens': finalUsage.outputTokens,\n                      },\n                    }),\n                  );\n\n                  // finish doStreamSpan before other operations for correct timing:\n                  doStreamSpan.end();\n\n                  // Add response information to the root span:\n                  rootSpan.setAttributes(\n                    selectTelemetryAttributes({\n                      telemetry,\n                      attributes: {\n                        'ai.usage.inputTokens': finalUsage.inputTokens,\n                        'ai.usage.outputTokens': finalUsage.outputTokens,\n                        'ai.usage.totalTokens': finalUsage.totalTokens,\n                        'ai.usage.reasoningTokens': finalUsage.reasoningTokens,\n                        'ai.usage.cachedInputTokens':\n                          finalUsage.cachedInputTokens,\n                        'ai.response.object': {\n                          output: () => JSON.stringify(object),\n                        },\n                        'ai.response.providerMetadata':\n                          JSON.stringify(providerMetadata),\n                      },\n                    }),\n                  );\n\n                  // call onFinish callback:\n                  await onFinish?.({\n                    usage: finalUsage,\n                    object,\n                    error,\n                    response: {\n                      ...fullResponse,\n                      headers: response?.headers,\n                    },\n                    warnings,\n                    providerMetadata,\n                  });\n                } catch (error) {\n                  controller.enqueue({ type: 'error', error });\n                } finally {\n                  rootSpan.end();\n                }\n              },\n            }),\n          );\n\n        stitchableStream.addStream(transformedStream);\n      },\n    })\n      .catch(error => {\n        // add an empty stream with an error to break the stream:\n        stitchableStream.addStream(\n          new ReadableStream({\n            start(controller) {\n              controller.enqueue({ type: 'error', error });\n              controller.close();\n            },\n          }),\n        );\n      })\n      .finally(() => {\n        stitchableStream.close();\n      });\n\n    this.outputStrategy = outputStrategy;\n  }\n\n  get object() {\n    return this._object.promise;\n  }\n\n  get usage() {\n    return this._usage.promise;\n  }\n\n  get providerMetadata() {\n    return this._providerMetadata.promise;\n  }\n\n  get warnings() {\n    return this._warnings.promise;\n  }\n\n  get request() {\n    return this._request.promise;\n  }\n\n  get response() {\n    return this._response.promise;\n  }\n\n  get finishReason() {\n    return this._finishReason.promise;\n  }\n\n  get partialObjectStream(): AsyncIterableStream<PARTIAL> {\n    return createAsyncIterableStream(\n      this.baseStream.pipeThrough(\n        new TransformStream<ObjectStreamPart<PARTIAL>, PARTIAL>({\n          transform(chunk, controller) {\n            switch (chunk.type) {\n              case 'object':\n                controller.enqueue(chunk.object);\n                break;\n\n              case 'text-delta':\n              case 'finish':\n              case 'error': // suppress error (use onError instead)\n                break;\n\n              default: {\n                const _exhaustiveCheck: never = chunk;\n                throw new Error(`Unsupported chunk type: ${_exhaustiveCheck}`);\n              }\n            }\n          },\n        }),\n      ),\n    );\n  }\n\n  get elementStream(): ELEMENT_STREAM {\n    return this.outputStrategy.createElementStream(this.baseStream);\n  }\n\n  get textStream(): AsyncIterableStream<string> {\n    return createAsyncIterableStream(\n      this.baseStream.pipeThrough(\n        new TransformStream<ObjectStreamPart<PARTIAL>, string>({\n          transform(chunk, controller) {\n            switch (chunk.type) {\n              case 'text-delta':\n                controller.enqueue(chunk.textDelta);\n                break;\n\n              case 'object':\n              case 'finish':\n              case 'error': // suppress error (use onError instead)\n                break;\n\n              default: {\n                const _exhaustiveCheck: never = chunk;\n                throw new Error(`Unsupported chunk type: ${_exhaustiveCheck}`);\n              }\n            }\n          },\n        }),\n      ),\n    );\n  }\n\n  get fullStream(): AsyncIterableStream<ObjectStreamPart<PARTIAL>> {\n    return createAsyncIterableStream(this.baseStream);\n  }\n\n  pipeTextStreamToResponse(response: ServerResponse, init?: ResponseInit) {\n    pipeTextStreamToResponse({\n      response,\n      textStream: this.textStream,\n      ...init,\n    });\n  }\n\n  toTextStreamResponse(init?: ResponseInit): Response {\n    return createTextStreamResponse({\n      textStream: this.textStream,\n      ...init,\n    });\n  }\n}\n\nexport type ObjectStreamInputPart =\n  | string\n  | {\n      type: 'stream-start';\n      warnings: LanguageModelV2CallWarning[];\n    }\n  | {\n      type: 'error';\n      error: unknown;\n    }\n  | {\n      type: 'response-metadata';\n      id?: string;\n      timestamp?: Date;\n      modelId?: string;\n    }\n  | {\n      type: 'finish';\n      finishReason: LanguageModelV2FinishReason;\n      usage: LanguageModelV2Usage;\n      providerMetadata?: SharedV2ProviderMetadata;\n    };\n","import {\n  GeneratedFile,\n  DefaultGeneratedFile,\n} from '../generate-text/generated-file';\n\n/**\n * A generated audio file.\n */\nexport interface GeneratedAudioFile extends GeneratedFile {\n  /**\n   * Audio format of the file (e.g., 'mp3', 'wav', etc.)\n   */\n  readonly format: string;\n}\n\nexport class DefaultGeneratedAudioFile\n  extends DefaultGeneratedFile\n  implements GeneratedAudioFile\n{\n  readonly format: string;\n\n  constructor({\n    data,\n    mediaType,\n  }: {\n    data: string | Uint8Array;\n    mediaType: string;\n  }) {\n    super({ data, mediaType });\n    let format = 'mp3';\n\n    // If format is not provided, try to determine it from the media type\n    if (mediaType) {\n      const mediaTypeParts = mediaType.split('/');\n\n      if (mediaTypeParts.length === 2) {\n        // Handle special cases for audio formats\n        if (mediaType !== 'audio/mpeg') {\n          format = mediaTypeParts[1];\n        }\n      }\n    }\n\n    if (!format) {\n      // TODO this should be an AI SDK error\n      throw new Error(\n        'Audio format must be provided or determinable from media type',\n      );\n    }\n\n    this.format = format;\n  }\n}\n\nexport class DefaultGeneratedAudioFileWithType extends DefaultGeneratedAudioFile {\n  readonly type = 'audio';\n\n  constructor(options: {\n    data: string | Uint8Array;\n    mediaType: string;\n    format: string;\n  }) {\n    super(options);\n  }\n}\n","import { JSONValue, SpeechModelV2 } from '@ai-sdk/provider';\nimport { ProviderOptions, withUserAgentSuffix } from '@ai-sdk/provider-utils';\nimport { NoSpeechGeneratedError } from '../error/no-speech-generated-error';\nimport { UnsupportedModelVersionError } from '../error/unsupported-model-version-error';\nimport { logWarnings } from '../logger/log-warnings';\nimport { SpeechWarning } from '../types/speech-model';\nimport { SpeechModelResponseMetadata } from '../types/speech-model-response-metadata';\nimport {\n  audioMediaTypeSignatures,\n  detectMediaType,\n} from '../util/detect-media-type';\nimport { prepareRetries } from '../util/prepare-retries';\nimport { SpeechResult } from './generate-speech-result';\nimport {\n  DefaultGeneratedAudioFile,\n  GeneratedAudioFile,\n} from './generated-audio-file';\nimport { VERSION } from '../version';\n/**\nGenerates speech audio using a speech model.\n\n@param model - The speech model to use.\n@param text - The text to convert to speech.\n@param voice - The voice to use for speech generation.\n@param outputFormat - The output format to use for speech generation e.g. \"mp3\", \"wav\", etc.\n@param instructions - Instructions for the speech generation e.g. \"Speak in a slow and steady tone\".\n@param speed - The speed of the speech generation.\n@param providerOptions - Additional provider-specific options that are passed through to the provider\nas body parameters.\n@param maxRetries - Maximum number of retries. Set to 0 to disable retries. Default: 2.\n@param abortSignal - An optional abort signal that can be used to cancel the call.\n@param headers - Additional HTTP headers to be sent with the request. Only applicable for HTTP-based providers.\n\n@returns A result object that contains the generated audio data.\n */\nexport async function generateSpeech({\n  model,\n  text,\n  voice,\n  outputFormat,\n  instructions,\n  speed,\n  language,\n  providerOptions = {},\n  maxRetries: maxRetriesArg,\n  abortSignal,\n  headers,\n}: {\n  /**\nThe speech model to use.\n     */\n  model: SpeechModelV2;\n\n  /**\nThe text to convert to speech.\n   */\n  text: string;\n\n  /**\nThe voice to use for speech generation.\n   */\n  voice?: string;\n\n  /**\n   * The desired output format for the audio e.g. \"mp3\", \"wav\", etc.\n   */\n  outputFormat?: 'mp3' | 'wav' | (string & {});\n\n  /**\n    Instructions for the speech generation e.g. \"Speak in a slow and steady tone\".\n  */\n  instructions?: string;\n\n  /**\n  The speed of the speech generation.\n   */\n  speed?: number;\n\n  /**\n  The language for speech generation. This should be an ISO 639-1 language code (e.g. \"en\", \"es\", \"fr\")\n  or \"auto\" for automatic language detection. Provider support varies.\n   */\n  language?: string;\n\n  /**\nAdditional provider-specific options that are passed through to the provider\nas body parameters.\n\nThe outer record is keyed by the provider name, and the inner\nrecord is keyed by the provider-specific metadata key.\n```ts\n{\n  \"openai\": {}\n}\n```\n     */\n  providerOptions?: ProviderOptions;\n\n  /**\nMaximum number of retries per speech model call. Set to 0 to disable retries.\n\n@default 2\n   */\n  maxRetries?: number;\n\n  /**\nAbort signal.\n */\n  abortSignal?: AbortSignal;\n\n  /**\nAdditional headers to include in the request.\nOnly applicable for HTTP-based providers.\n */\n  headers?: Record<string, string>;\n}): Promise<SpeechResult> {\n  if (model.specificationVersion !== 'v2') {\n    throw new UnsupportedModelVersionError({\n      version: model.specificationVersion,\n      provider: model.provider,\n      modelId: model.modelId,\n    });\n  }\n\n  const headersWithUserAgent = withUserAgentSuffix(\n    headers ?? {},\n    `ai/${VERSION}`,\n  );\n\n  const { retry } = prepareRetries({\n    maxRetries: maxRetriesArg,\n    abortSignal,\n  });\n\n  const result = await retry(() =>\n    model.doGenerate({\n      text,\n      voice,\n      outputFormat,\n      instructions,\n      speed,\n      language,\n      abortSignal,\n      headers: headersWithUserAgent,\n      providerOptions,\n    }),\n  );\n\n  if (!result.audio || result.audio.length === 0) {\n    throw new NoSpeechGeneratedError({ responses: [result.response] });\n  }\n\n  logWarnings(result.warnings);\n\n  return new DefaultSpeechResult({\n    audio: new DefaultGeneratedAudioFile({\n      data: result.audio,\n      mediaType:\n        detectMediaType({\n          data: result.audio,\n          signatures: audioMediaTypeSignatures,\n        }) ?? 'audio/mp3',\n    }),\n    warnings: result.warnings,\n    responses: [result.response],\n    providerMetadata: result.providerMetadata,\n  });\n}\n\nclass DefaultSpeechResult implements SpeechResult {\n  readonly audio: GeneratedAudioFile;\n  readonly warnings: Array<SpeechWarning>;\n  readonly responses: Array<SpeechModelResponseMetadata>;\n  readonly providerMetadata: Record<string, Record<string, JSONValue>>;\n\n  constructor(options: {\n    audio: GeneratedAudioFile;\n    warnings: Array<SpeechWarning>;\n    responses: Array<SpeechModelResponseMetadata>;\n    providerMetadata: Record<string, Record<string, JSONValue>> | undefined;\n  }) {\n    this.audio = options.audio;\n    this.warnings = options.warnings;\n    this.responses = options.responses;\n    this.providerMetadata = options.providerMetadata ?? {};\n  }\n}\n","import { LanguageModelV2CallOptions } from '@ai-sdk/provider';\nimport {\n  asSchema,\n  FlexibleSchema,\n  safeParseJSON,\n  safeValidateTypes,\n} from '@ai-sdk/provider-utils';\nimport { NoObjectGeneratedError } from '../error/no-object-generated-error';\nimport { FinishReason } from '../types/language-model';\nimport { LanguageModelResponseMetadata } from '../types/language-model-response-metadata';\nimport { LanguageModelUsage } from '../types/usage';\nimport { DeepPartial } from '../util/deep-partial';\nimport { parsePartialJson } from '../util/parse-partial-json';\n\nexport interface Output<OUTPUT, PARTIAL> {\n  readonly type: 'object' | 'text';\n\n  responseFormat: LanguageModelV2CallOptions['responseFormat'];\n\n  parsePartial(options: {\n    text: string;\n  }): Promise<{ partial: PARTIAL } | undefined>;\n\n  parseOutput(\n    options: { text: string },\n    context: {\n      response: LanguageModelResponseMetadata;\n      usage: LanguageModelUsage;\n      finishReason: FinishReason;\n    },\n  ): Promise<OUTPUT>;\n}\n\nexport const text = (): Output<string, string> => ({\n  type: 'text',\n\n  responseFormat: { type: 'text' },\n\n  async parsePartial({ text }: { text: string }) {\n    return { partial: text };\n  },\n\n  async parseOutput({ text }: { text: string }) {\n    return text;\n  },\n});\n\nexport const object = <OUTPUT>({\n  schema: inputSchema,\n}: {\n  schema: FlexibleSchema<OUTPUT>;\n}): Output<OUTPUT, DeepPartial<OUTPUT>> => {\n  const schema = asSchema(inputSchema);\n\n  return {\n    type: 'object',\n\n    responseFormat: {\n      type: 'json',\n      schema: schema.jsonSchema,\n    },\n\n    async parsePartial({ text }: { text: string }) {\n      const result = await parsePartialJson(text);\n\n      switch (result.state) {\n        case 'failed-parse':\n        case 'undefined-input':\n          return undefined;\n\n        case 'repaired-parse':\n        case 'successful-parse':\n          return {\n            // Note: currently no validation of partial results:\n            partial: result.value as DeepPartial<OUTPUT>,\n          };\n\n        default: {\n          const _exhaustiveCheck: never = result.state;\n          throw new Error(`Unsupported parse state: ${_exhaustiveCheck}`);\n        }\n      }\n    },\n\n    async parseOutput(\n      { text }: { text: string },\n      context: {\n        response: LanguageModelResponseMetadata;\n        usage: LanguageModelUsage;\n        finishReason: FinishReason;\n      },\n    ) {\n      const parseResult = await safeParseJSON({ text });\n\n      if (!parseResult.success) {\n        throw new NoObjectGeneratedError({\n          message: 'No object generated: could not parse the response.',\n          cause: parseResult.error,\n          text,\n          response: context.response,\n          usage: context.usage,\n          finishReason: context.finishReason,\n        });\n      }\n\n      const validationResult = await safeValidateTypes({\n        value: parseResult.value,\n        schema,\n      });\n\n      if (!validationResult.success) {\n        throw new NoObjectGeneratedError({\n          message: 'No object generated: response did not match schema.',\n          cause: validationResult.error,\n          text,\n          response: context.response,\n          usage: context.usage,\n          finishReason: context.finishReason,\n        });\n      }\n\n      return validationResult.value;\n    },\n  };\n};\n","import { AISDKError } from '@ai-sdk/provider';\nimport { TranscriptionModelResponseMetadata } from '../types/transcription-model-response-metadata';\n\n/**\nError that is thrown when no transcript was generated.\n */\nexport class NoTranscriptGeneratedError extends AISDKError {\n  readonly responses: Array<TranscriptionModelResponseMetadata>;\n\n  constructor(options: {\n    responses: Array<TranscriptionModelResponseMetadata>;\n  }) {\n    super({\n      name: 'AI_NoTranscriptGeneratedError',\n      message: 'No transcript generated.',\n    });\n\n    this.responses = options.responses;\n  }\n}\n","import { JSONValue, TranscriptionModelV2 } from '@ai-sdk/provider';\nimport { ProviderOptions, withUserAgentSuffix } from '@ai-sdk/provider-utils';\nimport { NoTranscriptGeneratedError } from '../error/no-transcript-generated-error';\nimport { UnsupportedModelVersionError } from '../error/unsupported-model-version-error';\nimport { logWarnings } from '../logger/log-warnings';\nimport { DataContent } from '../prompt';\nimport { convertDataContentToUint8Array } from '../prompt/data-content';\nimport { TranscriptionWarning } from '../types/transcription-model';\nimport { TranscriptionModelResponseMetadata } from '../types/transcription-model-response-metadata';\nimport {\n  audioMediaTypeSignatures,\n  detectMediaType,\n} from '../util/detect-media-type';\nimport { download } from '../util/download/download';\nimport { prepareRetries } from '../util/prepare-retries';\nimport { TranscriptionResult } from './transcribe-result';\nimport { VERSION } from '../version';\n/**\nGenerates transcripts using a transcription model.\n\n@param model - The transcription model to use.\n@param audio - The audio data to transcribe as DataContent (string | Uint8Array | ArrayBuffer | Buffer) or a URL.\n@param providerOptions - Additional provider-specific options that are passed through to the provider\nas body parameters.\n@param maxRetries - Maximum number of retries. Set to 0 to disable retries. Default: 2.\n@param abortSignal - An optional abort signal that can be used to cancel the call.\n@param headers - Additional HTTP headers to be sent with the request. Only applicable for HTTP-based providers.\n\n@returns A result object that contains the generated transcript.\n */\nexport async function transcribe({\n  model,\n  audio,\n  providerOptions = {},\n  maxRetries: maxRetriesArg,\n  abortSignal,\n  headers,\n}: {\n  /**\nThe transcription model to use.\n     */\n  model: TranscriptionModelV2;\n\n  /**\nThe audio data to transcribe.\n   */\n  audio: DataContent | URL;\n\n  /**\nAdditional provider-specific options that are passed through to the provider\nas body parameters.\n\nThe outer record is keyed by the provider name, and the inner\nrecord is keyed by the provider-specific metadata key.\n```ts\n{\n  \"openai\": {\n    \"temperature\": 0\n  }\n}\n```\n     */\n  providerOptions?: ProviderOptions;\n\n  /**\nMaximum number of retries per transcript model call. Set to 0 to disable retries.\n\n@default 2\n   */\n  maxRetries?: number;\n\n  /**\nAbort signal.\n */\n  abortSignal?: AbortSignal;\n\n  /**\nAdditional headers to include in the request.\nOnly applicable for HTTP-based providers.\n */\n  headers?: Record<string, string>;\n}): Promise<TranscriptionResult> {\n  if (model.specificationVersion !== 'v2') {\n    throw new UnsupportedModelVersionError({\n      version: model.specificationVersion,\n      provider: model.provider,\n      modelId: model.modelId,\n    });\n  }\n\n  const { retry } = prepareRetries({\n    maxRetries: maxRetriesArg,\n    abortSignal,\n  });\n\n  const headersWithUserAgent = withUserAgentSuffix(\n    headers ?? {},\n    `ai/${VERSION}`,\n  );\n\n  const audioData =\n    audio instanceof URL\n      ? (await download({ url: audio })).data\n      : convertDataContentToUint8Array(audio);\n\n  const result = await retry(() =>\n    model.doGenerate({\n      audio: audioData,\n      abortSignal,\n      headers: headersWithUserAgent,\n      providerOptions,\n      mediaType:\n        detectMediaType({\n          data: audioData,\n          signatures: audioMediaTypeSignatures,\n        }) ?? 'audio/wav',\n    }),\n  );\n\n  logWarnings(result.warnings);\n\n  if (!result.text) {\n    throw new NoTranscriptGeneratedError({ responses: [result.response] });\n  }\n\n  return new DefaultTranscriptionResult({\n    text: result.text,\n    segments: result.segments,\n    language: result.language,\n    durationInSeconds: result.durationInSeconds,\n    warnings: result.warnings,\n    responses: [result.response],\n    providerMetadata: result.providerMetadata,\n  });\n}\n\nclass DefaultTranscriptionResult implements TranscriptionResult {\n  readonly text: string;\n  readonly segments: Array<{\n    text: string;\n    startSecond: number;\n    endSecond: number;\n  }>;\n  readonly language: string | undefined;\n  readonly durationInSeconds: number | undefined;\n  readonly warnings: Array<TranscriptionWarning>;\n  readonly responses: Array<TranscriptionModelResponseMetadata>;\n  readonly providerMetadata: Record<string, Record<string, JSONValue>>;\n\n  constructor(options: {\n    text: string;\n    segments: Array<{\n      text: string;\n      startSecond: number;\n      endSecond: number;\n    }>;\n    language: string | undefined;\n    durationInSeconds: number | undefined;\n    warnings: Array<TranscriptionWarning>;\n    responses: Array<TranscriptionModelResponseMetadata>;\n    providerMetadata: Record<string, Record<string, JSONValue>> | undefined;\n  }) {\n    this.text = options.text;\n    this.segments = options.segments;\n    this.language = options.language;\n    this.durationInSeconds = options.durationInSeconds;\n    this.warnings = options.warnings;\n    this.responses = options.responses;\n    this.providerMetadata = options.providerMetadata ?? {};\n  }\n}\n","import { TypeValidationError } from '@ai-sdk/provider';\nimport {\n  lazyValidator,\n  StandardSchemaV1,\n  Tool,\n  validateTypes,\n  Validator,\n  zodSchema,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\nimport { InvalidArgumentError } from '../error';\nimport { providerMetadataSchema } from '../types/provider-metadata';\nimport {\n  DataUIPart,\n  InferUIMessageData,\n  InferUIMessageTools,\n  ToolUIPart,\n  UIMessage,\n} from './ui-messages';\n\nconst uiMessagesSchema = lazyValidator(() =>\n  zodSchema(\n    z\n      .array(\n        z.object({\n          id: z.string(),\n          role: z.enum(['system', 'user', 'assistant']),\n          metadata: z.unknown().optional(),\n          parts: z\n            .array(\n              z.union([\n                z.object({\n                  type: z.literal('text'),\n                  text: z.string(),\n                  state: z.enum(['streaming', 'done']).optional(),\n                  providerMetadata: providerMetadataSchema.optional(),\n                }),\n                z.object({\n                  type: z.literal('reasoning'),\n                  text: z.string(),\n                  state: z.enum(['streaming', 'done']).optional(),\n                  providerMetadata: providerMetadataSchema.optional(),\n                }),\n                z.object({\n                  type: z.literal('source-url'),\n                  sourceId: z.string(),\n                  url: z.string(),\n                  title: z.string().optional(),\n                  providerMetadata: providerMetadataSchema.optional(),\n                }),\n                z.object({\n                  type: z.literal('source-document'),\n                  sourceId: z.string(),\n                  mediaType: z.string(),\n                  title: z.string(),\n                  filename: z.string().optional(),\n                  providerMetadata: providerMetadataSchema.optional(),\n                }),\n                z.object({\n                  type: z.literal('file'),\n                  mediaType: z.string(),\n                  filename: z.string().optional(),\n                  url: z.string(),\n                  providerMetadata: providerMetadataSchema.optional(),\n                }),\n                z.object({\n                  type: z.literal('step-start'),\n                }),\n                z.object({\n                  type: z.string().startsWith('data-'),\n                  id: z.string().optional(),\n                  data: z.unknown(),\n                }),\n                z.object({\n                  type: z.literal('dynamic-tool'),\n                  toolName: z.string(),\n                  toolCallId: z.string(),\n                  state: z.literal('input-streaming'),\n                  input: z.unknown().optional(),\n                  providerExecuted: z.boolean().optional(),\n                  output: z.never().optional(),\n                  errorText: z.never().optional(),\n                }),\n                z.object({\n                  type: z.literal('dynamic-tool'),\n                  toolName: z.string(),\n                  toolCallId: z.string(),\n                  state: z.literal('input-available'),\n                  input: z.unknown(),\n                  providerExecuted: z.boolean().optional(),\n                  output: z.never().optional(),\n                  errorText: z.never().optional(),\n                  callProviderMetadata: providerMetadataSchema.optional(),\n                }),\n                z.object({\n                  type: z.literal('dynamic-tool'),\n                  toolName: z.string(),\n                  toolCallId: z.string(),\n                  state: z.literal('output-available'),\n                  input: z.unknown(),\n                  providerExecuted: z.boolean().optional(),\n                  output: z.unknown(),\n                  errorText: z.never().optional(),\n                  callProviderMetadata: providerMetadataSchema.optional(),\n                  preliminary: z.boolean().optional(),\n                }),\n                z.object({\n                  type: z.literal('dynamic-tool'),\n                  toolName: z.string(),\n                  toolCallId: z.string(),\n                  state: z.literal('output-error'),\n                  input: z.unknown(),\n                  providerExecuted: z.boolean().optional(),\n                  output: z.never().optional(),\n                  errorText: z.string(),\n                  callProviderMetadata: providerMetadataSchema.optional(),\n                }),\n                z.object({\n                  type: z.string().startsWith('tool-'),\n                  toolCallId: z.string(),\n                  state: z.literal('input-streaming'),\n                  providerExecuted: z.boolean().optional(),\n                  input: z.unknown().optional(),\n                  output: z.never().optional(),\n                  errorText: z.never().optional(),\n                  approval: z.never().optional(),\n                }),\n                z.object({\n                  type: z.string().startsWith('tool-'),\n                  toolCallId: z.string(),\n                  state: z.literal('input-available'),\n                  providerExecuted: z.boolean().optional(),\n                  input: z.unknown(),\n                  output: z.never().optional(),\n                  errorText: z.never().optional(),\n                  callProviderMetadata: providerMetadataSchema.optional(),\n                  approval: z.never().optional(),\n                }),\n                z.object({\n                  type: z.string().startsWith('tool-'),\n                  toolCallId: z.string(),\n                  state: z.literal('approval-requested'),\n                  input: z.unknown(),\n                  providerExecuted: z.boolean().optional(),\n                  output: z.never().optional(),\n                  errorText: z.never().optional(),\n                  callProviderMetadata: providerMetadataSchema.optional(),\n                  approval: z.object({\n                    id: z.string(),\n                    approved: z.never().optional(),\n                    reason: z.never().optional(),\n                  }),\n                }),\n                z.object({\n                  type: z.string().startsWith('tool-'),\n                  toolCallId: z.string(),\n                  state: z.literal('approval-responded'),\n                  input: z.unknown(),\n                  providerExecuted: z.boolean().optional(),\n                  output: z.never().optional(),\n                  errorText: z.never().optional(),\n                  callProviderMetadata: providerMetadataSchema.optional(),\n                  approval: z.object({\n                    id: z.string(),\n                    approved: z.boolean(),\n                    reason: z.string().optional(),\n                  }),\n                }),\n                z.object({\n                  type: z.string().startsWith('tool-'),\n                  toolCallId: z.string(),\n                  state: z.literal('output-available'),\n                  providerExecuted: z.boolean().optional(),\n                  input: z.unknown(),\n                  output: z.unknown(),\n                  errorText: z.never().optional(),\n                  callProviderMetadata: providerMetadataSchema.optional(),\n                  preliminary: z.boolean().optional(),\n                  approval: z\n                    .object({\n                      id: z.string(),\n                      approved: z.literal(true),\n                      reason: z.string().optional(),\n                    })\n                    .optional(),\n                }),\n                z.object({\n                  type: z.string().startsWith('tool-'),\n                  toolCallId: z.string(),\n                  state: z.literal('output-error'),\n                  providerExecuted: z.boolean().optional(),\n                  input: z.unknown(),\n                  output: z.never().optional(),\n                  errorText: z.string(),\n                  callProviderMetadata: providerMetadataSchema.optional(),\n                  approval: z\n                    .object({\n                      id: z.string(),\n                      approved: z.literal(true),\n                      reason: z.string().optional(),\n                    })\n                    .optional(),\n                }),\n                z.object({\n                  type: z.string().startsWith('tool-'),\n                  toolCallId: z.string(),\n                  state: z.literal('output-denied'),\n                  providerExecuted: z.boolean().optional(),\n                  input: z.unknown(),\n                  output: z.never().optional(),\n                  errorText: z.never().optional(),\n                  callProviderMetadata: providerMetadataSchema.optional(),\n                  approval: z.object({\n                    id: z.string(),\n                    approved: z.literal(false),\n                    reason: z.string().optional(),\n                  }),\n                }),\n              ]),\n            )\n            .nonempty('Message must contain at least one part'),\n        }),\n      )\n      .nonempty('Messages array must not be empty'),\n  ),\n);\n\nexport type SafeValidateUIMessagesResult<UI_MESSAGE extends UIMessage> =\n  | {\n      success: true;\n      data: Array<UI_MESSAGE>;\n    }\n  | {\n      success: false;\n      error: Error;\n    };\n\n/**\n * Validates a list of UI messages like `validateUIMessages`,\n * but instead of throwing it returns `{ success: true, data }`\n * or `{ success: false, error }`.\n */\nexport async function safeValidateUIMessages<UI_MESSAGE extends UIMessage>({\n  messages,\n  metadataSchema,\n  dataSchemas,\n  tools,\n}: {\n  messages: unknown;\n  metadataSchema?:\n    | Validator<UIMessage['metadata']>\n    | StandardSchemaV1<unknown, UI_MESSAGE['metadata']>;\n  dataSchemas?: {\n    [NAME in keyof InferUIMessageData<UI_MESSAGE> & string]?:\n      | Validator<InferUIMessageData<UI_MESSAGE>[NAME]>\n      | StandardSchemaV1<unknown, InferUIMessageData<UI_MESSAGE>[NAME]>;\n  };\n  tools?: {\n    [NAME in keyof InferUIMessageTools<UI_MESSAGE> & string]?: Tool<\n      InferUIMessageTools<UI_MESSAGE>[NAME]['input'],\n      InferUIMessageTools<UI_MESSAGE>[NAME]['output']\n    >;\n  };\n}): Promise<SafeValidateUIMessagesResult<UI_MESSAGE>> {\n  try {\n    if (messages == null) {\n      return {\n        success: false,\n        error: new InvalidArgumentError({\n          parameter: 'messages',\n          value: messages,\n          message: 'messages parameter must be provided',\n        }),\n      };\n    }\n\n    const validatedMessages = await validateTypes({\n      value: messages,\n      schema: uiMessagesSchema,\n    });\n\n    if (metadataSchema) {\n      for (const message of validatedMessages) {\n        await validateTypes({\n          value: message.metadata,\n          schema: metadataSchema,\n        });\n      }\n    }\n\n    if (dataSchemas) {\n      for (const message of validatedMessages) {\n        const dataParts = message.parts.filter(part =>\n          part.type.startsWith('data-'),\n        ) as DataUIPart<InferUIMessageData<UI_MESSAGE>>[];\n\n        for (const dataPart of dataParts) {\n          const dataName = dataPart.type.slice(5);\n          const dataSchema = dataSchemas[dataName];\n\n          if (!dataSchema) {\n            return {\n              success: false,\n              error: new TypeValidationError({\n                value: dataPart.data,\n                cause: `No data schema found for data part ${dataName}`,\n              }),\n            };\n          }\n\n          await validateTypes({\n            value: dataPart.data,\n            schema: dataSchema,\n          });\n        }\n      }\n    }\n\n    if (tools) {\n      for (const message of validatedMessages) {\n        const toolParts = message.parts.filter(part =>\n          part.type.startsWith('tool-'),\n        ) as ToolUIPart<InferUIMessageTools<UI_MESSAGE>>[];\n\n        for (const toolPart of toolParts) {\n          const toolName = toolPart.type.slice(5);\n          const tool = tools[toolName];\n\n          if (!tool) {\n            return {\n              success: false,\n              error: new TypeValidationError({\n                value: toolPart.input,\n                cause: `No tool schema found for tool part ${toolName}`,\n              }),\n            };\n          }\n\n          if (\n            toolPart.state === 'input-available' ||\n            toolPart.state === 'output-available' ||\n            toolPart.state === 'output-error'\n          ) {\n            await validateTypes({\n              value: toolPart.input,\n              schema: tool.inputSchema,\n            });\n          }\n\n          if (toolPart.state === 'output-available' && tool.outputSchema) {\n            await validateTypes({\n              value: toolPart.output,\n              schema: tool.outputSchema,\n            });\n          }\n        }\n      }\n    }\n\n    return {\n      success: true,\n      data: validatedMessages as Array<UI_MESSAGE>,\n    };\n  } catch (error) {\n    const err = error as Error;\n\n    return {\n      success: false,\n      error: err,\n    };\n  }\n}\n\n/**\n * Validates a list of UI messages.\n *\n * Metadata, data parts, and generic tool call structures are only validated if\n * the corresponding schemas are provided. Otherwise, they are assumed to be\n * valid.\n */\nexport async function validateUIMessages<UI_MESSAGE extends UIMessage>({\n  messages,\n  metadataSchema,\n  dataSchemas,\n  tools,\n}: {\n  messages: unknown;\n  metadataSchema?:\n    | Validator<UIMessage['metadata']>\n    | StandardSchemaV1<unknown, UI_MESSAGE['metadata']>;\n  dataSchemas?: {\n    [NAME in keyof InferUIMessageData<UI_MESSAGE> & string]?:\n      | Validator<InferUIMessageData<UI_MESSAGE>[NAME]>\n      | StandardSchemaV1<unknown, InferUIMessageData<UI_MESSAGE>[NAME]>;\n  };\n  tools?: {\n    [NAME in keyof InferUIMessageTools<UI_MESSAGE> & string]?: Tool<\n      InferUIMessageTools<UI_MESSAGE>[NAME]['input'],\n      InferUIMessageTools<UI_MESSAGE>[NAME]['output']\n    >;\n  };\n}): Promise<Array<UI_MESSAGE>> {\n  const response = await safeValidateUIMessages({\n    messages,\n    metadataSchema,\n    dataSchemas,\n    tools,\n  });\n\n  if (!response.success) throw response.error;\n\n  return response.data;\n}\n"]}