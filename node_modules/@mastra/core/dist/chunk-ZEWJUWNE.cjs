'use strict';

var chunkJ4KVR4DZ_cjs = require('./chunk-J4KVR4DZ.cjs');
var chunkU6CL7U6Y_cjs = require('./chunk-U6CL7U6Y.cjs');
var chunk4U7ZLI36_cjs = require('./chunk-4U7ZLI36.cjs');
var chunkDGV2FWB4_cjs = require('./chunk-DGV2FWB4.cjs');

// src/storage/base.ts
function normalizePerPage(perPageInput, defaultValue) {
  if (perPageInput === false) {
    return Number.MAX_SAFE_INTEGER;
  } else if (perPageInput === 0) {
    return 0;
  } else if (typeof perPageInput === "number" && perPageInput > 0) {
    return perPageInput;
  }
  return defaultValue;
}
function calculatePagination(page, perPageInput, normalizedPerPage) {
  return {
    offset: perPageInput === false ? 0 : page * normalizedPerPage,
    perPage: perPageInput === false ? false : normalizedPerPage
  };
}
var MastraStorage = class extends chunkDGV2FWB4_cjs.MastraBase {
  hasInitialized = null;
  shouldCacheInit = true;
  id;
  stores;
  /**
   * When true, automatic initialization (table creation/migrations) is disabled.
   */
  disableInit = false;
  constructor(config) {
    const name = config.name ?? "MastraStorage";
    if (!config.id || typeof config.id !== "string" || config.id.trim() === "") {
      throw new Error(`${name}: id must be provided and cannot be empty.`);
    }
    super({
      component: "STORAGE",
      name
    });
    this.id = config.id;
    this.disableInit = config.disableInit ?? false;
    if (config.default || config.domains) {
      const defaultStores = config.default?.stores;
      const domainOverrides = config.domains ?? {};
      const hasDefaultDomains = defaultStores && Object.values(defaultStores).some((v) => v !== void 0);
      const hasOverrideDomains = Object.values(domainOverrides).some((v) => v !== void 0);
      if (!hasDefaultDomains && !hasOverrideDomains) {
        throw new Error(
          "MastraStorage requires at least one storage source. Provide either a default storage with domains or domain overrides."
        );
      }
      this.stores = {
        memory: domainOverrides.memory ?? defaultStores?.memory,
        workflows: domainOverrides.workflows ?? defaultStores?.workflows,
        scores: domainOverrides.scores ?? defaultStores?.scores,
        observability: domainOverrides.observability ?? defaultStores?.observability,
        agents: domainOverrides.agents ?? defaultStores?.agents
      };
    }
  }
  /**
   * Get a domain-specific storage interface.
   *
   * @param storeName - The name of the domain to access ('memory', 'workflows', 'scores', 'observability', 'agents')
   * @returns The domain storage interface, or undefined if not available
   *
   * @example
   * ```typescript
   * const memory = await storage.getStore('memory');
   * if (memory) {
   *   await memory.saveThread({ thread });
   * }
   * ```
   */
  async getStore(storeName) {
    return this.stores?.[storeName];
  }
  /**
   * Initialize all domain stores.
   * This creates necessary tables, indexes, and performs any required migrations.
   */
  async init() {
    if (this.shouldCacheInit && await this.hasInitialized) {
      return;
    }
    const initTasks = [];
    if (this.stores?.memory) {
      initTasks.push(this.stores.memory.init());
    }
    if (this.stores?.workflows) {
      initTasks.push(this.stores.workflows.init());
    }
    if (this.stores?.scores) {
      initTasks.push(this.stores.scores.init());
    }
    if (this.stores?.observability) {
      initTasks.push(this.stores.observability.init());
    }
    if (this.stores?.agents) {
      initTasks.push(this.stores.agents.init());
    }
    this.hasInitialized = Promise.all(initTasks).then(() => true);
    await this.hasInitialized;
  }
};

// src/storage/domains/base.ts
var StorageDomain = class extends chunkDGV2FWB4_cjs.MastraBase {
  /**
   * Initialize the storage domain.
   * This should create any necessary tables/collections.
   * Default implementation is a no-op - override in adapters that need initialization.
   */
  async init() {
  }
};

// src/storage/domains/agents/base.ts
var AgentsStorage = class extends StorageDomain {
  constructor() {
    super({
      component: "STORAGE",
      name: "AGENTS"
    });
  }
  /**
   * Parses orderBy input for consistent sorting behavior.
   */
  parseOrderBy(orderBy, defaultDirection = "DESC") {
    return {
      field: orderBy?.field && orderBy.field in AGENT_ORDER_BY_SET ? orderBy.field : "createdAt",
      direction: orderBy?.direction && orderBy.direction in AGENT_SORT_DIRECTION_SET ? orderBy.direction : defaultDirection
    };
  }
};
var AGENT_ORDER_BY_SET = {
  createdAt: true,
  updatedAt: true
};
var AGENT_SORT_DIRECTION_SET = {
  ASC: true,
  DESC: true
};

// src/storage/domains/agents/inmemory.ts
var InMemoryAgentsStorage = class extends AgentsStorage {
  db;
  constructor({ db }) {
    super();
    this.db = db;
  }
  async dangerouslyClearAll() {
    this.db.agents.clear();
  }
  async getAgentById({ id }) {
    this.logger.debug(`InMemoryAgentsStorage: getAgentById called for ${id}`);
    const agent = this.db.agents.get(id);
    return agent ? {
      ...agent,
      metadata: agent.metadata ? { ...agent.metadata } : agent.metadata,
      model: { ...agent.model },
      tools: agent.tools ? [...agent.tools] : agent.tools,
      workflows: agent.workflows ? [...agent.workflows] : agent.workflows,
      agents: agent.agents ? [...agent.agents] : agent.agents,
      scorers: agent.scorers ? { ...agent.scorers } : agent.scorers
    } : null;
  }
  async createAgent({ agent }) {
    this.logger.debug(`InMemoryAgentsStorage: createAgent called for ${agent.id}`);
    if (this.db.agents.has(agent.id)) {
      throw new Error(`Agent with id ${agent.id} already exists`);
    }
    const now = /* @__PURE__ */ new Date();
    const newAgent = {
      ...agent,
      createdAt: now,
      updatedAt: now
    };
    this.db.agents.set(agent.id, newAgent);
    return { ...newAgent };
  }
  async updateAgent({ id, ...updates }) {
    this.logger.debug(`InMemoryAgentsStorage: updateAgent called for ${id}`);
    const existingAgent = this.db.agents.get(id);
    if (!existingAgent) {
      throw new Error(`Agent with id ${id} not found`);
    }
    const updatedAgent = {
      ...existingAgent,
      ...updates.name !== void 0 && { name: updates.name },
      ...updates.description !== void 0 && { description: updates.description },
      ...updates.instructions !== void 0 && { instructions: updates.instructions },
      ...updates.model !== void 0 && { model: updates.model },
      ...updates.tools !== void 0 && { tools: updates.tools },
      ...updates.defaultOptions !== void 0 && {
        defaultOptions: updates.defaultOptions
      },
      ...updates.workflows !== void 0 && { workflows: updates.workflows },
      ...updates.agents !== void 0 && { agents: updates.agents },
      ...updates.inputProcessors !== void 0 && { inputProcessors: updates.inputProcessors },
      ...updates.outputProcessors !== void 0 && { outputProcessors: updates.outputProcessors },
      ...updates.memory !== void 0 && { memory: updates.memory },
      ...updates.scorers !== void 0 && { scorers: updates.scorers },
      ...updates.metadata !== void 0 && {
        metadata: { ...existingAgent.metadata, ...updates.metadata }
      },
      updatedAt: /* @__PURE__ */ new Date()
    };
    this.db.agents.set(id, updatedAgent);
    return { ...updatedAgent };
  }
  async deleteAgent({ id }) {
    this.logger.debug(`InMemoryAgentsStorage: deleteAgent called for ${id}`);
    this.db.agents.delete(id);
  }
  async listAgents(args) {
    const { page = 0, perPage: perPageInput, orderBy } = args || {};
    const { field, direction } = this.parseOrderBy(orderBy);
    this.logger.debug(`InMemoryAgentsStorage: listAgents called`);
    const perPage = normalizePerPage(perPageInput, 100);
    if (page < 0) {
      throw new Error("page must be >= 0");
    }
    const maxOffset = Number.MAX_SAFE_INTEGER / 2;
    if (page * perPage > maxOffset) {
      throw new Error("page value too large");
    }
    const agents = Array.from(this.db.agents.values());
    const sortedAgents = this.sortAgents(agents, field, direction);
    const clonedAgents = sortedAgents.map((agent) => ({
      ...agent,
      metadata: agent.metadata ? { ...agent.metadata } : agent.metadata,
      model: { ...agent.model },
      tools: agent.tools ? [...agent.tools] : agent.tools,
      workflows: agent.workflows ? [...agent.workflows] : agent.workflows,
      agents: agent.agents ? [...agent.agents] : agent.agents,
      scorers: agent.scorers ? { ...agent.scorers } : agent.scorers
    }));
    const { offset, perPage: perPageForResponse } = calculatePagination(page, perPageInput, perPage);
    return {
      agents: clonedAgents.slice(offset, offset + perPage),
      total: clonedAgents.length,
      page,
      perPage: perPageForResponse,
      hasMore: offset + perPage < clonedAgents.length
    };
  }
  sortAgents(agents, field, direction) {
    return agents.sort((a, b) => {
      const aValue = new Date(a[field]).getTime();
      const bValue = new Date(b[field]).getTime();
      return direction === "ASC" ? aValue - bValue : bValue - aValue;
    });
  }
};

// src/storage/domains/inmemory-db.ts
var InMemoryDB = class {
  threads = /* @__PURE__ */ new Map();
  messages = /* @__PURE__ */ new Map();
  resources = /* @__PURE__ */ new Map();
  workflows = /* @__PURE__ */ new Map();
  scores = /* @__PURE__ */ new Map();
  traces = /* @__PURE__ */ new Map();
  agents = /* @__PURE__ */ new Map();
  /**
   * Clears all data from all collections.
   * Useful for testing.
   */
  clear() {
    this.threads.clear();
    this.messages.clear();
    this.resources.clear();
    this.workflows.clear();
    this.scores.clear();
    this.traces.clear();
    this.agents.clear();
  }
};

// src/storage/utils.ts
function safelyParseJSON(input) {
  if (input && typeof input === "object") return input;
  if (input == null) return {};
  if (typeof input === "string") {
    try {
      return JSON.parse(input);
    } catch {
      return input;
    }
  }
  return {};
}
function transformRow(row, tableName, options = {}) {
  const { preferredTimestampFields = {}, convertTimestamps = false, nullValuePattern, fieldMappings = {} } = options;
  const tableSchema = chunkU6CL7U6Y_cjs.TABLE_SCHEMAS[tableName];
  const result = {};
  for (const [key, columnSchema] of Object.entries(tableSchema)) {
    const sourceKey = fieldMappings[key] ?? key;
    let value = row[sourceKey];
    if (preferredTimestampFields[key]) {
      value = row[preferredTimestampFields[key]] ?? value;
    }
    if (value === void 0 || value === null) {
      continue;
    }
    if (nullValuePattern && value === nullValuePattern) {
      continue;
    }
    if (columnSchema.type === "jsonb") {
      if (typeof value === "string") {
        result[key] = safelyParseJSON(value);
      } else if (typeof value === "object") {
        result[key] = value;
      } else {
        result[key] = value;
      }
    } else if (columnSchema.type === "timestamp" && convertTimestamps && typeof value === "string") {
      result[key] = new Date(value);
    } else {
      result[key] = value;
    }
  }
  return result;
}
function transformScoreRow(row, options = {}) {
  return transformRow(row, chunkU6CL7U6Y_cjs.TABLE_SCORERS, options);
}
function toUpperSnakeCase(str) {
  return str.replace(/([a-z])([A-Z])/g, "$1_$2").replace(/([A-Z])([A-Z][a-z])/g, "$1_$2").toUpperCase().replace(/[^A-Z0-9]+/g, "_").replace(/^_+|_+$/g, "");
}
function createStoreErrorId(type, store, operation, status) {
  const normalizedStore = toUpperSnakeCase(store);
  const normalizedOperation = toUpperSnakeCase(operation);
  const normalizedStatus = toUpperSnakeCase(status);
  const typePrefix = type === "storage" ? "STORAGE" : "VECTOR";
  return `MASTRA_${typePrefix}_${normalizedStore}_${normalizedOperation}_${normalizedStatus}`;
}
function createStorageErrorId(store, operation, status) {
  return createStoreErrorId("storage", store, operation, status);
}
function createVectorErrorId(store, operation, status) {
  return createStoreErrorId("vector", store, operation, status);
}
function getSqlType(type) {
  switch (type) {
    case "text":
      return "TEXT";
    case "timestamp":
      return "TIMESTAMP";
    case "float":
      return "FLOAT";
    case "integer":
      return "INTEGER";
    case "bigint":
      return "BIGINT";
    case "jsonb":
      return "JSONB";
    case "boolean":
      return "BOOLEAN";
    default:
      return "TEXT";
  }
}
function getDefaultValue(type) {
  switch (type) {
    case "text":
    case "uuid":
      return "DEFAULT ''";
    case "timestamp":
      return "DEFAULT '1970-01-01 00:00:00'";
    case "integer":
    case "bigint":
    case "float":
      return "DEFAULT 0";
    case "jsonb":
      return "DEFAULT '{}'";
    case "boolean":
      return "DEFAULT FALSE";
    default:
      return "DEFAULT ''";
  }
}
function ensureDate(date) {
  if (!date) return void 0;
  return date instanceof Date ? date : new Date(date);
}
function serializeDate(date) {
  if (!date) return void 0;
  const dateObj = ensureDate(date);
  return dateObj?.toISOString();
}
function filterByDateRange(items, getCreatedAt, dateRange) {
  if (!dateRange) return items;
  let result = items;
  if (dateRange.start) {
    const startTime = ensureDate(dateRange.start).getTime();
    result = result.filter((item) => {
      const itemTime = getCreatedAt(item).getTime();
      return dateRange.startExclusive ? itemTime > startTime : itemTime >= startTime;
    });
  }
  if (dateRange.end) {
    const endTime = ensureDate(dateRange.end).getTime();
    result = result.filter((item) => {
      const itemTime = getCreatedAt(item).getTime();
      return dateRange.endExclusive ? itemTime < endTime : itemTime <= endTime;
    });
  }
  return result;
}

// src/storage/domains/memory/base.ts
var MemoryStorage = class extends StorageDomain {
  constructor() {
    super({
      component: "STORAGE",
      name: "MEMORY"
    });
  }
  async deleteMessages(_messageIds) {
    throw new Error(
      `Message deletion is not supported by this storage adapter (${this.constructor.name}). The deleteMessages method needs to be implemented in the storage adapter.`
    );
  }
  /**
   * Clone a thread and its messages to create a new independent thread.
   * The cloned thread will have clone metadata stored in its metadata field.
   *
   * @param args - Clone configuration options
   * @returns The newly created thread and the cloned messages
   */
  async cloneThread(_args) {
    throw new Error(
      `Thread cloning is not implemented by this storage adapter (${this.constructor.name}). The cloneThread method needs to be implemented in the storage adapter.`
    );
  }
  async getResourceById(_) {
    throw new Error(
      `Resource working memory is not implemented by this storage adapter (${this.constructor.name}). This is likely a bug - all Mastra storage adapters should implement resource support. Please report this issue at https://github.com/mastra-ai/mastra/issues`
    );
  }
  async saveResource(_) {
    throw new Error(
      `Resource working memory is not implemented by this storage adapter (${this.constructor.name}). This is likely a bug - all Mastra storage adapters should implement resource support. Please report this issue at https://github.com/mastra-ai/mastra/issues`
    );
  }
  async updateResource(_) {
    throw new Error(
      `Resource working memory is not implemented by this storage adapter (${this.constructor.name}). This is likely a bug - all Mastra storage adapters should implement resource support. Please report this issue at https://github.com/mastra-ai/mastra/issues`
    );
  }
  parseOrderBy(orderBy, defaultDirection = "DESC") {
    return {
      field: orderBy?.field && orderBy.field in THREAD_ORDER_BY_SET ? orderBy.field : "createdAt",
      direction: orderBy?.direction && orderBy.direction in THREAD_THREAD_SORT_DIRECTION_SET ? orderBy.direction : defaultDirection
    };
  }
};
var THREAD_ORDER_BY_SET = {
  createdAt: true,
  updatedAt: true
};
var THREAD_THREAD_SORT_DIRECTION_SET = {
  ASC: true,
  DESC: true
};

// src/storage/domains/memory/inmemory.ts
var InMemoryMemory = class extends MemoryStorage {
  db;
  constructor({ db }) {
    super();
    this.db = db;
  }
  async dangerouslyClearAll() {
    this.db.threads.clear();
    this.db.messages.clear();
    this.db.resources.clear();
  }
  async getThreadById({ threadId }) {
    this.logger.debug(`InMemoryMemory: getThreadById called for ${threadId}`);
    const thread = this.db.threads.get(threadId);
    return thread ? { ...thread, metadata: thread.metadata ? { ...thread.metadata } : thread.metadata } : null;
  }
  async saveThread({ thread }) {
    this.logger.debug(`InMemoryMemory: saveThread called for ${thread.id}`);
    const key = thread.id;
    this.db.threads.set(key, thread);
    return thread;
  }
  async updateThread({
    id,
    title,
    metadata
  }) {
    this.logger.debug(`InMemoryMemory: updateThread called for ${id}`);
    const thread = this.db.threads.get(id);
    if (!thread) {
      throw new Error(`Thread with id ${id} not found`);
    }
    if (thread) {
      thread.title = title;
      thread.metadata = { ...thread.metadata, ...metadata };
      thread.updatedAt = /* @__PURE__ */ new Date();
    }
    return thread;
  }
  async deleteThread({ threadId }) {
    this.logger.debug(`InMemoryMemory: deleteThread called for ${threadId}`);
    this.db.threads.delete(threadId);
    this.db.messages.forEach((msg, key) => {
      if (msg.thread_id === threadId) {
        this.db.messages.delete(key);
      }
    });
  }
  async listMessages({
    threadId,
    resourceId,
    include,
    filter,
    perPage: perPageInput,
    page = 0,
    orderBy
  }) {
    const threadIds = Array.isArray(threadId) ? threadId : [threadId];
    this.logger.debug(`InMemoryMemory: listMessages called for threads ${threadIds.join(", ")}`);
    if (threadIds.length === 0 || threadIds.some((id) => !id.trim())) {
      throw new Error("threadId must be a non-empty string or array of non-empty strings");
    }
    const threadIdSet = new Set(threadIds);
    const { field, direction } = this.parseOrderBy(orderBy, "ASC");
    const perPage = normalizePerPage(perPageInput, 40);
    if (page < 0) {
      throw new Error("page must be >= 0");
    }
    const maxOffset = Number.MAX_SAFE_INTEGER / 2;
    if (page * perPage > maxOffset) {
      throw new Error("page value too large");
    }
    const { offset, perPage: perPageForResponse } = calculatePagination(page, perPageInput, perPage);
    let threadMessages = Array.from(this.db.messages.values()).filter((msg) => {
      if (!threadIdSet.has(msg.thread_id)) return false;
      if (resourceId && msg.resourceId !== resourceId) return false;
      return true;
    });
    threadMessages = filterByDateRange(threadMessages, (msg) => new Date(msg.createdAt), filter?.dateRange);
    threadMessages.sort((a, b) => {
      const isDateField = field === "createdAt" || field === "updatedAt";
      const aValue = isDateField ? new Date(a[field]).getTime() : a[field];
      const bValue = isDateField ? new Date(b[field]).getTime() : b[field];
      if (typeof aValue === "number" && typeof bValue === "number") {
        return direction === "ASC" ? aValue - bValue : bValue - aValue;
      }
      return direction === "ASC" ? String(aValue).localeCompare(String(bValue)) : String(bValue).localeCompare(String(aValue));
    });
    const totalThreadMessages = threadMessages.length;
    const start = offset;
    const end = start + perPage;
    const paginatedThreadMessages = threadMessages.slice(start, end);
    const messages = [];
    const messageIds = /* @__PURE__ */ new Set();
    for (const msg of paginatedThreadMessages) {
      const convertedMessage = this.parseStoredMessage(msg);
      messages.push(convertedMessage);
      messageIds.add(msg.id);
    }
    if (include && include.length > 0) {
      for (const includeItem of include) {
        const targetMessage = this.db.messages.get(includeItem.id);
        if (targetMessage) {
          const convertedMessage = {
            id: targetMessage.id,
            threadId: targetMessage.thread_id,
            content: safelyParseJSON(targetMessage.content),
            role: targetMessage.role,
            type: targetMessage.type,
            createdAt: targetMessage.createdAt,
            resourceId: targetMessage.resourceId
          };
          if (!messageIds.has(convertedMessage.id)) {
            messages.push(convertedMessage);
            messageIds.add(convertedMessage.id);
          }
          if (includeItem.withPreviousMessages) {
            const allThreadMessages = Array.from(this.db.messages.values()).filter((msg) => msg.thread_id === (includeItem.threadId || threadId)).sort((a, b) => new Date(a.createdAt).getTime() - new Date(b.createdAt).getTime());
            const targetIndex = allThreadMessages.findIndex((msg) => msg.id === includeItem.id);
            if (targetIndex !== -1) {
              const startIndex = Math.max(0, targetIndex - (includeItem.withPreviousMessages || 0));
              for (let i = startIndex; i < targetIndex; i++) {
                const message = allThreadMessages[i];
                if (message && !messageIds.has(message.id)) {
                  const convertedPrevMessage = {
                    id: message.id,
                    threadId: message.thread_id,
                    content: safelyParseJSON(message.content),
                    role: message.role,
                    type: message.type,
                    createdAt: message.createdAt,
                    resourceId: message.resourceId
                  };
                  messages.push(convertedPrevMessage);
                  messageIds.add(message.id);
                }
              }
            }
          }
          if (includeItem.withNextMessages) {
            const allThreadMessages = Array.from(this.db.messages.values()).filter((msg) => msg.thread_id === (includeItem.threadId || threadId)).sort((a, b) => new Date(a.createdAt).getTime() - new Date(b.createdAt).getTime());
            const targetIndex = allThreadMessages.findIndex((msg) => msg.id === includeItem.id);
            if (targetIndex !== -1) {
              const endIndex = Math.min(
                allThreadMessages.length,
                targetIndex + (includeItem.withNextMessages || 0) + 1
              );
              for (let i = targetIndex + 1; i < endIndex; i++) {
                const message = allThreadMessages[i];
                if (message && !messageIds.has(message.id)) {
                  const convertedNextMessage = {
                    id: message.id,
                    threadId: message.thread_id,
                    content: safelyParseJSON(message.content),
                    role: message.role,
                    type: message.type,
                    createdAt: message.createdAt,
                    resourceId: message.resourceId
                  };
                  messages.push(convertedNextMessage);
                  messageIds.add(message.id);
                }
              }
            }
          }
        }
      }
    }
    messages.sort((a, b) => {
      const isDateField = field === "createdAt" || field === "updatedAt";
      const aValue = isDateField ? new Date(a[field]).getTime() : a[field];
      const bValue = isDateField ? new Date(b[field]).getTime() : b[field];
      if (typeof aValue === "number" && typeof bValue === "number") {
        return direction === "ASC" ? aValue - bValue : bValue - aValue;
      }
      return direction === "ASC" ? String(aValue).localeCompare(String(bValue)) : String(bValue).localeCompare(String(aValue));
    });
    let hasMore;
    if (include && include.length > 0) {
      const returnedThreadMessageIds = new Set(messages.filter((m) => m.threadId === threadId).map((m) => m.id));
      hasMore = returnedThreadMessageIds.size < totalThreadMessages;
    } else {
      hasMore = end < totalThreadMessages;
    }
    return {
      messages,
      total: totalThreadMessages,
      page,
      perPage: perPageForResponse,
      hasMore
    };
  }
  parseStoredMessage(message) {
    const { resourceId, content, role, thread_id, ...rest } = message;
    let parsedContent = safelyParseJSON(content);
    if (typeof parsedContent === "string") {
      parsedContent = {
        format: 2,
        content: parsedContent,
        parts: [{ type: "text", text: parsedContent }]
      };
    }
    return {
      ...rest,
      threadId: thread_id,
      ...message.resourceId && { resourceId: message.resourceId },
      content: parsedContent,
      role
    };
  }
  async listMessagesById({ messageIds }) {
    this.logger.debug(`InMemoryMemory: listMessagesById called`);
    const rawMessages = messageIds.map((id) => this.db.messages.get(id)).filter((message) => !!message);
    const list = new chunkJ4KVR4DZ_cjs.MessageList().add(
      rawMessages.map((m) => this.parseStoredMessage(m)),
      "memory"
    );
    return { messages: list.get.all.db() };
  }
  async saveMessages(args) {
    const { messages } = args;
    this.logger.debug(`InMemoryMemory: saveMessages called with ${messages.length} messages`);
    if (messages.some((msg) => msg.id === "error-message" || msg.resourceId === null)) {
      throw new Error("Simulated error for testing");
    }
    const threadIds = new Set(messages.map((msg) => msg.threadId).filter((id) => Boolean(id)));
    for (const threadId of threadIds) {
      const thread = this.db.threads.get(threadId);
      if (thread) {
        thread.updatedAt = /* @__PURE__ */ new Date();
      }
    }
    for (const message of messages) {
      const key = message.id;
      const storageMessage = {
        id: message.id,
        thread_id: message.threadId || "",
        content: JSON.stringify(message.content),
        role: message.role || "user",
        type: message.type || "text",
        createdAt: message.createdAt,
        resourceId: message.resourceId || null
      };
      this.db.messages.set(key, storageMessage);
    }
    const list = new chunkJ4KVR4DZ_cjs.MessageList().add(messages, "memory");
    return { messages: list.get.all.db() };
  }
  async updateMessages(args) {
    const updatedMessages = [];
    for (const update of args.messages) {
      const storageMsg = this.db.messages.get(update.id);
      if (!storageMsg) continue;
      const oldThreadId = storageMsg.thread_id;
      const newThreadId = update.threadId || oldThreadId;
      let threadIdChanged = false;
      if (update.threadId && update.threadId !== oldThreadId) {
        threadIdChanged = true;
      }
      if (update.role !== void 0) storageMsg.role = update.role;
      if (update.type !== void 0) storageMsg.type = update.type;
      if (update.createdAt !== void 0) storageMsg.createdAt = update.createdAt;
      if (update.resourceId !== void 0) storageMsg.resourceId = update.resourceId;
      if (update.content !== void 0) {
        let oldContent = safelyParseJSON(storageMsg.content);
        let newContent = update.content;
        if (typeof newContent === "object" && typeof oldContent === "object") {
          newContent = { ...oldContent, ...newContent };
          if (oldContent.metadata && newContent.metadata) {
            newContent.metadata = { ...oldContent.metadata, ...newContent.metadata };
          }
        }
        storageMsg.content = JSON.stringify(newContent);
      }
      if (threadIdChanged) {
        storageMsg.thread_id = newThreadId;
        const base = Date.now();
        let oldThreadNewTime;
        const oldThread = this.db.threads.get(oldThreadId);
        if (oldThread) {
          const prev = new Date(oldThread.updatedAt).getTime();
          oldThreadNewTime = Math.max(base, prev + 1);
          oldThread.updatedAt = new Date(oldThreadNewTime);
        }
        const newThread = this.db.threads.get(newThreadId);
        if (newThread) {
          const prev = new Date(newThread.updatedAt).getTime();
          let newThreadNewTime = Math.max(base + 1, prev + 1);
          if (oldThreadNewTime !== void 0 && newThreadNewTime <= oldThreadNewTime) {
            newThreadNewTime = oldThreadNewTime + 1;
          }
          newThread.updatedAt = new Date(newThreadNewTime);
        }
      } else {
        const thread = this.db.threads.get(oldThreadId);
        if (thread) {
          const prev = new Date(thread.updatedAt).getTime();
          let newTime = Date.now();
          if (newTime <= prev) newTime = prev + 1;
          thread.updatedAt = new Date(newTime);
        }
      }
      this.db.messages.set(update.id, storageMsg);
      updatedMessages.push({
        id: storageMsg.id,
        threadId: storageMsg.thread_id,
        content: safelyParseJSON(storageMsg.content),
        role: storageMsg.role === "user" || storageMsg.role === "assistant" ? storageMsg.role : "user",
        type: storageMsg.type,
        createdAt: storageMsg.createdAt,
        resourceId: storageMsg.resourceId === null ? void 0 : storageMsg.resourceId
      });
    }
    return updatedMessages;
  }
  async deleteMessages(messageIds) {
    if (!messageIds || messageIds.length === 0) {
      return;
    }
    this.logger.debug(`InMemoryMemory: deleteMessages called for ${messageIds.length} messages`);
    const threadIds = /* @__PURE__ */ new Set();
    for (const messageId of messageIds) {
      const message = this.db.messages.get(messageId);
      if (message && message.thread_id) {
        threadIds.add(message.thread_id);
      }
      this.db.messages.delete(messageId);
    }
    const now = /* @__PURE__ */ new Date();
    for (const threadId of threadIds) {
      const thread = this.db.threads.get(threadId);
      if (thread) {
        thread.updatedAt = now;
      }
    }
  }
  async listThreadsByResourceId(args) {
    const { resourceId, page = 0, perPage: perPageInput, orderBy } = args;
    const { field, direction } = this.parseOrderBy(orderBy);
    const perPage = normalizePerPage(perPageInput, 100);
    if (page < 0) {
      throw new Error("page must be >= 0");
    }
    const maxOffset = Number.MAX_SAFE_INTEGER / 2;
    if (page * perPage > maxOffset) {
      throw new Error("page value too large");
    }
    this.logger.debug(`InMemoryMemory: listThreadsByResourceId called for ${resourceId}`);
    const threads = Array.from(this.db.threads.values()).filter((t) => t.resourceId === resourceId);
    const sortedThreads = this.sortThreads(threads, field, direction);
    const clonedThreads = sortedThreads.map((thread) => ({
      ...thread,
      metadata: thread.metadata ? { ...thread.metadata } : thread.metadata
    }));
    const { offset, perPage: perPageForResponse } = calculatePagination(page, perPageInput, perPage);
    return {
      threads: clonedThreads.slice(offset, offset + perPage),
      total: clonedThreads.length,
      page,
      perPage: perPageForResponse,
      hasMore: offset + perPage < clonedThreads.length
    };
  }
  async getResourceById({ resourceId }) {
    this.logger.debug(`InMemoryMemory: getResourceById called for ${resourceId}`);
    const resource = this.db.resources.get(resourceId);
    return resource ? { ...resource, metadata: resource.metadata ? { ...resource.metadata } : resource.metadata } : null;
  }
  async saveResource({ resource }) {
    this.logger.debug(`InMemoryMemory: saveResource called for ${resource.id}`);
    this.db.resources.set(resource.id, resource);
    return resource;
  }
  async updateResource({
    resourceId,
    workingMemory,
    metadata
  }) {
    this.logger.debug(`InMemoryMemory: updateResource called for ${resourceId}`);
    let resource = this.db.resources.get(resourceId);
    if (!resource) {
      resource = {
        id: resourceId,
        workingMemory,
        metadata: metadata || {},
        createdAt: /* @__PURE__ */ new Date(),
        updatedAt: /* @__PURE__ */ new Date()
      };
    } else {
      resource = {
        ...resource,
        workingMemory: workingMemory !== void 0 ? workingMemory : resource.workingMemory,
        metadata: {
          ...resource.metadata,
          ...metadata
        },
        updatedAt: /* @__PURE__ */ new Date()
      };
    }
    this.db.resources.set(resourceId, resource);
    return resource;
  }
  async cloneThread(args) {
    const { sourceThreadId, newThreadId: providedThreadId, resourceId, title, metadata, options } = args;
    this.logger.debug(`InMemoryMemory: cloneThread called for source thread ${sourceThreadId}`);
    const sourceThread = this.db.threads.get(sourceThreadId);
    if (!sourceThread) {
      throw new Error(`Source thread with id ${sourceThreadId} not found`);
    }
    const newThreadId = providedThreadId || crypto.randomUUID();
    if (this.db.threads.has(newThreadId)) {
      throw new Error(`Thread with id ${newThreadId} already exists`);
    }
    let sourceMessages = Array.from(this.db.messages.values()).filter((msg) => msg.thread_id === sourceThreadId).sort((a, b) => new Date(a.createdAt).getTime() - new Date(b.createdAt).getTime());
    if (options?.messageFilter) {
      const { startDate, endDate, messageIds } = options.messageFilter;
      if (messageIds && messageIds.length > 0) {
        const messageIdSet = new Set(messageIds);
        sourceMessages = sourceMessages.filter((msg) => messageIdSet.has(msg.id));
      }
      if (startDate) {
        sourceMessages = sourceMessages.filter((msg) => new Date(msg.createdAt) >= startDate);
      }
      if (endDate) {
        sourceMessages = sourceMessages.filter((msg) => new Date(msg.createdAt) <= endDate);
      }
    }
    if (options?.messageLimit && options.messageLimit > 0 && sourceMessages.length > options.messageLimit) {
      sourceMessages = sourceMessages.slice(-options.messageLimit);
    }
    const now = /* @__PURE__ */ new Date();
    const lastMessageId = sourceMessages.length > 0 ? sourceMessages[sourceMessages.length - 1].id : void 0;
    const cloneMetadata = {
      sourceThreadId,
      clonedAt: now,
      ...lastMessageId && { lastMessageId }
    };
    const newThread = {
      id: newThreadId,
      resourceId: resourceId || sourceThread.resourceId,
      title: title || (sourceThread.title ? `Clone of ${sourceThread.title}` : void 0),
      metadata: {
        ...metadata,
        clone: cloneMetadata
      },
      createdAt: now,
      updatedAt: now
    };
    this.db.threads.set(newThreadId, newThread);
    const clonedMessages = [];
    for (const sourceMsg of sourceMessages) {
      const newMessageId = crypto.randomUUID();
      const parsedContent = safelyParseJSON(sourceMsg.content);
      const newStorageMessage = {
        id: newMessageId,
        thread_id: newThreadId,
        content: sourceMsg.content,
        role: sourceMsg.role,
        type: sourceMsg.type,
        createdAt: sourceMsg.createdAt,
        resourceId: resourceId || sourceMsg.resourceId
      };
      this.db.messages.set(newMessageId, newStorageMessage);
      clonedMessages.push({
        id: newMessageId,
        threadId: newThreadId,
        content: parsedContent,
        role: sourceMsg.role,
        type: sourceMsg.type,
        createdAt: sourceMsg.createdAt,
        resourceId: resourceId || sourceMsg.resourceId || void 0
      });
    }
    this.logger.debug(
      `InMemoryMemory: cloned thread ${sourceThreadId} to ${newThreadId} with ${clonedMessages.length} messages`
    );
    return {
      thread: newThread,
      clonedMessages
    };
  }
  sortThreads(threads, field, direction) {
    return threads.sort((a, b) => {
      const isDateField = field === "createdAt" || field === "updatedAt";
      const aValue = isDateField ? new Date(a[field]).getTime() : a[field];
      const bValue = isDateField ? new Date(b[field]).getTime() : b[field];
      if (typeof aValue === "number" && typeof bValue === "number") {
        if (direction === "ASC") {
          return aValue - bValue;
        } else {
          return bValue - aValue;
        }
      }
      return direction === "ASC" ? String(aValue).localeCompare(String(bValue)) : String(bValue).localeCompare(String(aValue));
    });
  }
};

// src/storage/domains/observability/base.ts
var ObservabilityStorage = class extends StorageDomain {
  constructor() {
    super({
      component: "STORAGE",
      name: "OBSERVABILITY"
    });
  }
  async dangerouslyClearAll() {
  }
  /**
   * Provides hints for tracing strategy selection by the DefaultExporter.
   * Storage adapters can override this to specify their preferred and supported strategies.
   */
  get tracingStrategy() {
    return {
      preferred: "batch-with-updates",
      // Default for most SQL stores
      supported: ["realtime", "batch-with-updates", "insert-only"]
    };
  }
  /**
   * Creates a single Span record in the storage provider.
   */
  async createSpan(_args) {
    throw new chunk4U7ZLI36_cjs.MastraError({
      id: "OBSERVABILITY_CREATE_SPAN_NOT_IMPLEMENTED",
      domain: "MASTRA_OBSERVABILITY" /* MASTRA_OBSERVABILITY */,
      category: "SYSTEM" /* SYSTEM */,
      text: "This storage provider does not support creating spans"
    });
  }
  /**
   * Updates a single Span with partial data. Primarily used for realtime trace creation.
   */
  async updateSpan(_args) {
    throw new chunk4U7ZLI36_cjs.MastraError({
      id: "OBSERVABILITY_STORAGE_UPDATE_SPAN_NOT_IMPLEMENTED",
      domain: "MASTRA_OBSERVABILITY" /* MASTRA_OBSERVABILITY */,
      category: "SYSTEM" /* SYSTEM */,
      text: "This storage provider does not support updating spans"
    });
  }
  /**
   * Retrieves a single span.
   */
  async getSpan(_args) {
    throw new chunk4U7ZLI36_cjs.MastraError({
      id: "OBSERVABILITY_STORAGE_GET_SPAN_NOT_IMPLEMENTED",
      domain: "MASTRA_OBSERVABILITY" /* MASTRA_OBSERVABILITY */,
      category: "SYSTEM" /* SYSTEM */,
      text: "This storage provider does not support getting spans"
    });
  }
  /**
   * Retrieves a single root span.
   */
  async getRootSpan(_args) {
    throw new chunk4U7ZLI36_cjs.MastraError({
      id: "OBSERVABILITY_STORAGE_GET_ROOT_SPAN_NOT_IMPLEMENTED",
      domain: "MASTRA_OBSERVABILITY" /* MASTRA_OBSERVABILITY */,
      category: "SYSTEM" /* SYSTEM */,
      text: "This storage provider does not support getting root spans"
    });
  }
  /**
   * Retrieves a single trace with all its associated spans.
   */
  async getTrace(_args) {
    throw new chunk4U7ZLI36_cjs.MastraError({
      id: "OBSERVABILITY_STORAGE_GET_TRACE_NOT_IMPLEMENTED",
      domain: "MASTRA_OBSERVABILITY" /* MASTRA_OBSERVABILITY */,
      category: "SYSTEM" /* SYSTEM */,
      text: "This storage provider does not support getting traces"
    });
  }
  /**
   * Retrieves a list of traces with optional filtering.
   */
  async listTraces(_args) {
    throw new chunk4U7ZLI36_cjs.MastraError({
      id: "OBSERVABILITY_STORAGE_LIST_TRACES_NOT_IMPLEMENTED",
      domain: "MASTRA_OBSERVABILITY" /* MASTRA_OBSERVABILITY */,
      category: "SYSTEM" /* SYSTEM */,
      text: "This storage provider does not support listing traces"
    });
  }
  /**
   * Creates multiple Spans in a single batch.
   */
  async batchCreateSpans(_args) {
    throw new chunk4U7ZLI36_cjs.MastraError({
      id: "OBSERVABILITY_STORAGE_BATCH_CREATE_SPAN_NOT_IMPLEMENTED",
      domain: "MASTRA_OBSERVABILITY" /* MASTRA_OBSERVABILITY */,
      category: "SYSTEM" /* SYSTEM */,
      text: "This storage provider does not support batch creating spans"
    });
  }
  /**
   * Updates multiple Spans in a single batch.
   */
  async batchUpdateSpans(_args) {
    throw new chunk4U7ZLI36_cjs.MastraError({
      id: "OBSERVABILITY_STORAGE_BATCH_UPDATE_SPANS_NOT_IMPLEMENTED",
      domain: "MASTRA_OBSERVABILITY" /* MASTRA_OBSERVABILITY */,
      category: "SYSTEM" /* SYSTEM */,
      text: "This storage provider does not support batch updating spans"
    });
  }
  /**
   * Deletes multiple traces and all their associated spans in a single batch operation.
   */
  async batchDeleteTraces(_args) {
    throw new chunk4U7ZLI36_cjs.MastraError({
      id: "OBSERVABILITY_STORAGE_BATCH_DELETE_TRACES_NOT_IMPLEMENTED",
      domain: "MASTRA_OBSERVABILITY" /* MASTRA_OBSERVABILITY */,
      category: "SYSTEM" /* SYSTEM */,
      text: "This storage provider does not support batch deleting traces"
    });
  }
};

// src/storage/domains/observability/inmemory.ts
var ObservabilityInMemory = class extends ObservabilityStorage {
  db;
  constructor({ db }) {
    super();
    this.db = db;
  }
  async dangerouslyClearAll() {
    this.db.traces.clear();
  }
  get tracingStrategy() {
    return {
      preferred: "realtime",
      supported: ["realtime", "batch-with-updates", "insert-only"]
    };
  }
  async createSpan(args) {
    const { span } = args;
    this.validateCreateSpan(span);
    const now = /* @__PURE__ */ new Date();
    const record = {
      ...span,
      createdAt: now,
      updatedAt: now
    };
    this.upsertSpanToTrace(record);
  }
  async batchCreateSpans(args) {
    const now = /* @__PURE__ */ new Date();
    for (const span of args.records) {
      this.validateCreateSpan(span);
      const record = {
        ...span,
        createdAt: now,
        updatedAt: now
      };
      this.upsertSpanToTrace(record);
    }
  }
  validateCreateSpan(record) {
    if (!record.spanId) {
      throw new chunk4U7ZLI36_cjs.MastraError({
        id: "OBSERVABILITY_SPAN_ID_REQUIRED",
        domain: "MASTRA_OBSERVABILITY" /* MASTRA_OBSERVABILITY */,
        category: "SYSTEM" /* SYSTEM */,
        text: "Span ID is required for creating a span"
      });
    }
    if (!record.traceId) {
      throw new chunk4U7ZLI36_cjs.MastraError({
        id: "OBSERVABILITY_TRACE_ID_REQUIRED",
        domain: "MASTRA_OBSERVABILITY" /* MASTRA_OBSERVABILITY */,
        category: "SYSTEM" /* SYSTEM */,
        text: "Trace ID is required for creating a span"
      });
    }
  }
  /**
   * Inserts or updates a span in the trace and recomputes trace-level properties
   */
  upsertSpanToTrace(span) {
    const { traceId, spanId } = span;
    let traceEntry = this.db.traces.get(traceId);
    if (!traceEntry) {
      traceEntry = {
        spans: {},
        rootSpan: null,
        status: "running" /* RUNNING */,
        hasChildError: false
      };
      this.db.traces.set(traceId, traceEntry);
    }
    traceEntry.spans[spanId] = span;
    if (span.parentSpanId === null) {
      traceEntry.rootSpan = span;
    }
    this.recomputeTraceProperties(traceEntry);
  }
  /**
   * Recomputes derived trace properties from all spans
   */
  recomputeTraceProperties(traceEntry) {
    const spans = Object.values(traceEntry.spans);
    if (spans.length === 0) return;
    traceEntry.hasChildError = spans.some((s) => s.error != null);
    const rootSpan = traceEntry.rootSpan;
    if (rootSpan) {
      if (rootSpan.error != null) {
        traceEntry.status = "error" /* ERROR */;
      } else if (rootSpan.endedAt === null) {
        traceEntry.status = "running" /* RUNNING */;
      } else {
        traceEntry.status = "success" /* SUCCESS */;
      }
    } else {
      traceEntry.status = "running" /* RUNNING */;
    }
  }
  async getSpan(args) {
    const { traceId, spanId } = args;
    const traceEntry = this.db.traces.get(traceId);
    if (!traceEntry) {
      return null;
    }
    const span = traceEntry.spans[spanId];
    if (!span) {
      return null;
    }
    return { span };
  }
  async getRootSpan(args) {
    const { traceId } = args;
    const traceEntry = this.db.traces.get(traceId);
    if (!traceEntry || !traceEntry.rootSpan) {
      return null;
    }
    return { span: traceEntry.rootSpan };
  }
  async getTrace(args) {
    const { traceId } = args;
    const traceEntry = this.db.traces.get(traceId);
    if (!traceEntry) {
      return null;
    }
    const spans = Object.values(traceEntry.spans);
    if (spans.length === 0) {
      return null;
    }
    spans.sort((a, b) => a.startedAt.getTime() - b.startedAt.getTime());
    return {
      traceId,
      spans
    };
  }
  async listTraces(args) {
    const { filters, pagination, orderBy } = chunkU6CL7U6Y_cjs.listTracesArgsSchema.parse(args);
    const matchingRootSpans = [];
    for (const [, traceEntry] of this.db.traces) {
      if (!traceEntry.rootSpan) continue;
      if (this.traceMatchesFilters(traceEntry, filters)) {
        matchingRootSpans.push(traceEntry.rootSpan);
      }
    }
    const { field: sortField, direction: sortDirection } = orderBy;
    matchingRootSpans.sort((a, b) => {
      if (sortField === "endedAt") {
        const aVal = a.endedAt;
        const bVal = b.endedAt;
        if (aVal == null && bVal == null) return 0;
        if (aVal == null) return sortDirection === "DESC" ? -1 : 1;
        if (bVal == null) return sortDirection === "DESC" ? 1 : -1;
        const diff = aVal.getTime() - bVal.getTime();
        return sortDirection === "DESC" ? -diff : diff;
      } else {
        const diff = a.startedAt.getTime() - b.startedAt.getTime();
        return sortDirection === "DESC" ? -diff : diff;
      }
    });
    const total = matchingRootSpans.length;
    const { page, perPage } = pagination;
    const start = page * perPage;
    const end = start + perPage;
    const paged = matchingRootSpans.slice(start, end);
    return {
      spans: paged,
      pagination: { total, page, perPage, hasMore: end < total }
    };
  }
  /**
   * Check if a trace matches all provided filters
   */
  traceMatchesFilters(traceEntry, filters) {
    if (!filters) return true;
    const rootSpan = traceEntry.rootSpan;
    if (!rootSpan) return false;
    if (filters.startedAt) {
      if (filters.startedAt.start && rootSpan.startedAt < filters.startedAt.start) {
        return false;
      }
      if (filters.startedAt.end && rootSpan.startedAt > filters.startedAt.end) {
        return false;
      }
    }
    if (filters.endedAt) {
      if (rootSpan.endedAt == null) {
        return false;
      }
      if (filters.endedAt.start && rootSpan.endedAt < filters.endedAt.start) {
        return false;
      }
      if (filters.endedAt.end && rootSpan.endedAt > filters.endedAt.end) {
        return false;
      }
    }
    if (filters.spanType !== void 0 && rootSpan.spanType !== filters.spanType) {
      return false;
    }
    if (filters.entityType !== void 0 && rootSpan.entityType !== filters.entityType) {
      return false;
    }
    if (filters.entityId !== void 0 && rootSpan.entityId !== filters.entityId) {
      return false;
    }
    if (filters.entityName !== void 0 && rootSpan.entityName !== filters.entityName) {
      return false;
    }
    if (filters.userId !== void 0 && rootSpan.userId !== filters.userId) {
      return false;
    }
    if (filters.organizationId !== void 0 && rootSpan.organizationId !== filters.organizationId) {
      return false;
    }
    if (filters.resourceId !== void 0 && rootSpan.resourceId !== filters.resourceId) {
      return false;
    }
    if (filters.runId !== void 0 && rootSpan.runId !== filters.runId) {
      return false;
    }
    if (filters.sessionId !== void 0 && rootSpan.sessionId !== filters.sessionId) {
      return false;
    }
    if (filters.threadId !== void 0 && rootSpan.threadId !== filters.threadId) {
      return false;
    }
    if (filters.requestId !== void 0 && rootSpan.requestId !== filters.requestId) {
      return false;
    }
    if (filters.environment !== void 0 && rootSpan.environment !== filters.environment) {
      return false;
    }
    if (filters.source !== void 0 && rootSpan.source !== filters.source) {
      return false;
    }
    if (filters.serviceName !== void 0 && rootSpan.serviceName !== filters.serviceName) {
      return false;
    }
    if (filters.scope != null && rootSpan.scope != null) {
      for (const [key, value] of Object.entries(filters.scope)) {
        if (!this.jsonValueEquals(rootSpan.scope[key], value)) {
          return false;
        }
      }
    } else if (filters.scope != null && rootSpan.scope == null) {
      return false;
    }
    if (filters.metadata != null && rootSpan.metadata != null) {
      for (const [key, value] of Object.entries(filters.metadata)) {
        if (!this.jsonValueEquals(rootSpan.metadata[key], value)) {
          return false;
        }
      }
    } else if (filters.metadata != null && rootSpan.metadata == null) {
      return false;
    }
    if (filters.tags != null && filters.tags.length > 0) {
      if (rootSpan.tags == null) {
        return false;
      }
      for (const tag of filters.tags) {
        if (!rootSpan.tags.includes(tag)) {
          return false;
        }
      }
    }
    if (filters.status !== void 0 && traceEntry.status !== filters.status) {
      return false;
    }
    if (filters.hasChildError !== void 0 && traceEntry.hasChildError !== filters.hasChildError) {
      return false;
    }
    return true;
  }
  /**
   * Deep equality check for JSON values
   */
  jsonValueEquals(a, b) {
    if (a === void 0 || b === void 0) {
      return a === b;
    }
    if (a === null || b === null) {
      return a === b;
    }
    if (typeof a !== typeof b) {
      return false;
    }
    if (a instanceof Date && b instanceof Date) {
      return a.getTime() === b.getTime();
    }
    if (a instanceof Date || b instanceof Date) {
      return false;
    }
    if (typeof a === "object") {
      if (Array.isArray(a) && Array.isArray(b)) {
        if (a.length !== b.length) return false;
        return a.every((val, i) => this.jsonValueEquals(val, b[i]));
      }
      if (Array.isArray(a) || Array.isArray(b)) {
        return false;
      }
      const aKeys = Object.keys(a);
      const bKeys = Object.keys(b);
      if (aKeys.length !== bKeys.length) return false;
      return aKeys.every(
        (key) => this.jsonValueEquals(a[key], b[key])
      );
    }
    return a === b;
  }
  async updateSpan(args) {
    const { traceId, spanId, updates } = args;
    const traceEntry = this.db.traces.get(traceId);
    if (!traceEntry) {
      throw new chunk4U7ZLI36_cjs.MastraError({
        id: "OBSERVABILITY_UPDATE_SPAN_NOT_FOUND",
        domain: "MASTRA_OBSERVABILITY" /* MASTRA_OBSERVABILITY */,
        category: "SYSTEM" /* SYSTEM */,
        text: "Trace not found for span update"
      });
    }
    const span = traceEntry.spans[spanId];
    if (!span) {
      throw new chunk4U7ZLI36_cjs.MastraError({
        id: "OBSERVABILITY_UPDATE_SPAN_NOT_FOUND",
        domain: "MASTRA_OBSERVABILITY" /* MASTRA_OBSERVABILITY */,
        category: "SYSTEM" /* SYSTEM */,
        text: "Span not found for update"
      });
    }
    const updatedSpan = {
      ...span,
      ...updates,
      updatedAt: /* @__PURE__ */ new Date()
    };
    traceEntry.spans[spanId] = updatedSpan;
    if (updatedSpan.parentSpanId === null) {
      traceEntry.rootSpan = updatedSpan;
    }
    this.recomputeTraceProperties(traceEntry);
  }
  async batchUpdateSpans(args) {
    for (const record of args.records) {
      await this.updateSpan(record);
    }
  }
  async batchDeleteTraces(args) {
    for (const traceId of args.traceIds) {
      this.db.traces.delete(traceId);
    }
  }
};

// src/storage/domains/scores/base.ts
var ScoresStorage = class extends StorageDomain {
  constructor() {
    super({
      component: "STORAGE",
      name: "SCORES"
    });
  }
  async dangerouslyClearAll() {
  }
  async listScoresBySpan({
    traceId,
    spanId,
    pagination: _pagination
  }) {
    throw new chunk4U7ZLI36_cjs.MastraError({
      id: "SCORES_STORAGE_GET_SCORES_BY_SPAN_NOT_IMPLEMENTED",
      domain: "STORAGE" /* STORAGE */,
      category: "SYSTEM" /* SYSTEM */,
      details: { traceId, spanId }
    });
  }
};

// src/storage/domains/scores/inmemory.ts
var ScoresInMemory = class extends ScoresStorage {
  db;
  constructor({ db }) {
    super();
    this.db = db;
  }
  async dangerouslyClearAll() {
    this.db.scores.clear();
  }
  async getScoreById({ id }) {
    return this.db.scores.get(id) ?? null;
  }
  async saveScore(score) {
    const newScore = { id: crypto.randomUUID(), createdAt: /* @__PURE__ */ new Date(), updatedAt: /* @__PURE__ */ new Date(), ...score };
    this.db.scores.set(newScore.id, newScore);
    return { score: newScore };
  }
  async listScoresByScorerId({
    scorerId,
    pagination,
    entityId,
    entityType,
    source
  }) {
    const scores = Array.from(this.db.scores.values()).filter((score) => {
      let baseFilter = score.scorerId === scorerId;
      if (entityId) {
        baseFilter = baseFilter && score.entityId === entityId;
      }
      if (entityType) {
        baseFilter = baseFilter && score.entityType === entityType;
      }
      if (source) {
        baseFilter = baseFilter && score.source === source;
      }
      return baseFilter;
    });
    const { page, perPage: perPageInput } = pagination;
    const perPage = normalizePerPage(perPageInput, Number.MAX_SAFE_INTEGER);
    const { offset: start, perPage: perPageForResponse } = calculatePagination(page, perPageInput, perPage);
    const end = perPageInput === false ? scores.length : start + perPage;
    return {
      scores: scores.slice(start, end),
      pagination: {
        total: scores.length,
        page,
        perPage: perPageForResponse,
        hasMore: perPageInput === false ? false : scores.length > end
      }
    };
  }
  async listScoresByRunId({
    runId,
    pagination
  }) {
    const scores = Array.from(this.db.scores.values()).filter((score) => score.runId === runId);
    const { page, perPage: perPageInput } = pagination;
    const perPage = normalizePerPage(perPageInput, Number.MAX_SAFE_INTEGER);
    const { offset: start, perPage: perPageForResponse } = calculatePagination(page, perPageInput, perPage);
    const end = perPageInput === false ? scores.length : start + perPage;
    return {
      scores: scores.slice(start, end),
      pagination: {
        total: scores.length,
        page,
        perPage: perPageForResponse,
        hasMore: perPageInput === false ? false : scores.length > end
      }
    };
  }
  async listScoresByEntityId({
    entityId,
    entityType,
    pagination
  }) {
    const scores = Array.from(this.db.scores.values()).filter((score) => {
      const baseFilter = score.entityId === entityId && score.entityType === entityType;
      return baseFilter;
    });
    const { page, perPage: perPageInput } = pagination;
    const perPage = normalizePerPage(perPageInput, Number.MAX_SAFE_INTEGER);
    const { offset: start, perPage: perPageForResponse } = calculatePagination(page, perPageInput, perPage);
    const end = perPageInput === false ? scores.length : start + perPage;
    return {
      scores: scores.slice(start, end),
      pagination: {
        total: scores.length,
        page,
        perPage: perPageForResponse,
        hasMore: perPageInput === false ? false : scores.length > end
      }
    };
  }
  async listScoresBySpan({
    traceId,
    spanId,
    pagination
  }) {
    const scores = Array.from(this.db.scores.values()).filter(
      (score) => score.traceId === traceId && score.spanId === spanId
    );
    scores.sort((a, b) => new Date(b.createdAt).getTime() - new Date(a.createdAt).getTime());
    const { page, perPage: perPageInput } = pagination;
    const perPage = normalizePerPage(perPageInput, Number.MAX_SAFE_INTEGER);
    const { offset: start, perPage: perPageForResponse } = calculatePagination(page, perPageInput, perPage);
    const end = perPageInput === false ? scores.length : start + perPage;
    return {
      scores: scores.slice(start, end),
      pagination: {
        total: scores.length,
        page,
        perPage: perPageForResponse,
        hasMore: perPageInput === false ? false : scores.length > end
      }
    };
  }
};

// src/storage/domains/workflows/base.ts
var WorkflowsStorage = class extends StorageDomain {
  constructor() {
    super({
      component: "STORAGE",
      name: "WORKFLOWS"
    });
  }
};

// src/storage/domains/workflows/inmemory.ts
var WorkflowsInMemory = class extends WorkflowsStorage {
  db;
  constructor({ db }) {
    super();
    this.db = db;
  }
  async dangerouslyClearAll() {
    this.db.workflows.clear();
  }
  getWorkflowKey(workflowName, runId) {
    return `${workflowName}-${runId}`;
  }
  async updateWorkflowResults({
    workflowName,
    runId,
    stepId,
    result,
    requestContext
  }) {
    this.logger.debug(`WorkflowsInMemory: updateWorkflowResults called for ${workflowName} ${runId} ${stepId}`, result);
    const key = this.getWorkflowKey(workflowName, runId);
    const run = this.db.workflows.get(key);
    if (!run) {
      return {};
    }
    let snapshot;
    if (!run.snapshot) {
      snapshot = {
        context: {},
        activePaths: [],
        activeStepsPath: {},
        timestamp: Date.now(),
        suspendedPaths: {},
        resumeLabels: {},
        serializedStepGraph: [],
        value: {},
        waitingPaths: {},
        status: "pending",
        runId: run.run_id
      };
      this.db.workflows.set(key, {
        ...run,
        snapshot
      });
    } else {
      snapshot = typeof run.snapshot === "string" ? JSON.parse(run.snapshot) : run.snapshot;
    }
    if (!snapshot || !snapshot?.context) {
      throw new Error(`Snapshot not found for runId ${runId}`);
    }
    snapshot.context[stepId] = result;
    snapshot.requestContext = { ...snapshot.requestContext, ...requestContext };
    this.db.workflows.set(key, {
      ...run,
      snapshot
    });
    return JSON.parse(JSON.stringify(snapshot.context));
  }
  async updateWorkflowState({
    workflowName,
    runId,
    opts
  }) {
    const key = this.getWorkflowKey(workflowName, runId);
    const run = this.db.workflows.get(key);
    if (!run) {
      return;
    }
    let snapshot;
    if (!run.snapshot) {
      snapshot = {
        context: {},
        activePaths: [],
        activeStepsPath: {},
        timestamp: Date.now(),
        suspendedPaths: {},
        resumeLabels: {},
        serializedStepGraph: [],
        value: {},
        waitingPaths: {},
        status: "pending",
        runId: run.run_id
      };
      this.db.workflows.set(key, {
        ...run,
        snapshot
      });
    } else {
      snapshot = typeof run.snapshot === "string" ? JSON.parse(run.snapshot) : run.snapshot;
    }
    if (!snapshot || !snapshot?.context) {
      throw new Error(`Snapshot not found for runId ${runId}`);
    }
    snapshot = { ...snapshot, ...opts };
    this.db.workflows.set(key, {
      ...run,
      snapshot
    });
    return snapshot;
  }
  async persistWorkflowSnapshot({
    workflowName,
    runId,
    resourceId,
    snapshot,
    createdAt,
    updatedAt
  }) {
    const key = this.getWorkflowKey(workflowName, runId);
    const now = /* @__PURE__ */ new Date();
    const data = {
      workflow_name: workflowName,
      run_id: runId,
      resourceId,
      snapshot,
      createdAt: createdAt ?? now,
      updatedAt: updatedAt ?? now
    };
    this.db.workflows.set(key, data);
  }
  async loadWorkflowSnapshot({
    workflowName,
    runId
  }) {
    this.logger.debug("Loading workflow snapshot", { workflowName, runId });
    const key = this.getWorkflowKey(workflowName, runId);
    const run = this.db.workflows.get(key);
    if (!run) {
      return null;
    }
    const snapshot = typeof run.snapshot === "string" ? JSON.parse(run.snapshot) : run.snapshot;
    return snapshot ? JSON.parse(JSON.stringify(snapshot)) : null;
  }
  async listWorkflowRuns({
    workflowName,
    fromDate,
    toDate,
    perPage,
    page,
    resourceId,
    status
  } = {}) {
    if (page !== void 0 && page < 0) {
      throw new Error("page must be >= 0");
    }
    let runs = Array.from(this.db.workflows.values());
    if (workflowName) runs = runs.filter((run) => run.workflow_name === workflowName);
    if (status) {
      runs = runs.filter((run) => {
        let snapshot = run?.snapshot;
        if (!snapshot) {
          return false;
        }
        if (typeof snapshot === "string") {
          try {
            snapshot = JSON.parse(snapshot);
          } catch {
            return false;
          }
        } else {
          snapshot = JSON.parse(JSON.stringify(snapshot));
        }
        return snapshot.status === status;
      });
    }
    if (fromDate && toDate) {
      runs = runs.filter(
        (run) => new Date(run.createdAt).getTime() >= fromDate.getTime() && new Date(run.createdAt).getTime() <= toDate.getTime()
      );
    } else if (fromDate) {
      runs = runs.filter((run) => new Date(run.createdAt).getTime() >= fromDate.getTime());
    } else if (toDate) {
      runs = runs.filter((run) => new Date(run.createdAt).getTime() <= toDate.getTime());
    }
    if (resourceId) runs = runs.filter((run) => run.resourceId === resourceId);
    const total = runs.length;
    runs.sort((a, b) => new Date(b.createdAt).getTime() - new Date(a.createdAt).getTime());
    if (perPage !== void 0 && page !== void 0) {
      const normalizedPerPage = normalizePerPage(perPage, Number.MAX_SAFE_INTEGER);
      const offset = page * normalizedPerPage;
      const start = offset;
      const end = start + normalizedPerPage;
      runs = runs.slice(start, end);
    }
    const parsedRuns = runs.map((run) => ({
      ...run,
      snapshot: typeof run.snapshot === "string" ? JSON.parse(run.snapshot) : JSON.parse(JSON.stringify(run.snapshot)),
      createdAt: new Date(run.createdAt),
      updatedAt: new Date(run.updatedAt),
      runId: run.run_id,
      workflowName: run.workflow_name,
      resourceId: run.resourceId
    }));
    return { runs: parsedRuns, total };
  }
  async getWorkflowRunById({
    runId,
    workflowName
  }) {
    const runs = Array.from(this.db.workflows.values()).filter((r) => r.run_id === runId);
    let run = runs.find((r) => r.workflow_name === workflowName);
    if (!run) return null;
    const parsedRun = {
      ...run,
      snapshot: typeof run.snapshot === "string" ? JSON.parse(run.snapshot) : JSON.parse(JSON.stringify(run.snapshot)),
      createdAt: new Date(run.createdAt),
      updatedAt: new Date(run.updatedAt),
      runId: run.run_id,
      workflowName: run.workflow_name,
      resourceId: run.resourceId
    };
    return parsedRun;
  }
  async deleteWorkflowRunById({ runId, workflowName }) {
    const key = this.getWorkflowKey(workflowName, runId);
    this.db.workflows.delete(key);
  }
};

// src/storage/mock.ts
var InMemoryStore = class extends MastraStorage {
  stores;
  /**
   * Internal database layer shared across all domains.
   * This is an implementation detail - domains interact with this
   * rather than managing their own data structures.
   */
  #db;
  constructor({ id = "in-memory" } = {}) {
    super({ id, name: "InMemoryStorage" });
    this.hasInitialized = Promise.resolve(true);
    this.#db = new InMemoryDB();
    this.stores = {
      memory: new InMemoryMemory({ db: this.#db }),
      workflows: new WorkflowsInMemory({ db: this.#db }),
      scores: new ScoresInMemory({ db: this.#db }),
      observability: new ObservabilityInMemory({ db: this.#db }),
      agents: new InMemoryAgentsStorage({ db: this.#db })
    };
  }
  /**
   * Clears all data from the in-memory database.
   * Useful for testing.
   * @deprecated Use dangerouslyClearAll() on individual domains instead.
   */
  clear() {
    this.#db.clear();
  }
};
var MockStore = InMemoryStore;

// src/storage/domains/operations/base.ts
var StoreOperations = class extends chunkDGV2FWB4_cjs.MastraBase {
  constructor() {
    super({
      component: "STORAGE",
      name: "OPERATIONS"
    });
  }
  getSqlType(type) {
    switch (type) {
      case "text":
        return "TEXT";
      case "timestamp":
        return "TIMESTAMP";
      case "float":
        return "FLOAT";
      case "integer":
        return "INTEGER";
      case "bigint":
        return "BIGINT";
      case "jsonb":
        return "JSONB";
      default:
        return "TEXT";
    }
  }
  getDefaultValue(type) {
    switch (type) {
      case "text":
      case "uuid":
        return "DEFAULT ''";
      case "timestamp":
        return "DEFAULT '1970-01-01 00:00:00'";
      case "integer":
      case "bigint":
      case "float":
        return "DEFAULT 0";
      case "jsonb":
        return "DEFAULT '{}'";
      default:
        return "DEFAULT ''";
    }
  }
  /**
   * DATABASE INDEX MANAGEMENT
   * Optional methods for database index management.
   * Storage adapters can override these to provide index management capabilities.
   */
  /**
   * Creates a database index on specified columns
   * @throws {MastraError} if not supported by the storage adapter
   */
  async createIndex(_options) {
    throw new chunk4U7ZLI36_cjs.MastraError({
      id: "MASTRA_STORAGE_CREATE_INDEX_NOT_SUPPORTED",
      domain: "STORAGE" /* STORAGE */,
      category: "SYSTEM" /* SYSTEM */,
      text: `Index management is not supported by this storage adapter`
    });
  }
  /**
   * Drops a database index by name
   * @throws {MastraError} if not supported by the storage adapter
   */
  async dropIndex(_indexName) {
    throw new chunk4U7ZLI36_cjs.MastraError({
      id: "MASTRA_STORAGE_DROP_INDEX_NOT_SUPPORTED",
      domain: "STORAGE" /* STORAGE */,
      category: "SYSTEM" /* SYSTEM */,
      text: `Index management is not supported by this storage adapter`
    });
  }
  /**
   * Lists database indexes for a table or all tables
   * @throws {MastraError} if not supported by the storage adapter
   */
  async listIndexes(_tableName) {
    throw new chunk4U7ZLI36_cjs.MastraError({
      id: "MASTRA_STORAGE_LIST_INDEXES_NOT_SUPPORTED",
      domain: "STORAGE" /* STORAGE */,
      category: "SYSTEM" /* SYSTEM */,
      text: `Index management is not supported by this storage adapter`
    });
  }
  /**
   * Gets detailed statistics for a specific index
   * @throws {MastraError} if not supported by the storage adapter
   */
  async describeIndex(_indexName) {
    throw new chunk4U7ZLI36_cjs.MastraError({
      id: "MASTRA_STORAGE_DESCRIBE_INDEX_NOT_SUPPORTED",
      domain: "STORAGE" /* STORAGE */,
      category: "SYSTEM" /* SYSTEM */,
      text: `Index management is not supported by this storage adapter`
    });
  }
  /**
   * Returns definitions for automatic performance indexes
   * Storage adapters can override this to define indexes that should be created during initialization
   * @returns Array of index definitions to create automatically
   */
  getAutomaticIndexDefinitions() {
    return [];
  }
};

// src/storage/domains/operations/inmemory.ts
var StoreOperationsInMemory = class extends StoreOperations {
  data;
  constructor() {
    super();
    this.data = {
      mastra_workflow_snapshot: /* @__PURE__ */ new Map(),
      mastra_messages: /* @__PURE__ */ new Map(),
      mastra_threads: /* @__PURE__ */ new Map(),
      mastra_traces: /* @__PURE__ */ new Map(),
      mastra_resources: /* @__PURE__ */ new Map(),
      mastra_scorers: /* @__PURE__ */ new Map(),
      mastra_ai_spans: /* @__PURE__ */ new Map(),
      mastra_agents: /* @__PURE__ */ new Map()
    };
  }
  getDatabase() {
    return this.data;
  }
  async insert({ tableName, record }) {
    const table = this.data[tableName];
    let key = record.id;
    if ([chunkU6CL7U6Y_cjs.TABLE_WORKFLOW_SNAPSHOT].includes(tableName) && !record.id && record.run_id) {
      key = record.workflow_name ? `${record.workflow_name}-${record.run_id}` : record.run_id;
      record.id = key;
    } else if (!record.id) {
      key = `auto-${Date.now()}-${Math.random()}`;
      record.id = key;
    }
    table.set(key, record);
  }
  async batchInsert({ tableName, records }) {
    const table = this.data[tableName];
    for (const record of records) {
      let key = record.id;
      if ([chunkU6CL7U6Y_cjs.TABLE_WORKFLOW_SNAPSHOT].includes(tableName) && !record.id && record.run_id) {
        key = record.run_id;
        record.id = key;
      } else if (!record.id) {
        key = `auto-${Date.now()}-${Math.random()}`;
        record.id = key;
      }
      table.set(key, record);
    }
  }
  async load({ tableName, keys }) {
    this.logger.debug(`MockStore: load called for ${tableName} with keys`, keys);
    const table = this.data[tableName];
    const records = Array.from(table.values());
    return records.filter((record) => Object.keys(keys).every((key) => record[key] === keys[key]))?.[0];
  }
  async createTable({
    tableName,
    schema
  }) {
    this.logger.debug(`MockStore: createTable called for ${tableName} with schema`, schema);
    this.data[tableName] = /* @__PURE__ */ new Map();
  }
  async clearTable({ tableName }) {
    this.logger.debug(`MockStore: clearTable called for ${tableName}`);
    this.data[tableName].clear();
  }
  async dropTable({ tableName }) {
    this.logger.debug(`MockStore: dropTable called for ${tableName}`);
    this.data[tableName].clear();
  }
  async alterTable({
    tableName,
    schema
  }) {
    this.logger.debug(`MockStore: alterTable called for ${tableName} with schema`, schema);
  }
  async hasColumn(table, column) {
    this.logger.debug(`MockStore: hasColumn called for ${table} with column ${column}`);
    return true;
  }
};

exports.AgentsStorage = AgentsStorage;
exports.InMemoryAgentsStorage = InMemoryAgentsStorage;
exports.InMemoryDB = InMemoryDB;
exports.InMemoryMemory = InMemoryMemory;
exports.InMemoryStore = InMemoryStore;
exports.MastraStorage = MastraStorage;
exports.MemoryStorage = MemoryStorage;
exports.MockStore = MockStore;
exports.ObservabilityInMemory = ObservabilityInMemory;
exports.ObservabilityStorage = ObservabilityStorage;
exports.ScoresInMemory = ScoresInMemory;
exports.ScoresStorage = ScoresStorage;
exports.StorageDomain = StorageDomain;
exports.StoreOperations = StoreOperations;
exports.StoreOperationsInMemory = StoreOperationsInMemory;
exports.WorkflowsInMemory = WorkflowsInMemory;
exports.WorkflowsStorage = WorkflowsStorage;
exports.calculatePagination = calculatePagination;
exports.createStorageErrorId = createStorageErrorId;
exports.createStoreErrorId = createStoreErrorId;
exports.createVectorErrorId = createVectorErrorId;
exports.ensureDate = ensureDate;
exports.filterByDateRange = filterByDateRange;
exports.getDefaultValue = getDefaultValue;
exports.getSqlType = getSqlType;
exports.normalizePerPage = normalizePerPage;
exports.safelyParseJSON = safelyParseJSON;
exports.serializeDate = serializeDate;
exports.transformRow = transformRow;
exports.transformScoreRow = transformScoreRow;
//# sourceMappingURL=chunk-ZEWJUWNE.cjs.map
//# sourceMappingURL=chunk-ZEWJUWNE.cjs.map