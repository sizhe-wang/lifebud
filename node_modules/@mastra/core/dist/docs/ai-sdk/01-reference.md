# Ai sdk API Reference

> API reference for ai sdk - 5 entries


---

## Reference: chatRoute()

> API reference for chatRoute(), a function to create chat route handlers for streaming agent conversations in AI SDK-compatible format.

Creates a chat route handler for streaming agent conversations using the AI SDK format. This function registers an HTTP `POST` endpoint that accepts messages, executes an agent, and streams the response back to the client in AI SDK-compatible format. You have to use it inside a [custom API route](https://mastra.ai/docs/v1/server/custom-api-routes).

Use [`handleChatStream()`](https://mastra.ai/reference/v1/ai-sdk/handle-chat-stream) if you need a framework-agnostic handler.

## Usage example

This example shows how to set up a chat route at the `/chat` endpoint that uses an agent with the ID `weatherAgent`.

```typescript title="src/mastra/index.ts"
import { Mastra } from "@mastra/core";
import { chatRoute } from "@mastra/ai-sdk";

export const mastra = new Mastra({
  server: {
    apiRoutes: [
      chatRoute({
        path: "/chat",
        agent: "weatherAgent",
      }),
    ],
  },
});
```

You can also use dynamic agent routing based on an `agentId`. The URL `/chat/weatherAgent` will resolve to the agent with the ID `weatherAgent`.

```typescript title="src/mastra/index.ts"
import { Mastra } from "@mastra/core";
import { chatRoute } from "@mastra/ai-sdk";

export const mastra = new Mastra({
  server: {
    apiRoutes: [
      chatRoute({
        path: "/chat/:agentId",
      }),
    ],
  },
});
```

## Parameters

## Additional configuration

You can use [`prepareSendMessagesRequest`](https://ai-sdk.dev/docs/reference/ai-sdk-ui/use-chat#transport.default-chat-transport.prepare-send-messages-request) to customize the request sent to the chat route, for example to pass additional configuration to the agent:

```typescript
const { error, status, sendMessage, messages, regenerate, stop } = useChat({
  transport: new DefaultChatTransport({
    api: "http://localhost:4111/chat",
    prepareSendMessagesRequest({ messages }) {
      return {
        body: {
          messages,
          // Pass memory config
          memory: {
            thread: "user-1",
            resource: "user-1",
          },
        },
      };
    },
  }),
});
```

---

## Reference: networkRoute()

> API reference for networkRoute(), a function to create network route handlers for streaming network execution in AI SDK-compatible format.

Creates a network route handler for streaming network execution using the AI SDK format. This function registers an HTTP `POST` endpoint that accepts messages, executes an agent network, and streams the response back to the client in AI SDK-compatible format. Agent networks allow a routing agent to delegate tasks to other agents. You have to use it inside a [custom API route](https://mastra.ai/docs/v1/server/custom-api-routes).

Use [`handleNetworkStream()`](https://mastra.ai/reference/v1/ai-sdk/handle-network-stream) if you need a framework-agnostic handler.

## Usage example

This example shows how to set up a network route at the `/network` endpoint that uses an agent with the ID `weatherAgent`.

```typescript title="src/mastra/index.ts"
import { Mastra } from "@mastra/core";
import { networkRoute } from "@mastra/ai-sdk";

export const mastra = new Mastra({
  server: {
    apiRoutes: [
      networkRoute({
        path: "/network",
        agent: "weatherAgent",
      }),
    ],
  },
});
```

You can also use dynamic agent routing based on an `agentId`. The URL `/network/weatherAgent` will resolve to the agent with the ID `weatherAgent`.

```typescript title="src/mastra/index.ts"
import { Mastra } from "@mastra/core";
import { networkRoute } from "@mastra/ai-sdk";

export const mastra = new Mastra({
  server: {
    apiRoutes: [
      networkRoute({
        path: "/network/:agentId",
      }),
    ],
  },
});
```

## Parameters

## Additional configuration

You can use [`prepareSendMessagesRequest`](https://ai-sdk.dev/docs/reference/ai-sdk-ui/use-chat#transport.default-chat-transport.prepare-send-messages-request) to customize the request sent to the network route, for example to pass additional configuration to the agent:

```typescript
const { error, status, sendMessage, messages, regenerate, stop } = useChat({
  transport: new DefaultChatTransport({
    api: "http://localhost:4111/network",
    prepareSendMessagesRequest({ messages }) {
      return {
        body: {
          messages,
          // Pass memory config
          memory: {
            thread: "user-1",
            resource: "user-1",
          },
        },
      };
    },
  }),
});
```

---

## Reference: toAISdkStream()

> API reference for toAISdkStream(), a function to convert Mastra streams to AI SDK-compatible streams.

Converts Mastra streams (agent, network, or workflow) to AI SDK-compatible streams. Use this function when you need to manually transform Mastra streams for use with AI SDK's `createUIMessageStream()` and `createUIMessageStreamResponse()`.

This is useful when building custom streaming endpoints outside Mastra's provided route helpers such as [`chatRoute()`](https://mastra.ai/reference/v1/ai-sdk/chat-route) or [`workflowRoute()`](https://mastra.ai/reference/v1/ai-sdk/workflow-route).

## Usage example

Next.js App Router example:

```typescript title="app/api/chat/route.ts"
import { mastra } from "../../mastra";
import { createUIMessageStream, createUIMessageStreamResponse } from "ai";
import { toAISdkStream } from "@mastra/ai-sdk";

export async function POST(req: Request) {
  const { messages } = await req.json();
  const myAgent = mastra.getAgent("weatherAgent");
  const stream = await myAgent.stream(messages);

  const uiMessageStream = createUIMessageStream({
    originalMessages: messages,
    execute: async ({ writer }) => {
      for await (const part of toAISdkStream(stream, { from: "agent" })) {
        await writer.write(part);
      }
    },
  });

  return createUIMessageStreamResponse({
    stream: uiMessageStream,
  });
}
```

> **Note:**

Pass `messages` to `originalMessages` in `createUIMessageStream()` to avoid duplicated assistant messages in the UI. See [Troubleshooting: Repeated Assistant Messages](https://ai-sdk.dev/docs/troubleshooting/repeated-assistant-messages) for details.

## Parameters

The first parameter is the Mastra stream to convert. It can be one of:
- `MastraModelOutput` - An agent stream from `agent.stream()`
- `MastraAgentNetworkStream` - A network stream from `agent.network()`
- `MastraWorkflowStream` or `WorkflowRunOutput` - A workflow stream

The second parameter is an options object:

## Examples

### Converting a workflow stream

```typescript title="app/api/workflow/route.ts" {13}
import { mastra } from "../../mastra";
import { createUIMessageStream, createUIMessageStreamResponse } from "ai";
import { toAISdkStream } from "@mastra/ai-sdk";

export async function POST(req: Request) {
  const { input } = await req.json();
  const workflow = mastra.getWorkflow("myWorkflow");
  const run = workflow.createRun();
  const stream = await run.stream({ inputData: input });

  const uiMessageStream = createUIMessageStream({
    execute: async ({ writer }) => {
      for await (const part of toAISdkStream(stream, { from: "workflow" })) {
        await writer.write(part);
      }
    },
  });

  return createUIMessageStreamResponse({
    stream: uiMessageStream,
  });
}
```

### Converting a network stream

```typescript title="app/api/network/route.ts" {12}
import { mastra } from "../../mastra";
import { createUIMessageStream, createUIMessageStreamResponse } from "ai";
import { toAISdkStream } from "@mastra/ai-sdk";

export async function POST(req: Request) {
  const { messages } = await req.json();
  const routingAgent = mastra.getAgent("routingAgent");
  const stream = await routingAgent.network(messages);

  const uiMessageStream = createUIMessageStream({
    execute: async ({ writer }) => {
      for await (const part of toAISdkStream(stream, { from: "network" })) {
        await writer.write(part);
      }
    },
  });

  return createUIMessageStreamResponse({
    stream: uiMessageStream,
  });
}
```

### Converting an agent stream with reasoning enabled

```typescript title="app/api/reasoning/route.ts" {8-12,17-20}
import { mastra } from "../../mastra";
import { createUIMessageStream, createUIMessageStreamResponse } from "ai";
import { toAISdkStream } from "@mastra/ai-sdk";

export async function POST(req: Request) {
  const { messages } = await req.json();
  const reasoningAgent = mastra.getAgent("reasoningAgent");
  const stream = await reasoningAgent.stream(messages, {
    providerOptions: {
      openai: { reasoningEffort: "high" },
    },
  });

  const uiMessageStream = createUIMessageStream({
    originalMessages: messages,
    execute: async ({ writer }) => {
      for await (const part of toAISdkStream(stream, {
        from: "agent",
        sendReasoning: true,
      })) {
        await writer.write(part);
      }
    },
  });

  return createUIMessageStreamResponse({
    stream: uiMessageStream,
  });
}
```

### Using messageMetadata

```typescript title="app/api/chat-with-metadata/route.ts" {13-19}
import { mastra } from "../../mastra";
import { createUIMessageStream, createUIMessageStreamResponse } from "ai";
import { toAISdkStream } from "@mastra/ai-sdk";

export async function POST(req: Request) {
  const { messages } = await req.json();
  const myAgent = mastra.getAgent("weatherAgent");
  const stream = await myAgent.stream(messages);

  const uiMessageStream = createUIMessageStream({
    originalMessages: messages,
    execute: async ({ writer }) => {
      for await (const part of toAISdkStream(stream, {
        from: "agent",
        messageMetadata: ({ part }) => ({
          timestamp: Date.now(),
          partType: part.type,
        }),
      })) {
        await writer.write(part);
      }
    },
  });

  return createUIMessageStreamResponse({
    stream: uiMessageStream,
  });
}
```

### Client-side stream transformation

If you're using the Mastra client SDK (`@mastra/client-js`) on the client side and want to convert streams to AI SDK format:

```typescript title="client-stream-to-ai-sdk.ts" {14-23,25-35}
import { MastraClient } from "@mastra/client-js";
import { createUIMessageStream } from "ai";
import { toAISdkStream } from "@mastra/ai-sdk";
import type { ChunkType, MastraModelOutput } from "@mastra/core/stream";

const client = new MastraClient({
  baseUrl: "http://localhost:4111",
});

const agent = client.getAgent("weatherAgent");
const response = await agent.stream("What is the weather in Tokyo?");

// Convert the client SDK stream to a ReadableStream<ChunkType>
const chunkStream = new ReadableStream<ChunkType>({
  async start(controller) {
    await response.processDataStream({
      onChunk: async (chunk) => {
        controller.enqueue(chunk);
      },
    });
    controller.close();
  },
});

// Transform to AI SDK format
const uiMessageStream = createUIMessageStream({
  execute: async ({ writer }) => {
    for await (const part of toAISdkStream(
      chunkStream as unknown as MastraModelOutput,
      { from: "agent" }
    )) {
      await writer.write(part);
    }
  },
});

for await (const part of uiMessageStream) {
  console.log(part);
}
```

---

## Reference: withMastra()

> API reference for withMastra(), a function to use Mastra functionality in AI SDK.

Wraps an AI SDK model with Mastra processors and/or memory.

## Usage example

```typescript title="src/example.ts"
import { openai } from '@ai-sdk/openai';
import { generateText } from 'ai';
import { withMastra } from '@mastra/ai-sdk';
import type { Processor } from '@mastra/core/processors';

const loggingProcessor: Processor<'logger'> = {
  id: 'logger',
  async processInput({ messages }) {
    console.log('Input:', messages.length, 'messages');
    return messages;
  },
};

const model = withMastra(openai('gpt-4o'), {
  inputProcessors: [loggingProcessor],
});

const { text } = await generateText({
  model,
  prompt: 'What is 2 + 2?',
});
```

## Parameters

## Returns

A wrapped model compatible with `generateText`, `streamText`, `generateObject`, and `streamObject`.

---

## Reference: workflowRoute()

> API reference for workflowRoute(), a function to create workflow route handlers for streaming workflow execution in AI SDK-compatible format.

Creates a workflow route handler for streaming workflow execution using the AI SDK format. This function registers an HTTP `POST` endpoint that accepts input data, executes a workflow, and streams the response back to the client in AI SDK-compatible format. You have to use it inside a [custom API route](https://mastra.ai/docs/v1/server/custom-api-routes).

Use [`handleWorkflowStream()`](https://mastra.ai/reference/v1/ai-sdk/handle-workflow-stream) if you need a framework-agnostic handler.

> **Note:** Agent streaming in workflows

When a workflow step pipes an agent's stream to the workflow writer (e.g., `await response.fullStream.pipeTo(writer)`), the agent's text chunks and tool calls are forwarded to the UI stream in real time, even when the agent runs inside workflow steps.

See [Workflow Streaming](https://mastra.ai/docs/v1/streaming/workflow-streaming) for more details.

## Usage example

This example shows how to set up a workflow route at the `/workflow` endpoint that uses a workflow with the ID `weatherWorkflow`.

```typescript title="src/mastra/index.ts"
import { Mastra } from "@mastra/core";
import { workflowRoute } from "@mastra/ai-sdk";

export const mastra = new Mastra({
  server: {
    apiRoutes: [
      workflowRoute({
        path: "/workflow",
        workflow: "weatherWorkflow",
      }),
    ],
  },
});
```

You can also use dynamic workflow routing based on a `workflowId`. The URL `/workflow/weatherWorkflow` will resolve to the workflow with the ID `weatherWorkflow`.

```typescript title="src/mastra/index.ts"
import { Mastra } from "@mastra/core";
import { workflowRoute } from "@mastra/ai-sdk";

export const mastra = new Mastra({
  server: {
    apiRoutes: [
      workflowRoute({
        path: "/workflow/:workflowId",
      }),
    ],
  },
});
```

## Parameters

## Additional configuration

You can use [`prepareSendMessagesRequest`](https://ai-sdk.dev/docs/reference/ai-sdk-ui/use-chat#transport.default-chat-transport.prepare-send-messages-request) to customize the request sent to the workflow route, for example to pass additional configuration to the workflow:

```typescript
const { error, status, sendMessage, messages, regenerate, stop } = useChat({
  transport: new DefaultChatTransport({
    api: "http://localhost:4111/workflow",
    prepareSendMessagesRequest({ messages }) {
      return {
        body: {
          inputData: {
            city: messages[messages.length - 1].parts[0].text,
          },
          // Or resumeData for resuming a suspended workflow
          resumeData: {
            confirmation: messages[messages.length - 1].parts[0].text
          }
        },
      };
    },
  }),
});
```